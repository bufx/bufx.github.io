{"posts":[{"title":"Bus组件的使用","text":"什么是Bus官方：https://spring.io/projects/spring-cloud-bus Spring Cloud Bus links nodes of a distributed system with a lightweight message broker. This can then be used to broadcast state changes (e.g. configuration changes) or other management instructions. AMQP and Kafka broker implementations are included with the project. Alternatively, any Spring Cloud Stream binder found on the classpath will work out of the box as a transport. –摘自官网 翻译：springcloudbus使用轻量级消息代理将分布式系统的节点连接起来。然后，可以使用它来广播状态更改（例如配置更改）或其他管理指令。AMQP和Kafka broker实现包含在项目中。或者，在类路径上找到的任何springcloudstream绑定器都可以作为传输使用。 通俗定义：bus称之为springcloud中消息总线,主要用来在微服务系统中实现远端配置更新时通过广播形式通知所有客户端刷新配置信息,避免手动重启服务的工作 实现配置刷新原理 搭建RabbitMQ服务下载安装包可以直接使用docker安装更方便 官网下载地址: https://www.rabbitmq.com/download.html 最新版本: 3.7.18 下载的安装包 注意:这里的安装包是centos7安装的包 安装步骤12345678910111213141516171819# 1.将rabbitmq安装包上传到linux系统中 erlang-22.0.7-1.el7.x86_64.rpm rabbitmq-server-3.7.18-1.el7.noarch.rpm# 2.安装Erlang依赖包 rpm -ivh erlang-22.0.7-1.el7.x86_64.rpm# 3.安装RabbitMQ安装包(需要联网) yum install -y rabbitmq-server-3.7.18-1.el7.noarch.rpm 注意:默认安装完成后配置文件模板在:/usr/share/doc/rabbitmq-server-3.7.18/rabbitmq.config.example目录中,需要 将配置文件复制到/etc/rabbitmq/目录中,并修改名称为rabbitmq.config# 4.复制配置文件 cp /usr/share/doc/rabbitmq-server-3.7.18/rabbitmq.config.example /etc/rabbitmq/rabbitmq.config# 5.查看配置文件位置 ls /etc/rabbitmq/rabbitmq.config# 6.修改配置文件(参见下图:) vim /etc/rabbitmq/rabbitmq.config 将上图中配置文件中红色部分去掉%%,以及最后的,逗号 修改为下图: 123456789101112131415161718192021222324252627282930313233343536373839# 7.执行如下命令,启动rabbitmq中的插件管理 rabbitmq-plugins enable rabbitmq_management 出现如下说明: Enabling plugins on node rabbit@localhost: rabbitmq_management The following plugins have been configured: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatch Applying plugin configuration to rabbit@localhost... The following plugins have been enabled: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatch set 3 plugins. Offline change; changes will take effect at broker restart.# 8.启动RabbitMQ的服务 systemctl start rabbitmq-server systemctl restart rabbitmq-server systemctl stop rabbitmq-server # 9.查看服务状态(见下图:) systemctl status rabbitmq-server ● rabbitmq-server.service - RabbitMQ broker Loaded: loaded (/usr/lib/systemd/system/rabbitmq-server.service; disabled; vendor preset: disabled) Active: active (running) since 三 2019-09-25 22:26:35 CST; 7s ago Main PID: 2904 (beam.smp) Status: &quot;Initialized&quot; CGroup: /system.slice/rabbitmq-server.service ├─2904 /usr/lib64/erlang/erts-10.4.4/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf - MBlmbcs... ├─3220 erl_child_setup 32768 ├─3243 inet_gethost 4 └─3244 inet_gethost 4 ......... 12345678# 10.关闭防火墙服务 systemctl disable firewalld Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service. Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. systemctl stop firewalld # 11.访问web管理界面 http://localhost:15672 123# 12.登录管理界面 username: guest password: guest 1# 13.MQ服务搭建成功 实现自动配置刷新在所有项目中引入bus依赖12345&lt;!--引入bus依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置文件包括统一配置中心（config server）和每个配置客户端（config client）的，由于每个配置客户端的配置在远程仓库，所以把下面配置复制到远程仓库上即可。 12345678#mq的连接主机spring.rabbitmq.host=localhost#mq的连接端口(web界面是15672，TCP协议是5672)spring.rabbitmq.port=5672#mq的连接用户名spring.rabbitmq.username=guest#mq的连接密码spring.rabbitmq.password=guest 启动config server和config client若config client项目发现报一下错误，则是因为：springcloud新版本中（BUG）默认链接不到远程服务器不会报错,但是在使用bus消息总线时必须开启连接远程服务失败报错，不过后续SpringCloud官方会修复 解决办法：在config client项目的配置文件中加入下面配置 12#开启连接不到远程服务器立即报错spring.cloud.config.fail-fast=true 修改远程仓库配置后刷新配置修改远程配置后，只需要在统一配置中心执行post接口就可以刷新所有客户端服务的配置了 修改前： 别忘记把config server项目配置：开启所有web端点暴漏 12#开启所有web端点暴漏management.endpoints.web.exposure.include=* 执行post请求： 1curl -X POST http://localhost:7878/actuator/bus-refresh 修改后： 指定服务刷新配置说明默认情况下使用curl -X POST http://localhost:7878/actuator/bus-refresh这种方式刷新配置是全部广播形式,也就是所有的微服务都能接收到刷新配置通知,但有时我们修改的仅仅是某个服务的配置,这个时候对于其他服务的通知是多余的,因此就需要指定服务进行通知 指定服务刷新配置实现 指定端口刷新某个具体服务: curl -X POST http://localhost:7878/actuator/bus-refresh/configclient:9090 指定服务id刷新服务集群节点: curl -X POST http://localhost:7878/actuator/bus-refresh/configclient 注意：configclient代表刷新服务的唯一标识 集成webhook实现自动刷新配置webhooks 添加webhooks 在webhooks中添加刷新配置的接口 解决404错误问题在配置中心config server服务端加入过滤器进行解决(springcloud新版本中一个BUG) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110/** * @author buubiu **/@Componentpublic class UrlFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest httpServletRequest = (HttpServletRequest)request; HttpServletResponse httpServletResponse = (HttpServletResponse)response; String url = new String(httpServletRequest.getRequestURI()); //只过滤/actuator/bus-refresh请求 if (!url.endsWith(&quot;/bus-refresh&quot;)) { chain.doFilter(request, response); return; } //获取原始的body String body = readAsChars(httpServletRequest); System.out.println(&quot;original body: &quot;+ body); //使用HttpServletRequest包装原始请求达到修改post请求中body内容的目的 CustometRequestWrapper requestWrapper = new CustometRequestWrapper(httpServletRequest); chain.doFilter(requestWrapper, response); } @Override public void destroy() { } private class CustometRequestWrapper extends HttpServletRequestWrapper { public CustometRequestWrapper(HttpServletRequest request) { super(request); } @Override public ServletInputStream getInputStream() throws IOException { byte[] bytes = new byte[0]; ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes); return new ServletInputStream() { @Override public boolean isFinished() { return byteArrayInputStream.read() == -1 ? true:false; } @Override public boolean isReady() { return false; } @Override public void setReadListener(ReadListener readListener) { } @Override public int read() throws IOException { return byteArrayInputStream.read(); } }; } } public static String readAsChars(HttpServletRequest request) { BufferedReader br = null; StringBuilder sb = new StringBuilder(&quot;&quot;); try { br = request.getReader(); String str; while ((str = br.readLine()) != null) { sb.append(str); } br.close(); } catch (IOException e) { e.printStackTrace(); } finally { if (null != br) { try { br.close(); } catch (IOException e) { e.printStackTrace(); } } } return sb.toString(); }} 在入口类加入扫描filter的注解 1234567891011@SpringBootApplication@EnableDiscoveryClient@EnableConfigServer@ServletComponentScan(&quot;com.buubiu.filters&quot;)//扫描filters包public class Springcloud09Configserver7878Application { public static void main(String[] args) { SpringApplication.run(Springcloud09Configserver7878Application.class, args); }} 启动项目，修改远程配置并测试","link":"/Bus%E7%BB%84%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Centos下载rpm全量依赖包的方式","text":"介绍通常生产环境由于安全原因都无法访问互联网。此时就需要进行离线安装，主要有两种方式：源码编译、rpm包安装。源码编译耗费时间长且缺乏编译环境，所以一般都选择使用离线 rpm 包安装。 验证环境Red Hat 8.4 ，用的 Centos8 的 yum 源 查看依赖包语法：yum deplist NAME 例如: 1234567891011121314151617$ yum deplist tarpackage: tar-2:1.30-5.el8.x86_64 dependency: /bin/sh provider: bash-4.4.20-1.el8_4.x86_64 dependency: /sbin/install-info provider: info-6.5-6.el8.x86_64 dependency: libacl.so.1()(64bit) provider: libacl-2.2.53-1.el8.x86_64 dependency: libacl.so.1(ACL_1.0)(64bit) provider: libacl-2.2.53-1.el8.x86_64 dependency: libc.so.6(GLIBC_2.17)(64bit) provider: glibc-2.28-151.el8.x86_64 dependency: libselinux.so.1()(64bit) provider: libselinux-2.9-5.el8.x86_64 dependency: rtld(GNU_HASH) provider: glibc-2.28-151.el8.i686 provider: glibc-2.28-151.el8.x86_64 下载依赖包repotrack(推荐)f只下载不安装 安装 yum-utils 1$ yum -y install yum-utils 下载 tar依赖包 12# --destdir 指定下载目录（不指定时，默认为当前目录）$ repotrack tar --destdir=/opt/rpm yumdownloader只下载不安装 安装 yum-utils 1$ yum -y install yum-utils 下载 tar依赖包 123# --destdir 指定下载目录（不指定时，默认为当前目录）# --resolve 下载依赖的 rpm 包（不指定时，默认只下载 tar 包)$ yumdownloader tar --resolve --destdir=/opt/rpm 仅会将主软件包和基于你现在的操作系统所缺少的依赖关系包一并下载。 若想 像 repotrack 下载全量的，请使用下面命令： 1&gt;$ yumdownloader tar --resolve --installroot=/opt/rpm --destdir=/opt/rpm --releasever=/ downloadonly只下载不安装 安装 yum-download 1$ yum -y install yum-download 下载 tar依赖包 1$ yum -y install tar --downloadonly --downloaddir=/opt/rpm 与 yumdownloader 命令一样，也是仅会将主软件包和基于你现在的操作系统所缺少的依赖关系包一并下载。 若想 像 repotrack 下载全量的，请使用下面命令： 1&gt;$ yum -y install tar --downloadonly --downloaddir=/opt/rpm --installroot=/opt/rpm --destdir=/opt/rpm --releasever=/ 离线安装 rpm12# 忽略依赖安装$ rpm -Uvh --force --nodeps *.rpm","link":"/Centos%E4%B8%8B%E8%BD%BDrpm%E5%85%A8%E9%87%8F%E4%BE%9D%E8%B5%96%E5%8C%85%E7%9A%84%E6%96%B9%E5%BC%8F/"},{"title":"Config组件使用","text":"什么是Config介绍官方：https://spring.io/projects/spring-cloud-config 简要描述：config(配置)又称为 统一配置中心顾名思义,就是将配置统一管理,配置统一管理的好处是在日后大规模集群部署服务应用时相同的服务配置一致,日后再修改配置只需要统一修改全部同步,不需要一个一个服务手动维护。 统一配置中心组件流程图 Config Server开发新建项目引入依赖12345&lt;!--引入config server 依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 在入口类开启统一配置中心服务123456789@SpringBootApplication@EnableConfigServerpublic class Springcloud09Configserver7878Application { public static void main(String[] args) { SpringApplication.run(Springcloud09Configserver7878Application.class, args); }} 修改配置文件 必须配置统一配置中心服务中修改配置文件指向远程仓库地址 指定分支和本地仓库的位置（建议） 1234567891011121314151617server.port=7878spring.application.name=configserverspring.cloud.consul.host=localhostspring.cloud.consul.port=8500spring.cloud.consul.discovery.service-name=${spring.application.name}#必须配置远程仓库地址，否则启动失败(github有网络问题)spring.cloud.config.server.git.uri=https://gitee.com/xxx/xxx.git#私有仓库访问用户名#spring.cloud.config.server.git.username=#私有仓库访问密码#spring.cloud.config.server.git.password=#一定要是个空目录，因为在首次会将该目录清空spring.cloud.config.server.git.basedir=/Users/xxx/localconfig#指定使用远程仓库中哪个分支中的内容spring.cloud.config.server.git.default-label=master 启动工程并拉取远程配置三种方式拉取 http://localhost:7878/users-xxx.properties http://localhost:7878/users-xxx.json http://localhost:7878/users-xxx.ymal 拉取远程配置规则label/name-profiles.yml label:代表去哪个分支获取，默认使用master分支 name:代表读取哪个具体的配置文件名称 profiles:代表读取配置文件环境（有dev,prod,test等） 查看拉取配置详情信息http://localhost:7878/users/dev users：代表远程仓库的配置名称 dev：代表远程仓库的配置环境 Config Client开发新建项目进入依赖12345&lt;!--引入Config Client依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 编写配置文件(application.properties)12345678910#开启统一配置中心服务，让本客户端去远程仓库去查找配置，而不是本地spring.cloud.config.discovery.enabled=true#指定统一配置服务中心的服务唯一标识(consul里面的服务名称)spring.cloud.config.discovery.service-id=configserver#指定从仓库的哪个分支拉取配置spring.cloud.config.label=master#指定拉取配置文件的名称spring.cloud.config.name=clients#指定拉取配置文件的环境spring.cloud.config.profile=dev 远程仓库创建配置文件 clients.properties 【用来存放公共配置】 12345spring.application.name=configclientspring.cloud.consul.host=localhostspring.cloud.consul.port=8500spring.cloud.consul.discovery.service-name=${spring.application.name}username=buubiu clients-dev.properties 【用来存放开发环境相关配置，这里以端口为例】 1server.port=7880 clients-prod.properties 【用来存放生产相关配置】 1server.port=7879 启动客户端直接启动发现启动报错 报错原因：项目中目前使用的是application.properties启动项目,使用这个配置文件在springboot项目启动过程中不会等待远程配置拉取,直接根据配置文件中内容启动,因此当需要注册中心,服务端口等信息时,远程配置还没有拉取到,所以直接报错。 解决办法： 应该在项目启动时先等待拉取远程配置,拉取远程配置成功之后再根据远程配置信息启动即可,为了完成上述要求springboot官方提供了一种解决方案,就是在使用统一配置中心时应该将微服务的配置文件名修改为bootstrap.(properties|yml),bootstrap.properties作为配置启动项目时,会优先拉取远程配置,远程配置拉取成功之后根据远程配置启动当前应用。 在重新启动，成功！ 在客户端内获取远程配置1234567891011121314151617/** * @author buubiu **/@RestControllerpublic class ClientController { @Value(&quot;${server.port}&quot;) private String port; @Value(&quot;${username}&quot;) private String username; @GetMapping(&quot;/client/init&quot;) public String init() { return &quot;当前请求的端口为：&quot;+port+&quot;;username为：&quot;+username; }} 访问页面 手动配置刷新说明在生产环境中,微服务可能非常多,每次修改完远端配置之后,不可能对所有服务进行重新启动,这个时候需要让修改配置的服务能够刷新远端修改之后的配置,从而不要每次重启服务才能生效,进一步提高微服务系统的维护效率。在springcloud中也为我们提供了手动刷新配置和自动刷新配置两种策略,这里我们先试用手动配置文件刷新。 在config client端加入刷新暴漏端点12#开启所有web端点暴漏management.endpoints.web.exposure.include=* 在需要刷新代码的类中加入刷新配置的注解123456789101112131415161718/** * @author buubiu **/@RestController@RefreshScope //刷新配置注解public class ClientController { @Value(&quot;${server.port}&quot;) private int port; @Value(&quot;${username}&quot;) private String username; @GetMapping(&quot;/client/init&quot;) public String init() { return &quot;当前请求的端口为：&quot;+port+&quot;;username为：&quot;+username; }} 启动并测试 手动调用刷新配置接口修改远程仓库的username值，然后执行curl命令 12➜ curl -X POST http://localhost:7879/actuator/refresh[&quot;config.client.version&quot;,&quot;username&quot;]%","link":"/Config%E7%BB%84%E4%BB%B6%E4%BD%BF%E7%94%A8/"},{"title":"Consul基本使用","text":"简介官网：https://www.consul.io consul是一个可以提供服务发现，健康检查，多数据中心，Key/Value存储等功能的分布式服务框架，用于实现分布式系统的服务发现与配置。与其他分布式服务注册与发现的方案，使用起来也较为简单。Consul用Golang实现，因此具有天然可移植性(支持Linux、Windows和Mac OS X)；安装包仅包含一个可执行文件，方便部署。 安装consul下载consul地址：https://www.consul.io/downloads 安装consul官方安装视频地址: https://learn.hashicorp.com/consul/getting-started/install.html 解压之后发现consul只有一个脚本文件 根据解压缩目录配置环境变量[这里是macos和linux系统配置] 路径：~/.bash_profile 123#consul配置export CONSUL_HOME=/Users/buubiu/tools/consulexport PATH=$PATH:$CONSUL_HOME/ 查看consul环境变量是否配置成功,执行命令出现如下信息代表成功 consul -v 123Consul v1.8.5Revision 1e03567d3Protocol 2 spoken by default, understands 2 to 3 (agent will automatically use protocol &gt;2 when speaking to compatible agents) 启动consul服务 consul agent -dev 访问consul的web服务端口 地址：http://localhost:8500 consul默认服务端口是8500 开发consul客户端（即微服务）创建项目并引入consul client依赖12345&lt;!--引入consul client 依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 编写配置12345678server.port=8889spring.application.name=consulclient#注册consul服务的主机spring.cloud.consul.host=localhost#注册consul服务的端口spring.cloud.consul.port=8500#指定注册的服务名称 默认就是应用名spring.cloud.consul.discovery.service-name=${spring.application.name} 启动服务查看consul界面服务信息 consul开启健康监控检查默认情况加consul监控健康是开启的,但是必须依赖健康监控依赖才能正确监控健康状态所以直接启动会显示错误,引入健康监控依赖之后服务正常 12345&lt;!--注意：必须引入健康检查依赖，如果没有引入这个依赖，即使服务可用，但是在consul服务注册中获取不到服务状态，consul注册中心始终认为不可用--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; consul关闭健康监控检查（不推荐）12#关闭consul服务的健康检查（不推荐）spring.cloud.consul.discovery.register-health-check=false","link":"/Consul%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"title":"DataGrip：如何以SYSDBA身份连接到Oracle","text":"在连接配置页面，选择 Advanced 选项卡，并找到 Name 为 internal_logon 参数，赋予值 Value 为 sysdba 即可。如图所示：","link":"/DataGrip%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BB%A5SYSDBA%E8%BA%AB%E4%BB%BD%E8%BF%9E%E6%8E%A5%E5%88%B0Oracle/"},{"title":"Debian 9快速开启Google BBR的方法","text":"方法 修改系统变量 12echo &quot;net.core.default_qdisc=fq&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.ipv4.tcp_congestion_control=bbr&quot; &gt;&gt; /etc/sysctl.conf 保存生效 1sysctl -p 查看内核是否已开启 BBR 1sysctl net.ipv4.tcp_available_congestion_control 显示以下即已开启： 12# sysctl net.ipv4.tcp_available_congestion_controlnet.ipv4.tcp_available_congestion_control = bbr cubic reno 查看 BBR 是否启动 1lsmod | grep bbr 显示以下即启动成功： 12# lsmod | grep bbrtcp_bbr 20480 14","link":"/Debian-9%E5%BF%AB%E9%80%9F%E5%BC%80%E5%90%AFGoogle-BBR%E7%9A%84%E6%96%B9%E6%B3%95/"},{"title":"Docker Compose使用","text":"简介Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。 其代码目前在 https://github.com/docker/compose 上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 安装与卸载linux在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。例如，在 Linux 64 位系统上直接下载对应的二进制包。 12$ sudo curl -L https://github.com/docker/compose/releases/download/1.25.5/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose macos、windowCompose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。Docker Desktop for Mac/Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 bash命令补全通用下载1$ curl -L https://raw.githubusercontent.com/docker/compose/1.25.5/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose 卸载 如果是二进制包方式安装的，删除二进制文件即可。 1$ sudo rm /usr/local/bin/docker-compose 测试安装成功12$ docker-compose --version docker-compose version 1.27.4, build 40524192 docker compose入门两个重要概念 项目 (project)：有多个服务共同组成一个完整业务单元，定义在docker-compose.yml文件中 服务 (service)：一个服务对应一个应用容器，一个项目中可以存在多个服务 第一个docker-compose程序 在一个空目录中创建一个docker-compose.yml文件 在配置文件中定义一个项目存在哪些服务 123456version: &quot;3.0&quot; #定义版本，官方要求，最高为4.0services: #所有的服务 tomcat: #服务名，唯一 image: tomcat:8.0-jre8 #创建当前这个服务使用哪个镜像 ports: #映射端口，是个数组 - 8080:8080 运行docker-compose 注意：必须保障运行命令的目录存在docker-compose.yml 12docker-compose up #启动这个项目的所有服务docker-compose up -d #后台启动这个项目的所有服务 docker-compose模版文件模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。这里面大部分指令跟 docker run 相关参数的含义都是类似的。 container-name指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 1container_name: tomcat01 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 image指定镜像名称或者镜像ID或者镜像摘要。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 123image: tomcatimage: tomcat:8.0image: a4j32def ports暴漏端口信息。使用 宿主机端口:容器端口 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 12345ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; 注意：当使用 宿主机端口:容器端口 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 volumes数据卷所挂载路径设置。可以设置为宿主机路径(HOST:CONTAINER)或者数据卷名称(VOLUME:CONTAINER)，并且可以设置访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 1234volumes: - /root/mysqldata:/var/lib/mysql - cache:/tmp/cache - ~/configs:/etc/configs/:ro 如果路径为数据卷名称，必须在文件中配置数据卷。 123456789101112version: &quot;3.0&quot;service: tomcat01: #服务名称 volumes: #完成宿主机与容器中的目录做数据卷挂载 相当于 run -v - /root/apps:/usr/local/tomcat/webapps #使用自定义路径映射 - tomcatwebapps01:/usr/local/tomcat/webapps #使用自动创建卷名映射，但前提需要用指令‘volume’在下面声明这个卷名 volumes: #声明上面服务所使用的自动创建卷名 tomcatwebapps01: #声明指令的卷名 compose自动创建该卷名，但是卷名之前会自动加上项目名（当前目录名），若要使用自定义卷名，需要使用命令‘external‘ external: #使用自定义卷名 true #true：确定使用指定卷名，但是前提需要先手动用‘docker volume create xxx’ 创建卷名，否则启动报错 networks配置容器连接的网络。 123456789101112version: &quot;3.0&quot;service: tomcat01: #服务名称 image: tomcat:8.0-jre8 #使用哪个镜像 相当于 run image networks: #代表当前服务使用哪个网络桥 - hello #跟volumes类似，前提需要用指令‘networks’在下面声明这个卷名 networks: #定义服务用到的网络桥 hello: #定义上面的服务用到的网桥名称 默认创建的是bridge,但是卷名之前会自动加上项目名（当前目录名），若要使用自定义卷名，需要使用命令‘external‘ external: #使用自定义网桥名 true: #true：确定使用指定网桥，但是前提需要先手动用‘docker network create hello’ 创建卷名，否则启动报错 environment设置环境变量。可以使用数组key:value或字典-key=value两种格式。 只写环境变量的名称，则Compose会自动获取宿主机上对应的环境变量的值，可以用来防止泄露不必要的数据。 123456789environment: MYSQL_ROOT_PASSWORD: root MYSQL_ROOT_PASSWORD: IS_ENABLE: &quot;yes&quot;#或者environment: - MYSQL_ROOT_PASSWORD=root - MYSQL_ROOT_PASSWORD - IS_ENABLE=&quot;yes&quot; 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 1y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF command覆盖容器启动后默认执行的命令 1command: echo &quot;hello world&quot; env_file从文件中获取环境变量，可以为单独的文件路径或列表，支持相对路径和绝对路径 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 123456env_file: .envenv_file: - ./mysql.env - ./apps/mysql.env - /opt/mysql.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 12# mysql.env: Set development environmentMYSQL_ROOT_PASSWORD=root depends_on解决容器的依赖、启动先后的问题。以下例子中会先启动 tomcat02 redis mysql 再启动 tomcat01 123456789101112131415161718version: &quot;3.0&quot;service: tomcat01: image: tomcat:8.0-jre8 depends_on: #代表这个容器必须依赖哪些容器启动之后才能启动 - tomcat02 #这里是服务名，不是容器名 - redis - mysql tomcat02: image: tomcat:8.0-jre8 mysql: image: mysql:5.7.32 redis: image: reids:5.0.10 注意：tomcat02 服务不会等待 tomcat02 redis mysql「完全启动」之后才启动。 healthcheck通过命令检查容器是否健康运行。 12345healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 1m30s timeout: 10s retries: 3 sysctls配置容器内核参数，可以使用数组key:value或字典-key=value两种格式。 用来修改容器中系统内部参数，并不是必须的，有些服务启动会受容器内操作系统参数限制，可能会无法启动，所以必须通过修改容器中参数才能启动。 1234567sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0#或者sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits指定容器的 ulimits 限制值。 用来修改容器中系统内部进程数限制，日后使用时可以根据当前容器运行的服务要求镜像修改。 例如，es指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 12345ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 build指定Dockerfile所在文件夹的路径（可以是绝对路径或者相对docker-compose.yml文件的路径）。Compose将会利用它自动构建这个镜像，然后使用这个镜像。 使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 123456789101112131415version: &quot;3.0&quot;service: demo: build: #启动服务时先将build命令中指定的Dockerfile打包成镜像，再运行容器 context: ./demo #指定上下文目录Dockerfile所在目录，相对docker-compose.yml的路径，或者绝对路径 dockerfile: Dockerfile #指定Dockerfile文件名 container_name: demo #指定容器名称 ports: #指定端口 - &quot;8082:8082&quot; networks: - hello depends_on: #依赖哪些服务 - tomcat01 完整的简单模版文件docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192version: &quot;3.0&quot; #https://docs.docker.com/compose/compose-file/ 目前最高3.8service: demo: build: #启动服务时先将build命令中指定的Dockerfile打包成镜像，再运行容器 context: demo #指定上下文目录Dockerfile所在目录，相对docker-compose.yml的路径，或者绝对路径 dockerfile: Dockerfile #指定Dockerfile文件名 container_name: demo #指定容器名称 ports: #指定端口 - &quot;8082:8082&quot; networks: - hello depends_on: - tomcat01 tomcat01: #服务名称 container_name: tomcat01 #相当于 run --name image: tomcat:8.0-jre8 #使用哪个镜像 相当于 run image ports: #用来完成宿主机与容器的端口映射 相当于 run -p - &quot;8080:8080&quot; volumes: #完成宿主机与容器中的目录做数据卷挂载 相当于 run -v - /root/apps:/usr/local/tomcat/webapps #使用自定义路径映射 - tomcatwebapps01:/usr/local/tomcat/webapps #使用自动创建卷名映射，但前提需要用指令‘volumes’在下面声明这个卷名 networks: #代表当前服务使用哪个网络桥 - hello #跟volumes类似，前提需要用指令‘networks’在下面声明这个卷名 depends_on: #代表这个服务必须依赖哪些服务启动之后才能启动 - tomcat02 #这里是服务名，不是容器名 - redis - mysql healthcheck: #用来检查容器是否健康运行 test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 1m30s timeout: 10s retries: 3 sysctls: #配置容器内核参数 - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits: #指定容器的 ulimits 限制值 nproc: 65535 nofile: soft: 20000 hard: 40000 tomcat02: container_name: tomcat02 image: tomcat:8.0-jre8 ports: - &quot;8081:8080&quot; volumes: - tomcatwebapps02:/usr/local/tomcat/webapps networks: - hello mysql: container_name: mysql image: mysql:5.7.32 ports: - &quot;3306:3306&quot; volumes: - mysqldata:/var/lib/mysql - mysqlconf:/etc/mysql networks: - hello environment: #配置环境变量 相当于 run -e - MYSQL_ROOT_PASSWORD=root env_file: #用来将environment环境中的配置放入到指定配置文件中，支持绝对路径和相对路径 - mysql.evn #当前目录下 redis: container_name: redis image: reids:5.0.10 ports: - &quot;6379:6379&quot; volumes: - redisdata:/data networks: - hello command: &quot;redis-server --appendonly yes&quot; #覆盖容器启动后运行的默认命令 volumes: #声明上面服务所使用的自动创建卷名 tomcatwebapps01: #声明指令的卷名 compose自动创建该卷名，但是卷名之前会自动加上项目名（当前目录名），若要使用自定义卷名，需要使用命令‘external‘ external: #使用自定义卷名 true #true：确定使用指定卷名，但是前提需要先手动用‘docker volume create tomcatwebapps01’ 创建卷名，否则启动报错 tomcatwebapps02: mysqldata: mysqlconf: networks: #定义服务用到的网络桥 hello: #定义上面的服务用到的网桥名称 默认创建的是bridge,但是卷名之前会自动加上项目名（当前目录名），若要使用自定义卷名，需要使用命令‘external‘ external: #使用自定义网桥名 true: #true：确定使用指定网桥，但是前提需要先手动用‘docker network create hello’ 创建卷名，否则启动报错 docker-compose 常用指令模版指令和指令的区别 模版指令：用来书写在docker-compose.yml文件中的指令称之为模版指令 用来为项目中的服务进行操作的。 指令：用来对整个docker-compose.yml对应的这个项目操作，书写docker-compose命令之后的命令。 命令对象与格式对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。 执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。 docker-compose 命令的基本的使用格式是 1docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...] 命令选项 -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --x-networking 使用 Docker 的可拔插网络后端特性 --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 常用命令up用来启动所有docker-compose服务 格式为 docker-compose up [options] [SERVICE...]。 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 链接的服务都将会被自动启动，除非已经处于运行状态。 可以说，大部分时候都可以直接通过该命令来启动一个项目。 默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。 当通过 Ctrl-C 停止命令时，所有容器将会停止。 如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。 默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容 down用来关闭所有docker-compose服务，如果网络不是自定义创建的，会一并移除。 格式为docker-compose down [SERVICE...] exec进入指定容器 格式为：docker-compose exec SERVICE bash ps列出项目中目前的所有容器 格式为 docker-compose ps [options] [SERVICE...] 选项： -q 只打印容器的 ID 信息。 restart重启项目中的服务，如果不写服务ID，默认重启所有服务 格式为 docker-compose restart [options] [SERVICE...] 选项： -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 格式为 docker-compose rm [options] [SERVICE...] 选项： -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷，谨慎操作。 start启动项目中的服务 格式为 docker-compose start [SERVICE...] stop停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器 格式为 docker-compose stop [options] [SERVICE...] 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top查看某个容器内运行的进程 格式为docker-compose top [SERVICE...] pause暂停项目中某个服务 格式为docker-compose pause [SERVICE...] uppause恢复处于暂停状态中的服务。 格式为 docker-compose unpause [SERVICE...] logs查看项目中服务的日志 格式为docker-compose logs [options] [SERVICE...] 选项： -f 滚动查看日志","link":"/Docker-Compose%E4%BD%BF%E7%94%A8/"},{"title":"Docker Machine使用","text":"简介官方：https://docs.docker.com/machine/ Docker Machine 是一种可以让您在虚拟主机上安装 Docker 的工具，并可以使用 docker-machine 命令来管理主机。 Docker Machine 也可以集中管理所有的 docker 主机，比如快速的给 100 台服务器安装上 docker。 Docker Machine 管理的虚拟主机可以是机上的，也可以是云供应商，如阿里云，腾讯云，AWS，或 DigitalOcean。 使用 docker-machine 命令，您可以启动，检查，停止和重新启动托管主机，也可以升级 Docker 客户端和守护程序，以及配置 Docker 客户端与您的主机进行通信。 安装Docker Machine不再包含在Docker Desktop安装程序中，可通过以下方法进行安装。 安装Docker Machine之前要先安装Docker，然后通过下载Docker Machine二进制文件的方式安装。 Docker Machine 可以在多种操作系统平台上安装，包括 Linux、macOS，以及 Windows。 macOS 安装命令123$ base=https://github.com/docker/machine/releases/download/v0.16.0 &amp;&amp; curl -L $base/docker-machine-$(uname -s)-$(uname -m) &gt;/usr/local/bin/docker-machine &amp;&amp; chmod +x /usr/local/bin/docker-machine Linux 安装命令1234$ base=https://github.com/docker/machine/releases/download/v0.16.0 &amp;&amp; curl -L $base/docker-machine-$(uname -s)-$(uname -m) &gt;/tmp/docker-machine &amp;&amp; sudo mv /tmp/docker-machine /usr/local/bin/docker-machine &amp;&amp; chmod +x /usr/local/bin/docker-machine Windows 安装命令1234$ base=https://github.com/docker/machine/releases/download/v0.16.0 &amp;&amp; mkdir -p &quot;$HOME/bin&quot; &amp;&amp; curl -L $base/docker-machine-Windows-x86_64.exe &gt; &quot;$HOME/bin/docker-machine.exe&quot; &amp;&amp; chmod +x &quot;$HOME/bin/docker-machine.exe&quot; 仅当使用支持Git BASH之类的终端仿真器（如Git BASH）时，以上命令才能在Windows上运行chmod。 查看是否安装成功12$ docker-machine -v #或者 docker-machine versiondocker-machine version 0.16.0, build 702c267f 卸载删除执行文件即可：rm $(which docker-machine) Docker Machine的使用Docker Machine 支持多种后端驱动，包括虚拟机、本地主机和云平台等。 创建本地主机实例Virtualbox 驱动首先下载最新的virtualbox，官方：https://www.virtualbox.org/wiki/Downloads 使用 virtualbox 类型的驱动，创建一台 Docker 主机，命名为 test。 1docker-machine create -d virtualbox test 也可以在创建时加上如下参数，来配置主机或者主机上的 Docker。 --engine-opt dns=114.114.114.114 配置 Docker 的默认 DNS --engine-registry-mirror https://hub-mirror.c.163.com 配置 Docker 的仓库镜像 --virtualbox-memory 2048 配置主机内存 --virtualbox-cpu-count 2 配置主机 CPU 更多参数请使用 docker-machine create --driver virtualbox --help 命令查看。 macOS xhyve 驱动xhyve 驱动 GitHub: https://github.com/zchee/docker-machine-driver-xhyve xhyve 是 macOS 上轻量化的虚拟引擎，使用其创建的 Docker Machine 较 VirtualBox 驱动创建的运行效率要高。 安装xhyve驱动 123brew install docker-machine-driver-xhyvesudo chown root:wheel /usr/local/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyvesudo chmod u+s /usr/local/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyve 创建主机 1$ docker-machine create -d xhyve test 也可以在创建时加上如下参数，来配置主机或者主机上的 Docker。 --xhyve-boot2docker-url ~/.docker/machine/cache/boot2docker.iso指定本地ISO镜像 --engine-opt dns=114.114.114.114 配置 Docker 的默认 DNS --engine-registry-mirror https://hub-mirror.c.163.com 配置 Docker 的仓库镜像 --xhyve-memory 2048 配置主机内存 --xhyve-rawdisk使用简单的“原始磁盘”格式和virtio-blk驱动程序进行存储。 --xhyve-cpu-count 2 配置主机 CPU 更多参数请使用 docker-machine create --driver xhyve --help 命令查看。 注意：非首次创建时建议加上 --xhyve-boot2docker-url ~/.docker/machine/cache/boot2docker.iso 参数，避免每次创建时都从 GitHub 下载 ISO 镜像。 Windows 10Windows 10 安装 Docker Desktop for Windows 之后不能再安装 VirtualBox，也就不能使用 virtualbox 驱动来创建 Docker Machine，我们可以选择使用 hyperv 驱动。 注意，必须事先在 Hyper-V 管理器中新建一个 外部虚拟交换机 执行下面的命令时，使用 --hyperv-virtual-switch=MY_SWITCH 指定虚拟交换机名称 1$ docker-machine create --driver hyperv --hyperv-virtual-switch=MY_SWITCH vm 更多参数请使用 docker-machine create --driver hyperv --help 命令查看。 使用介绍创建好主机之后，查看主机 123$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORStest - virtualbox Stopped Unknown 创建主机成功后，可以通过 env 命令来让后续操作对象都是目标主机。 1$ docker-machine env test 后续根据提示在命令行输入命令之后就可以操作 test 主机。 也可以通过 SSH 登录到主机。 1234$ docker-machine ssh testdocker@test:~$ docker --versionDocker version 19.03.12, build 48a66213fe shell连接到主机之后你就可以在其上使用 Docker 了。 官方支持驱动通过 -d 选项可以选择支持的驱动类型。 amazonec2 azure digitalocean exoscale generic google hyperv none openstack rackspace softlayer virtualbox vmwarevcloudair vmwarefusion vmwarevsphere 第三方驱动请到 第三方驱动列表 查看 Docker Machine 操作命令 active 查看活跃的 Docker 主机 config 输出连接的配置信息 create 创建一个 Docker 主机 env 显示连接到某个主机需要的环境变量 inspect 输出主机更多信息 ip 获取主机地址 kill 停止某个主机 ls 列出所有管理的主机 provision 重新设置一个已存在的主机 regenerate-certs 为某个主机重新生成 TLS 认证信息 restart 重启主机 rm 删除某台主机 ssh SSH 到主机上执行命令 scp 在主机之间复制文件 mount 挂载主机目录到本地 start 启动一个主机 status 查看主机状态 stop 停止一个主机 upgrade 更新主机 Docker 版本为最新 url 获取主机的 URL version 输出 docker-machine 版本信息 help 输出帮助信息 每个命令，又带有不同的参数，可以通过 1$ docker-machine COMMAND --help 来查看具体的用法。","link":"/Docker-Machine%E4%BD%BF%E7%94%A8/"},{"title":"Docker Swarm使用","text":"简介官方：https://docs.docker.com/engine/swarm/ Docker Swarm 是 Docker 官方项目之一，提供 Docker 容器集群服务，是 Docker 官方对容器云生态进行支持的核心方案。使用它，用户可以将多个 Docker 主机封装为单个大型的虚拟 Docker 主机，快速打造一套容器云平台。 Docker 1.12 Swarm mode 已经内嵌入 Docker 引擎，成为了 docker 子命令 docker swarm。请注意与旧的 Docker Swarm 区分开来。 Swarm mode 内置 kv 存储功能，提供了众多的新特性，比如：具有容错能力的去中心化设计、内置服务发现、负载均衡、路由网格、动态伸缩、滚动更新、安全传输等。使得 Docker 原生的 Swarm 集群具备与 Mesos、Kubernetes 竞争的实力。 相关概念Swarm 是使用 SwarmKit 构建的 Docker 引擎内置（原生）的集群管理和编排工具。使用 Swarm 集群之前需要了解以下几个概念。 节点运行Docker的主机可以主动初始化一个Swarm集群或者加入一个已经存在的Swarm集群，这样这个运行Docker的主机就成为了一个Swarm集群的节点（node）。 节点分为管理 (manager) 节点和工作 (worker) 节点。 管理节点管理节点用于 Swarm 集群的管理，docker swarm 命令基本只能在管理节点执行（节点退出集群命令 docker swarm leave 可以在工作节点执行）。一个 Swarm 集群可以有多个管理节点，但只有一个管理节点可以成为 leader，leader 通过 raft 协议实现。 raft：就是保证集群中一半以上的机器正常才算集群有效，这就是为什么大部分集群的机器都是奇数台，假如有四台机器，其中两台挂了，则集群也就失效了，这和总共有三台机器的效果一样，所以为了保证资源充分利用，集群的机器数为奇数台。 工作节点工作节点是任务执行节点，管理节点将服务 (service) 下发至工作节点执行。管理节点默认也作为工作节点。你也可以通过配置让服务只运行在管理节点。 来自 Docker 官网的这张图片形象的展示了集群中管理节点与工作节点的关系。 服务和任务任务 （Task）是 Swarm 中的最小的调度单位，目前来说就是一个单一的容器。 服务 （Services） 是指一组任务的集合，服务定义了任务的属性。服务有两种模式： replicated services 按照一定规则在各个工作节点上运行指定个数的任务。 global services 每个工作节点上运行一个任务 两种模式通过 docker service create 的 --mode 参数指定。 来自 Docker 官网的这张图片形象的展示了容器、任务、服务的关系。 创建Swarm集群我们来创建一个包含一个管理节点和两个工作节点的最小 Swarm 集群。 初始化集群在 Docker Machine 一节中我们了解到 Docker Machine 可以在数秒内创建一个虚拟的 Docker 主机，下面我们使用它来创建三个 Docker 主机，并加入到集群中。 我们首先创建一个 Docker 主机作为管理节点。 1$ docker-machine create -d virtualbox manager SSH到manager机器上执行命令 1$ docker-machine ssh manager 我们使用docker swarm init在管理节点初始化一个Swarm集群 如果你的 Docker 主机有多个网卡，拥有多个 IP，必须使用 --advertise-addr 指定 IP，否会提示报错 12docker@manager:~$ docker swarm initError response from daemon: could not choose an IP address to advertise since this system has multiple addresses on different interfaces (10.0.2.15 on eth0 and 192.168.99.101 on eth1) - specify one with --advertise-addr 执行 docker swarm init 命令的节点自动成为管理节点。 12345678docker@manager:~$ docker swarm init --advertise-addr 192.168.99.101Swarm initialized: current node (ss6edkoczov6ha2xkl7muqm4a) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-4iwiay7mou608578t0xiluv381i2k0y3uuu1t0sfabowww84qr-54x2xsupnmlr18ealfgp8uaqk 192.168.99.101:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 增加工作节点创建两个 Docker 主机作为工作节点，并加入到集群中 1234567891011$ docker-machine create -d virtualbox worker1$ docker-machine ssh worker1 ( '&gt;') /) TC (\\ Core is distributed with ABSOLUTELY NO WARRANTY. (/-_--_-\\) www.tinycorelinux.netdocker@worker1:~$ docker swarm join --token SWMTKN-1-4iwiay7mou608578t0xiluv381i2k0y3uuu1t0sfabowww84qr-54x2xsupnmlr18ealfgp8uaqk 192.168.99.101:2377This node joined a swarm as a worker. 1234567891011$ docker-machine create -d virtualbox worker2$ docker-machine ssh worker2 ( '&gt;') /) TC (\\ Core is distributed with ABSOLUTELY NO WARRANTY. (/-_--_-\\) www.tinycorelinux.netdocker@worker1:~$ docker swarm join --token SWMTKN-1-4iwiay7mou608578t0xiluv381i2k0y3uuu1t0sfabowww84qr-54x2xsupnmlr18ealfgp8uaqk 192.168.99.101:2377This node joined a swarm as a worker. 查看所有节点的IP1234docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmanager - virtualbox Running tcp://192.168.99.110:2376 v19.03.12worker1 - virtualbox Running tcp://192.168.99.111:2376 v19.03.12 查看集群docker node ls在管理节点使用 docker node ls 查看集群列表 12345docker@manager:~$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONhztlhn18uasmj981k6q5k32sa * manager Ready Active Leader 19.03.12t7ats765xa9bmq2xeyytlroj1 worker1 Ready Active 19.03.12s1yb705h1ebur8ojxttu9ikr1 worker2 Ready Active 19.03.12 部署服务我们使用docker service命令来管理 Swarm 集群中的服务，该命令只能在管理节点运行。 注意，最好每个节点都把镜像源替换为阿里云，否则下载很慢。 新建服务docker service现在我们在managerj节点创建的 Swarm 集群中运行一个名为 tomcat 服务。 12# --replicas 3 启用 3 个副本docker@manager:~$ docker service create --replicas 3 -p 8080:8080 --name tomcat tomcat:8.0-jre8 现在我们使用浏览器，输入任意节点 IP:8080 ，即可看到 tomcat 默认页面。 查看服务docker service ls使用 docker service ls 来查看当前 Swarm 集群运行的服务 123docker@manager:~$ docker service lsID NAME MODE REPLICAS IMAGE PORTSgb68wnbd9g46 tomcat replicated 3/3 tomcat:8.0-jre8 *:8080-&gt;8080/tcp docker service ps使用 docker service ps 来查看某个服务的详情 12345docker@manager:~$ docker service ps tomcatID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSnuvede7hmggu tomcat.1 tomcat:8.0-jre8 worker2 Running Preparing 3 minutes agow5psn6cpr16m tomcat.2 tomcat:8.0-jre8 manager Running Preparing 3 minutes agopshili013nya tomcat.3 tomcat:8.0-jre8 worker1 Running Preparing 3 minutes ago docker service logs使用 docker service logs 来查看某个服务的日志 12345678910111213docker@manager:~$ docker service logs tomcatdocker@manager:~$ docker service logs tomcattomcat.1.8v0xggulqhx0@manager | 27-Mar-2021 16:22:26.051 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/8.0.53...tomcat.1.8v0xggulqhx0@manager | 27-Mar-2021 16:22:28.449 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;http-apr-8080&quot;]tomcat.1.8v0xggulqhx0@manager | 27-Mar-2021 16:22:28.466 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;ajp-apr-8009&quot;]tomcat.1.8v0xggulqhx0@manager | 27-Mar-2021 16:22:28.472 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 2133 mstomcat.2.f566j6imruvq@worker1 | 27-Mar-2021 16:22:51.954 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/8.0.53tomcat.2.f566j6imruvq@worker1 | 27-Mar-2021 16:22:51.958 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: Jun 29 2018 14:42:45 UTC.....tomcat.2.f566j6imruvq@worker1 | 27-Mar-2021 16:22:53.753 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;http-apr-8080&quot;]tomcat.2.f566j6imruvq@worker1 | 27-Mar-2021 16:22:53.787 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;ajp-apr-8009&quot;]tomcat.2.f566j6imruvq@worker1 | 27-Mar-2021 16:22:53.810 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 1624 ms 访问页面随便打开一个ip:8080都可以 http://192.168.99.111:8080/ 服务伸缩docker service scale我们可以使用 docker service scale 对一个服务运行的容器数量进行伸缩。 当业务处于高峰期时，我们需要扩展服务运行的容器数量。 123456789docker@manager:~$ docker service scale tomcat=5tomcat scaled to 5overall progress: 5 out of 5 tasks1/5: running [==================================================&gt;]2/5: running [==================================================&gt;]3/5: running [==================================================&gt;]4/5: running [==================================================&gt;]5/5: running [==================================================&gt;]verify: Service converged 当业务平稳时，我们需要减少服务运行的容器数量。 123456docker@manager:~$ docker service scale tomcat=2tomcat scaled to 2overall progress: 2 out of 2 tasks1/2: running [==================================================&gt;]2/2: running [==================================================&gt;]verify: Service converged 删除服务docker service rm使用 docker service rm 来从 Swarm 集群移除某个服务。 1docker@manager:~$ docker service rm tomcat 使用 docker compose文件在 Swarm 集群中也可以使用 compose 文件 （docker-compose.yml） 来配置、启动多个服务。 我们使用 docker service create 一次只能部署一个服务，使用 docker-compose.yml 我们可以一次启动多个关联的服务。 我们使用 docker stack deploy 而不是 docker service create，Stack 会帮我们管理这些对象。 我们可以直接用 docker-compose.yml 文件，但是不能 build 镜像，Swarm 只接收构建好的镜像，新加了一个 deploy 字段。当使用 docker-compose 执行这个文件时，会忽略 deploy 字段。docker stack 中会忽略 build 字段，所以我们可以开发和发布都使用一个 docker-compose.yml 文件。 创建docker-compose.yml文件 在一个空目录中创建一个docker-compose.yml文件 在配置文件中定义一个项目存在哪些服务 相对于之前新加了一个 deploy 字段。 1234567891011121314151617181920version: &quot;3.0&quot; #定义版本，官方要求，最高为4.0services: #所有的服务 tomcat: #服务名，唯一 image: tomcat:8.0-jre8 #创建当前这个服务使用哪个镜像 ports: #映射端口，是个数组 - 8080:8080 networks: #指定自定义网络 - overlay deploy: # 部署 mode: replicated # 复制模式 replicas: 3 #启动多少个容器 #update_config: # 更新规则 #parallelism: 2 # 一次两个 #delay: 10s # 更新延迟 10s，给 app 一个启动时间 #restart_policy: # 重启规则 #condition: on-failure #遇到失败就重启 #placement: #constraints: [node.role == manager] # 只部署在 manager 节点networks: overlay: 运行docker-compose部署服务部署服务使用 docker stack deploy，其中 -c 参数指定 compose 文件名 命令：docker stack deploy -c docker-compose.yml tomcat -c 指定配置文件 deploy 也可以换成 up 123docker@manager:~$ docker stack deploy -c docker-compose.yml tomcatCreating network tomcat_overlayCreating service tomcat_tomcat 查看compose服务命令：docker stack ls 123docker@manager:~$ docker stack lsNAME SERVICES ORCHESTRATORtomcat 1 Swarm 查看compose容器命令：docker stack ps tomcat 12345docker@manager:~$ docker stack ps tomcatID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSkn4sesyafad3 tomcat_tomcat.1 tomcat:8.0-jre8 manager Running Running about a minute agoyiqfmly0simi tomcat_tomcat.2 tomcat:8.0-jre8 manager Running Running about a minute agov9ygrv2al221 tomcat_tomcat.3 tomcat:8.0-jre8 worker1 Running Running about a minute ago 移除服务命令：docker stack rm tomcat 该命令不会移除服务所使用的 数据卷，如果你想移除数据卷请使用 docker volume rm 123docker@manager:~$ docker stack rm tomcatRemoving service tomcat_tomcatRemoving network tomcat_overlay 更新服务如果我们更新这个配置文件，可以重新执行docker-compose.yml文件即可。 管理密钥在动态的、大规模的分布式集群上，管理和分发 密码、证书 等敏感信息是极其重要的工作。传统的密钥分发方式（如密钥放入镜像中，设置环境变量，volume 动态挂载等）都存在着潜在的巨大的安全风险。 Docker 目前已经提供了 secrets 管理功能，用户可以在 Swarm 集群中安全地管理密码、密钥证书等敏感数据，并允许在多个 Docker 容器实例之间共享访问指定的敏感数据。它最大支持 500KB 的字符串或二进制内容。 Secret 会被加密的保存在管理节点的硬盘上，被加密传输。只有被允许的容器才能查看 Secret，在容器中它只会被存在内存中，可以在 /run/secrets/&lt;secret_name | secret_alias&gt; 访问到。 注意： secret 也可以在 Docker Compose 中使用。 我们可以用 docker secret 命令来管理敏感信息。 创建secret我们使用 docker secret create 命令创建 secret。 Secret 可以通过两种方式创建，一种是文件另一种是 stdin(管道符｜) 创建。 文件创建 先创建文件，并填写需要加密的内容 执行创建命令 命令格式：docker secret create [KEY] [FILENAME] 12345docker@manager:~$ cat mysql_root_password.txt123456docker@manager:~$ docker secret create mysql_root_password mysql_root_password.txtlvn3k6ajcytuno476mferezr5docker@manager:~$ 管道符形式创建​ 命令格式：[可以生成字符串的命令] | docker secret create [KEY] 123docker@manager:~$ echo '123456' | docker secret create mysql_password -p94kxcvqfmkwdg55om2i8fmbedocker@manager:~$ 查看secret命令格式：使用 docker secret ls 12345docker@manager:~$ docker secret lsID NAME DRIVER CREATED UPDATEDp94kxcvqfmkwdg55om2i8fmbe mysql_password 21 seconds ago 21 seconds agolvn3k6ajcytuno476mferezr5 mysql_root_password 30 seconds ago 30 seconds agodocker@manager:~$ 使用secret创建服务如果你没有在 target 中显式的指定路径时，secret 默认通过 tmpfs 文件系统挂载到容器的 /run/secrets 目录中。 1 12345678910111213141516docker@manager:~$ docker service create \\ --name mysql \\ --replicas 2 \\ --secret source=mysql_root_password,target=mysql_root_password \\ --secret source=mysql_password,target=mysql_password \\ -e MYSQL_ROOT_PASSWORD_FILE=&quot;/run/secrets/mysql_root_password&quot; \\ -e MYSQL_PASSWORD_FILE=&quot;/run/secrets/mysql_password&quot; \\ -e MYSQL_USER=&quot;buubiu&quot; \\ -e MYSQL_DATABASE=&quot;buubiu&quot; \\ mysql:latestoverall progress: 2 out of 2 tasks1/2: running [==================================================&gt;]2/2: running [==================================================&gt;]verify: Service convergeddocker@manager:~$ –secret用来指定 Service 能使用那个secret` 查看通过secret创建的服务1234docker@manager:~$ docker service lsID NAME MODE REPLICAS IMAGE PORTSmai1e55esrrs mysql replicated 2/2 mysql:latestdocker@manager:~$ 删除服务的secret 单纯的删除secret，命令：docker secret rm [KEY][KEY]... 123docker@manager:~$ docker secret rm my_passwordmy_passworddocker@manager:~$ 如果我们现在删除 Service 的 secret，可以使用 --secret-rm 注意：删除 Service 的 secret，容器会自动重建，因为 Service 是容器的一部分。 1docker@manager:~$ docker service update --secret-rm mysql_user 通过以上方法，我们没有像以前通过设置环境变量来设置 MySQL 密码， 而是采用 docker secret 来设置密码，防范了密码泄露的风险。 管理配置信息在动态的、大规模的分布式集群上，管理和分发配置文件也是很重要的工作。传统的配置文件分发方式（如配置文件放入镜像中，设置环境变量，volume 动态挂载等）都降低了镜像的通用性。 在 Docker 17.06 以上版本中，Docker 新增了 docker config 子命令来管理集群中的配置信息，以后你无需将配置文件放入镜像或挂载到容器中就可实现对服务的配置。 注意：config 仅能在 Swarm 集群中使用。 这里我们以在 Swarm 集群中部署 redis 服务为例。 创建config命令格式：docker config create [NAME] [FILE] 新建 redis.conf 文件 1port 6380 此项配置 Redis 监听 6380 端口 创建config 123docker@manager:~$ docker config create redis.conf redis.confiqxk8sghv1vtj2kzkc2bwgp1edocker@manager:~$ 查看config命令格式：docker config ls 123docker@manager:~$ docker config lsID NAME CREATED UPDATEDiqxk8sghv1vtj2kzkc2bwgp1e redis.conf 52 seconds ago 52 seconds ago 使用config1234567docker@manager:~$ docker service create \\ --name redis \\ # --config source=redis.conf,target=/etc/redis.conf \\ --config redis.conf \\ -p 6380:6380 \\ redis:latest \\ redis-server /redis.conf 如果你没有在 target 中显式的指定路径时，默认的 redis.conf 以 tmpfs 文件系统挂载到容器的 /config.conf。 经过测试，redis 可以正常使用。 以前我们通过监听主机目录来配置 Redis，就需要在集群的每个节点放置该文件，如果采用 docker config 来管理服务的配置信息，我们只需在集群中的管理节点创建 config，当部署服务时，集群会自动的将配置文件分发到运行服务的各个节点中，大大降低了配置信息的管理和分发难度。 滚动升级滚动升级是一次只升级一部分副本，不一次性全部升级，它降低了应用更新的风险，如果某个副本更新失败，整个更新将暂停，其他副本则可以继续提供服务。在更新的过程中，总是有副本在运行的，也保证了业务的连续性。 现在我们把 nginx:1.16 版本升级到 nginx:1.17。 创建服务12345678docker@manager:~$ docker service create --name nginx --replicas=3 nginx:1.16jzxnmnhw2lif7uklj8cp6d4qwoverall progress: 3 out of 3 tasks1/3: running [==================================================&gt;]2/3: running [==================================================&gt;]3/3: running [==================================================&gt;]verify: Service convergeddocker@manager:~$ 升级服务版本命令格式：docker service update swarm 会停止一个容器，更新它，如果失败就会暂停整个更新过程 123456789101112131415161718docker@manager:~$ docker service update --image nginx:1.17 nginxnginxoverall progress: 2 out of 3 tasks1/3: running [==================================================&gt;]2/3: running [==================================================&gt;]3/3: pending [================&gt; ]docker@manager:~$ docker service ps nginxID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSu25clkz1vw5p nginx.1 nginx:1.17 manager Running Running 2 minutes ago3urf32x2gn39 \\_ nginx.1 nginx:1.16 manager Shutdown Shutdown 3 minutes ago210z5dcn3lg2 nginx.2 nginx:1.17 manager Running Running 2 minutes agozns691zenqd5 \\_ nginx.2 nginx:1.16 manager Shutdown Shutdown 2 minutes agokx7709qb8d6l nginx.3 nginx:1.17 manager Running Running 2 minutes agol6s0tyoxqhrs \\_ nginx.3 nginx:1.16 manager Shutdown Shutdown 2 minutes agodocker@manager:~$ 以上命令使用 --image 选项更新了服务的镜像。当然我们也可以使用 docker service update 更新任意的配置。 --secret-add 选项可以增加一个密钥 --secret-rm 选项可以删除一个密钥 更多选项可以通过 docker service update -h 命令查看。 服务回退命令格式：docker service update --rollback [NAME] 或者docker serivice rollback [NAME] 注意：只能回滚到上一次执行 docker service update 之前的状态，并不能无限制地回滚。 12345678910111213141516171819202122docker@manager:~$ docker service update --rollback nginxnginxrollback: manually requested rollbackoverall progress: rolling back update: 3 out of 3 tasks1/3: running [&gt; ]2/3: running [&gt; ]3/3: running [&gt; ]verify: Waiting 5 seconds to verify that tasks are stable...docker@manager:~$ docker service ps nginxID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSc8jq0s3ezu0s nginx.1 nginx:1.16 manager Running Running 20 seconds agou25clkz1vw5p \\_ nginx.1 nginx:1.17 manager Shutdown Shutdown 20 seconds ago3urf32x2gn39 \\_ nginx.1 nginx:1.16 manager Shutdown Shutdown 6 minutes ago9jjghoimxmcv nginx.2 nginx:1.16 manager Running Running 22 seconds ago210z5dcn3lg2 \\_ nginx.2 nginx:1.17 manager Shutdown Shutdown 22 seconds agozns691zenqd5 \\_ nginx.2 nginx:1.16 manager Shutdown Shutdown 6 minutes agoqg7b61je5l9a nginx.3 nginx:1.16 manager Running Running 18 seconds agokx7709qb8d6l \\_ nginx.3 nginx:1.17 manager Shutdown Shutdown 19 seconds agol6s0tyoxqhrs \\_ nginx.3 nginx:1.16 manager Shutdown Shutdown 6 minutes agodocker@manager:~$","link":"/Docker-Swarm%E4%BD%BF%E7%94%A8/"},{"title":"Dockerfile构建springboot项目","text":"准备开发好的Springboot应用程序对springboot应用进行打包jar包方式（主流）​ 这种方式要以 jdk的镜像为基础构建 执行maven package命令 war方式（过度）​ 这种方式要以 tomcat镜像为基础构建 把包上传到服务器或者本机的一个目录这里由于我本机安装了docker，所以就在项目下新建个目录 在服务器或本机创建Dockerfile上下文目录context创建目录mkdir demo 这个目录作为context目录 在demo目录中创建Dockerfile文件并编写123456789101112#基于哪个镜像进行构建FROM openjdk:8-jre#定义进入容器时默认位置，接下来后续操作的工作位置WORKDIR /app #将上下文中名字为docker01-demo-xxx.jar复制到工作目录，同时修改名称为app.jarADD docker01-demo-0.0.1-SNAPSHOT.jar app.jar #让当前容器暴漏8081端口，因为项目使用的端口为8081EXPOSE 8081#启动应用固定命令ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;]#执行jar包命令CMD [&quot;app.jar&quot;] 执行构建1docker build -t docker-demo:0.1 . 运行容器1docker run -d - p 8081:8081 --name docker-demo docker-demo:0.1","link":"/Dockerfile%E6%9E%84%E5%BB%BAspringboot%E9%A1%B9%E7%9B%AE/"},{"title":"Dockerfile的使用","text":"什么是DockerfileDockerfile可以认为是Docker镜像的描述文件，是由一系列命令和参数构成的脚本。主要作用是用来帮助我们自己构建一个自定义镜像，日后用户可以将自己应用打包成镜像，这样就可以让我们应用进行容器运行。 Dockerfile构建镜像原理 构建镜像命令 先在需要打包的目录下建Dockerfile文件 书写Dockerfile命令 运行Dockerfile 1docker build -t 镜像名:TAG -f Dockerfile . -t：指定生成镜像的名称和标签 -f：指定dockerfile文件 .：表示打包当前文件夹所有文件 Dockerfile的基本命令官方说明:https://docs.docker.com/engine/reference/builder/ 保留字 作用 FROM 当前镜像是基于哪个镜像的 第一个指令必须是FROM MAINTAINER 镜像维护者的姓名和邮箱地址(将要弃用) RUN 构建镜像时需要运行的指令 EXPOSE 当前容器对外暴露出的端口号 WORKDIR 指定在创建容器后，终端默认登录进来的工作目录，一个落脚点 ENV 用来在构建镜像过程中设置环境变量 ADD 将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar包 COPY 类似于ADD，拷贝文件和目录到镜像中将从构建上下文目录中&lt;原路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置 VOLUME 容器数据卷，用于数据保存和持久化工作 CMD 指定一个容器启动时要运行的命令Dockerfile中可以有多个CMD指令，但只有最后一个生效，CMD会被docker run之后的参数替换 ENTRYPOINT 指定一个容器启动时要运行的命令ENTRYPOINT的目的和CMD一样，都是在指定容器启动程序及其参数 FROM命令 基于那个镜像进行构建新的镜像,在构建时会自动从docker hub拉取base镜像 必须作为Dockerfile的第一个指令出现 语法: 123FROM &lt;image&gt;FROM &lt;image&gt;[:&lt;tag&gt;] #使用版本不写为latestFROM &lt;image&gt;[@&lt;digest&gt;] #使用摘要 例如： 1FORM centos:7 MAINTAINER 命令 镜像维护者的姓名和邮箱地址[废弃] 语法: 1MAINTAINER &lt;name&gt; 例如： 1MAINTAINER buubiu.com RUN命令 RUN指令将在当前映像之上的新层中执行任何命令并提交结果。生成的提交映像将用于Dockerfile中的下一步 语法:可以直接跟命令行，也可以json数据形式 12345RUN &lt;command&gt; (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows)RUN echo helloRUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form)RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;] 例如： 123RUN yum install -y vim#或者 json数组形式RUN [&quot;yum&quot;,&quot;install&quot;,&quot;-y&quot;,&quot;vim&quot;] EXPOSE命令 用来指定构建的镜像在运行为容器时对外暴露的端口 语法： 12EXPOSE 80/tcp 如果没有显示指定则默认暴露都是tcpEXPOSE 80/udp 例如： 12EXPOSE 8080EXPOSE 8081 WORKDIR命令 用来为Dockerfile中的任何RUN、CMD、ENTRYPOINT、COPY和ADD指令设置工作目录。如果WORKDIR不存在，即使它没有在任何后续Dockerfile指令中使用，它也将被创建。 注意:WORKDIR指令可以在Dockerfile中多次使用。如果提供了相对路径，则该路径将与先前WORKDIR指令的路径相对 语法：可以绝对路径，也可以相对路径 12345WORKDIR /path/to/workdirWORKDIR /aWORKDIR bWORKDIR c 例如： 123WORKDIR /dataWORKDIR aa ENV 命令 用来为构建镜像设置环境变量。这个值将出现在构建阶段中所有后续指令的环境中。 语法： 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key&gt;=&lt;value&gt; ... 例如： 1234ENV BASE_DIR /mydirENV BASE_DIR=/mydir#其他引用是用$符号WORKDIR $BASE_DIR/aa ADD命令 用来从context上下文复制文件、目录或远程文件URL，并将它们添加到位于指定路径的镜像文件系统中，跟COPY命令类似，区别在于ADD命令会自动处理URL和解压tar包 语法： 1234ADD 原文件 目标路径 ADD [&quot;原文件&quot;,&quot;目标路径&quot;] #也支持json数据形式ADD url #添加远程文件(直接跟URL 不会自动解压压缩包)ADD 文件名.tar.gz 目标路径 #直接跟压缩包会自动解压 例如： 1234567891011ADD hom* /mydir/ #通配符添加多个文件ADD hom?.txt /mydir/ #通配符添加ADD test.txt relativeDir/ #可以指定相对路径ADD test.txt /absoluteDir/ #可以指定绝对路径ADD [&quot;test.txt&quot;,&quot;/mydir/&quot;] #也支持json数据形式ADD https://mirrors.bfsu.edu.cn/apache/tomcat/tomcat-8/v8.5.64/bin/apache-tomcat-8.5.64.tar.gz /mydir/ #添加远程文件ADD apache-tomcat-8.5.64.tar.gz /mydir/ #会自动解压到mydir目录#可以与以下命令连用RUN mv apache-tomcat-8.5.64 tomcat #改名为tomcatWORKDIR tomcat #指定容器运行后的目录为tomcat COPY命令 用来将context上下文目录中的指定文件复制到镜像的指定目录中，跟ADD命令类似 语法： 12ADD 原文件 目标路径 ADD [&quot;原文件&quot;,&quot;目标路径&quot;] #也支持json数据形式 例如： 12COPY test.txt /mydir/COPY [&quot;test.txt&quot;,&quot;/mydir/&quot;] #也支持json数据形式 VOLUME命令 用来定义容器运行时可以挂载到宿主机的目录 语法： 12VOLUME 容器内部待挂载的绝对路径VOLUME [&quot;容器内部待挂载的绝对路径&quot;] #也支持json格式 例如： 1234VOLUME /mydir/tomcat/webappsVOLUME [&quot;/mydir/tomcat/webapps&quot;]#后续运行容器才能指定挂载目录docker run -v tomcatwebapps:/mydir/tomcat/webapps centos7 CMD 命令 用来为启动的容器指定执行的命令,在Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。 注意: Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。 我们可以在run容器时覆盖掉cmd命令 语法: 12CMD commandCMD [&quot;command&quot;, &quot;command&quot;, &quot;command&quot;] #也支持json格式 例如： 123456CMD ls /mydir/tomcat #查看目录下文件#或者CMD [&quot;ls&quot;,&quot;/mydir/tomcat&quot;]#docker run 覆盖CMD命令docker run centos7 ls /mydir/tomcat/webapps ENTRYPOINT命令 用来指定容器启动时执行命令和CMD类似 注意： 我们不可以在run容器时像CMD那样覆盖命令，但是如果想覆盖ENTRYPOINT的命令，可以加上 --entrypoint=command 语法: 12ENTRYPOINT commandENTRYPOINT [&quot;command&quot;, &quot;command&quot;, &quot;command&quot;] #也支持json格式 例如： 123456ENTRYPOINT ls /mydir/tomcat #查看目录下文件#或者ENTRYPOINT [&quot;ls&quot;,&quot;/mydir/tomcat&quot;]#docker run 覆盖ENTRYPOINT命令docker run centos7 --entrypoint=ls /mydir/tomcat/webapps CMD与ENTRYPOINT的区别 ENTRYPOINT指令，往往用于设置容器启动后的第一个命令，这对一个容器来说往往是固定的。 CMD指令，往往用于设置容器启动的第一个命令的默认参数，这对一个容器来说可以是变化的。 联合使用 注意：联合使用时，必须是json数组格式的命令，否则无法联合使用 12345678910#第一种应用：展示目录ENTRYPOINT [&quot;ls&quot;]CMD [&quot;/mydir/tomcat&quot;]#第二种应用：运行不同的jar包ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;]CMD [&quot;buubiu.jar&quot;]#启动容器docker run centos7 #结果展示tomcat目录docker run centos7 /mydir/tomcat/webapps #结果展示webapps目录，因为覆盖了CMD命令","link":"/Dockerfile%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Docker中的数据卷配置","text":"数据卷作用用来实现容器与宿主机之间数据共享 数据卷特点数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性： 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效，双向都生效 对 数据卷 的更新，不会影响镜像，只影响容器 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。 数据卷操作自定义数据卷目录注意：宿主机目录会覆盖容器内目录内容 123docker run -v 宿主机绝对目录:容器内绝对目录 容器名称｜容器IDdocker run -v 宿主机绝对目录:容器内绝对目录:ro 容器名称｜容器ID #ro代表容器内目录只读# 例如：docker run -d -p 8080:8080 --name myTomcat -v /root/apps:/usr/local/tomcat/webapps tomcat 自动数据卷目录注意：这种方式会在docker运行容器时自动在宿主机中创建一个目录,并将容器目录文件复制到宿主机中 123docker run -v 卷名(任意别名):容器内绝对路径 容器名称｜容器IDdocker run -v 卷名(任意别名):容器内绝对路径:ro 容器名称｜容器ID #ro代表容器内目录只读#例如：docker run -d -p 8080:8080 --name myTomcat -v aa:/usr/local/tomcat/webapps tomcat 容器内部执行的流程 aa代表一个数据卷名称，名称可以随便写，docker在发现aa目录不存在时，会自动创建这个数据卷，并自动映射宿主机某个目录 同时在启动容器时会将aa对应容器目录中全部内容复制到aa映射到目录中 这个aa目录在宿主机：/var/lib/docker/volumes/aa/_data Docker操作数据卷查看数据卷1docker volume ls 查看数据卷详情123docker volume inspect 卷名#或者docker inspect 卷名 创建数据卷1docker volume create 卷名 删除数据卷1234#删除没有使用的所有数据卷docker volume prune#删除指定的数据卷docker volume rm 卷名","link":"/Docker%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8D%B7%E9%85%8D%E7%BD%AE/"},{"title":"Docker中的网络配置","text":"为什么要提供网络功能Docker 允许通过外部访问容器互联的方式来提供网络服务。 Docker 容器与操作系统通信机制当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。 同时，Docker 随机分配一个本地未占用的私有网段（在 RFC1918 中定义）中的一个地址给 docker0 接口。比如典型的 172.17.42.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。 当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。 Docker 网络使用注意：一般在使用docker网桥(bridge)实现容器与容器通信时，都是站在一个应用角度进行容器通信的。 查看网桥配置1docker network ls 创建自定义网桥123docker network create buubiu(网桥名称)#或者 默认就是 bridgedocker network create -d bridge buubiu(网桥名称) 查看网桥详情1docker inspect buubiu(网桥名称) 删除一个网桥1docker network rm 网桥名称 启动容器指定使用网桥12docker run -d -p 8080:8080 --name myTomcat01 --network buubiu tomcat docker run -d -p 8081:8080 --name myTomcat02 --network buubiu tomcat 注意: 1. 一旦指定网桥后--name指定名字就是主机名,多个容器指定在同一个网桥时,可以在任意一个容器中使用主机名与容器进行互通 2. 使用run命令指定网桥时，这个网桥必须存在，否则创建不成功","link":"/Docker%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"title":"Docker可视化工具Portainer的使用","text":"简介官网：https://www.portainer.io Portainer is the definitive open source container management tool for Kubernetes, Docker, Docker Swarm and Azure ACI. It allows anyone to deploy and manage containers without the need to write code. 翻译： Portainer是Kubernetes，Docker，Docker Swarm和Azure ACI的权威性开源容器管理工具。它允许任何人无需编写代码即可部署和管理容器。 安装官方安装文档：https://documentation.portainer.io/quickstart/ 下载镜像 1docker pull portainer/portainer-ce 由于需要挂载操作数据，所有要提前创建volume 1docker volume create portainer_data 运行容器 1docker run -d -p 8000:8000 -p 9000:9000 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce 说明： 8000 是portainer与docker引擎交互docker.sock的 9000是供用户访问界面的 --restart=always 表示容器重启的方式，always 一停掉就重启，即一直保持启动状态 var/run/docker.sock挂载这个目录，为了操作docker引擎 登录和使用Portainer浏览器访问：http://localhost:9000","link":"/Docker%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7Portainer%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Docker安装常用服务","text":"基础安装步骤 安装哪个服务就去docker hub搜索对应服务的镜像 点击进入该服务的docker hub，如图： Description：描述信息 Tags：版本信息 确定使用的版本 docker pull mysql:5.7 安装mysql 基本启动mysql服务 12docker run -e MYSQL_ROOT_PASSWORD=root mysql:5.7# -e MYSQL_ROOT_PASSWORD=root e是指环境变量；代表给root用户指定密码 启动一个mysql服务，后台运行，指定映射端口，指定root用户密码，指定容器名字 1docker run -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=root --name mysql mysql:5.7 启动一个mysql服务，后台运行，指定映射端口，指定root用户密码，指定容器名字，使用数据卷将数据持久化到宿主机系统 注意：通过docker hub描述得知，mysql存储数据文件目录是/var/lib/mysql 1docker run -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=root --name mysql -v mysqldata:/var/lib/mysql mysql:5.7 启动一个mysql服务，后台运行，指定映射端口，指定root用户密码，指定容器名字，使用数据卷将数据持久化到宿主机系统，用已修改之后的配置文件启动 注意：通过docker hub描述得知，mysql配置文件的路径是/etc/mysql 1docker run -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=root --name mysql -v mysqldata:/var/lib/mysql -v mysqlconfig:/etc/mysql mysql:5.7 将mysql数据库备份为sql文件 12345678#导出全部数据docker exec mysql|容器id sh -c 'exec mysqldump --all-databases -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &gt; /root/all-databases.sql#导出指定库数据docker exec mysql sh -c 'exec mysqldump --databases 库表 -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &gt; /root/all-databases.sql#导出指定库数据不要数据docker exec mysql sh -c 'exec mysqldump --no-data --databases 库表 -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &gt; /root/all-databases.sql 执行sql文件到mysql中 1docker exec -i mysql sh -c 'exec mysql -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &lt; /root/xxx.sql 安装tomcat 启动一个基本tomcat服务 1docker run -d -p 8081:8080 --name tomcat tomcat:8.0-jre8 启动tomcat服务，并将部署应用目录通过数据卷挂载到宿主机系统 注意：通过docker hub描述得知，部署web应用在容器中目录为/usr/local/tomcat/webapps 1docker run -d -p 8081:8080 --name tomcat -v apps:/usr/local/tomcat/webapps tomcat:8.0-jre8 修改配置文件，并将部署应用目录通过数据卷挂载到宿主机系统（如果修改端口的话，需要重新起一个容器才能生效） 注意：通过docker hub描述得知，配置文件在/usr/local/tomcat/conf 1docker run -d -p 8081:8080 --name tomcat -v apps:/usr/local/tomcat/webapps -v confs:/usr/local/tomcat/conf tomcat:8.0-jre8 安装redis 启动一个基本redis服务 1docker run -d -p 6379:6379 --name redis redis:5.0 开启redis持久化( --appendonly yes)，并将持久化的目录通过数据卷挂载到宿主机系统 注意：一旦开启持久化后，持久化生成的aof文件会被放入容器中/data目录中 1docker run -d -p 6379:6379 -v redisdata:/data --appendonly yes --name redis redis:5.0 加载外部配置文件，以配置文件方式启动 注意： 1. 默认情况下redis官方镜像中没有redis.conf配置文件 需要去官网下载指定版本的配置文件 2. 将官方安装包中配置文件进行复制到宿主机指定目录中如 /root/redis/redis.conf文件 3. 修改需要自定义的配置 12bind 0.0.0.0 开启远程权限appenonly yes 开启aof持久化 4. 加载配置启动，并让配置生效(redis-server /usr/local/etc/redis/redis.conf) 1docker run -d -p 6379:6379 -v /root/redis/redis.conf:/usr/local/etc/redis --name redis redis:5.0 redis-server /usr/local/etc/redis/redis.conf 安装nginx 启动一个基本nginx服务 1docker run -d -p 80:80 --name mynginx nginx 挂载nginx配置文件以及html到宿主机系统 进入容器 1docker exec -it mynginx /bin/bash 查找目录：whereis nginx 配置文件路径：/etc/nginx/nginx.conf 复制配置文件到宿主机 1docker cp mynginx(容器id|容器名称):/etc/nginx/nginx.conf /root/nginx/nginx.conf(宿主机目录) 启动容器 1docker run -d -p 80:80 --name mynginx -v /root/nginx/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/html:/usr/share/nginx/html nginx 安装elasticsearch 启动一个基础服务 1docker run -d -p 9200:9200 -p 9300:9300 --name elasticsearch -e &quot;discovery.type=single-node&quot; elasticsearch:7.9.3 注意：如果启动出现如下错误的解决办法 在centos中修改配置/etc/sysctl.conf 加入或修改如下配置 vm.max_map_count=262144 启用配置sysctl -p 启动服务，并持久化索引数据和配置 注意： 1. ES中所有数据都在容器中的/usr/share/elasticsearch/data 2. ES中的配置文件在容器中的/usr/share/elasticsearch/config 1docker run -d -p 9200:9200 -p 9300:9300 --name elasticsearch -e &quot;discovery.type=single-node&quot; -v esdata:/usr/share/elasticsearch/data -v esconfig:/usr/share/elasticsearch/config elasticsearch:7.9.3 启动服务，并持久化索引数据，持久化配置，安装ik分词器 注意：ES中的分词插件路径为/usr/share/elasticsearch/plugins 下载对应版本的IK分词器 1wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.9.3/elasticsearch-analysis-ik-7.9.3.zip 解压到plugins文件夹中 12yum install -y unzipunzip -d ik elasticsearch-analysis-ik-7.9.3.zip 添加自定义扩展词和停用词 vim plugins/elasticsearch/config/IKAnalyzer.cfg.xml 1234567&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=&quot;ext_dict&quot;&gt;ext_dict.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;ext_stopwords.dic&lt;/entry&gt;&lt;/properties&gt; 在ik分词器目录下config目录中创建ext_dict.dic文件 编码一定要为UTF-8才能生效 vim ext_dict.dic 加入扩展词即可 在ik分词器目录下config目录中创建ext_stopword.dic文件 vim ext_stopwords.dic 加入停用词即可 启动容器生效 1docker run -d -p 9200:9200 -p 9300:9300 --name elasticsearch -e &quot;discovery.type=single-node&quot; -v esdata:/usr/share/elasticsearch/data -v esconfig:/usr/share/elasticsearch/config -v esplugins:/usr/share/elasticsearch/plugins elasticsearch:7.9.3 加密es登录 在启动命令中加入环境变量： 12345678910$ docker run -d -p 9200:9200 -p 9300:9300 \\ ---name elasticsearch \\ -e &quot;discovery.type=single-node&quot; \\ -v esdata:/usr/share/elasticsearch/data \\ -v esconfig:/usr/share/elasticsearch/config \\ -v esplugins:/usr/share/elasticsearch/plugins \\ -e xpack.security.enabled=true \\ -e xpack.security.transport.ssl.enabled: true \\ -e ELASTIC_PASSWORD=buubiu elasticsearch:7.9.3 安装kibana 启动一个基本的kibana服务 1docker run -d -p 5601:5601 --name kibana kibana:7.9.3 启动kibana，并通过设置环境变量连接ES -e ELASTICSEARCH_HOSTS 1docker run -d -p 5601:5601 -e ELASTICSEARCH_HOSTS=http://127.0.0.1:9200 --name kibana kibana:7.9.3 启动kibana，并通过配置文件连接ES 注意：kibana的配置文件在容器中/usr/share/kibana/config 1docker run -d -p 5601:5601 -v kibanaconif:/usr/share/kibana/config --name kibana kibana:7.9.3 修改宿主机中kibana的配置文件kibana.yml 若es加了用户名密码访问，则还需要追加后两行： 123456elasticsearcch.hosts:[&quot;http://127.0.0.1:9200&quot;]elasticsearch.username: &quot;kibana&quot;elasticsearch.password: &quot;Aa000000&quot;xpack.security.enabled: true#32位以上的随机数即可，用作信息的加密xpack.security.encryptionKey: &quot;4297f44b13955235245b2497399d7a93&quot; 重启容器即可 登录kibana的时候，输入的用户名和密码是:elastic/Aa000000 安装mariadb与mysql类似 1234567$ docker load -i mariadb-10.2.12.tar$ mkdir -p /home/mariadb/data /home/mariadb/binlog$ docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root --name mariadb --mount type=bind,source=/home/mariadb/binlog,target=/var/log/mysql/mariadb-bin --restart=always -v /home/mariadb/data:/var/lib/mysql mariadb:10.2.12# 创建并开启binlog$ docker exec mariadb bash -c &quot;echo 'log_bin=/var/log/mysql/mariadb-bin' &gt;&gt; /etc/mysql/mariadb.cnf&quot;$ docker exec mariadb bash -c &quot;echo 'server-id=123456' &gt;&gt; /etc/mysql/mariadb.cnf&quot; 安装nacos1$ docker run -d -p 8848:8848 -e MODE=standalone --name nacos nacos/nacos-server:1.4.1 安装apollo初始化sql 12$ docker exec -i mariadb sh -c 'exec mysql -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &lt; /opt/software/docker-images/apollo/apollo_sql/apolloconfigdb.sql$ docker exec -i mariadb sh -c 'exec mysql -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &lt; /opt/software/docker-images/apollo/apollo_sql/apolloportaldb.sql 通过sql脚本修改默认config地址： 12UPDATE ApolloConfigDB.ServerConfig t SET t.Value = 'http://192.168.91.100:8080/eureka/' WHERE t.Id = 1;UPDATE ApolloPortalDB.ServerConfig t SET t.Value = '[{&quot;orgId&quot;:&quot;TEST1&quot;,&quot;orgName&quot;:&quot;样例部门1&quot;},{&quot;orgId&quot;:&quot;TEST2&quot;,&quot;orgName&quot;:&quot;样例部门2&quot;},{&quot;orgId&quot;:&quot;BOMS&quot;,&quot;orgName&quot;:&quot;BOMS&quot;}]' WHERE t.Id = 2; 导入apollo镜像，并启动： 123456789101112131415161718192021$ docker run -d -p 8080:8080 \\ -e SPRING_DATASOURCE_URL=&quot;jdbc:mysql://192.168.91.100:3306/ApolloConfigDB?characterEncoding=utf8&quot; \\ -e SPRING_DATASOURCE_USERNAME=root \\ -e SPRING_DATASOURCE_PASSWORD=root \\ -e EUREKA_INSTANCE_IP_ADDRESS=192.168.91.100 \\ --name apollo-configservice apolloconfig/apollo-configservice:1.7.1 $ docker run -d -p 8090:8090 \\ -e SPRING_DATASOURCE_URL=&quot;jdbc:mysql://192.168.91.100:3306/ApolloConfigDB?characterEncoding=utf8&quot; \\ -e SPRING_DATASOURCE_USERNAME=root \\ -e SPRING_DATASOURCE_PASSWORD=root \\ -e EUREKA_INSTANCE_IP_ADDRESS=192.168.91.100 \\ --name apollo-adminservice apolloconfig/apollo-adminservice:1.7.1 $ docker run -d -p 8070:8070 \\ -e SPRING_DATASOURCE_URL=&quot;jdbc:mysql://192.168.91.100:3306/ApolloPortalDB?characterEncoding=utf8&quot; \\ -e SPRING_DATASOURCE_USERNAME=root \\ -e SPRING_DATASOURCE_PASSWORD=root \\ -e APOLLO_PORTAL_ENVS=dev \\ -e DEV_META=http://192.168.91.100:8080 \\ --name apollo-portal apolloconfig/apollo-portal:1.7.1 安装Zookeeper创建挂载目录： 1$ mkdir -p /home/zookeeper 先不挂载目录启动容器，然后把相应的目录拷贝出来 1234$ docker run -d -p 2181:2181 \\--name zookeeper zookeeper:3.7.0$ docker cp zookeeper:/conf /home/zookeeper$ docker cp zookeeper:/data /home/zookeeper 修改配置文件： 路径：/home/zookeeper/conf/zoo.cfg 若是集群需要修改server.1，否则不需要变 1234567891011dataDir=/datadataLogDir=/datalogtickTime=2000initLimit=5syncLimit=2autopurge.snapRetainCount=3autopurge.purgeInterval=0maxClientCnxns=60standaloneEnabled=trueadmin.enableServer=trueserver.1=localhost:2888:3888;2181 删除zookeeper容器，重新以挂载目录启动: 1234$ docker run -d -p 2181:2181 \\ -v /home/zookeeper/conf:/conf \\ -v /home/zookeeper/data:/data \\ --name zookeeper zookeeper:3.7.0 安装Kafka创建挂载目录： 1$ mkdir -p /home/kafka 先不挂载目录启动容器，然后把相应的目录拷贝出来 12345678$ docker run -d -p 9092:9092 \\ -e KAFKA_BROKER_ID=0 \\ -e KAFKA_ZOOKEEPER_CONNECT=192.168.91.100:2181/kafka \\ -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.91.100:9092 \\ -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\ -v /etc/localtime:/etc/localtime \\ --name kafka wurstmeister/kafka:2.13-2.7.0$ docker cp kafka:/opt/kafka/config /home/kafka 删除kafka容器，重新以挂载目录启动: 12345678$ docker run -d -p 9092:9092 \\ -e KAFKA_BROKER_ID=0 \\ -e KAFKA_ZOOKEEPER_CONNECT=192.168.91.100:2181/kafka \\ -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.91.100:9092 \\ -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\ -v /home/kafka/config:/opt/kafka/config \\ -v /etc/localtime:/etc/localtime \\ --name kafka wurstmeister/kafka:2.13-2.7.0 安装Logstash创建挂载目录： 1$ mkdir -p /home/logstash 先不挂载目录启动容器，然后把相应的目录拷贝出来 12345$ docker run -d -p 5044:5044 -p 9600:9600 \\ --privileged=true \\ --name logstash logstash:7.9.3$ docker cp logstash:/usr/share/logstash/config/ /home/logstash$ docker cp logstash:/usr/share/logstash/pipeline/ /home/logstash 修改配置文件： 路径：/home/logstash/config/logstash.yml 把es地址写上，若是集群就用逗号隔开，格式[“”,””,””] 后面三行直接追加 12345678910http.host: &quot;0.0.0.0&quot;xpack.monitoring.elasticsearch.hosts: [ &quot;http://192.168.91.100:9200&quot; ]path.config: /usr/share/logstash/pipeline/*.confpipeline.batch.size: 500pipeline.batch.delay: 50# 若es有安全校验，加上如下三行，用户名不用变，修改相应的密码即可xpack.monitoring.enabled: true# 若是docker启动的es，用户名写elastic，若是虚拟机启动的，用户名写 logstash_systemxpack.monitoring.elasticsearch.username: elasticxpack.monitoring.elasticsearch.password: Aa000000 新建配置文件 并修改相应的kafka地址 192.168.91.100:9092 es地址 10.10.23.85:9200，若是集群，格式[“”,””,””] 日志名前缀 jnbank-logs 若es有安全校验，在elasticsearch配置的地方加上相应的密码即可 路径：/home/logstash/pipeline/test.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# Sample Logstash configuration for creating a simple# Beats -&gt; Logstash -&gt; Elasticsearch pipeline.input { kafka { codec =&gt; &quot;json&quot; topics =&gt; [&quot;elk-log&quot;] bootstrap_servers =&gt; &quot;192.168.91.100:9092&quot; auto_offset_reset =&gt; &quot;latest&quot; }}#input {# beats {# port =&gt; 5044# codec =&gt; json# codec =&gt; multiline# {# pattern =&gt; &quot;^[0-9]{4}-[0-9]{2}-[0-9]{2}&quot;# negate =&gt; true# what =&gt; &quot;previous&quot;# }# }#}filter { if &quot;test-logs&quot; in [tags] { json { source =&gt; &quot;message&quot; target =&gt; &quot;messages&quot; } date { match =&gt; [&quot;[messages][timestamp]&quot;,&quot;yyyy-MM-dd HH:mm:ss.SSS&quot;] target =&gt; &quot;@log_timestamp&quot; #timezone =&gt; &quot;Asia/Shanghai&quot; } ruby { code =&gt; &quot; path = event.get('log')['file']['path'] #puts format('path = %&lt;path&gt;s', path: path) if (!path.nil?) &amp;&amp; (!path.empty?) event.set('app_index', path.split('/')[-1].split('.')[0]) end mytid = event.get('messages')['tid'] if (!mytid.nil?) &amp;&amp; (!mytid.empty?) event.set('tid',mytid.split(':')[1]) end #event.set('@log_timestamp',event.get('@log_timestamp').time.localtime - 8*60*60) &quot; } mutate{ add_field=&gt;{ 'thread' =&gt; &quot;%{[messages][thread]}&quot; 'level' =&gt; &quot;%{[messages][level]}&quot; 'logger_name' =&gt; &quot;%{[messages][logger_name]}&quot; } remove_field =&gt; [&quot;agent&quot;,&quot;ecs&quot;,&quot;@version&quot;,&quot;host&quot;,&quot;messages&quot;] } }}output { if &quot;test-logs&quot; in [tags] { elasticsearch { hosts =&gt; [&quot;192.168.91.100:9200&quot;] index =&gt; &quot;%{log_source}-%{+YYYY.MM.dd}&quot; user =&gt; &quot;elastic&quot; password =&gt; &quot;Aa000000&quot; } }else{ elasticsearch { hosts =&gt; [&quot;192.168.91.100:9200&quot;] index =&gt; &quot;%{my-index}-log-%{+YYYY.MM.dd}&quot; user =&gt; &quot;elastic&quot; password =&gt; &quot;Aa000000&quot; } }# stdout{# codec =&gt; json# }} 删除logstash容器，重新以挂载目录启动: 12345$ docker run -d -p 5044:5044 -p 9600:9600 \\ --privileged=true \\ -v /home/logstash/config:/usr/share/logstash/config \\ -v /home/logstash/pipeline:/usr/share/logstash/pipeline \\ --name logstash logstash:7.9.3 安装Filebeat创建挂载目录： 1$ mkdir -p /home/filebeat 先不挂载目录启动容器，然后把相应的目录拷贝出来 12$ docker run -d --name filebeat docker.elastic.co/beats/filebeat:7.9.3$ docker cp filebeat:/usr/share/filebeat/filebeat.yml /home/filebeat 修改配置文件： 路径：/home/filebeat/filebeat.yml， 配置好收集路径规则 - /opt/boms-sc-demo/*/logs/*.log 配置好日志前缀 test-logs 配置好kafka地址 192.168.91.100:9092 12345678910111213141516171819202122232425#=========================== Filebeat inputs =============================filebeat.inputs:- type: log enabled: true paths: - /opt/boms-sc-demo/*/logs/*.log fields: log_source: test-logs fields_under_root: true tags: [&quot;test-logs&quot;]# multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}'# multiline.negate: true# multiline.match: after #output.logstash:# enabled: true# index: &quot;test-logstash-%{+yyyy.MM.dd}&quot;# hosts: [&quot;10.10.23.66:5044&quot;]output.kafka: enabled: true hosts: [&quot;192.168.92.100:9092&quot;] topic: elk-log#logging.level: debug 删除filebeat容器，重新以挂载目录启动: 123$ docker run -d --name filebeat \\ -v /home/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml \\ docker.elastic.co/beats/filebeat:7.9.3 安装Skywalking加载skywalking两个镜像 12$ docker load -i skywalking-oap-8.2.0-20210425.tar$ docker load -i skywalking-ui-8.2.0-20210425.tar 创建一个目录，上传文件夹skywalking-config.tar.gz到此目录并解压缩 123$ mkdir -p /home/skywalking$ cd /home/skywalking$ tar -zxvf skywalking-config.tar.gz 创建挂载目录： 1$ mkdir -p /home/skywalking/logs 编辑配置： 路径：/home/skywalking/docker-compose/.env 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# skywalking-oap镜像的tag标签，通过docker images获得TAG=8.2.0-20210425# jvmJAVA_OPTS=&quot;-Xms256M -Xmx512M&quot;# 是否集群，若是单机填写：standalone，若是集群在nacos和consul中选择SW_CLUSTER=nacos#--------如果注册中心是nacos--------# nacos地址，集群用逗号隔开SW_CLUSTER_NACOS_HOST_PORT=192.168.91.100:8848# Nacos Configuration namespaceSW_CLUSTER_NACOS_NAMESPACE=public# Nacos auth usernameSW_CLUSTER_NACOS_USERNAME=nacosSW_CLUSTER_NACOS_PASSWORD=nacos#--------如果注册中心是 consul--------# Consul cluster nodes, example: 10.0.0.1:8500,10.0.0.2:8500,10.0.0.3:8500SW_CLUSTER_CONSUL_HOST_PORT=127.0.0.1:8500# tokenSW_CLUSTER_CONSUL_ACLTOKEN=# restHostSW_CORE_REST_HOST=0.0.0.0#链路数据保存的期限，包括链路追踪和告警。单位：天SW_CORE_RECORD_DATA_TTL=3#指标数据保存的期限，包括包括百分比，热图，成功率，cpm（rpm）等。单位：天SW_CORE_METRICS_DATA_TTL=7# ----elasticsearch7配置------SW_STORAGE=elasticsearch7# 索引前缀配置，谨慎修改，boms工程中broker会用到SW_NAMESPACE=boms# es地址，集群用逗号隔开SW_STORAGE_ES_CLUSTER_NODES=192.168.91.100:9200# 若es配置了用户名和密码，填写下面两个配置SW_ES_USER=elasticSW_ES_PASSWORD=Aa000000# ----配置中心apollo----SW_CONFIGURATION=apollo#apollo meta地址SW_META_APOLLO=http://192.168.91.100:8080#apollo config地址，这个地址和meta地址的值一直，但是作用不同，场景不同。# 一般情况下都建议使用Apollo的Meta Server机制来实现Config Service的服务发现，从而可以实现Config Service的高可用。不过apollo-client也支持跳过Meta Server服务发现，主要用于以下场景：# ## #1. Config Service部署在公有云上，注册到Meta Server的是内网地址，本地开发环境无法直接连接，如果通过公网 SLB 对外暴露 Config Service的话，记得要设置 IP 白名单，避免数据泄露# ## #2. Config Service部署在docker环境中，注册到Meta Server的是docker内网地址，本地开发环境无法直接连接# ## #3. Config Service部署在kubernetes中，希望使用kubernetes自带的服务发现能力（Service）# ## #针对以上场景，可以通过直接指定Config Service地址的方式来跳过Meta Server服务发现# ## #要想让skywalking跳过Meta Server，只需要让参数apolloMeta为空，apolloConfig为Apollo的Config Service地址即可。SW_CONFIG_APOLLO=# apollo 集群名称，默认即可SW_CONFIG_APOLLO_CLUSTER=default# apollo 环境名称，默认DEVSW_CONFIG_APOLLO_ENV=DEV# skywalking在Apollo中的项目名称，默认skywalking即可SW_CONFIG_APOLLO_APP_ID=skywalking# skywalking OAP服务的rest地址和端口(上面配置文件设置)，若是集群，地址用逗号隔开SW_OAP_ADDRESS=192.168.91.100:12800 运行docker compose 进入目录/home/skywalking/docker-compose 12$ cd /home/skywalking/docker-compose$ docker-compose -f docker-compose-boms.yml up -d 查看日志： 1docker-compose -f docker-compose-boms.yml logs -f 查看页面是否正常： http://192.168.91.100:18080 安装seata 加载镜像： 123$ docker load -i seataio/seata-server-1.4.2.tar# 或者$ docker pull seataio/seata-server:1.4.2 创建挂载目录，并且从官方下载registry.conf 和 file.conf拷贝到此目录中 1$ mkdir -p /home/seata/config 在 registry.conf 文件中将 config 配置改为以下内容，name 的值为容器中对应的路径 1234567config { type = &quot;file&quot; file { name = &quot;file:/root/seata-config/file.conf&quot; }} 启动容器： 1234567$ docker run -d --name seata-server \\ -p 8091:8091 \\ -e SEATA_IP=10.10.103.56 \\ -e SEATA_PORT=8091 \\ -e SEATA_CONFIG_NAME=file:/root/seata-config/registry \\ -v /home/seata/config:/root/seata-config \\ seataio/seata-server:1.4.2 查看启动日志 1$ docker logs -f seata-server 安装青龙面板项目地址：GitHub docker-compose.yml123456789101112131415161718version: '2'services: web: image: whyour/qinglong:latest volumes: - ./data/config:/ql/config - ./data/log:/ql/log - ./data/db:/ql/db - ./data/scripts:/ql/scripts - ./data/repo:/ql/repo - ./data/raw:/ql/raw - ./data/jbot:/ql/jbot ports: - 5700:5700 environment: - ENABLE_HANGUP=true - ENABLE_WEB_PANEL=true restart: always 安装consul 创建挂载目录： 1$ mkdir -p /home/consul 新增配置文件： 路径：/home/consul/config/acl.json acl.json123456{ &quot;acl_datacenter&quot;: &quot;buubiudatacentor&quot;, &quot;acl_master_token&quot;: &quot;p2BE1AtpwPbrxZdC6k+eXA==&quot;, &quot;acl_default_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;extend-cache&quot;} 字段说明： acl_datacenter:该配置项指定了对ACL信息具有权威性的数据中心。 必须提供它才能启用ACL。 所有Server实例和数据中心必须就ACL数据中心达成一致。必须在整个集群的Server节点上设置该配置项。在Consul 0.8及更高版本中，还可以启用代理级别的ACL。 有关详细信息，请参阅ACL指南。 acl_master_token:该配置项只能用在acl_datacenter中的Server节点上。 如果该令牌不存在，则将使用管理级权限创建该令牌。 它允许操作员使用众所周知的令牌ID来引导ACL系统。 acl_default_policy:该配置项可选的值为allow和deny。默认值为’allow’。默认的策略控制token在没有匹配的规则时的行为。 在allow模式下，ACL规则是一个黑名单：任何没有被禁止的操作都是可以执行的。 在deny模式下，ACL规则是一个白名单，任何没有明确指定的操作都是被禁止的。 注意：该配置项只有在配置了acl_datacenter后才起作用 acl_down_policy:该配置项可选的值为allow，deny或extend-cache， 默认值是extend-cache。假如不能从acl_datacenter或Leader节点获取一个token的acl信息，则该配置项指定的策略被使用。 allow模式下，所有的操作都允许。 deny模式下，所有的操作都被禁止。 extend-cache模式下,使用缓存的 ACL规则并忽略这些规则的过期时间。如果一个不可缓存的ＡＣＬ的规则被使用，则当作deny策略来处理。 路径：/home/consul/config/server.json server.json123456789101112{ &quot;datacenter&quot;: &quot;buubiudatacentor&quot;, &quot;retry_join&quot;: [&quot;0.0.0.0&quot;], &quot;retry_interval&quot;: &quot;15s&quot;, &quot;rejoin_after_leave&quot;: true, &quot;start_join&quot;: [&quot;0.0.0.0&quot;], &quot;bootstrap_expect&quot;: 1, &quot;server&quot;: true, &quot;ui&quot;: true, &quot;dns_config&quot;: {&quot;allow_stale&quot;: true, &quot;max_stale&quot;: &quot;5s&quot;}, &quot;node_name&quot;: &quot;consul&quot;} 先不挂载目录启动容器，然后把相应的目录拷贝出来 123456# agent consul核心，运行一个agent# -server：定义agent运行在server模式，每个集群至少有一个server，建议每个集群的server不要超过5个# -bootstrap-expect：在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导整个集群，该标记不能和bootstrap同时使用# -ui：开启自带的ui web-server，可以通过HTTP API端口外部访问$ docker run -d --name consul consul:1.4.2 agent -server -bootstrap-expect=1 -ui$ docker cp consul:/consul/data /home/consul/data 删除consul容器，重新以挂载目录启动: 123456789$ docker run -d \\ -p 8500:8500 \\ -p 8600:8600/udp \\ -v /home/consul/data:/consul/data \\ -v /home/consul/config:/consul/config \\ --name consul consul:1.4.2 \\ agent -server -bootstrap-expect=1 -ui \\ -bind=0.0.0.0 \\ -client=0.0.0.0","link":"/Docker%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E6%9C%8D%E5%8A%A1/"},{"title":"Docker开启远程安全访问","text":"介绍docker可以开启远程访问API，供外部调用，这里介绍一下如何开启的。 MAC环境处于安全原因，Docker Mac 客户端并没有开启 2375 端口的配置，所以我们可以用 socat 来 fork 一个端口出来： 1234$ docker run -d \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -p 127.0.0.1:2376:2376 bobrik/socat \\ TCP-LISTEN:1234,fork UNIX-CONNECT:/var/run/docker.sock Linux环境不安全开启编辑docker文件：/usr/lib/systemd/system/docker.service 1$ vim /usr/lib/systemd/system/docker.service 修改ExecStart行为下面内容 1ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix://var/run/docker.sock \\ 重新加载daemon并重启docker 12$ systemctl daemon-reload $ systemctl restart docker 安全开启（推荐）思路：服务端生成证书以及配置白名单等，用来达到验证客户端身份的目的。 服务端配置生成私钥公钥 创建certs文件夹，用来存放CA私钥和公钥 12$ mkdir -pv /opt/docker/certs$ cd /opt/docker/certs/ 创建密码 需要连续输入两次相同的密码 1$ openssl genrsa -aes256 -out ca-key.pem 4096 依次输入密码、国家、省、市、组织名称等（除了密码外其他的可以直接回车跳过） 1$ openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem 生成server-key.pem 1$ openssl genrsa -out server-key.pem 4096 生成server.csr（把下面的IP换成你自己服务器外网的IP或者域名） 1$ openssl req -subj &quot;/CN=www.example.com&quot; -sha256 -new -key server-key.pem -out server.csr 配置白名单 0.0.0.0表示所有ip都可以连接。（这里需要注意，虽然0.0.0.0可以匹配任意，但是仍需要配置你的外网ip和127.0.0.1，否则客户端会连接不上） 1$ echo subjectAltName = IP:123.123.123.123,IP:0.0.0.0,IP:127.0.0.1 &gt;&gt; extfile.cnf 或者也可以设置成域名 1$ echo subjectAltName = DNS:docker.buubiu.com,IP:0.0.0.0,IP:127.0.0.1 &gt;&gt; extfile.cnf 将Docker守护程序密钥的扩展使用属性设置为仅用于服务器身份验证 1$ echo extendedKeyUsage = serverAuth &gt;&gt; extfile.cnf 生成server-cert.pem，输入之前设置的密码，生成签名证书 12$ openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \\ -CAcreateserial -out server-cert.pem -extfile extfile.cnf 生成供客户端发起远程访问时使用的key.pem 1$ openssl genrsa -out key.pem 4096 生成client.csr（把下面的IP换成你自己服务器外网的IP或者域名） 1$ openssl req -subj &quot;/CN=docker.example.com&quot; -new -key key.pem -out client.csr 创建扩展配置文件，把密钥设置为客户端身份验证用 1$ echo extendedKeyUsage = clientAuth &gt; extfile-client.cnf 生成cert.pem，输入前面设置的密码，生成签名证书 12$ openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \\ -CAcreateserial -out cert.pem -extfile extfile-client.cnf 删除不需要的配置文件和两个证书的签名请求（可选） 1$ rm -v client.csr server.csr extfile.cnf extfile-client.cnf 为了防止私钥文件被更改以及被其他用户查看，修改其权限为所有者只读（可选） 1$ chmod -v 0400 ca-key.pem key.pem server-key.pem 为了防止公钥文件被更改，修改其权限为只读 1$ chmod -v 0444 ca.pem server-cert.pem cert.pem Docker配置 修改Docker配置，使Docker守护程序仅接受来自提供CA信任的证书的客户端的连接 注意：docker升级会覆盖这个配置，升级后记得重复修改一下 1$ vi /lib/systemd/system/docker.service 在ExecStart=/usr/bin/dockerd-current修改成下面： 123456789# for containers run by dockerExecStart=/usr/bin/dockerd \\--tlsverify \\--tlscacert=/opt/docker/certs/ca.pem \\--tlscert=/opt/docker/certs/server-cert.pem \\--tlskey=/opt/docker/certs/server-key.pem \\-H tcp://0.0.0.0:2376 \\-H unix:///var/run/docker.sock \\-H fd:// --containerd=/run/containerd/containerd.sock 重新加载daemon并重启docker 12$ systemctl daemon-reload$ systemctl restart docker 使用 netstat -lnpt 查看2376端口是否被监听，记得开放云服务器端口防火墙 客户端配置保存相关客户端的pem文件到本地，文件为ca.pem、cert.pem、key.pem，idea工具连接直接选择客户端证书文件夹就行， portainer等安装要求选择特定的文件即可。 IDEA配置如图： portainer配置如图：","link":"/Docker%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E5%AE%89%E5%85%A8%E8%AE%BF%E9%97%AE/"},{"title":"Docker的基本概念","text":"官方文档地址:https://www.docker.com/get-started 中文参考手册:https://yeasy.gitbook.io/docker_practice 什么是Docker官方定义 We have a complete container solution for you - no matter who you are and where you are on your containerization journey. 我们为您提供完整的容器解决方案-不管你是谁,不管你在哪,你都可以开始容器的的旅程。 Docker的起源 Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目 已经超过 5 万 7 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 为什么要用Docker 在开发的时候，在本机测试环境可以跑，生产环境跑不起来 这里我们拿java Web应用程序举例，我们一个java Web应用程序涉及很多东西，比如jdk、tomcat、mysql等软件环境。当这些其中某一项版本不一致的时候，可能就会导致应用程序跑不起来这种情况。Docker则将程序以及使用软件环境直接打包在一起，无论在那个机器上保证了环境一致。 优势1: 一致的运行环境,更轻松的迁移 服务器自己的程序挂了，结果发现是别人程序出了问题把内存吃完了，自己程序因为内存不够就挂了 这种也是一种比较常见的情况，如果你的程序重要性不是特别高的话，公司基本上不可能让你的程序独享一台服务器的，这时候你的服务器就会跟公司其他人的程序共享一台服务器，所以不可避免地就会受到其他程序的干扰，导致自己的程序出现问题。Docker就很好解决了环境隔离的问题，别人程序不会影响到自己的程序。 优势2：对进程进行封装隔离,容器与容器之间互不影响,更高效的利用系统资源 公司要弄一个活动，可能会有大量的流量进来，公司需要再多部署几十台服务器 在没有Docker的情况下，要在几天内部署几十台服务器，这对运维来说是一件非常折磨人的事，而且每台服务器的环境还不一定一样，就会出现各种问题，最后部署地头皮发麻。用Docker的话，我只需要将程序打包到镜像，你要多少台服务，我就给力跑多少容器，极大地提高了部署效率。 优势3: 通过镜像复制N多个环境一致容器 Docker和虚拟机区别 比较上面两张图，我们发现虚拟机是携带操作系统，本身很小的应用程序却因为携带了操作系统而变得非常大，很笨重。Docker是不携带操作系统的，所以Docker的应用就非常的轻巧。另外在调用宿主机的CPU、磁盘等等这些资源的时候，拿内存举例，虚拟机是利用Hypervisor去虚拟化内存，整个调用过程是虚拟内存-&gt;虚拟物理内存-&gt;真正物理内存，但是Docker是利用Docker Engine去调用宿主的的资源，这时候过程是虚拟内存-&gt;真正物理内存。 传统虚拟机 Docker容器 磁盘占用 几个GB到几十个GB左右 几十MB到几百MB左右 CPU内存占用 虚拟操作系统非常占用CPU和内存 Docker引擎占用极低 启动速度 （从开机到运行项目）几分钟 （从开启容器到运行项目）几秒 安装管理 需要专门的运维技术 安装、管理方便 应用部署 每次部署都费时费力 从第二次部署开始轻松简捷 耦合性 多个应用服务安装到一起，容易互相影响 每个应用服务一个容器，达成隔离 系统依赖 无 需求相同或相似的内核，目前推荐是Linux Docker的安装注意：docker引擎支持主流操作系统 Windows macOS Linux unix Docker在Windows系统安装下载：https://desktop.docker.com/win/stable/Docker%20Desktop%20Installer.exe 安装：直接点击.exe进行安装 windows10安装时要开启Hyper-V（若版本为 v1903 及以上则无需开启 Hyper-V） 方法：控制面板-&gt;程序-&gt;卸载程序-&gt;启用和关闭window功能-&gt;Hyper-V 勾选-&gt;完成后重启 Docker在Linux系统安装通用方式安装 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，Raspberry Pi OS 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装： 若你想安装测试版的 Docker, 请从 test.docker.com 获取脚本 1234# $ curl -fsSL https://test.docker.com -o get-docker.sh$ curl -fsSL https://get.docker.com -o get-docker.sh$ sudo sh get-docker.sh --mirror Aliyun# $ sudo sh get-docker.sh --mirror AzureChinaCloud 执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 的稳定(stable)版本安装在系统中。 启动docker 12$ sudo systemctl enable docker$ sudo systemctl start docker 创建docker用户组 默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。 1$ sudo groupadd docker 将当前用户加入 docker 组： 1$ sudo usermod -aG docker $USER 测试docker安装是否正确 1$ docker run hello-world 根据系统类型安装CentOS系统要求 Docker 支持 64 位版本 CentOS 7/8，并且要求内核版本不低于 3.10。 CentOS 7 满足最低内核的要求，但由于内核版本比较低，部分功能（如 overlay2 存储层驱动）无法使用，并且部分功能可能不太稳定。 卸载原始docker 12345678$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装docker依赖 1$ sudo yum install -y yum-utils 设置docker的yum源 123$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 安装最新版的docker 1$ sudo yum install -y docker-ce docker-ce-cli containerd.io 指定版本安装docker 123$ yum list docker-ce --showduplicates | sort -r$ sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io$ sudo yum install docker-ce-18.09.5-3.el7 docker-ce-cli-18.09.5-3.el7 containerd.io 启动docker 12$ sudo systemctl enable docker$ sudo systemctl start docker 关闭docker 1$ sudo systemctl stop docker 测试docker安装 1$ sudo docker run hello-world CentOS8 额外设置由于 CentOS8 防火墙使用了 nftables，但 Docker 尚未支持 nftables， 我们可以使用如下设置使用 iptables： 更改 /etc/firewalld/firewalld.conf 12# FirewallBackend=nftablesFirewallBackend=iptables 或者执行如下命令： 12$ firewall-cmd --permanent --zone=trusted --add-interface=docker0$ firewall-cmd --reload 创建非root用户（可选） 创建用户组： 1$ sudo groupadd docker 创建docker用户[可选：创建密码]： 123#-g参数来制定 所属用户组$ sudo useradd -g docker docker$ sudo passwd docker 将用户加入 docker 组： 1$ sudo usermod -aG docker docker Docker配置阿里镜像加速服务docker运行流程 docker配置阿里云镜像加速 访问阿里云登录自己账号查看docker镜像加速服务 (点击管理控制台 -&gt; 登录账号(淘宝账号) -&gt; 右侧镜像中心 -&gt; 镜像加速器 -&gt; 复制地址) 在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件）： 12345{ &quot;registry-mirrors&quot;: [ &quot;https://lz2nib3q.mirror.aliyuncs.com&quot; ]} 注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。 之后重新启动服务。 12$ sudo systemctl daemon-reload$ sudo systemctl restart docker 验证docker的镜像加速是否生效 1234567[root@localhost ~]# docker info .......... 127.0.0.0/8 Registry Mirrors: 'https://lz2nib3q.mirror.aliyuncs.com/' Live Restore Enabled: false Product License: Community Engine Docker的核心架构 镜像: 一个镜像代表一个应用环境,他是一个只读的文件,如 mysql镜像,tomcat镜像,nginx镜像等 容器: 镜像每次运行之后就是产生一个容器,就是正在运行的镜像,特点就是可读可写 仓库:用来存放镜像的位置,类似于maven仓库,也是镜像下载和上传的位置 dockerFile:docker生成镜像配置文件,用来书写自定义镜像的一些配置 tar:一个对镜像打包的文件,日后可以还原成镜像 Docker的入门应用docker的第一个程序docker run hello-world 12345678910111213141516171819202122[root@localhost ~]# docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ Docker的卸载centos 卸载 Docker Engine、CLI 和 Containerd 包： 1$ sudo yum remove -y docker-ce docker-ce-cli containerd.io 主机上的映像、容器、卷或自定义配置文件不会自动删除。删除所有镜像、容器和卷： 12$ sudo rm -rf /var/lib/docker$ sudo rm -rf /var/lib/containerd","link":"/Docker%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"},{"title":"Docker的常用命令","text":"基本命令123456docker version #查看docker的版本信息docker info #查看更详细的信息docker --help || docker #帮助命令#docker执行命令格式docker [options] command(具体命令) Images镜像命令查看本机中所有镜像123docker images [镜像名] #列出本地所有镜像 -a #列出所有镜像（包含中间映像层） -q #只显示镜像id 搜索镜像123docker search [options] 镜像名 #去dockerhub上查询当前镜像 -s 指定值 #列出收藏数不少于指定值的镜像 --no-trunc #显示完整的镜像信息 从仓库下载镜像1234567#1.根据版本号下载docker pull 镜像名[:TAG] #推荐使用#例如：docker pull mysql:5.6.0#2.根据摘要下载docker pull 镜像名 [@DIGEST]#例如：docker pull mysql@sha256:870892ea5cc8c623b389717c2eedd58248c82a8569d7601ede62a63d527641bd 删除镜像1234567#删除指定镜像docker image rm 镜像名[:TAG]｜镜像IDdocker rmi 镜像名[:TAG]｜镜像ID #简写 -f #强制删除#删除所有镜像docker rmi -f $(docker images -q) Contrainer容器命令运行容器 12345678910docker run 镜像名:tag ｜ 镜像ID ##镜像名新建并启动容器 --name #别名 为容器起一个名字 -d #启动守护容器（在后台启动容器） -p #指定端口号启动（映射的外部端口号:容器内部端口号）可书写多个 -P #大写P，随机一个端口号映射到容器内部du a -i #以交互模式运行容器，通常与-t一起使用 -t #分配一个伪终端shell窗口#例如：#docker run -it --name myTomcat -p 8888:8080 tomcat#docker run -d --name myTomcat -P tomcat 查看运行的容器123docker ps #列出所有正在运行的容器 -a #查看所有容器（运行和非运行） -q #静默模式，只显示运行容器的ID 容器ID 基于某镜像 内部启动命令 创建时间 当前状态 内部监听的端口(0.0.0.0:表示任意机器都可以访问) 容器名称 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9b816120e028 tomcat “catalina.sh run” 6 seconds ago Up 6 seconds 0.0.0.0:8080-&gt;8080/tcp frosty_tharp 停止｜关闭｜重启容器1234docker start 容器名字或者容器id # 开启容器docker restart 容器名或者容器id # 重启容器docker stop 容器名或者容器id # 正常停止容器运行docker kill 容器名或者容器id # 立即停止容器运行 删除容器123docker rm 容器名称｜容器ID #删除停止的容器docker rm -f 容器名称｜容器ID #删除正在运行的容器docker rm -f $(docker ps -aq) #删除所有的容器 查看容器内服务运行日志1234docker logs [OPITONS] 容器名称｜容器ID #查看容器日志 -f #查看实时日志 -t #加入时间戳 --tail N #显示最后N行日志 查看容器内进程1docker top 容器名称｜容器ID 进入容器内部1234docker exec [OPTIONS] 容器名称｜容器ID 容器内部命令(bash) -i #以交互模式运行容器，通常与-t一起使用 -t #分配一个伪终端shell窗口exit #退出容器 容器和宿主机之间传输文件1234567# 从容器复制文件到宿主机docker cp 容器名称｜容器ID:容器内资源文件｜目录 宿主机文件｜目录#例如： docker cp 3334ad:/usr/local/tomcat/text.txt ./text.txt# 从宿主机复制文件到容器docker cp 宿主机资源文件｜目录 容器名称｜容器ID:容器内文件｜目录#例如 docker cp text2.txt 3334ad:/usr/local/tomcat 查看容器内部细节1docker inspect 容器名称｜容器ID 数据卷(volum)作用实现宿主机系统与容器之间的文件共享 使用自定义数据卷目录注意：宿主机目录会覆盖容器内目录内容 123docker run -v 宿主机绝对目录:容器内绝对目录 容器名称｜容器IDdocker run -v 宿主机绝对目录:容器内绝对目录:ro 容器名称｜容器ID #ro代表容器内目录只读# 例如：docker run -d -p 8080:8080 --name myTomcat -v /root/apps:/usr/local/tomcat/webapps tomcat 自动数据卷目录注意：这种方式会在docker运行容器时自动在宿主机中创建一个目录,并将容器目录文件复制到宿主机中 123docker run -v 卷名(任意别名):容器内绝对路径 容器名称｜容器IDdocker run -v 卷名(任意别名):容器内绝对路径:ro 容器名称｜容器ID #ro代表容器内目录只读#例如：docker run -d -p 8080:8080 --name myTomcat -v aa:/usr/local/tomcat/webapps tomcat 容器内部执行的流程 aa代表一个数据卷名称，名称可以随便写，docker在发现aa目录不存在时，会自动创建这个数据卷，并自动映射宿主机某个目录 同时在启动容器时会将aa对应容器目录中全部内容复制到aa映射到目录中 这个aa目录在宿主机：/var/lib/docker/volumes/aa/_data 容器打包成新的镜像12docker commit -m &quot;描述信息&quot; -a &quot;作者信息&quot; 容器名称｜容器ID 打包后的镜像名称(必须全部小写字母):标签#例如：docker commit -m &quot;deploy&quot; -a &quot;buubiu&quot; myTomcat my-tomcat:1.0 打包镜像（备份镜像）12docker save 镜像名:TAG -o 文件名称.tar#例如：docker save my-tomcat:1.0 -o my-tomcat-1.0.tar 载入镜像（导入tar包镜像文件）12docker load -i 导入镜像的tar文件名# -i image缩写","link":"/Docker%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"title":"Docker的镜像原理","text":"镜像是什么？镜像是一种轻量级的，可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时所需的库、环境变量和配置文件。 一个镜像会那么大？ 镜像就是花卷 UnionFS（联合文件系统）: Union文件系统是一种分层，轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。Union文件系统是Docker镜像的基础。这种文件系统特性:就是一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 。 Docker镜像原理docker的镜像实际是由一层一层的文件系统组成。 bootfs（boot file system）主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统。在docker镜像的最底层就是bootfs。这一层与Linux/Unix 系统是一样的，包含boot加载器（bootloader）和内核（kernel）。当boot加载完,后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时会卸载bootfs。 rootfs（root file system），在bootfs之上，包含的就是典型的linux系统中的/dev，/proc，/bin，/etc等标准的目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu/CentOS等等。 我们平时安装进虚拟机的centos都有1到几个GB，为什么docker这里才200MB？对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令，工具，和程序库就可以了，因为底层直接使用Host的Kernal，自己只需要提供rootfs就行了。由此可见不同的linux发行版，他们的bootfs是一致的，rootfs会有差别。因此不同的发行版可以共用bootfs。 为什么docker镜像要采用这种分层结构呢?最大的一个好处就是资源共享 比如：有多个镜像都是从相同的base镜像构建而来的，那么宿主机只需在磁盘中保存一份base镜像。同时内存中也只需要加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。Docker镜像都是只读的。当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称为容器层，容器层之下都叫镜像层。","link":"/Docker%E7%9A%84%E9%95%9C%E5%83%8F%E5%8E%9F%E7%90%86/"},{"title":"Docker配置私有仓库registry","text":"介绍有时候使用 Docker Hub 这样的公共仓库可能不方便，用户可以创建一个本地仓库供私人使用。 docker-registry 是官方提供的工具，可以用于构建私有的镜像仓库。本文内容基于 docker-registry v2.x 版本。 安装docker-registry这里使用官方的 registry 镜像来启动私有仓库。 12345# 先创建两个目录# data存放镜像# config存放配置$ mkdir -p volumes/data volumes/config$ vim volumes/config/config.yml config.yml123456789101112131415161718version: 0.1log: fields: service: registrystorage: cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registryhttp: addr: :5000 headers: X-Content-Type-Options: [nosniff]health: storagedriver: enabled: true interval: 10s threshold: 3 使用docker-compose启动容器 docker-compose.yml12345678910111213141516version: &quot;3.0&quot;services: registry: container_name: registry image: registry:latest ports: - &quot;5000:5000&quot; volumes: - ./volumes/config/registry:/etc/docker/registry - ./volumes/data/registry:/var/lib/registry networks: - registrynetworks: registry: driver: bridge 上传下载镜像创建好私有仓库之后，就可以使用 docker tag 来标记一个镜像，然后推送它到仓库。例如私有仓库地址为 127.0.0.1:5000。 上传 先在本机查看已有的镜像： 123$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest f652ca386ed1 12 days ago 141MB 使用 docker tag 将 nginx:latest 这个镜像标记为 127.0.0.1:5000/nginx:latest。 格式：docker tag IMAGE[:TAG] [REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG] 123$ docker tag nginx:latest 127.0.0.1:5000/nginx:latestREPOSITORY TAG IMAGE ID CREATED SIZE127.0.0.1:5000/nginx latest f652ca386ed1 12 days ago 141MB 使用docker push上传标记的镜像 123456789$ docker push 127.0.0.1:5000/nginx:latestThe push refers to repository [127.0.0.1:5000/nginx]2bed47a66c07: Pushed82caad489ad7: Pushedd3e1dca44e82: Pushedc9fcd9c6ced8: Pushed0664b7821b60: Pushed9321ff862abb: Pushedlatest: digest: sha256:4424e31f2c366108433ecca7890ad527b243361577180dfd9a5bb36e828abf47 size: 1570 查看用浏览器或者curl查看仓库中的镜像 12$ curl http://127.0.0.1:5000/v2/_catalog{&quot;repositories&quot;:[&quot;nginx&quot;]} 表明镜像已经被成功上传了. 下载先删除已有镜像，再尝试从私有仓库中下载这个镜像。 123456789101112131415$ docker rmi 127.0.0.1:5000/nginx:latestUntagged: 127.0.0.1:5000/nginx:latestUntagged: 127.0.0.1:5000/nginx@sha256:4424e31f2c366108433ecca7890ad527b243361577180dfd9a5bb36e828abf47$ docker pull 127.0.0.1:5000/nginx:latestlatest: Pulling from nginxe5ae68f74026: Pull complete21e0df283cd6: Pull completeed835de16acd: Pull complete881ff011f1c9: Pull complete77700c52c969: Pull complete44be98c0fab6: Pull completeDigest: sha256:4424e31f2c366108433ecca7890ad527b243361577180dfd9a5bb36e828abf47Status: Downloaded newer image for 127.0.0.1:5000/nginx:latest127.0.0.1:5000/nginx:latest 配置非 https 仓库地址如果你不想使用 127.0.0.1:5000 作为仓库地址，比如想让本网段的其他主机也能把镜像推送到私有仓库。你就得把例如 192.168.199.100:5000 这样的内网地址作为私有仓库地址，这时你会发现无法成功推送镜像。 这是因为 Docker 默认不允许非 HTTPS 方式推送镜像。我们可以通过 Docker 的配置选项来取消这个限制，或者查看配置能够通过 HTTPS 访问的私有仓库。 linux系统设置请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件）,然后重启docker 123456789{ &quot;registry-mirror&quot;: [ &quot;https://hub-mirror.c.163.com&quot;, &quot;https://mirror.baidubce.com&quot; ], &quot;insecure-registries&quot;: [ &quot;192.168.199.100:5000&quot; ]} 注意：该文件必须符合 json 规范，否则 Docker 将不能启动。 macOS、Windows对于 Docker Desktop for Windows 、 Docker Desktop for Mac 在设置中的 Docker Engine 中进行编辑 ，增加和上边一样的字符串即可。 配置https仓库地址原生配置新建目录，volumes/config/registry/ssl 配置https需要证书，两个文件：.key和.crt,放到上面的ssl目录 若你拥有一个域名，国内各大云服务商都提供免费的站点证书，直接下载下来即可 若没有域名，也你可以使用openssl自行签发证书，放到ssl目录 准备站点证书这里假设我们将要搭建的私有仓库地址为 docker.domain.com，下面我们介绍使用 openssl 自行签发 docker.domain.com 的站点 SSL 证书。 第一步创建 CA 私钥。 123456$ cd volumes/config/registry/ssl$ openssl genrsa -out &quot;root-ca.key&quot; 4096Generating RSA private key, 4096 bit long modulus..................................................................................................................................................++..........................................++e is 65537 (0x10001) 第二步利用私钥创建 CA 根证书请求文件。 1234$ openssl req \\ -new -key &quot;root-ca.key&quot; \\ -out &quot;root-ca.csr&quot; -sha256 \\ -subj '/C=CN/ST=JiangSu/L=SuZhou/O=Your Company Name/CN=Your Company Name Docker Registry CA' 以上命令中 -subj 参数里的 /C 表示国家，如 CN；/ST 表示省；/L 表示城市或者地区；/O 表示组织名；/CN 通用名称。 第三步配置 CA 根证书，新建 root-ca.cnf。 12345$ vim root-ca.cnf[root_ca]basicConstraints = critical,CA:TRUE,pathlen:1keyUsage = critical, nonRepudiation, cRLSign, keyCertSignsubjectKeyIdentifier=hash 第四步签发根证书。 1234$ openssl x509 -req -days 3650 -in &quot;root-ca.csr&quot; \\ -signkey &quot;root-ca.key&quot; -sha256 -out &quot;root-ca.crt&quot; \\ -extfile &quot;root-ca.cnf&quot; -extensions \\ root_ca 第五步生成站点 SSL 私钥。 1$ openssl genrsa -out &quot;docker.domain.com.key&quot; 4096 第六步使用私钥生成证书请求文件。 12$ openssl req -new -key &quot;docker.domain.com.key&quot; -out &quot;site.csr&quot; -sha256 \\ -subj '/C=CN/ST=JiangSu/L=SuZhou/O=Your Company Name/CN=docker.domain.com' 以上命令中 -subj 参数里的 /C 表示国家，如 CN；/ST 表示省；/L 表示城市或者地区；/O 表示组织名；/CN 通用名称。 第七步配置证书，新建 site.cnf 文件。 12345678$ vim site.cnf[server]authorityKeyIdentifier=keyid,issuerbasicConstraints = critical,CA:FALSEextendedKeyUsage=serverAuthkeyUsage = critical, digitalSignature, keyEnciphermentsubjectAltName = DNS:docker.domain.com, IP:127.0.0.1subjectKeyIdentifier=hash 第八步签署站点 SSL 证书。 123$ openssl x509 -req -days 750 -in &quot;site.csr&quot; -sha256 \\ -CA &quot;root-ca.crt&quot; -CAkey &quot;root-ca.key&quot; -CAcreateserial \\ -out &quot;docker.domain.com.crt&quot; -extfile &quot;site.cnf&quot; -extensions server 这样已经拥有了 docker.domain.com 的网站 SSL 私钥 docker.domain.com.key 和 SSL 证书 docker.domain.com.crt 及 CA 根证书 root-ca.crt。 将 docker.domain.com.key docker.domain.com.crt root-ca.crt 这三个保留，删除其他文件。 生成http认证文件123456$ mkdir volumes/config/registry/auth$ docker run --rm \\ --entrypoint htpasswd \\ httpd:alpine \\ -Bbn username password &gt; auth/nginx.htpasswd 将上面的 username password 替换为你自己的用户名和密码。 配置私有仓库编辑配置文件：volumes/config/registry/config.yml 官方配置文件文档：https://docs.docker.com/registry/configuration/ 1234567891011121314151617181920212223242526272829303132333435version: 0.1log: accesslog: disabled: true level: debug formatter: text fields: service: registry environment: stagingstorage: delete: enabled: true cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registryauth: htpasswd: realm: basic-realm path: /etc/docker/registry/auth/nginx.htpasswdhttp: addr: :443 host: https://docker.domain.com headers: X-Content-Type-Options: [nosniff] http2: disabled: false tls: certificate: /etc/docker/registry/ssl/docker.domain.com.crt key: /etc/docker/registry/ssl/docker.domain.com.keyhealth: storagedriver: enabled: true interval: 10s threshold: 3 修改本地hosts编辑 /etc/hosts 12$ vim /etc/hosts127.0.0.1 docker.domain.com 修改docker-compose.yml文件把端口改为443 重启docker-compose12$ docker-compose down$ docker-compose up -d 测试私有仓库功能由于自行签发的 CA 根证书不被系统信任，所以我们需要将 CA 根证书 ssl/root-ca.crt 移入 /etc/docker/certs.d/docker.domain.com 文件夹中。 123$ sudo mkdir -p /etc/docker/certs.d/docker.domain.com$ sudo cp ssl/root-ca.crt /etc/docker/certs.d/docker.domain.com/root-ca.crt 登录到私有仓库。 12345678$ docker login docker.domain.comUsername: usernamePassword:WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded 尝试推送、拉取镜像。 12345678910111213141516171819202122232425$ docker tag nginx:latest docker.domain.com/nginx:latest$ docker push docker.domain.com/nginx:latestThe push refers to repository [docker.domain.com/nginx]2bed47a66c07: Pushed82caad489ad7: Pushedd3e1dca44e82: Pushedc9fcd9c6ced8: Pushed0664b7821b60: Pushed9321ff862abb: Pushedlatest: digest: sha256:4424e31f2c366108433ecca7890ad527b243361577180dfd9a5bb36e828abf47 size: 1570$ docker rmi docker.domain.com/nginx:latest$ docker pull docker.domain.com/nginx:latestlatest: Pulling from nginxe5ae68f74026: Pull complete21e0df283cd6: Pull completeed835de16acd: Pull complete881ff011f1c9: Pull complete77700c52c969: Pull complete44be98c0fab6: Pull completeDigest: sha256:4424e31f2c366108433ecca7890ad527b243361577180dfd9a5bb36e828abf47Status: Downloaded newer image for docker.domain.com/nginx:latestdocker.domain.com/nginx:latest 测试成功，如果我们退出登录，尝试推送镜像。 12345$ docker logout docker.domain.comRemoving login credentials for docker.domain.com$ docker push docker.domain.com/nginx:latestError response from daemon: Head https://docker.domain.com/v2/buubiu/nginx/manifests/latest: no basic auth credentials 发现会提示没有登录，不能将镜像推送到私有仓库中。 使用NGINX 加密代理配置如果你本机占用了 443 端口，你也可以用以下配置 官方示例： Nginx 代理 准备站点证书见 准备站点证书 配置nginx这里用docker启动nginx NGINX 示例配置如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152upstream register{ #端口为上面添加私有镜像仓库时设置的 HTTP 选项的端口号 #例如：server 192.168.199.100:5000 server &quot;YourHostName OR IP&quot;:5000;}map $http_upgrade $connection_upgrade { default upgrade; '' close;}server { #如果没有 DNS 服务器做解析，请删除此选项使用本机 IP 地址访问；或者在本机配置hosts #例如：docker.domain.com server_name YourDomainName; listen 443 ssl; ssl_certificate /etc/nginx/conf.d/ssl/example.crt; # docker.domain.com.crt ssl_certificate_key /etc/nginx/conf.d/ssl/example.key; # docker.domain.com.key ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; large_client_header_buffers 4 32k; client_max_body_size 300m; client_body_buffer_size 512k; proxy_connect_timeout 600; proxy_read_timeout 600; proxy_send_timeout 600; proxy_buffer_size 128k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 512k; location /v2 { proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_pass http://register; proxy_read_timeout 900s; } error_page 500 502 503 504 /50x.html;} 启动命令： 记得把证书放到conf.d目录中，挂载到容器中 12345$ docker run -d \\ -p 5043:443 \\ -name nginx \\ -v ./volumes/config/conf.d:/etc/nginx/conf.d \\ nginx:latest 配置https12345678# 在docker客户端操作# 生成密钥# 例如：openssl s_client -showcerts -connect docker.domain.com:5043 &lt;/dev/null 2&gt;/dev/null|openssl x509 -outform PEM &gt;ca.crt$ openssl s_client -showcerts -connect YourDomainName OR HostIP:443 &lt;/dev/null 2&gt;/dev/null|openssl x509 -outform PEM &gt;ca.crt# 把密钥放到linux环境下面$ cat ca.crt | sudo tee -a /etc/ssl/certs/ca-certificates.crt# 重启docker$ systemctl restart docker 测试私有仓库功能登录到私有仓库。 12345678$ docker login docker.domain.com:5043Username: usernamePassword:WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded 尝试推送、拉取镜像。 12345678910111213141516171819202122232425$ docker tag nginx:latest docker.domain.com/nginx:latest$ docker push docker.domain.com:5043/nginx:latestThe push refers to repository [docker.domain.com:5043/nginx]2bed47a66c07: Pushed82caad489ad7: Pushedd3e1dca44e82: Pushedc9fcd9c6ced8: Pushed0664b7821b60: Pushed9321ff862abb: Pushedlatest: digest: sha256:4424e31f2c366108433ecca7890ad527b243361577180dfd9a5bb36e828abf47 size: 1570$ docker rmi docker.domain.com:5043/nginx:latest$ docker pull docker.domain.com:5043/nginx:latestlatest: Pulling from nginxe5ae68f74026: Pull complete21e0df283cd6: Pull completeed835de16acd: Pull complete881ff011f1c9: Pull complete77700c52c969: Pull complete44be98c0fab6: Pull completeDigest: sha256:4424e31f2c366108433ecca7890ad527b243361577180dfd9a5bb36e828abf47Status: Downloaded newer image for docker.domain.com/nginx:latestdocker.domain.com:5043/nginx:latest 测试成功，如果我们退出登录，尝试推送镜像。 12345$ docker logout docker.domain.com:5043Removing login credentials for docker.domain.com:5043$ docker push docker.domain.com:5043/nginx:latestError response from daemon: Head https://docker.domain.com:5043/v2/nginx/manifests/latest: no basic auth credentials 发现会提示没有登录，不能将镜像推送到私有仓库中。","link":"/Docker%E9%85%8D%E7%BD%AE%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93registry/"},{"title":"ES6 Map 与 Set","text":"Map 对象Map 对象保存键值对。任何值(对象或者原始值) 都可以作为一个键或一个值。 Maps 和 Objects 的区别 一个 Object 的键只能是字符串或者 Symbols，但一个 Map 的键可以是任意值。 Map 中的键值是有序的（FIFO 原则），而添加到对象中的键则不是。 Map 的键值对个数可以从 size 属性获取，而 Object 的键值对个数只能手动计算。 Object 都有自己的原型，原型链上的键名有可能和你自己在对象上的设置的键名产生冲突。 Map 中的 keykey 是字符串 12345678var myMap = new Map();var keyString = &quot;a string&quot;; myMap.set(keyString, &quot;和键'a string'关联的值&quot;); myMap.get(keyString); // &quot;和键'a string'关联的值&quot;myMap.get(&quot;a string&quot;); // &quot;和键'a string'关联的值&quot; // 因为 keyString === 'a string' key 是对象 1234567var myMap = new Map();var keyObj = {}, myMap.set(keyObj, &quot;和键 keyObj 关联的值&quot;); myMap.get(keyObj); // &quot;和键 keyObj 关联的值&quot;myMap.get({}); // undefined, 因为 keyObj !== {} key 是函数 1234567var myMap = new Map();var keyFunc = function () {}, // 函数 myMap.set(keyFunc, &quot;和键 keyFunc 关联的值&quot;); myMap.get(keyFunc); // &quot;和键 keyFunc 关联的值&quot;myMap.get(function() {}) // undefined, 因为 keyFunc !== function () {} key 是 NaN 1234567var myMap = new Map();myMap.set(NaN, &quot;not a number&quot;); myMap.get(NaN); // &quot;not a number&quot; var otherNaN = Number(&quot;foo&quot;);myMap.get(otherNaN); // &quot;not a number&quot; 虽然 NaN 和任何值甚至和自己都不相等(NaN !== NaN 返回true)，NaN作为Map的键来说是没有区别的。 Map 的迭代对 Map 进行遍历，以下两个最高级。 for…of123456789101112131415161718192021222324var myMap = new Map();myMap.set(0, &quot;zero&quot;);myMap.set(1, &quot;one&quot;); // 将会显示两个 log。 一个是 &quot;0 = zero&quot; 另一个是 &quot;1 = one&quot;for (var [key, value] of myMap) { console.log(key + &quot; = &quot; + value);}for (var [key, value] of myMap.entries()) { console.log(key + &quot; = &quot; + value);}/* 这个 entries 方法返回一个新的 Iterator 对象，它按插入顺序包含了 Map 对象中每个元素的 [key, value] 数组。 */ // 将会显示两个log。 一个是 &quot;0&quot; 另一个是 &quot;1&quot;for (var key of myMap.keys()) { console.log(key);}/* 这个 keys 方法返回一个新的 Iterator 对象， 它按插入顺序包含了 Map 对象中每个元素的键。 */ // 将会显示两个log。 一个是 &quot;zero&quot; 另一个是 &quot;one&quot;for (var value of myMap.values()) { console.log(value);}/* 这个 values 方法返回一个新的 Iterator 对象，它按插入顺序包含了 Map 对象中每个元素的值。 */ forEach()12345678var myMap = new Map();myMap.set(0, &quot;zero&quot;);myMap.set(1, &quot;one&quot;); // 将会显示两个 logs。 一个是 &quot;0 = zero&quot; 另一个是 &quot;1 = one&quot;myMap.forEach(function(value, key) { console.log(key + &quot; = &quot; + value);}, myMap) Map 对象的操作Map 与 Array的转换 1234567var kvArray = [[&quot;key1&quot;, &quot;value1&quot;], [&quot;key2&quot;, &quot;value2&quot;]]; // Map 构造函数可以将一个 二维 键值对数组转换成一个 Map 对象var myMap = new Map(kvArray); // 使用 Array.from 函数可以将一个 Map 对象转换成一个二维键值对数组var outArray = Array.from(myMap); Map 的克隆 12345var myMap1 = new Map([[&quot;key1&quot;, &quot;value1&quot;], [&quot;key2&quot;, &quot;value2&quot;]]);var myMap2 = new Map(myMap1); console.log(original === clone); // 打印 false。 Map 对象构造函数生成实例，迭代出新的对象。 Map 的合并 12345var first = new Map([[1, 'one'], [2, 'two'], [3, 'three'],]);var second = new Map([[1, 'uno'], [2, 'dos']]); // 合并两个 Map 对象时，如果有重复的键值，则后面的会覆盖前面的，对应值即 uno，dos， threevar merged = new Map([...first, ...second]); Set 对象Set 对象允许你存储任何类型的唯一值，无论是原始值或者是对象引用。 Set 中的特殊值Set 对象存储的值总是唯一的，所以需要判断两个值是否恒等。有几个特殊值需要特殊对待： +0 与 -0 在存储判断唯一性的时候是恒等的，所以不重复； undefined 与 undefined 是恒等的，所以不重复； NaN 与 NaN 是不恒等的，但是在 Set 中只能存一个，不重复。 代码 123456789101112let mySet = new Set(); mySet.add(1); // Set(1) {1}mySet.add(5); // Set(2) {1, 5}mySet.add(5); // Set(2) {1, 5} 这里体现了值的唯一性mySet.add(&quot;some text&quot;); // Set(3) {1, 5, &quot;some text&quot;} 这里体现了类型的多样性var o = {a: 1, b: 2}; mySet.add(o);mySet.add({a: 1, b: 2}); // Set(5) {1, 5, &quot;some text&quot;, {…}, {…}} // 这里体现了对象之间引用不同不恒等，即使值相同，Set 也能存储 类型转换Set 与 Array 的相互转换 1234// Array 转 Setvar mySet = new Set([&quot;value1&quot;, &quot;value2&quot;, &quot;value3&quot;]);// 用...操作符，将 Set 转 Arrayvar myArray = [...mySet]; String 转 Set 12// String 转 Setvar mySet = new Set('hello'); // Set(4) {&quot;h&quot;, &quot;e&quot;, &quot;l&quot;, &quot;o&quot;} 注：Set 中 toString 方法是不能将 Set 转换成 String Set 对象作用数组去重 12var mySet = new Set([1, 2, 3, 4, 4]);[...mySet]; // [1, 2, 3, 4] 并集 123var a = new Set([1, 2, 3]);var b = new Set([4, 3, 2]);var union = new Set([...a, ...b]); // {1, 2, 3, 4} 交集 123var a = new Set([1, 2, 3]);var b = new Set([4, 3, 2]);var intersect = new Set([...a].filter(x =&gt; b.has(x))); // {2, 3} 差集 123var a = new Set([1, 2, 3]);var b = new Set([4, 3, 2]);var difference = new Set([...a].filter(x =&gt; !b.has(x))); // {1}","link":"/ES6-Map-%E4%B8%8E-Set/"},{"title":"ES6 Reflect 与 Proxy","text":"概述Proxy 与 Reflect 是 ES6 为了操作对象引入的 API 。 Proxy 可以对目标对象的读取、函数调用等操作进行拦截，然后进行操作处理。它不直接操作对象，而是像代理模式，通过对象的代理对象进行操作，在进行这些操作时，可以添加一些需要的额外操作。 Reflect 可以用于获取目标对象的行为，它与 Object 类似，但是更易读，为操作对象提供了一种更优雅的方式。它的方法与 Proxy 是对应的。 Proxy基本用法一个 Proxy 对象由两个部分组成： target 、 handler 。在通过 Proxy 构造函数生成实例对象时，需要提供这两个参数。 target 即目标对象， handler 是一个对象，声明了代理 target 的指定行为。 123456789101112131415161718192021222324252627282930313233343536373839404142434445let target = { name: 'Tom', age: 24}let handler = { get: function(target, key) { console.log('getting '+key); return target[key]; // 不是target.key }, set: function(target, key, value) { console.log('setting '+key); target[key] = value; }}let proxy = new Proxy(target, handler)proxy.name // 实际执行 handler.getproxy.age = 25 // 实际执行 handler.set// getting name// setting age// 25 // target 可以为空对象let targetEpt = {}let proxyEpt = new Proxy(targetEpt, handler)// 调用 get 方法，此时目标对象为空，没有 name 属性proxyEpt.name // getting name// 调用 set 方法，向目标对象中添加了 name 属性proxyEpt.name = 'Tom'// setting name// &quot;Tom&quot;// 再次调用 get ，此时已经存在 name 属性proxyEpt.name// getting name// &quot;Tom&quot; // 通过构造函数新建实例时其实是对目标对象进行了浅拷贝，因此目标对象与代理对象会互相// 影响targetEpt// {name: &quot;Tom&quot;} // handler 对象也可以为空，相当于不设置拦截操作，直接访问目标对象let targetEmpty = {}let proxyEmpty = new Proxy(targetEmpty,{})proxyEmpty.name = &quot;Tom&quot;targetEmpty // {name: &quot;Tom&quot;} 实例方法get(target, propKey, receiver)1get(target, propKey, receiver) 用于 target 对象上 propKey 的读取操作。 12345678910111213let exam ={ name: &quot;Tom&quot;, age: 24}let proxy = new Proxy(exam, { get(target, propKey, receiver) { console.log('Getting ' + propKey); return target[propKey]; }})proxy.name // Getting name// &quot;Tom&quot; get() 方法可以继承。 1234567891011121314let proxy = new Proxy({}, { get(target, propKey, receiver) { // 实现私有属性读取保护 if(propKey[0] === '_'){ throw new Erro(`Invalid attempt to get private &quot;${propKey}&quot;`); } console.log('Getting ' + propKey); return target[propKey]; }}); let obj = Object.create(proxy);obj.name// Getting name set(target, propKey, value, receiver)1set(target, propKey, value, receiver) 用于拦截 target 对象上的 propKey 的赋值操作。如果目标对象自身的某个属性，不可写且不可配置，那么set方法将不起作用。 12345678910111213141516171819let validator = { set: function(obj, prop, value) { if (prop === 'age') { if (!Number.isInteger(value)) { throw new TypeError('The age is not an integer'); } if (value &gt; 200) { throw new RangeError('The age seems invalid'); } } // 对于满足条件的 age 属性以及其他属性，直接保存 obj[prop] = value; }};let proxy= new Proxy({}, validator)proxy.age = 100;proxy.age // 100proxy.age = 'oppps' // 报错proxy.age = 300 // 报错 第四个参数 receiver 表示原始操作行为所在对象，一般是 Proxy 实例本身。 12345678910111213const handler = { set: function(obj, prop, value, receiver) { obj[prop] = receiver; }};const proxy = new Proxy({}, handler);proxy.name= 'Tom';proxy.name=== proxy // true const exam = {}Object.setPrototypeOf(exam, proxy)exam.name = &quot;Tom&quot;exam.name === exam // true 注意，严格模式下，set代理如果没有返回true，就会报错。 apply(target, ctx, args)1apply(target, ctx, args) 用于拦截函数的调用、call 和 reply 操作。target 表示目标对象，ctx 表示目标对象上下文，args 表示目标对象的参数数组。 12345678910111213function sub(a, b){ return a - b;}let handler = { apply: function(target, ctx, args){ console.log('handle apply'); return Reflect.apply(...arguments); }}let proxy = new Proxy(sub, handler)proxy(2, 1) // handle apply// 1 has(target, propKey)1has(target, propKey) 用于拦截 HasProperty 操作，即在判断 target 对象是否存在 propKey 属性时，会被这个方法拦截。此方法不判断一个属性是对象自身的属性，还是继承的属性。 1234567891011let handler = { has: function(target, propKey){ console.log(&quot;handle has&quot;); return propKey in target; }}let exam = {name: &quot;Tom&quot;}let proxy = new Proxy(exam, handler)'name' in proxy// handle has// true 注意：此方法不拦截 for … in 循环。 construct(target, args)1construct(target, args) 用于拦截 new 命令。返回值必须为对象。 12345678910111213141516let handler = { construct: function (target, args, newTarget) { console.log('handle construct') return Reflect.construct(target, args, newTarget) }}class Exam { constructor (name) { this.name = name }}let ExamProxy = new Proxy(Exam, handler)let proxyObj = new ExamProxy('Tom')console.log(proxyObj)// handle construct// exam {name: &quot;Tom&quot;} deleteProperty(target, propKey)1deleteProperty(target, propKey) 用于拦截 delete 操作，如果这个方法抛出错误或者返回 false ，propKey 属性就无法被 delete 命令删除。 defineProperty(target, propKey, propDesc)1defineProperty(target, propKey, propDesc) 用于拦截 Object.definePro若目标对象不可扩展，增加目标对象上不存在的属性会报错；若属性不可写或不可配置，则不能改变这些属性。 12345678910111213141516171819202122232425let handler = { defineProperty: function(target, propKey, propDesc){ console.log(&quot;handle defineProperty&quot;); return true; }}let target = {}let proxy = new Proxy(target, handler)proxy.name = &quot;Tom&quot;// handle definePropertytarget// {name: &quot;Tom&quot;} // defineProperty 返回值为false，添加属性操作无效let handler1 = { defineProperty: function(target, propKey, propDesc){ console.log(&quot;handle defineProperty&quot;); return false; }}let target1 = {}let proxy1 = new Proxy(target1, handler1)proxy1.name = &quot;Jerry&quot;target1// {} getOwnPropertyDescriptor(target, propKey)erty 操作 1getOwnPropertyDescriptor(target, propKey) 用于拦截 Object.getOwnPropertyD() 返回值为属性描述对象或者 undefined 。 12345678910let handler = { getOwnPropertyDescriptor: function(target, propKey){ return Object.getOwnPropertyDescriptor(target, propKey); }}let target = {name: &quot;Tom&quot;}let proxy = new Proxy(target, handler)Object.getOwnPropertyDescriptor(proxy, 'name')// {value: &quot;Tom&quot;, writable: true, enumerable: true, configurable: // true} getPrototypeOf(target)ptor 属性 1getPrototypeOf(target) 主要用于拦截获取对象原型的操作。包括以下操作： 12345- Object.prototype._proto_- Object.prototype.isPrototypeOf()- Object.getPrototypeOf()- Reflect.getPrototypeOf()- instanceof 1234567let exam = {}let proxy = new Proxy({},{ getPrototypeOf: function(target){ return exam; }})Object.getPrototypeOf(proxy) // {} 注意，返回值必须是对象或者 null ，否则报错。另外，如果目标对象不可扩展（non-extensible），getPrototypeOf 方法必须返回目标对象的原型对象。 1234567let proxy = new Proxy({},{ getPrototypeOf: function(target){ return true; }})Object.getPrototypeOf(proxy)// TypeError: 'getPrototypeOf' on proxy: trap returned neither object // nor null isExtensible(target)用于拦截 Object.isExtensible 操作。 该方法只能返回布尔值，否则返回值会被自动转为布尔值。 123456let proxy = new Proxy({},{ isExtensible:function(target){ return true; }})Object.isExtensible(proxy) // true 注意：它的返回值必须与目标对象的isExtensible属性保持一致，否则会抛出错误。","link":"/ES6-Reflect-%E4%B8%8E-Proxy/"},{"title":"ES6 Symbol","text":"概述ES6 引入了一种新的原始数据类型 Symbol ，表示独一无二的值，最大的用法是用来定义对象的唯一属性名。 ES6 数据类型除了 Number 、 String 、 Boolean 、 Object、 null 和 undefined ，还新增了 Symbol 。 基本用法Symbol 函数栈不能用 new 命令，因为 Symbol 是原始数据类型，不是对象。可以接受一个字符串作为参数，为新创建的 Symbol 提供描述，用来显示在控制台或者作为字符串的时候使用，便于区分。 1234567let sy = Symbol(&quot;KK&quot;);console.log(sy); // Symbol(KK)typeof(sy); // &quot;symbol&quot; // 相同参数 Symbol() 返回的值不相等let sy1 = Symbol(&quot;kk&quot;); sy === sy1; // false 使用场景作为属性名用法 由于每一个 Symbol 的值都是不相等的，所以 Symbol 作为对象的属性名，可以保证属性不重名。 1234567891011121314151617let sy = Symbol(&quot;key1&quot;); // 写法1let syObject = {};syObject[sy] = &quot;kk&quot;;console.log(syObject); // {Symbol(key1): &quot;kk&quot;} // 写法2let syObject = { [sy]: &quot;kk&quot;};console.log(syObject); // {Symbol(key1): &quot;kk&quot;} // 写法3let syObject = {};Object.defineProperty(syObject, sy, {value: &quot;kk&quot;});console.log(syObject); // {Symbol(key1): &quot;kk&quot;} Symbol 作为对象属性名时不能用.运算符，要用方括号。因为.运算符后面是字符串，所以取到的是字符串 sy 属性，而不是 Symbol 值 sy 属性。 12345let syObject = {};syObject[sy] = &quot;kk&quot;; syObject[sy]; // &quot;kk&quot;syObject.sy; // undefined 注意点 Symbol 值作为属性名时，该属性是公有属性不是私有属性，可以在类的外部访问。但是不会出现在 for…in 、 for…of 的循环中，也不会被 Object.keys() 、 Object.getOwnPropertyNames() 返回。如果要读取到一个对象的 Symbol 属性，可以通过 Object.getOwnPropertySymbols() 和 Reflect.ownKeys() 取到。 1234567891011let syObject = {};syObject[sy] = &quot;kk&quot;;console.log(syObject); for (let i in syObject) { console.log(i);} // 无输出 Object.keys(syObject); // []Object.getOwnPropertySymbols(syObject); // [Symbol(key1)]Reflect.ownKeys(syObject); // [Symbol(key1)] 定义常量在 ES5 使用字符串表示常量。例如： 123const COLOR_RED = &quot;red&quot;;const COLOR_YELLOW = &quot;yellow&quot;;const COLOR_BLUE = &quot;blue&quot;; 但是用字符串不能保证常量是独特的，这样会引起一些问题： 123456789101112131415161718192021222324252627282930313233const COLOR_RED = &quot;red&quot;;const COLOR_YELLOW = &quot;yellow&quot;;const COLOR_BLUE = &quot;blue&quot;;const MY_BLUE = &quot;blue&quot;; function ColorException(message) { this.message = message; this.name = &quot;ColorException&quot;;} function getConstantName(color) { switch (color) { case COLOR_RED : return &quot;COLOR_RED&quot;; case COLOR_YELLOW : return &quot;COLOR_YELLOW &quot;; case COLOR_BLUE: return &quot;COLOR_BLUE&quot;; case MY_BLUE: return &quot;MY_BLUE&quot;; default: throw new ColorException(&quot;Can't find this color&quot;); }} try { var color = &quot;green&quot;; // green 引发异常 var colorName = getConstantName(color);} catch (e) { var colorName = &quot;unknown&quot;; console.log(e.message, e.name); // 传递异常对象到错误处理} 但是使用 Symbol 定义常量，这样就可以保证这一组常量的值都不相等。用 Symbol 来修改上面的例子。 1234567891011121314151617181920212223242526272829303132const COLOR_RED = Symbol(&quot;red&quot;);const COLOR_YELLOW = Symbol(&quot;yellow&quot;);const COLOR_BLUE = Symbol(&quot;blue&quot;);const MY_BLUE = Symbol(&quot;blue&quot;); function ColorException(message) { this.message = message; this.name = &quot;ColorException&quot;;}function getConstantName(color) { switch (color) { case COLOR_RED : return &quot;COLOR_RED&quot;; case COLOR_YELLOW : return &quot;COLOR_YELLOW &quot;; case COLOR_BLUE: return &quot;COLOR_BLUE&quot;; case MY_BLUE: return &quot;MY_BLUE&quot;; default: throw new ColorException(&quot;Can't find this color&quot;); }} try { var color = &quot;green&quot;; // green 引发异常 var colorName = getConstantName(color);} catch (e) { var colorName = &quot;unknown&quot;; console.log(e.message, e.name); // 传递异常对象到错误处理} Symbol 的值是唯一的，所以不会出现相同值的常量，即可以保证 switch 按照代码预想的方式执行。 Symbol.for()Symbol.for() 类似单例模式，首先会在全局搜索被登记的 Symbol 中是否有该字符串参数作为名称的 Symbol 值，如果有即返回该 Symbol 值，若没有则新建并返回一个以该字符串参数为名称的 Symbol 值，并登记在全局环境中供搜索。 123456let yellow = Symbol(&quot;Yellow&quot;);let yellow1 = Symbol.for(&quot;Yellow&quot;);yellow === yellow1; // false let yellow2 = Symbol.for(&quot;Yellow&quot;);yellow1 === yellow2; // true Symbol.keyFor()Symbol.keyFor() 返回一个已登记的 Symbol 类型值的 key ，用来检测该字符串参数作为名称的 Symbol 值是否已被登记。 12let yellow1 = Symbol.for(&quot;Yellow&quot;);Symbol.keyFor(yellow1); // &quot;Yellow&quot;","link":"/ES6-Symbol/"},{"title":"ES6 let 与 const","text":"ES2015(ES6) 新增加了两个重要的 JavaScript 关键字: let 和 const。 let 声明的变量只在 let 命令所在的代码块内有效。 const 声明一个只读的常量，一旦声明，常量的值就不能改变。 let 命令基本用法12345{ let a = 0; a // 0}a // 报错 ReferenceError: a is not defined 代码块内有效let 是在代码块内有效，var 是在全局范围内有效: 123456{ let a = 0; var b = 1;}a // ReferenceError: a is not definedb // 1 不能重复声明let 只能声明一次 var 可以声明多次: 123456let a = 1;let a = 2;var b = 3;var b = 4;a // Identifier 'a' has already been declaredb // 4 for 循环计数器很适合用 let123456789101112for (var i = 0; i &lt; 10; i++) { setTimeout(function(){ console.log(i); })}// 输出十个 10for (let j = 0; j &lt; 10; j++) { setTimeout(function(){ console.log(j); })}// 输出 0123456789 变量 i 是用 var 声明的，在全局范围内有效，所以全局中只有一个变量 i, 每次循环时，setTimeout 定时器里面的 i 指的是全局变量 i ，而循环里的十个 setTimeout 是在循环结束后才执行，所以此时的 i 都是 10。 变量 j 是用 let 声明的，当前的 j 只在本轮循环中有效，每次循环的 j 其实都是一个新的变量，所以 setTimeout 定时器里面的 j 其实是不同的变量，即最后输出 12345。（若每次循环的变量 j 都是重新声明的，如何知道前一个循环的值？这是因为 JavaScript 引擎内部会记住前一个循环的值）。 不存在变量提升let 不存在变量提升，var 会变量提升: 12345console.log(a); //ReferenceError: a is not definedlet a = &quot;apple&quot;; console.log(b); //undefinedvar b = &quot;banana&quot;; 变量 b 用 var 声明存在变量提升，所以当脚本开始运行的时候，b 已经存在了，但是还没有赋值，所以会输出 undefined。 变量 a 用 let 声明不存在变量提升，在声明变量 a 之前，a 不存在，所以会报错。 const 命令const 声明一个只读变量，声明之后不允许改变。意味着，一旦声明必须初始化，否则会报错。 基本用法1234const PI = &quot;3.1415926&quot;;PI // 3.1415926const MY_AGE; // SyntaxError: Missing initializer in const declaration 暂时性死区12345var PI = &quot;a&quot;;if(true){ console.log(PI); // ReferenceError: PI is not defined const PI = &quot;3.1415926&quot;;} ES6 明确规定，代码块内如果存在 let 或者 const，代码块会对这些命令声明的变量从块的开始就形成一个封闭作用域。代码块内，在声明变量 PI 之前使用它会报错。 注意要点const 如何做到变量在声明初始化之后不允许改变的？ 其实 const 其实保证的不是变量的值不变，而是保证变量指向的内存地址所保存的数据不允许改动。此时，你可能已经想到，简单类型和复合类型保存值的方式是不同的。是的，对于简单类型（数值 number、字符串 string 、布尔值 boolean）,值就保存在变量指向的那个内存地址，因此 const 声明的简单类型变量等同于常量。而复杂类型（对象 object，数组 array，函数 function），变量指向的内存地址其实是保存了一个指向实际数据的指针，所以 const 只能保证指针是固定的，至于指针指向的数据结构变不变就无法控制了，所以使用 const 声明复杂类型对象时要慎重。","link":"/ES6-let-%E4%B8%8E-const/"},{"title":"ES6 环境搭建","text":"目前各大浏览器基本上都支持 ES6 的新特性，其中 Chrome 和 Firefox 浏览器对 ES6 新特性最友好，IE7~11 基本不支持 ES6。 以下是各大浏览器支持情况及开始时间: Chrome 58 Edge 14 Firefox 54 Safari 10 Opera 55 2017 年 1 月 2016 年 8 月 2017 年 3 月 2016 年 7 月 2018 年 8 月 浏览器支持的详细的内容可以参考：http://kangax.github.io/compat-table/es6/ Node.js 是运行在服务端的 JavaScript，它对 ES6 的支持度更高。 Node.js 安装可以参考 Node.js 安装配置。 在 Node.js 环境中运行 ES61234567$ node&gt; let sitename=&quot;buubiu&quot;undefined&gt; console.log(sitename)runoobundefined&gt; 使用下面的命令，可以查看 Node 已经实现的 ES6 特性。 1node --v8-options | grep harmony webpackwebpack 是一个现代 JavaScript 应用程序的静态模块打包器 (module bundler) 。当 webpack 处理应用程序时，它会递归地构建一个依赖关系图 (dependency graph) ，其中包含应用程序需要的每个模块，然后将所有这些模块打包成一个或多个 bundle 。 webpack 主要有四个核心概念: 入口 (entry) 输出 (output) loader 插件 (plugins) 入口 (entry)入口会指示 webpack 应该使用哪个模块，来作为构建其内部依赖图的开始。进入入口起点后，webpack 会找出有哪些模块和库是入口起点（直接和间接）依赖的。在 webpack 中入口有多种方式来定义，如下面例子： 单个入口（简写）语法: 123const config = { entry: &quot;./src/main.js&quot;} 对象语法: 1234const config = { app: &quot;./src/main.js&quot;, vendors: &quot;./src/vendors.js&quot;} 输出 (output)output 属性会告诉 webpack 在哪里输出它创建的 bundles ，以及如何命名这些文件，默认值为 ./dist: 1234567const config = { entry: &quot;./src/main.js&quot;, output: { filename: &quot;bundle.js&quot;, path: path.resolve(__dirname, 'dist') }} loaderloader 让 webpack 可以去处理那些非 JavaScript 文件（ webpack 自身只理解 JavaScript ）。loader 可以将所有类型的文件转换为 webpack 能够有效处理的模块，例如，开发的时候使用 ES6 ，通过 loader 将 ES6 的语法转为 ES5 ，如下配置： 12345678910111213141516171819const config = { entry: &quot;./src/main.js&quot;, output: { filename: &quot;bundle.js&quot;, path: path.resolve(__dirname, 'dist') }, module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, loader: &quot;babel-loader&quot;, options: [ presets: [&quot;env&quot;] ] } ] }} 插件 (plugins)loader 被用于转换某些类型的模块，而插件则可以做更多的事情。包括打包优化、压缩、定义环境变量等等。插件的功能强大，是 webpack 扩展非常重要的利器，可以用来处理各种各样的任务。使用一个插件也非常容易，只需要 require() ，然后添加到 plugins 数组中。 12345678910111213141516171819// 通过 npm 安装const HtmlWebpackPlugin = require('html-webpack-plugin');// 用于访问内置插件 const webpack = require('webpack'); const config = { module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, loader: &quot;babel-loader&quot; } ] }, plugins: [ new HtmlWebpackPlugin({template: './src/index.html'}) ]}; 利用 webpack 搭建应用webpack.config.js1234567891011121314151617181920212223242526const path = require('path'); module.exports = { mode: &quot;development&quot;, // &quot;production&quot; | &quot;development&quot; // 选择 development 为开发模式， production 为生产模式 entry: &quot;./src/main.js&quot;, output: { filename: &quot;bundle.js&quot;, path: path.resolve(__dirname, 'dist') }, module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, loader: &quot;babel-loader&quot;, options: [ presets: [&quot;env&quot;] ] } ] }, plugins: [ ... ]} 上述例子构建了一个最简单的配置，webpack 会从入口 main.js 文件进行构建，通过 loader 进行js转换，输出一个为 bundle.js 的文件，至此一整个过程就构建完成。 gulpgulp 是一个基于流的自动化构建工具，具有易于使用、构建快速、插件高质和易于学习的特点，常用于轻量级的工程中。 如何使用？全局安装 gulp: 1$ npm install --global gulp 在项目中引入依赖: 1$ npm install --save-dev gulp 在项目根目录下创建名为 gulpfile.js 的文件: gulpfile.js123456const gulp = require('gulp');// default 表示一个任务名，为默认执行任务gulp.task('default', function() { // 放置默认的任务代码}) 运行 gulp: 1$ gulp 利用 gulp 搭建应用12345678const gulp = require('gulp');const uglify = require(&quot;gulp-uglify&quot;); gulp.task('default', function() { gulp.src('./src/main.js') .pipe(uglify()) .pipe(gulp.dest('./dist'));})","link":"/ES6-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"ES6 解构赋值","text":"概述解构赋值是对赋值运算符的扩展。 他是一种针对数组或者对象进行模式匹配，然后对其中的变量进行赋值。 在代码书写上简洁且易读，语义更加清晰明了；也方便了复杂对象中数据字段获取。 解构模型在解构中，有下面两部分参与： 解构的源，解构赋值表达式的右边部分。 解构的目标，解构赋值表达式的左边部分。 数组模型的解构（Array）基本 1234let [a, b, c] = [1, 2, 3];// a = 1// b = 2// c = 3 可嵌套 1234let [a, [[b], c]] = [1, [[2], 3]];// a = 1// b = 2// c = 3 可忽略 123let [a, , b] = [1, 2, 3];// a = 1// b = 3 不完全解构 1let [a = 1, b] = []; // a = 1, b = undefined 剩余运算符 123let [a, ...b] = [1, 2, 3];//a = 1//b = [2, 3] 字符串等 在数组的解构中，解构的目标若为可遍历对象，皆可进行解构赋值。可遍历对象即实现 Iterator 接口的数据。 123456let [a, b, c, d, e] = 'hello';// a = 'h'// b = 'e'// c = 'l'// d = 'l'// e = 'o' 解构默认值 1let [a = 2] = [undefined]; // a = 2 当解构模式有匹配结果，且匹配结果是 undefined 时，会触发默认值作为返回结果。 123let [a = 3, b = a] = []; // a = 3, b = 3let [a = 3, b = a] = [1]; // a = 1, b = 1let [a = 3, b = a] = [1, 2]; // a = 1, b = 2 a 与 b 匹配结果为 undefined ，触发默认值：a = 3; b = a =3 a 正常解构赋值，匹配结果：a = 1，b 匹配结果 undefined ，触发默认值：b = a =1 a 与 b 正常解构赋值，匹配结果：a = 1，b = 2 对象模型的解构（Object）基本 123456let { foo, bar } = { foo: 'aaa', bar: 'bbb' };// foo = 'aaa'// bar = 'bbb' let { baz : foo } = { baz : 'ddd' };// foo = 'ddd' 可嵌套可忽略 1234567let obj = {p: ['hello', {y: 'world'}] };let {p: [x, { y }] } = obj;// x = 'hello'// y = 'world'let obj = {p: ['hello', {y: 'world'}] };let {p: [x, { }] } = obj;// x = 'hello' 不完全解构 1234let obj = {p: [{y: 'world'}] };let {p: [{ y }, x ] } = obj;// x = undefined// y = 'world' 剩余运算符 1234let {a, b, ...rest} = {a: 10, b: 20, c: 30, d: 40};// a = 10// b = 20// rest = {c: 30, d: 40} 解构默认值 1234let {a = 10, b = 5} = {a: 3};// a = 3; b = 5;let {a: aa = 10, b: bb = 5} = {a: 3};// aa = 3; bb = 5;","link":"/ES6-%E8%A7%A3%E6%9E%84%E8%B5%8B%E5%80%BC/"},{"title":"ES6简介","text":"简介ES6， 全称 ECMAScript 6.0 ，是 JavaScript 的下一个版本标准，2015.06 发版。 ES6 主要是为了解决 ES5 的先天不足，比如 JavaScript 里并没有类的概念，但是目前浏览器的 JavaScript 是 ES5 版本，大多数高版本的浏览器也支持 ES6，不过只实现了 ES6 的部分特性和功能。 ECMAScript 的背景JavaScript 是大家所了解的语言名称，但是这个语言名称是商标（ Oracle 公司注册的商标）。因此，JavaScript 的正式名称是 ECMAScript 。1996年11月，JavaScript 的创造者网景公司将 JS 提交给国际化标准组织 ECMA（European computer manufactures association，欧洲计算机制造联合会），希望这种语言能够成为国际标准，随后 ECMA 发布了规定浏览器脚本语言的标准，即 ECMAScript。这也有利于这门语言的开放和中立。 ECMAScript 的历史ES6 是 ECMAScript 标准十余年来变动最大的一个版本，为其添加了许多新的语法特性。 1997 年 ECMAScript 1.0 诞生。 1998 年 6 月 ECMAScript 2.0 诞生，包含一些小的更改，用于同步独立的 ISO 国际标准。 1999 年 12 月 ECMAScript 3.0诞生，它是一个巨大的成功，在业界得到了广泛的支持，它奠定了 JS 的基本语法，被其后版本完全继承。直到今天，我们一开始学习 JS ，其实就是在学 3.0 版的语法。 2000 年的 ECMAScript 4.0 是当下 ES6 的前身，但由于这个版本太过激烈，对 ES 3 做了彻底升级，所以暂时被”和谐”了。 2009 年 12 月，ECMAScript 5.0 版正式发布。ECMA 专家组预计 ECMAScript 的第五个版本会在 2013 年中期到 2018 年作为主流的开发标准。2011年6月，ES 5.1 版发布，并且成为 ISO 国际标准。 2013 年，ES6 草案冻结，不再添加新的功能，新的功能将被放到 ES7 中；2015年6月， ES6 正式通过，成为国际标准。 ES6 的目标与愿景成为更好编写的开发语言有以下目标。 适应更复杂的应用；实现代码库之间的共享；不断迭代维护新版本。 本教程的内容","link":"/ES6%E7%AE%80%E4%BB%8B/"},{"title":"ElasticSearch中的基本概念","text":"接近实时(NRT Near Real Time )Elasticsearch是一个接近实时的搜索平台。这意味着，从索引一个文档直到这个文档能够被搜索到有一个轻微的延迟(通常是1秒内) 索引(index)一个索引就是一个拥有几分相似特征的文档的集合。比如说，你可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。一个索引由一个名字来标识(必须全部是小写字母的)，并且当我们要对这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。索引类似于关系型数据库中Database 的概念。在一个集群中，如果你想，可以定义任意多的索引。 类型(type)在一个索引中，你可以定义一种或多种类型。一个类型是你的索引的一个逻辑上的分类/分区，其语义完全由你来定。通常，会为具有一组共同字段的文档定义一个类型。比如说，我们假设你运营一个博客平台并且将你所有的数 据存储到一个索引中。在这个索引中，你可以为用户数据定义一个类型，为博客数据定义另一个类型，当然，也可 以为评论数据定义另一个类型。类型类似于关系型数据库中Table的概念。 NOTE: 在5.x版本以前可以在一个索引中定义多个类型,6.x之后版本也可以使用,但是不推荐,在7~8.x版本中彻底移除一个索引中创建多个类型 映射(Mapping)Mapping是ES中的一个很重要的内容，它类似于传统关系型数据中table的schema，用于定义一个索引(index)中的类型(type)的数据的结构。 在ES中，我们可以手动创建type(相当于table)和mapping(相关与schema),也可以采用默认创建方式。在默认配置下，ES可以根据插入的数据自动地创建type及其mapping。 mapping中主要包括字段名、字段数据类型和字段索引类型 文档(document)一个文档是一个可被索引的基础信息单元，类似于表中的一条记录。比如，你可以拥有某一个员工的文档,也可以拥有某个商品的一个文档。文档以采用了轻量级的数据交换格式JSON(Javascript Object Notation)来表示。 概念关系图","link":"/ElasticSearch%E4%B8%AD%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"},{"title":"ElasticSearch中的过滤查询(Filter Query)","text":"介绍其实准确来说，ES中的查询操作分为2种: 查询(query)和过滤(filter)。查询即是之前提到的query查询，它 (查询)默认会计算每个返回文档的得分，然后根据得分排序。而过滤(filter)只会筛选出符合的文档，并不计算 得分，且它可以缓存文档 。所以，单从性能考虑，过滤比查询更快。 换句话说，过滤适合在大范围筛选数据，而查询则适合精确匹配数据。一般应用时， 应先使用过滤操作过滤数据， 然后使用查询匹配数据。 过滤语法 在执行filter和query时,先执行filter在执行query Elasticsearch会自动缓存经常使用的过滤器，以加快性能。 1234567891011121314151617GET /buubiu/user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ {&quot;match_all&quot;: {}} ], &quot;filter&quot;: { &quot;range&quot;: { &quot;age&quot;: { &quot;gte&quot;: 10 } } } } }} 常用的过滤器类型range filter123456789101112131415161718192021222324GET /buubiu/user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;term&quot;: { &quot;content&quot;: { &quot;value&quot;: &quot;框架&quot; } } } ], &quot;filter&quot;: { &quot;range&quot;: { &quot;age&quot;: { &quot;gte&quot;: 0, &quot;lte&quot;: 23 } } } } }} term filter123456789101112131415161718192021GET /buubiu/user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;term&quot;: { &quot;name&quot;: { &quot;value&quot;: &quot;小黑&quot; } } } ], &quot;filter&quot;: { &quot;term&quot;: { &quot;content&quot;: &quot;框架&quot; } } } }} terms filter多关键字是或的关系，下面表示：content包含框架或者分层 123456789101112131415161718192021222324GET /buubiu/user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;term&quot;: { &quot;name&quot;: { &quot;value&quot;: &quot;小黑&quot; } } } ], &quot;filter&quot;: { &quot;terms&quot;: { &quot;content&quot;: [ &quot;框架&quot;, &quot;分层&quot; ] } } } }} exists filter过滤存在指定字段，下面表示：只获取文档包含字段address的数据 1234567891011121314151617GET /buubiu/user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match_all&quot;: {} } ], &quot;filter&quot;: { &quot;exists&quot;: { &quot;field&quot;: &quot;address&quot; } } } }} ids filter过滤含有指定字段的索引记录 1234567891011121314151617181920GET /buubiu/user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match_all&quot;: {} } ], &quot;filter&quot;: { &quot;ids&quot;: { &quot;values&quot;: [ &quot;TVoUk3YBZ23tdxk-vWeC&quot;, &quot;TloUk3YBZ23tdxk-vWeC&quot; ] } } } }}","link":"/ElasticSearch%E4%B8%AD%E7%9A%84%E8%BF%87%E6%BB%A4%E6%9F%A5%E8%AF%A2-Filter-Query/"},{"title":"ElasticSearch中的集群","text":"相关概念集群(cluster) 一个集群就是由一个或多个节点组织在一起，它们共同持有你整个的数据，并一起提供索引和搜索功能。 一个集群是由一个唯一的名字标识，这个名字默认就是elasticsearch。这个名字是重要的，因为一个节点只能通过指定某个集群的名字，来加入这个集群。在产品环境中显式地设定这个名字是一个好习惯，但是使用默认值来进行测试/开发也是不错的。 节点(node) 一个节点是你集群中的一个服务器，作为集群的一部分，它存储你的数据，参与集群的索引和搜索功能。和集群类似，一个节点也是由一个名字来标识的，默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的时候赋予节点。这个名字对于管理工作来说挺重要的，因为在这个管理过程中，你会去确定网络中的哪些服务器对应于Elasticsearch集群中的哪些节点。 一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫 做elasticsearch的集群中，这意味着，如果你在你的网络中启动了若干个节点，并假定它们能够相互发现彼此，它们将会自动地形成并加入到一个叫做elasticsearch的集群中。 在一个集群里，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何Elasticsearch节点， 这时启动一个节点，会默认创建并加入一个叫做elasticsearch的集群。 分片和复制(shards &amp; replicas) 一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间;或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置 到集群中的任何节点上。 分片之所以重要，主要有两方面的原因: 允许你水平分割/扩展你的内容容量 允许你在分片(潜在地，位于多个节点上)之上进行分布式的、并行的操作，进而提高性能/吞吐量 至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。 在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因 消失了。这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch允许你创建分 片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。复制之所以重要，主要有两方面的原因: 在分片/节点失败的情况下，提供了高可用性。因为这个原因，复制分片从不与原/主要 (original/primary)分片置于同一节点上是非常重要的。 扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行 总之，每个索引可以被分成多个分片。一个索引也可以被复制0次(意思是没有复制)或多次。一旦复制了，每个索引就有了主分片(作为复制源的原来的分片)和复制分片(主分片的拷贝)之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制数量，但是不能改变分片的数量。 默认情况下（在7.0版本之前），Elasticsearch中的每个索引被分片5个主分片和1个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片(1个完全拷贝)，这样的话每个索引总共就有10个分片。一个 索引的多个分片可以存放在集群中的一台主机上，也可以存放在多台主机上，这取决于你的集群机器数量。主分片和复制分片的具体位置是由ES内在的策略所决定的。 7.0版本之后：默认情况下，Elasticsearch中的每个索引被分片1个主分片和1个复制 集群架构图 搭建集群ES 搭建集群非常简单，就是分别启动多台ES服务，并且保持集群的名称一致以及每个节点的名称不同即可；如果在同一台机器搭建集群，要保重 9200 9300 端点不能冲突 搭建步骤 将原有ES安装包复制三份 123cp -r elasticsearch-6.8.0/ elasticsearch-6.8.0-node1/cp -r elasticsearch-6.8.0/ elasticsearch-6.8.0-node2/cp -r elasticsearch-6.8.0/ elasticsearch-6.8.0-node3/ 删除复制目录中的data目录 注意:由于复制目录之前使用过因此需要在创建集群时将原来数据删除 123rm -rf elasticsearch-6.8.0-node1/datarm -rf elasticsearch-6.8.0-node2/datarm -rf elasticsearch-6.8.0-node3/data 编辑每个节点config目录中的jvm.options文件修改启动内存 分别修改：-Xms512m -Xmx512m 123vim elasticsearch-6.8.0-node1/config/jvm.optionsvim elasticsearch-6.8.0-node2/config/jvm.optionsvim elasticsearch-6.8.0-node3/config/jvm.options 编辑每个节点config目录中elasticsearch.yml文件 123456789101112vim elasticsearch-6.8.0-node1/config/elasticsearch.ymlvim elasticsearch-6.8.0-node2/config/elasticsearch.ymlvim elasticsearch-6.8.0-node3/config/elasticsearch.yml#分别修改如下配置: cluster.name: my-es #集群名称(集群名称必须一致) node.name: es-1 #节点名称(节点名称不能一致) network.host: 0.0.0.0 #监听地址(必须开启远程权限,并关闭防火墙) http.port: 9201 #监听端口(在一台机器时服务端口不能一致) discovery.zen.ping.unicast.hosts: [&quot;172.30.2.175:9302&quot;, &quot;172.30.2.201:9303&quot;] #另外两个节点的ip gateway.recover_after_nodes: 3 #集群可做master的最小节点数 transport.tcp.port: 9301 #集群TCP端口(在一台机器搭建必须修改) 启动每个ES 123./elasticsearch-6.8.0-node1/bin/elasticsearch./elasticsearch-6.8.0-node2/bin/elasticsearch./elasticsearch-6.8.0-node3/bin/elasticsearch 查看每个节点启动状态 123curl http://127.0.0.1:9201curl http://127.0.0.1:9202curl http://127.0.0.1:9203 查看集群健康状态 直接浏览器查看 1curl http://127.0.0.1:9201/_cat/health?v 在kibana上查看 修改kibana的配置文件，改为任意节点的IP+端口 12vim kibana.ymlelasticsearch.hosts: [&quot;http://127.0.0.1:9201&quot;] 执行命令 1GET /_cat/health?v 安装elasticsearch-head 插件下载elasticsearch-head123git clone git://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headnpm install #编译安装 编写ES配置文件开启head插件的访问在每个ES节点的elastsearch.yml最后添加以下内容，并重启 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 进入elasticsearch-head的目录启动插件1npm run start 通过插件查看集群状态1http://127.0.0.1:9100 Java对集群的操作在初始化ES客户端的代码处，把说有节点都写上，之后的操作都和单节点一样了。 123456789101112131415161718/** * @author buubiu **/@Configurationpublic class ElasticSearchRestClientConfig extends AbstractElasticsearchConfiguration { //这个client用来替换transportClient(9300)对象 @Override @Bean public RestHighLevelClient elasticsearchClient() { //定义客户端配置对象 RestClient 9200 final ClientConfiguration clientConfiguration = ClientConfiguration.builder() .connectedTo(&quot;127.0.0.1:9201&quot;,&quot;127.0.0.1:9202&quot;,&quot;127.0.0.1:9203&quot;) .build(); //通过RestClients对象创建 return RestClients.create(clientConfiguration).rest(); }}","link":"/ElasticSearch%E4%B8%AD%E7%9A%84%E9%9B%86%E7%BE%A4/"},{"title":"ElasticSearch中的高级检索","text":"两种检索方式(_search)ES官方提供了两中检索方式:一种是通过 URL 参数进行搜索,另一种是通过 DSL(Domain Specified Language) 进行搜索。官方更推荐使用第二种方式第二种方式是基于传递JSON作为请求体(request body)格式与ES进行交互，这种方式更强大，更简洁。 使用语法 URL查询: GET /索引/类型/_search?参数 DSL查询: GET /索引/类型/_search {} 测试数据删除索引1DELETE /buubiu 创建索引并指定类型123456789101112131415161718192021222324PUT /buubiu{ &quot;mappings&quot;:{ &quot;user&quot;:{ &quot;properties&quot;:{ &quot;name&quot;:{ &quot;type&quot;:&quot;text&quot; }, &quot;age&quot;:{ &quot;type&quot;:&quot;integer&quot; }, &quot;bir&quot;:{ &quot;type&quot;:&quot;date&quot; }, &quot;content&quot;:{ &quot;type&quot;:&quot;text&quot; }, &quot;address&quot;:{ &quot;type&quot;:&quot;keyword&quot; } } } }} 插入数据12345678910111213PUT /buubiu/user/_bulk {&quot;index&quot;:{}} {&quot;name&quot;:&quot;小黑&quot;,&quot;age&quot;:23,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;为开发团队选择一款优秀的MVC框架是件难事儿，在众多可行的方案中决择需要很高的经验和水平&quot;,&quot;address&quot;:&quot;北京&quot;} {&quot;index&quot;:{}} {&quot;name&quot;:&quot;王小黑&quot;,&quot;age&quot;:24,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;Spring 框架是一个分层架构，由 7 个定义良好的模块组成。Spring 模块构建在核心容器之上，核心容器定义了创建、配置和管理 bean 的方式&quot;,&quot;address&quot;:&quot;上海&quot;} {&quot;index&quot;:{}} {&quot;name&quot;:&quot;张小五&quot;,&quot;age&quot;:8,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;Spring Cloud 作为Java 语言的微服务框架，它依赖于Spring Boot，有快速开发、持续交付和容易部署等特点。Spring Cloud 的组件非常多，涉及微服务的方方面面，井在开源社区Spring 和Netflix 、Pivotal 两大公司的推动下越来越完善&quot;,&quot;address&quot;:&quot;无锡&quot;} {&quot;index&quot;:{}} {&quot;name&quot;:&quot;win7&quot;,&quot;age&quot;:9,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;Spring的目标是致力于全方位的简化Java开发。 这势必引出更多的解释， Spring是如何简化Java开发的？&quot;,&quot;address&quot;:&quot;南京&quot;} {&quot;index&quot;:{}} {&quot;name&quot;:&quot;梅超风&quot;,&quot;age&quot;:43,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API&quot;,&quot;address&quot;:&quot;杭州&quot;} {&quot;index&quot;:{}} {&quot;name&quot;:&quot;张无忌&quot;,&quot;age&quot;:59,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口&quot;,&quot;address&quot;:&quot;北京&quot;} 索引库原理图 QueryString检索常用的API1GET /buubiu/user/_search?q=*&amp;sort=age:desc&amp;size=2&amp;from=0&amp;_source=age,name,bir q=* 匹配所有文档 sort 以结果中的指定字段排序（默认asc升序，desc降序 size 分页用到的，每页显示的条数 from 分页用到的，第几条开始显示 _source 筛选结果显示的字段 QueryDSL检索返回结果解释12345678910111213141516171819202122232425262728293031{ &quot;took&quot; : 1, #响应时间：毫秒 &quot;timed_out&quot; : false, #是否超时 &quot;_shards&quot; : { #分片情况 &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 }, &quot;hits&quot; : { #击中结果（查询结果） &quot;total&quot; : 6, #总数 &quot;max_score&quot; : null,#最大得分 &quot;hits&quot; : [ #具体的击中结果 { &quot;_index&quot; : &quot;buubiu&quot;, #索引名称 &quot;_type&quot; : &quot;user&quot;, #索引类型 &quot;_id&quot; : &quot;lBBijXYBDhufrFchzxS8&quot;, #索引id &quot;_score&quot; : null,#得分 &quot;_source&quot; : { #文档内容 &quot;address&quot; : &quot;北京&quot;, &quot;name&quot; : &quot;张无忌&quot;, &quot;age&quot; : 59 }, &quot;sort&quot; : [ #排序 59, &quot;北京&quot; ] } ] }} 查询所有match_all关键字: 返回索引中的全部文档 123456GET /buubiu/user/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }} 查询所有并排序sort关键字：默认升序 12345678910111213141516GET /buubiu/user/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;age&quot;: { &quot;order&quot;: &quot;desc&quot; }, &quot;address&quot;:{ &quot;order&quot;: &quot;desc&quot; } } ]} 查询结果中返回指定条数(size)size 关键字: 指定查询结果中返回指定条数。 默认返回值10条 1234567891011121314151617GET /buubiu/user/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;age&quot;: { &quot;order&quot;: &quot;desc&quot; }, &quot;address&quot;:{ &quot;order&quot;: &quot;desc&quot; } } ], &quot;size&quot;: 2} 分页查询from 关键字: 用来指定起始返回位置 **size关键字:**每次取多少条,默认10条 123456789101112131415161718GET /buubiu/user/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;age&quot;: { &quot;order&quot;: &quot;desc&quot; }, &quot;address&quot;:{ &quot;order&quot;: &quot;desc&quot; } } ], &quot;size&quot;: 2, &quot;from&quot;: 0} 查询结果中指定字段__source关键字：是一个数组,在数组中用来指定展示那些字段 12345678910111213141516171819GET /buubiu/user/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;age&quot;: { &quot;order&quot;: &quot;desc&quot; }, &quot;address&quot;:{ &quot;order&quot;: &quot;desc&quot; } } ], &quot;size&quot;: 2, &quot;from&quot;: 0, &quot;_source&quot;: [&quot;age&quot;,&quot;address&quot;,&quot;name&quot;]} 关键词查询（term）term 关键字: 用来使用关键词查询 注意： 通过使用term查询得知,在ES的Mapping Type 中 keyword , date ,integer, long , double , boolean or ip 这些类型不分词，只有text类型分词。 通过使用term查询得知ES中默认使用分词器为标准分词器(StandardAnalyzer),标准分词器对于英文单词分词,对于中文单字分词。 12345678910GET /buubiu/user/_search{ &quot;query&quot;: { &quot;term&quot;: { &quot;content&quot;: { &quot;value&quot;: &quot;框&quot; } } }} 范围查询（range）range 关键字: 用来指定查询指定范围内的文档 1234567891011GET /buubiu/user/_search{ &quot;query&quot;: { &quot;range&quot;: { &quot;age&quot;: { &quot;gte&quot;: 8,#大于等于 &quot;lte&quot;: 20 #小于等于 } } }} 前缀查询（prefix）prefix 关键字: 用来检索含有指定前缀的关键词分词的相关文档 12345678910GET /buubiu/user/_search{ &quot;query&quot;: { &quot;prefix&quot;: { &quot;address&quot;: { &quot;value&quot;: &quot;北&quot; } } }} 通配符查询（wildcard）wildcard 关键字: 通配符查询 ? 用来匹配一个任意字符 *用来匹配多个任意字符 12345678910GET /buubiu/user/_search{ &quot;query&quot;: { &quot;wildcard&quot;: { &quot;address&quot;: { &quot;value&quot;: &quot;北?&quot; } } }} 多id查询（ids）ids 关键字 : 值为数组类型,用来根据一组id获取多个对应的文档，前提需要知道有哪些id 12345678GET /buubiu/user/_search{ &quot;query&quot;: { &quot;ids&quot;: { &quot;values&quot;: [&quot;kBBijXYBDhufrFchzxS8&quot;,&quot;kxBijXYBDhufrFchzxS8&quot;] } }} 模糊查询（fuzzy）fuzzy 关键字: 用来模糊查询含有指定关键字的文档，最大模糊错误 必须在0-2之间 搜索关键词长度为 2 不允许存在模糊 0 搜索关键词长度为3-5 允许一次模糊 0 1 搜索关键词长度大于5 允许最大2模糊 12345678GET /buubiu/user/_search{ &quot;query&quot;: { &quot;fuzzy&quot;: { &quot;content&quot;: &quot;elasticse99ch&quot; } }} 布尔查询（bool）bool 关键字: 用来组合多个条件实现复杂查询 must: 相当于&amp;&amp; 同时成立 should: 相当于|| 成立一个就行 must_not: 相当于! 不能满足任何一个 123456789101112131415161718192021222324252627282930313233GET /buubiu/user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;term&quot;: { &quot;address&quot;: { &quot;value&quot;: &quot;北京&quot; } } }, { &quot;range&quot;: { &quot;age&quot;: { &quot;gte&quot;: 10, &quot;lte&quot;: 30 } } } ], &quot;must_not&quot;: [ { &quot;term&quot;: { &quot;age&quot;: { &quot;value&quot;: 59 } } } ] } }} 高亮查询（highlight）highlight 关键字: 可以让符合条件的文档中的关键词高亮 *表示所有字段都高亮 自定义高亮html标签: 可以在highlight中使用pre_tags和post_tags 多字段高亮 使用require_field_match开启多个字段高亮 12345678910111213141516171819GET /buubiu/user/_search{ &quot;query&quot;: { &quot;term&quot;: { &quot;content&quot;: { &quot;value&quot;: &quot;的&quot; } } }, &quot;highlight&quot;: { &quot;fields&quot;: { &quot;*&quot;:{} }, &quot;pre_tags&quot;: [&quot;&lt;span style='color:red'&gt;&quot;], &quot;post_tags&quot;: [&quot;&lt;/span&gt;&quot;], &quot;require_field_match&quot;: &quot;false&quot; }} 多字段查询（multi_match） 如果搜索的字段分词，它会对query进行先分词在搜索 如果搜索的字段不分词，它会直接使用query整体进行改字段搜索 123456789GET /buubiu/user/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;Redis小&quot;, &quot;fields&quot;: [&quot;name&quot;,&quot;content&quot;,&quot;address&quot;] } }} 多字段分词查询（query_string）query_string关键字： default_field：根据哪个字段查询 query：搜索条件，会把值先进行分词在进行查询 filleds：根据哪些字段查询 1234567891011121314151617181920GET /buubiu/user/_search{ &quot;query&quot;: { &quot;query_string&quot;: { &quot;default_field&quot;: &quot;content&quot;, &quot;query&quot;: &quot;redis是一个好的语言&quot; } }}#该写法结果与multi_match一致GET /buubiu/user/_search{ &quot;query&quot;: { &quot;query_string&quot;: { &quot;query&quot;: &quot;redis是一个好的语言&quot;, &quot;fields&quot;: [&quot;name&quot;,&quot;content&quot;,&quot;address&quot;] } }} 去重聚合查询collapse关键字：指定字段进行去重，相当于数据库中的distinct agg，cardinality关键字：指定字段进行聚合，相当于数据库中的count，group by 12345678910111213141516GET /buubiu/user/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;collapse&quot;: { &quot;field&quot;: &quot;name&quot; }, &quot;aggs&quot;: { &quot;distinct_name_count&quot;: { &quot;cardinality&quot;: { &quot;field&quot;: &quot;name&quot; } } }}","link":"/ElasticSearch%E4%B8%AD%E7%9A%84%E9%AB%98%E7%BA%A7%E6%A3%80%E7%B4%A2/"},{"title":"ElasticSearch介绍","text":"什么是RestFulREST : 表现层状态转化(Representational State Transfer)，如果一个架构符合REST原则，就称它为 RESTful 架构风格。 资源: 所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息 表现层 :我们把”资源”具体呈现出来的形式，叫做它的”表现层”(Representation)。 状态转化(State Transfer):如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转 化”(State Transfer)。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。 REST原则就是指一个URL代表一个唯一资源，并且通过HTTP协议里面四个动词:GET、POST、PUT、DELETE对应四种服务器端的基本操作: GET用来获取资源，POST用来添加资源(也可以用于更新资源)，PUT用来更新资源，DELETE用来删除资源。 什么是全文检索全文检索是计算机程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置。当用户查询时根据建立的索引查找，类似于通过字典的检索字表查字的过程。 检索: 索(建立索引) 检:(检索索引) 全文检索（Full-Text Retrieval(检索)）以文本作为检索对象，找出含有指定词汇的文本。全面、准确和快速是衡量全文检索系统的关键指标。 关于全文检索，我们要知道： 1. 只处理文本。 2. 不处理语义。 3. 搜索时英文不区分大小写。 4. 结果列表有相关度排序。 什么是ElasticSearchElasticSearch 简称 ES ，是基于Apache Lucene构建的开源搜索引擎，是当前流行的企业级搜索引擎。Lucene本身就可以被认为迄今为止性能最好的一款开源搜索引擎工具包，但是lucene的API相对复杂，需要深厚的搜索理论。很难集成到实际的应用中去。但是ES是采用java语言编写，提供了简单易用的RestFul API，开发者可以使用其简单的RestFul API，开发相关的搜索功能，从而避免lucene的复杂性。 ES的诞生多年前，一个叫做Shay Banon的刚结婚不久的失业开发者，由于妻子要去伦敦学习厨师，他便跟着也去了。在他找工作的过程中，为了给妻子构建一个食谱的搜索引擎，他开始构建一个早期版本的Lucene。 直接基于Lucene工作会比较困难，所以Shay开始抽象Lucene代码以便Java程序员可以在应用中添加搜索功能。他发布了他的第一个开源项目，叫做“Compass”。 后来Shay找到一份工作，这份工作处在高性能和内存数据网格的分布式环境中，因此高性能的、实时的、分布式的搜索引擎也是理所当然需要的。然后他决定重写Compass库使其成为一个独立的服务叫做Elasticsearch。 第一个公开版本出现在2010年2月，在那之后Elasticsearch已经成为Github上最受欢迎的项目之一，代码贡献者超过300人。一家主营Elasticsearch的公司就此成立，他们一边提供商业支持一边开发新功能，不过Elasticsearch将永远开源且对所有人可用。 Shay的妻子依旧等待着她的食谱搜索…… ES的应用场景ES主要以轻量级JSON作为数据存储格式，这点与MongoDB有点类似，但它在读写性能上优于 MongoDB 。同时也支持地理位置查询 ，还方便地理位置和文本混合查询 。 以及在统计、日志类数据存储和分析、可视化这方面是引领者。 国外: ​ Wikipedia(维基百科)使用ES提供全文搜索并高亮关键字、StackOverflow(IT问答网站)结合全文搜索与地理位置查询、Github使用Elasticsearch检索1300亿行的代码。 国内: 百度(在云分析、网盟、预测、文库、钱包、风控等业务上都应用了ES，单集群每天导入30TB+数据， 总共每天60TB+)、新浪 、阿里巴巴、腾讯等公司均有对ES的使用。 使用比较广泛的平台ELK(ElasticSearch, Logstash, Kibana)。","link":"/ElasticSearch%E4%BB%8B%E7%BB%8D/"},{"title":"ElasticSearch的安装","text":"准备环境安装前准备 Linux / Mac Java8+ elastic 6.X 7.X 在官方网站下载EShttps://www.elastic.co/cn/downloads 安装ES服务ES不能以root用户身份启动必须创建普通用户 在Linux中创建新的组 1groupadd es 创建新的用户es，并将es用户放入es组中 1useradd es -g es 修改es用户密码 1passwd es 使用es用户登录并上传安装包解压缩elasticsearch1tar -zxvf elasticsearch-6.8.0.tar.gz 进入ES安装目录查看目录结构123456- bin 可执行的二进制文件的目录- config 配置文件的目录- lib 运行时依赖的库- logs 运行时日志文件- modules 运行时依赖的模块- plugins 可以安装官方以及第三方插件 进入bin目录启动ES服务1./elaticsearch 出现下图红框日志表示启动成功 执行如下命令测试客户端操作1curl http://localhost:9200 开启远程连接权限注意:ES服务默认启动是受保护的,只允许本地客户端连接,如果想要通过远程客户端访问,必须开启远程连接 开启ES远程访问12vim elasticsearch.yml 将原来network修改为以下配置:network.host: 0.0.0.0 原始配置 修改后配置 重启启动ES服务1./elasticsearch 重新启动es出现如下错误 1234ERROR: [3] bootstrap checks failed [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535] [2]: max number of threads [3802] for user [es] is too low, increase to at least [4096] [3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决错误[1] 使用root用户修改系统配置 12345vim /etc/security/limits.conf 在最后面追加下面内容 * soft nofile 65536 * hard nofile 65536 * soft nproc 4096 * hard nproc 4096 登录重新在检测配置是否生效 1234ulimit -Hnulimit -Snulimit -Huulimit -Su 解决错误[2] 使用root用户修改系统配置 12vim /etc/security/limits.d/20-nproc.conf 启动ES用户名 soft nproc 4096 解决错误[3] 使用root用户修改系统配置 12vim /etc/sysctl.confvm.max_map_count=655360 执行如下命令检测是否生效 1sysctl -p 退出从新登录之后重新启动ES服务 1./elasticsearch 通过浏览器访问ES服务http://192.168.31.23:9200/ 加密es修改配置文件：elasticsearch.yml 最后追加： 12xpack.security.enabled: truexpack.security.transport.ssl.enabled: true 进入bin目录执行命令，提示输入密码，确认密码 1$ ./elasticsearch-setup-passwords interactive 重新启动es，输入elastic和密码即可。 12curl http://localhost:9200 --user elastic:Aa000000curl -X DELETE http://localhost:9200/.kibana* --user elastic:Aa000000","link":"/ElasticSearch%E7%9A%84%E5%AE%89%E8%A3%85/"},{"title":"Elasticsearch7的索引模板","text":"前言 Elasticsearch环境:7.9.3版本 在Elasticsearch 7.8中引入的可组合索引模板。 索引模板的定义索引模板是一种告诉Elasticsearch在创建索引时如何配置索引的方法。对于数据流，索引模板在创建流的后备索引时对其进行配置。在创建索引之前先配置模板，然后在手动创建索引或通过对文档建立索引创建索引时，模板设置将用作创建索引的基础。 模板有两种类型，索引模板和组件模板。组件模板是可重用的构建块，用于配置映射，设置和别名。您使用组件模板构造索引模板，但它们不会直接应用于一组索引。索引模板可以包含组件模板的集合，也可以直接指定设置，映射和别名。 索引模板的作用一般创建索引的时候都会进行字段配置分片配置分词配置等等，有些操作是重复的。比如建立多个索引但是分词分析器的配置是一样的，时间字段的格式化是一样的等等。而模板就是把这些重复的操作抽出来，每次发现有重复的直接使用模板就行。就相当于我们写代码，遇到很多重复片段的代码就抽出一个方法。复用性比较好。 索引模板就是方便我们创建索引而产生的，Elasticsearch内置了metrics-*-*和logs-*-*索引模板，每个模板的优先级为100，主要是为了让Elastic Agent使用的。为防止模板被内置模板覆盖，建议自己的模板设置的优先级（priority）大于100。 比如要使用 Rollover API 的时候，还是配合模板使用的。 索引模板的使用模板可分为索引模板和组件模板。先讲索引模板 动态模板创建索引的时候，可以指定properties、settings等其他之外还可以添加**动态模板(dynamic_templates)**。看看demo 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 创建topic索引的时候，添加动态模板PUT http://172.16.1.236:9201/topic{ &quot;settings&quot;: { &quot;number_of_shards&quot;: 3, &quot;number_of_replicas&quot;: 1 }, &quot;mappings&quot;: { &quot;dynamic_templates&quot;: [ { &quot;my_template_name&quot;: { &quot;match&quot;: &quot;*num&quot;, &quot;unmatch&quot;: &quot;*_text&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;long&quot; } } }, { &quot;time_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*time&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd || epoch_millis&quot; } } }, { &quot;reg_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match_pattern&quot;:&quot;regex&quot;, &quot;match&quot;: &quot;.*(status|id|type).*&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }, { &quot;text_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot;, &quot;term_vector&quot;: &quot;with_positions_offsets&quot; } } } ], &quot;properties&quot;: { &quot;is_del&quot;: { &quot;type&quot;: &quot;boolean&quot; }, &quot;location&quot;: { &quot;type&quot;: &quot;geo_point&quot;, &quot;ignore_malformed&quot;: &quot;true&quot; }, &quot;status&quot;: { &quot;type&quot;: &quot;short&quot; } } }} 字段解析： 123456789101112131415161718dynamic_templates // 一个数组，随便自定义匹配规则模板，数组里面对象是个json,key就是名称match_mapping_type //检测数据类型，可以检测出boolean、long、string、double 等等match //匹配通配符unmatch //不匹配match_pattern //正则匹配path_match //和math 一样，只不过是对于对象类型的属性匹配path_unmatch //和unmath 一样，只不过是对于对象类型的属性匹配，// 解释动态模板意思// my_template_name 字段名称匹配 “num”结尾，不匹配“_text”结尾的使用 long类型// time_template 字段名称以“time”结尾的使用 date 类型并格式化// reg_template 字段名称正则匹配 包含 “status、id、type”其中一个的使用 keyword类型// text_template 上面都不匹配直接使用text 类型，并建立分词// 文档地址：https://www.elastic.co/guide/en/elasticsearch/reference/7.9/dynamic-templates.html 索引模板这里分为两个，一个是新版的API,一个是旧版的API。先讲新版的。 新版简单的栗子： 12345678910PUT /_index_template/template_name{ &quot;index_patterns&quot; : [&quot;te*&quot;], &quot;priority&quot; : 1, &quot;template&quot;: { &quot;settings&quot; : { &quot;number_of_shards&quot; : 2 } }} 请求体参数不止上面的几个，如下： 参数 参数类型 是否必传 描述 index_patterns 字符串数组 是 通配符表达式数组，用于在创建过程中匹配数据流和索引的名称。 data_stream 对象 否 指示模板是否用于创建数据流及其支持索引 template 对象 否 应用的模板。它可任选地包括一个aliases，mappings或 settings配置，这些参数和创建索引的时候配置的一样 composed_of 字符串数组 否 组件模板名称的有序数组。组件模板按照指定的顺序合并，这意味着指定的最后一个组件模板具有最高优先级 priority 整数 否 确定索引模板优先级的优先级，如果未指定优先级，则将模板视为优先级为0（最低优先级） version 整数 否 用于从外部管理索引模板的版本号，用户自定义 _meta 对象 否 有关索引模板的可选用户元数据，用户自定义 Index Template API 创建或更新一个名为 topic_template 索引模板 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889PUT http://172.16.1.236:9201/_index_template/topic_template{ &quot;index_patterns&quot; : [&quot;test*&quot;,&quot;topic*&quot;], &quot;template&quot;:{ &quot;settings&quot;: { &quot;number_of_shards&quot;: 3, &quot;number_of_replicas&quot;: 1 }, &quot;mappings&quot;: { &quot;dynamic_templates&quot;: [ { &quot;time_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*num&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;long&quot; } } }, { &quot;time_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*time&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd || epoch_millis&quot; } } }, { &quot;id_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*id&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }, { &quot;text_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*&quot;, &quot;mapping&quot;: { &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot;, &quot;term_vector&quot;: &quot;with_positions_offsets&quot; } } } ], &quot;properties&quot;: { &quot;update_time&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd'T'HH:mm:ss.SSS || yyyy-MM-dd || epoch_millis&quot; }, &quot;create_time&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd'T'HH:mm:ss.SSS || yyyy-MM-dd || epoch_millis&quot; }, &quot;user_id&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;is_del&quot;: { &quot;type&quot;: &quot;boolean&quot; }, &quot;location&quot;: { &quot;type&quot;: &quot;geo_point&quot;, &quot;ignore_malformed&quot;: &quot;true&quot; }, &quot;id&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;title&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;content&quot;: { &quot;term_vector&quot;: &quot;with_positions_offsets&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot;, &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot; }, &quot;status&quot;: { &quot;type&quot;: &quot;short&quot; } } } }, &quot;priority&quot;: 200} 这个模板创建成功之后，如果我们新建一个符合index_patterns 匹配规则的时候就会使用这个模板，比如创建一个叫 “topic2” 的索引，如果我们没有定义字段，那它的字段如果符合模板字段就会应用模板的字段。（因为“topic2”匹配index_patterns 的topic*字符串） 获取所有索引模板 1GET http://172.16.1.236:9201/_index_template 索引模板topic_template是否存在 12# 返回200 代表存在，404 代表不存在HEAD http://172.16.1.236:9201/_index_template/topic_template 删除topic_template索引模板 1DELETE http://172.16.1.236:9201/_index_template/topic_template 文档地址:https://www.elastic.co/guide/en/elasticsearch/reference/7.9/indices-put-template.html 旧版和新版差不多 123456789101112131415161718192021PUT _template/template_1{ &quot;index_patterns&quot;: [&quot;te*&quot;, &quot;bar*&quot;], &quot;settings&quot;: { &quot;number_of_shards&quot;: 1 }, &quot;mappings&quot;: { &quot;_source&quot;: { &quot;enabled&quot;: false }, &quot;properties&quot;: { &quot;host_name&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;created_at&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;EEE MMM dd HH:mm:ss Z yyyy&quot; } } }} 可以看到请求路径不一样，还要就是它没有优先级这个参数，但是有order这个字段和优先级一样的作用。API 就是改前缀地址就行，如下： 1234567891011121314151617181920212223242526272829303132333435# 添加模板PUT _template/topic_template{ &quot;index_patterns&quot;: [&quot;te*&quot;, &quot;bar*&quot;], &quot;settings&quot;: { &quot;number_of_shards&quot;: 1 }, &quot;mappings&quot;: { &quot;_source&quot;: { &quot;enabled&quot;: false }, &quot;properties&quot;: { &quot;host_name&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;created_at&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;EEE MMM dd HH:mm:ss Z yyyy&quot; } } }}# 获取所有索引模板GET http://172.16.1.236:9201/_template# 索引模板`topic_template`是否存在# 返回200 代表存在，404 代表不存在HEAD http://172.16.1.236:9201/_template/topic_template# 删除`topic_template`索引模板DELETE http://172.16.1.236:9201/_template/topic_template 有兴趣可以看官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/7.9/indices-templates-v1.html 组合模板通俗点讲，组合模板就是把索引模板又拆成小部分，相当于方法里的方法一样。她的参数和索引模板一样，只是请求的api变了。比如上面创建的索引模板，可以做成一个组件模板： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 创建一个名为my_dynamic_template 的组合模板PUT http://172.16.1.236:9201/_component_template/my_dynamic_template{ &quot;template&quot;: { &quot;mappings&quot;: { &quot;dynamic_templates&quot;: [ { &quot;time_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*num&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;long&quot; } } }, { &quot;time_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*time&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd || epoch_millis&quot; } } }, { &quot;id_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*id&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }, { &quot;text_template&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*&quot;, &quot;mapping&quot;: { &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot;, &quot;term_vector&quot;: &quot;with_positions_offsets&quot; } } } ] } }} 或者把settings 配置做成一个组件 12345678910# 创建一个名为my_setting_template，只有 settings 属性的组合模板PUT http://172.16.1.236:9201/_component_template/my_setting_template{ &quot;template&quot;: { &quot;settings&quot;: { &quot;number_of_shards&quot;: 3, &quot;number_of_replicas&quot;:1 } }} 使用她的时候只需要在创建模板的时候，使用：composed_of 参数即可： 12345678910111213141516171819202122232425262728293031323334353637383940# 创建索引，引用组合模板PUT http://172.16.1.236:9201/_index_template/my_component_template{ &quot;index_patterns&quot; : [&quot;index*&quot;,&quot;topic*&quot;], &quot;template&quot;:{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;update_time&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd'T'HH:mm:ss.SSS || yyyy-MM-dd || epoch_millis&quot; }, &quot;create_time&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd'T'HH:mm:ss.SSS || yyyy-MM-dd || epoch_millis&quot; }, &quot;is_del&quot;: { &quot;type&quot;: &quot;boolean&quot; }, &quot;location&quot;: { &quot;type&quot;: &quot;geo_point&quot;, &quot;ignore_malformed&quot;: &quot;true&quot; }, &quot;title&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;content&quot;: { &quot;term_vector&quot;: &quot;with_positions_offsets&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot;, &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot; }, &quot;status&quot;: { &quot;type&quot;: &quot;short&quot; } } } }, &quot;priority&quot;: 201, &quot;composed_of&quot;:[&quot;my_setting_template&quot;,&quot;my_dynamic_template&quot;]} 查看所有模板API12# 返回所有模板信息，参数v 返回头部名称GET http://172.16.1.236:9201/_cat/templates?v ok，最后放上官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/7.9/simulate-multi-component-templates.html 转载：https://rstyro.github.io/blog/2020/09/23/Elasticsearch7索引模板/","link":"/Elasticsearch7%E7%9A%84%E7%B4%A2%E5%BC%95%E6%A8%A1%E6%9D%BF/"},{"title":"Elasticsearch的集群添加节点证书","text":"背景集群搭建完成后，但是没配置账号密码，集群中各节点之间的通信是也没有什么校验措施的，别人随随便便就连上集群。这样在互联网中就相当于裸奔！ 准备工作防止出现不确定的错误，需要按照以下顺序执行： 停止与es相关的软件，比如：kafka logstash filebeat skywalking 等 停止es集群所有机器 生成证书 修改配置文件 配置证书 启动es 配置密码 配置证书TLS需要X.509证书才能对与之通信的应用程序执行加密和身份验证。为了使节点之间的通信真正安全，必须对证书进行验证。在Elasticsearch集群中验证证书真实性的推荐方法是信任签署证书的证书颁发机构（CA）。这样，将节点添加到群集时，它们只需要使用由同一CA签名的证书，即可自动允许该节点加入群集。 生成节点证书命令 elasticsearch-certutil 简化了生成证书的过程，它负责生成CA并与CA签署证书。 创建证书颁发机构CA 在任意一个节点执行即可 随便进入一个节点的bin 目录下执行elasticsearch-certutil 命令即可，如下 123# 该命令输出单个文件，默认名称为elastic-stack-ca.p12。此文件是PKCS＃12密钥库# 其中包含CA的公共证书和用于对每个节点的证书签名的私钥。$ ./elasticsearch-certutil ca 执行这个命令之后： 会让你输入生成elastic-stack-ca.p12文件放在哪。（直接回车，放在了上层目录） 回车之后让你输入密码，该密码是让你保护文件和密钥的。如果你以后还要加集群的话，要记得输入的密码。 生成证书和私钥 在任意一个节点执行即可，bin 目录下执行 12# 此命令生成证书凭证，输出的文件是单个PKCS＃12密钥库，其中包括节点证书，节点密钥和CA证书。$ ./elasticsearch-certutil cert --ca /usr/share/elasticsearch/elastic-stack-ca.p12 执行命令之后需要你操作3次： 第一次，输入上面生成CA的密码，没有设置直接回车 第二次，生成的文件路径，直接回车 第三次，生成这次证书与私钥文件的密码，建议和上面生成CA一致（怕忘记密码，也可以直接回车） 如下图需要输入密码的地方： 命令执行完之后会生成一个elastic-certificates.p12 文件（放在了上层目录），这个就是各节点通信的凭证 配置证书复制证书凭证 每个节点执行 把证书凭证复制到各个节点一份，最好复制到与elasticsearch.yml一个目录下， 方便管理。 123$ cp elastic-certificates.p12 /etc/elasticsearch/config# 授可以访问权限$ chmod 660 elastic-certificates.p12 修改配置文件 在每个节点执行 在各个节点下的elasticsearch.yml文件添加如下配置 123456xpack.security.enabled: truexpack.security.authc.accept_default_password: falsexpack.security.transport.ssl.enabled: truexpack.security.transport.ssl.verification_mode: certificatexpack.security.transport.ssl.keystore.path: /etc/elasticsearch/config/elastic-certificates.p12xpack.security.transport.ssl.truststore.path: /etc/elasticsearch/config/elastic-certificates.p12 xpack.security.enabled：是否启用xpack xpack.security.authc.accept_default_password：是否启用默认密码，默认为changeme xpack.security.transport.ssl.enabled：是否启用ssl证书 xpack.security.transport.ssl.verification_mode：证书类型 xpack.security.transport.ssl.keystore.path：节点证书路径 xpack.security.transport.ssl.truststore.path：节点证书的密钥库的路径 添加密码到密码库 在每个节点执行，bin 目录下执行 因为之前生成CA 和生成凭证都设置了密码，所以把密码添加到密钥库中 123# 执行之后，输入上面设置的密码，回车即可$ ./elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password$ ./elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password 若你的jdk是8版本，会有个警告，不必理会。 启动各个节点若配置了系统服务则： 1$ systemctl start elasticsearch 若没有配置系统服务则： 1$. /elasticsearch -d 可以看看日志，不出意外集群启动成功了。随便请求一个节点地址连接查看，但是需要账户和密码访问 配置密码在安装Elasticsearch时，如果内置用户elastic用户没有密码，它将使用默认的引导密码。引导程序密码是一个临时密码，从随机 keystore.seed 设置派生的会在安装过程中添加到密钥库中。我们压根不知道密码是啥，所以需要为内置用户elastic设置密码。首次设置可以用elasticsearch-setup-passwords命令 初始化密码 任意节点执行即可，bin目录下执行 elasticsearch-setup-passwords工具是首次设置内置用户密码的最简单方法。它使用elastic用户的引导程序密码来运行用户管理API请求。执行命令如下： 1$ ./elasticsearch-setup-passwords interactive 它在“互动”模式下提示你输入：elastic，kibana_system，logstash_system，beats_system，apm_system，和remote_monitoring_user用户的密码 至此ES集群的账号跟密码就设置完成了，我们设置密码之后会有一个名为.security-7的索引文档。 修改密码 可以重新初始化密码 也可以按照以下url修改 1234567# 随便一个节点地址修改即可，一个集群共用一个账号密码# 用Postman 请求时，选择 Authorization -&gt; 选择 Basic Auth -&gt; 右边选择上面设置的账号密码：elastic用户与密码POST http://127.0.0.1:9200/_xpack/security/user/elastic/_password{ &quot;password&quot;: &quot;yourNewPassword&quot;}","link":"/Elasticsearch%E7%9A%84%E9%9B%86%E7%BE%A4%E6%B7%BB%E5%8A%A0%E8%8A%82%E7%82%B9%E8%AF%81%E4%B9%A6/"},{"title":"Elasticsearch的高级设置","text":"常用配置实际生产环境中会遇到各种配置优化，这里记录一下： 分片数设置以下两种方法： 在任意支持curl命令的服务中执行: 1curl -X PUT http://127.0.0.1:9200/_cluster/settings -d '{ &quot;transient&quot;: { &quot;cluster&quot;: { &quot;max_shards_per_node&quot;:10000 } }}' -H 'Content-Type: application/json' 在相应的kibana中执行： 12345678PUT /_cluster/settings{ &quot;transient&quot;: { &quot;cluster&quot;: { &quot;max_shards_per_node&quot;:10000 } }} 分页查询数量设置设置当前索引1234PUT 索引名/_settings{ &quot;index&quot; : { &quot;max_result_window&quot; : 10000000 } } 设置当前所有已存在的索引1234PUT /_settings{ &quot;index&quot; : { &quot;max_result_window&quot; : 10000000 } } 或者 1234PUT /_all/_settings?preserve_existing=true{ &quot;index.max_result_window&quot; : &quot;13000&quot;} 通过索引模版设置以下两种方法： 在任意支持curl命令的服务中执行： 1curl -XPUT -H &quot;Content-Type: application/json&quot; http://127.0.0.1:9200/_template/index_max_result_window -d '{&quot;order&quot;:100,&quot;index_patterns&quot;:[&quot;*&quot;],&quot;settings&quot;:{&quot;index.max_result_window&quot;:100000000}}' 在相应的kibana中执行： 12345678PUT _template/index_max_result_window{ &quot;order&quot;: 100, &quot;index_patterns&quot;: [&quot;*&quot;], &quot;settings&quot;: { &quot;index.max_result_window&quot;: 100000000 }} 过滤删除索引1DELETE /*,-buubiu4*,-.kibana_* 忽略索引是否存在查询123456789101112131415161718192021222324252627GET /localhost_github_apm_8_2_0_segment-20210208/_search?ignore_unavailable=true{ &quot;from&quot;: 0, &quot;size&quot;: 15, &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [{ &quot;range&quot;: { &quot;time_bucket&quot;: { &quot;from&quot;: 20200201000000, &quot;to&quot;: 20210218999999, &quot;include_lower&quot;: true, &quot;include_upper&quot;: true, &quot;boost&quot;: 1.0 } } }], &quot;adjust_pure_negative&quot;: true, &quot;boost&quot;: 1.0 } }, &quot;sort&quot;: [{ &quot;latency&quot;: { &quot;order&quot;: &quot;desc&quot; } }]} 清除缓存123POST /_all/_cache/clear?fielddata=true #仅清除字段缓存POST /_all/_cache/clear?query=true #仅清除查询缓存POST /_all/_cache/clear?request=true #仅清除请求缓存","link":"/Elasticsearch%E7%9A%84%E9%AB%98%E7%BA%A7%E8%AE%BE%E7%BD%AE/"},{"title":"Eureka基本使用","text":"简介官网：https://github.com/Netflix/eureka/wiki Eureka是Netflix开发的服务发现框架，本身是一个基于REST的服务。SpringCloud将它集成在其子项目spring-cloud-netflix中，以实现SpringCloud的服务注册和发现功能。Eureka包含两个组件：Eureka Server和Eureka Client。 开发Eureka Server创建项目并引入eureka server依赖12345&lt;!--引入Eureka Server依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 编写配置application.properties12345678910#执行服务端口server.port=8761#指定服务名称 唯一标识spring.application.name=eurekaserver#指定服务注册中心的地址eureka.client.service-url.defaultZone=http://localhost:8761/eureka#不再将自己同时作为客户端进行注册eureka.client.register-with-eureka=false#关闭 作为客户端时从eureka server获取服务信息eureka.client.fetch-registry=false 开启Eureka Server，入口类加入注解123456789@SpringBootApplication@EnableEurekaServerpublic class Springcoud02Eurekaserver8761Application { public static void main(String[] args) { SpringApplication.run(Springcoud02Eurekaserver8761Application.class, args); }} 访问页面http://localhost:8761 开发Eureka Client创建项目并引入eureka client依赖12345&lt;!--引入eureka client 依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 编写配置123456#服务端口号server.port=8888#服务名称唯一标识spring.application.name=eruekaclient#eureka注册中心地址eureka.client.service-url.defaultZone=http://localhost:8761/eureka 开启Eureka Client，入口类加入注解123456789@SpringBootApplication@EnableEurekaClientpublic class Springcloud03Eurekaclient8888Application { public static void main(String[] args) { SpringApplication.run(Springcloud03Eurekaclient8888Application.class, args); }} 访问页面 Eureka自我保护机制服务频繁启动时 EurekaServer出现警告 EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY'RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 自我保护机制 官网地址: https://github.com/Netflix/eureka/wiki/Server-Self-Preservation-Mode 默认情况下，如果Eureka Server在一定时间内（默认90秒）没有接收到某个微服务实例的心跳，Eureka Server将会移除该实例。但是当网络分区故障发生时，微服务与Eureka Server之间无法正常通信，而微服务本身是正常运行的，此时不应该移除这个微服务，所以引入了自我保护机制。Eureka Server在运行期间会去统计心跳失败比例在 15 分钟之内是否低于 85%，如果低于 85%，Eureka Server 会将这些实例保护起来，让这些实例不会过期。这种设计的哲学原理就是”宁可信其有不可信其无!”。自我保护模式正是一种针对网络异常波动的安全保护措施，使用自我保护模式能使Eureka集群更加的健壮、稳定的运行。 在eureka server端关闭自我保护机制（不建议）1234#关闭自我保护（不建议）eureka.server.enable-self-preservation=false#超时3s自动清除（不建议）eureka.server.eviction-interval-timer-in-ms=3000 在eureka client端（微服务）修改减短服务心跳的时间（不建议）1234#用来修改eureka server默认接收心跳的最大时间 默认是90s（不建议）eureka.instance.lease-expiration-duration-in-seconds=10#指定客户端多久向eureka server发送一次心跳 默认是30s（不建议）eureka.instance.lease-renewal-interval-in-seconds=5 尽管如此关闭自我保护机制还是会出现警告 THE SELF PRESERVATION MODE IS TURNED OFF. THIS MAY NOT PROTECT INSTANCE EXPIRY IN CASE OF NETWORK/OTHER PROBLEMS. 官方并不建议在生产情况下关闭 Eureka 停止更新官方停止更新说明 https://github.com/Netflix/eureka/wiki 在1.x版本项目还是活跃的,但是在2.x版本中停止维护,出现问题后果自负!!!","link":"/Eureka%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"title":"Gateway组件的使用","text":"简介官方：https://spring.io/projects/spring-cloud-gateway This project provides a library for building an API Gateway on top of Spring MVC. Spring Cloud Gateway aims to provide a simple, yet effective way to route to APIs and provide cross cutting concerns to them such as: security, monitoring/metrics, and resiliency. 翻译：这个项目提供了一个在springmvc之上构建API网关的库。springcloudgateway旨在提供一种简单而有效的方法来路由到api，并为api提供横切关注点，比如：安全性、监控/度量和弹性。 特性基于springboot2.x 和 spring webFlux 和 Reactor 构建 响应式异步非阻塞IO模型 动态路由 请求过滤 开发网关动态路由配置方式创建项目引入网关依赖 123456789101112131415&lt;!--引入gateway网关依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--引入consul依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--引入actuator 健康检查依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 快捷方式配置路由（推荐）修改配置文件 12345678910111213141516171819spring: application: name: gateway cloud: consul: host: localhost port: 8500 gateway: routes: - id: user_route #指定路由唯一标识 uri: http://localhost:9999/ #指定路由服务的地址 predicates: - Path=/user/**,/feign/** #指定路由规则 - id: product_route uri: http://localhost:9998 predicates: - Path=/product/**server: port: 8989 启动工程，并访问测试 http://localhost:8989/feign/findAll Java方式配置路由开发Java类并注解 1234567891011121314/** * @author buubiu **/@Configurationpublic class GatewayConfig { @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder) { return builder.routes() .route(&quot;user_route&quot;,r -&gt; r.path(&quot;/user/**&quot;,&quot;/feign/**&quot;).uri(&quot;http://localhost:9999/&quot;)) .route(&quot;product_route&quot;,r -&gt; r.path(&quot;/product/**&quot;).uri(&quot;http://localhost:9998/&quot;)) .build(); }} 启动工程，并访问测试 http://localhost:8989/feign/findAll 查看网关路由规则列表介绍gateway提供了路由访问规则列表的web界面，但是默认是关闭的，如果想要查看服务器路由规则可以在配置文件中开启 开启路由规则列表123456789101112131415161718192021222324252627spring: application: name: gateway cloud: consul: host: localhost port: 8500 gateway: routes: - id: user_route #指定路由唯一标识 uri: http://localhost:9999/ #指定路由服务的地址 predicates: - Path=/user/**,/feign/** #指定路由规则 - id: product_route uri: http://localhost:9998 predicates: - Path=/product/**server: port: 8989#开启所有web端点暴露management: endpoints: web: exposure: include: &quot;*&quot; 访问路由管理列表地址http://localhost:8989/actuator/gateway/routes 配置路由服务负载均衡介绍现有路由配置方式，都是基于服务地址写死的路由转发，能不能根据服务名称进行路由转发的同时实现负载均衡呢？ 动态路由以及负载均衡转发配置1234567891011121314151617181920212223242526272829303132spring: application: name: gateway cloud: consul: host: localhost port: 8500 gateway: routes: - id: user_route #指定路由唯一标识 #uri: http://localhost:9999/ #指定路由服务的地址 uri: lb://users #lb(loadbalance): 代表转发后服务使用负载均衡，users代表服务注册中心上的服务名 predicates: - Path=/user/**,/feign/** #指定路由规则 - id: product_route #uri: http://localhost:9998 uri: lb://products predicates: - Path=/product/** discovery: locator: enabled: true #若想使用服务名进行负载均衡，必须开启根据服务名动态获取路由server: port: 8989#开启所有web端点暴露management: endpoints: web: exposure: include: &quot;*&quot; 访问页面并进行测试http://localhost:8989/feign/findOneById?productId=11 常用路由predicate（断言，验证）Gateway支持多种方式的predicate 使用predicate修改配置文件 1234567891011121314151617181920212223242526272829303132333435363738spring: application: name: gateway cloud: consul: host: localhost port: 8500 gateway: routes: - id: user_route #指定路由唯一标识 #uri: http://localhost:9999/ #指定路由服务的地址 uri: lb://users #lb(loadbalance): 代表转发后服务使用负载均衡，users代表服务注册中心上的服务名 predicates: - Path=/user/**,/feign/** #指定路由规则# - After=2020-11-23T11:39:33.993+08:00[Asia/Shanghai]# - Before=2020-11-23T11:39:33.993+08:00[Asia/Shanghai]# - Between=2020-07-21T11:39:33.993+08:00[Asia/Shanghai],2020-07-21T11:39:33.993+08:00[Asia/Shanghai]# - Cookie=username,buubiu# - Cookie=username,[A-Za-z0-9]+# - Header=X-Request-Id,\\id+ - id: product_route #uri: http://localhost:9998 uri: lb://products predicates: - Path=/product/** discovery: locator: enabled: true #若想使用服务名进行负载均衡，必须开启根据服务名动态获取路由server: port: 8989#开启所有web端点暴露management: endpoints: web: exposure: include: &quot;*&quot; 常用断言说明官方：https://docs.spring.io/spring-cloud-gateway/docs/2.2.5.RELEASE/reference/html/#gateway-request-predicates-factories 1234567891011121314151617181920`指定日期之后的请求进行路由`- After=2020-07-21T11:33:33.993+08:00[Asia/Shanghai] `指定日期之前的请求进行路由`- Before=2020-07-21T11:33:33.993+08:00[Asia/Shanghai] `指定日期之间的请求进行路由`- Between=2017-01-20T17:42:47.789-07:00[America/Denver], 2017-01-21T17:42:47.789-07:00[America/Denver]`基于指定cookie的请求进行路由（支持正则表达式）`- Cookie=username,chenyn - Cookie=username,[A-Za-z0-9]+ 例如： `curl http://localhost:8989/user/findAll --cookie &quot;username=zhangsna&quot;` `基于请求头中的指定属性的正则匹配路由(这里全是整数)`- Header=X-Request-Id, \\d+ 例如： `curl http://localhost:8989/user/findAll -H &quot;X-Request-Id:11&quot;` `基于指定的请求方式请求进行路由`- Method=GET,POST 常用的Filter以及自定义Filter介绍官方：https://docs.spring.io/spring-cloud-gateway/docs/2.2.5.RELEASE/reference/html/#gatewayfilter-factories Route filters allow the modification of the incoming HTTP request or outgoing HTTP response in some manner. Route filters are scoped to a particular route. Spring Cloud Gateway includes many built-in GatewayFilter Factories. 翻译：路由过滤器允许以某种方式修改传入的HTTP请求或传出的HTTP响应。路由筛选器的作用域是特定路由。springcloudgateway包括许多内置的GatewayFilter工厂。 作用：当我们有很多个服务时，比如下图中的user-service、order-service、product-service等服务，客户端请求各个服务的Api时，每个服务都需要做相同的事情，比如鉴权、限流、日志输出等。 使用内置过滤器官方：https://docs.spring.io/spring-cloud-gateway/docs/2.2.5.RELEASE/reference/html/#gatewayfilter-factories 使用方法：在配置文件添加fileters配置 123456789101112131415161718192021222324252627282930313233343536373839404142spring: application: name: gateway cloud: consul: host: localhost port: 8500 gateway: routes: - id: user_route #指定路由唯一标识 #uri: http://localhost:9999/ #指定路由服务的地址 uri: lb://users #lb(loadbalance): 代表转发后服务使用负载均衡，users代表服务注册中心上的服务名 predicates: - Path=/user/**,/feign/** #指定路由规则# - After=2020-11-23T11:39:33.993+08:00[Asia/Shanghai]# - Before=2020-11-23T11:39:33.993+08:00[Asia/Shanghai]# - Between=2020-07-21T11:39:33.993+08:00[Asia/Shanghai],2020-07-21T11:39:33.993+08:00[Asia/Shanghai]# - Cookie=username,buubiu# - Cookie=username,[A-Za-z0-9]+# - Header=X-Request-Id,\\id+ filters: - AddRequestParameter=productId,12 - AddResponseHeader=username,buubiu - id: product_route #uri: http://localhost:9998 uri: lb://products predicates: - Path=/product/** discovery: locator: enabled: true #若想使用服务名进行负载均衡，必须开启根据服务名动态获取路由server: port: 8989#开启所有web端点暴露management: endpoints: web: exposure: include: &quot;*&quot; 自定义Filter的使用书写自定义filter类123456789101112131415161718192021222324252627/** * @author buubiu * 自定义全局Filter * 作用：在进入所有路由转发之前都要经过，而内置filter只是针对某一个路由转发拦截的 **/@Configuration@Slf4jpublic class CustomGlobalFilter implements GlobalFilter, Ordered { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { log.info(&quot;进入自定义的filter&quot;); if (exchange.getRequest().getQueryParams().get(&quot;username&quot;) != null) { log.info(&quot;用户身份信息合法，放行请求继续执行！！！&quot;); return chain.filter(exchange); } log.info(&quot;非法用户，拒绝访问！！！&quot;); return exchange.getResponse().setComplete(); } //filter 数字越小越先执行 //-1 最先执行 @Override public int getOrder() { return -1; }} 访问页面并测试请求 predicate(断言),filte(过滤),route(路由)三者关系数据请求流程： predicate--&gt;filte--&gt;route 先经过断言，放行后在经过filter，最后才到路由转发，返回时原路返回。类似于栈 其中，web Handler相当于断言（predicate）","link":"/Gateway%E7%BB%84%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Gateway配置HTTPS证书","text":"介绍 The gateway can listen for requests on HTTPS by following the usual Spring server configuration. （网关可以通过遵循通常的Spring服务器配置监听HTTPS上的请求） –SpringCloud官网 下面举例说明如何进行配置： 生成证书目前Java支持 类型为 JKS、P12的证书。 证书本应是花钱买，客户端才能通过根CA仓库识别证书。 如果是自定义生成的证书，客户端访问时，会提示不安全的链接 是否继续访问，或者客户端可以将证书导入自己的本地CA仓库。 生成证书可以通过 OpenSSL创建证书，或者jdk的工具Keytool创建证书生成 gateway配置在yml文件启用ssl： PKCS12方式1234567891011server: ssl: enabled: true # 别名 key-alias: serverkey # 设置的密码 key-store-password: 123456 # p12文件，放在resources路径下 key-store: classpath:server-keystore.p12 # 密钥类型 key-store-type: PKCS12 JKS方式123456789101112131415server: ssl: enabled: true # 别名 key-alias: serverkey # 设置的密钥库密码 key-store-password: 123456 # 设置的密钥密码 key-password: 123456 # jks文件，放在resources路径下 key-store: classpath:server.keystore # 密钥类型 key-store-type: JKS # 密钥提供方：默认SUN key-store-provider: SUN","link":"/Gateway%E9%85%8D%E7%BD%AEHTTPS%E8%AF%81%E4%B9%A6/"},{"title":"Git操作总结","text":"git简介在实际开发中，会使用git作为版本控制工具来完成团队协作。因此，对基本的git操作指令进行总结是十分有必要的，本文对一些术语或者理论基础，不重新码字，可以参考廖雪峰老师的博文，本文只对命令做归纳总结。 git的通用操作流程如下图（来源于网络） 主要涉及到四个关键点： 工作区(workspace)：本地电脑存放项目文件的地方，比如learnGitProject文件夹； 暂存区（Index/Stage）：在使用git管理项目文件的时候，其本地的项目文件会多出一个.git的文件夹，将这个.git文件夹称之为版本库。其中.git文件夹中包含了两个部分，一个是暂存区（Index或者Stage）,顾名思义就是暂时存放文件的地方，通常使用add命令将工作区的文件添加到暂存区里； 本地仓库(Repository)：.git文件夹里还包括git自动创建的master分支，并且将HEAD指针指向master分支。使用commit命令可以将暂存区中的文件添加到本地仓库中； 远程仓库(Remote)：不是在本地仓库中，项目代码在远程git服务器上，比如项目放在github上，就是一个远程仓库，通常使用clone命令将远程仓库拷贝到本地仓库中，开发后推送到远程仓库中即可； 更细节的来看： 日常开发时代码实际上放置在工作区中，也就是本地的XXX.java这些文件，通过add等这些命令将代码文件提交给暂存区（Index/Stage），也就意味着代码全权交给了git进行管理，之后通过commit等命令将暂存区提交给master分支上，也就是意味打了一个版本，也可以说代码提交到了本地仓库中。另外，团队协作过程中自然而然还涉及到与远程仓库的交互。 因此，经过这样的分析，git命令可以分为这样的逻辑进行理解和记忆： git管理配置的命令； 几个核心存储区的交互命令： 工作区与暂存区的交互； 暂存区与本地仓库（分支）上的交互； 本地仓库与远程仓库的交互。 git配置命令查询配置信息 列出当前配置：git config --list; 列出repository配置：git config --local --list; 列出全局配置：git config --global --list; 列出系统配置：git config --system --list; 第一次使用git，配置用户信息 配置用户名：git config --global user.name &quot;your name&quot;; 配置用户邮箱：git config --global user.email &quot;youremail@github.com&quot;; 其他配置 配置解决冲突时使用哪种差异分析工具，比如要使用vimdiff：git config --global merge.tool vimdiff; 配置git命令输出为彩色的：git config --global color.ui auto; 配置git使用的文本编辑器：git config --global core.editor vi; 工作区上的操作命令新建仓库 将工作区中的项目文件使用git进行管理，即创建一个新的本地仓库：git init； 从远程git仓库复制项目：git clone &lt;url&gt;，如：git clone git://github.com/wasd/example.git;克隆项目时如果想定义新的项目名，可以在clone命令后指定新的项目名：git clone git://github.com/wasd/example.git mygit； 提交 提交工作区所有文件到暂存区：git add . 提交工作区中指定文件到暂存区：git add &lt;file1&gt; &lt;file2&gt; ...; 提交工作区中某个文件夹中所有文件到暂存区：git add [dir]; 撤销 删除工作区文件，并且也从暂存区也删除对应文件的记录：git rm &lt;file1&gt; &lt;file2&gt;; 从暂存区中删除文件，但是工作区依然还有该文件:git rm --cached &lt;file&gt;; 取消暂存区已经暂存的文件：git reset HEAD &lt;file&gt;...; 撤销上一次对文件的操作：git checkout --&lt;file&gt;。要确定上一次对文件的修改不再需要，如果想保留上一次的修改以备以后继续工作，可以使用stashing和分支来处理； 隐藏当前变更，以便能够切换分支：git stash； 查看当前所有的储藏：git stash list； 应用最新的储藏：git stash apply，如果想应用更早的储藏：git stash apply stash@{2}；重新应用被暂存的变更，需要加上--index参数：git stash apply --index; 使用apply命令只是应用储藏，而内容仍然还在栈上，需要移除指定的储藏：git stash drop stash{0};如果使用pop命令不仅可以重新应用储藏，还可以立刻从堆栈中清除：git stash pop; 在某些情况下，你可能想应用储藏的修改，在进行了一些其他的修改后，又要取消之前所应用储藏的修改。Git没有提供类似于 stash unapply 的命令，但是可以通过取消该储藏的补丁达到同样的效果：git stash show -p stash@{0} | git apply -R；同样的，如果你沒有指定具体的某个储藏，Git 会选择最近的储藏：git stash show -p | git apply -R； 更新文件 重命名文件，并将已改名文件提交到暂存区：git mv [file-original] [file-renamed]; 查新信息 查询当前工作区所有文件的状态：git status; 查询当前工作区所有文件的状态（简要输出）：git status -s; 比较工作区中当前文件和暂存区之间的差异，也就是修改之后还没有暂存的内容：git diff；指定文件在工作区和暂存区上差异比较：git diff &lt;file-name&gt;; 暂存区上的操作命令提交文件到版本库 将暂存区中的文件提交到本地仓库中，即打上新版本：git commit -m &quot;commit_info&quot;; 将所有已经使用git管理过的文件暂存后一并提交，跳过add到暂存区的过程：git commit -a -m &quot;commit_info&quot;; 提交文件时，发现漏掉几个文件，或者注释写错了，可以撤销上一次提交：git commit --amend; 查看信息 比较暂存区与上一版本的差异：git diff --staged或者git diff --cached; 指定文件在暂存区和本地仓库的不同：git diff &lt;file-name&gt; --cached; 查看提交历史：git log；参数-p展开每次提交的内容差异，用-2显示最近的两次更新，如git log -p -2; 打标签Git 使用的标签有两种类型：轻量级的（lightweight）和含附注的（annotated）。轻量级标签就像是个不会变化的分支，实际上它就是个指向特定提交对象的引用。而含附注标签，实际上是存储在仓库中的一个独立对象，它有自身的校验和信息，包含着标签的名字，电子邮件地址和日期，以及标签说明，标签本身也允许使用 GNU Privacy Guard (GPG) 来签署或验证。一般我们都建议使用含附注型的标签，以便保留相关信息；当然，如果只是临时性加注标签，或者不需要旁注额外信息，用轻量级标签也没问题。 列出现在所有的标签：git tag; 使用特定的搜索模式列出符合条件的标签，例如只对1.4.2系列的版本感兴趣：git tag -l &quot;v1.4.2.*&quot;; 创建一个含附注类型的标签，需要加-a参数，如git tag -a v1.4 -m &quot;my version 1.4&quot;; 使用git show命令查看相应标签的版本信息，并连同显示打标签时的提交对象：git show v1.4; 如果有自己的私钥，可以使用GPG来签署标签，只需要在命令中使用-s参数：git tag -s v1.5 -m &quot;my signed 1.5 tag&quot;; 验证已签署的标签：git tag -v &lt;tag-name&gt;，如git tag -v v1.5; 创建一个轻量级标签的话，就直接使用git tag命令即可，连-a,-s以及-m选项都不需要，直接给出标签名字即可，如git tag v1.5; 删除本地标签：git tag -d &lt;tag-name&gt;，如：git tag -d v1.5； 删除远程标签：git push origin :refs/tags/&lt;tag-name&gt;，如：git push origin :refs/tags/v1.5 将标签推送到远程仓库中：git push origin &lt;tag-name&gt;，如git push origin v1.5； 将本地所有的标签全部推送到远程仓库中：git push origin --tags; 分支管理 创建分支：git branch &lt;branch-name&gt;，如git branch testing； 从当前所处的分支切换到其他分支：git checkout &lt;branch-name&gt;，如git checkout testing； 新建并切换到新建分支上：git checkout -b &lt;branch-name&gt;; 删除分支：git branch -d &lt;branch-name&gt;； 删除远程分支：git push origin --delete &lt;branch-name&gt;； 将当前分支与指定分支进行合并：git merge &lt;branch-name&gt;; 显示本地仓库的所有分支：git branch; 查看所有分支：git branch -a，其中，remote/origin/开头的表示是远程分支； 查看各个分支最后一个提交对象的信息：git branch -v; 查看哪些分支已经合并到当前分支：git branch --merged; 查看当前哪些分支还没有合并到当前分支：git branch --no-merged; 把远程分支合并到当前分支：git merge &lt;remote-name&gt;/&lt;branch-name&gt;，如git merge origin/serverfix；如果是单线的历史分支不存在任何需要解决的分歧，只是简单的将HEAD指针前移，所以这种合并过程可以称为快进（Fast forward），而如果是历史分支是分叉的，会以当前分叉的两个分支作为两个祖先，创建新的提交对象；如果在合并分支时，遇到合并冲突需要人工解决后，再才能提交； 在远程分支的基础上创建新的本地分支：git checkout -b &lt;branch-name&gt; &lt;remote-name&gt;/&lt;branch-name&gt;，如git checkout -b serverfix origin/serverfix; 从远程分支checkout出来的本地分支，称之为跟踪分支。在跟踪分支上向远程分支上推送内容：git push。该命令会自动判断应该向远程仓库中的哪个分支推送数据；在跟踪分支上合并远程分支：git pull； 将一个分支里提交的改变移到基底分支上重放一遍：git rebase &lt;rebase-branch&gt; &lt;branch-name&gt;，如git rebase master server，将特性分支server提交的改变在基底分支master上重演一遍；使用rebase操作最大的好处是像在单个分支上操作的，提交的修改历史也是一根线；如果想把基于一个特性分支上的另一个特性分支变基到其他分支上，可以使用--onto操作：git rebase --onto &lt;rebase-branch&gt; &lt;feature branch&gt; &lt;sub-feature-branch&gt;，如git rebase --onto master server client；使用rebase操作应该遵循的原则是：一旦分支中的提交对象发布到公共仓库，就千万不要对该分支进行rebase操作； 将分支推送到远程仓库中：git push origin &lt;branch-name&gt;，如git push origin testing； 将分支推送到远程仓库中并重命名：git push origin &lt;branch-name&gt;:&lt;remote-name&gt;，如git push origin testing:testing1； 本地仓库上的操作 查看本地仓库关联的远程仓库：git remote；在克隆完每个远程仓库后，远程仓库默认为origin;加上-v的参数后，会显示远程仓库的url地址； 添加远程仓库，一般会取一个简短的别名：git remote add [remote-name] [url]，比如：git remote add example git://github.com/example/example.git; 从远程仓库中抓取本地仓库中没有的更新：git fetch [remote-name]，如git fetch origin;使用fetch只是将远端数据拉到本地仓库，并不自动合并到当前工作分支，只能人工合并。如果设置了某个分支关联到远程仓库的某个分支的话，可以使用git pull来拉去远程分支的数据，然后将远端分支自动合并到本地仓库中的当前分支； 将本地仓库某分支推送到远程仓库上：git push [remote-name] [branch-name]，如git push origin master；如果想将本地分支推送到远程仓库的不同名分支：git push &lt;remote-name&gt; &lt;local-branch&gt;:&lt;remote-branch&gt;，如git push origin serverfix:awesomebranch;如果想删除远程分支：git push [romote-name] :&lt;remote-branch&gt;，如git push origin :serverfix。这里省略了本地分支，也就相当于将空白内容推送给远程分支，就等于删掉了远程分支。 查看远程仓库的详细信息：git remote show origin； 修改某个远程仓库在本地的简称：git remote rename [old-name] [new-name]，如git remote rename origin org； 移除远程仓库：git remote rm [remote-name]； 忽略文件.gitignore一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。如下例： 12345678910111213## 此为注释 – 将被 Git 忽略## 忽略所有 .a 结尾的文件*.a## 但 lib.a 除外!lib.a## 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO/TODO## 忽略 build/ 目录下的所有文件build/## 会忽略 doc/notes.txt 但不包括 doc/server/arch.txtdoc/*.txt## 忽略 doc/ 目录下所有扩展名为 txt 的文件doc/**/*.txt","link":"/Git%E6%93%8D%E4%BD%9C%E6%80%BB%E7%BB%93/"},{"title":"Gradle与IDEA的集成","text":"默认情况下Gradle不需要与idea任何配置，可以直接打开idea创建一个Gradle项目即可 idea中创建gradle的Java项目 新建Module 选择Gradle项目 创建完成的项目结构 Gradle的项目结构12345678910111213141516171819//gradle -----项目名 ├── .gradle //用来存放当前使用gradle的信息 如版本等相关信息 ├── .idea //存放项目的配置信息，这个文件夹是自动IDEA生成的，包含版本控制信息，历史记录等信息 └── src ├── main │ ├── java //用来存放生产环境中java代码，也就是运行时必须的java代码 │ └── resources //用来存放生成环境中配置文件 └── test ├── java //用来存放测试环境中java代码，生产中不需要的代码 └── resources //用来存放测试环境中配置文件 ├── build.gradle //这个文件是整个项目的构建脚本，脚本中内容是以Groovy语言来写的，相当于maven项目中的pom.xml 文件【重点】 ├── gradle │ └── wrapper │ ├── gradle-wrapper.jar │ └── gradle-wrapper.properties ├── gradlew ├── gradlew.bat ├── settings.gradle //针对module的全局配置，它的作用域所包含的所有module是通过settings.gradle来配置的。 Gradle项目配置文件详解build.gradle用来对当前gradle项目做局部配置 1234567891011121314151617181920212223242526272829303132// 用来声明项目中使用了哪些插件plugins { //就是将java的一些构建任务tasks引入进来，项目在打包编译的时候，会执行java插件中的任务 id 'java'}//项目的坐标中的一部分：组织名 类似maven中的项目的groupIdgroup 'com.buubiu'//项目的坐标中的一部分：版本号 类似于maven中的项目versionversion '1.0-SNAPSHOT'//使用的远程仓库是什么repositories { //用的maven的远程仓库，他会下载从maven远程仓库下载后，存放到计算机的 .gradle目录中 mavenCentral()}//用来管理项目中的依赖dependencies { //testImplementation 仅仅在测试时可用,打包不会用，类似于maven中 scope的test testImplementation 'org.junit.jupiter:junit-jupiter-api:5.7.2' testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.7.2' //implementation group 表示 编译、运行、打包可用，类似于maven中scope的complie implementation group: 'mysql', name: 'mysql-connector-java', version: '8.0.27' //compileOnly group 仅仅在当前环境可用（IDEA）,在服务器中不用，因为tomcat已经包含了jar包，防止冲突，类似于maven中scope的provided compileOnly group: 'javax.servlet', name: 'servlet-api', version: '2.5'}test { useJUnitPlatform()} setting.gradle用来对当前的gradle项目进行全局配置 12//用来指定项目名称rootProject.name = 'gradle_01'","link":"/Gradle%E4%B8%8EIDEA%E7%9A%84%E9%9B%86%E6%88%90/"},{"title":"Gradle的介绍与安装","text":"引言​ 项目构建：所谓构建，值得就是对项目进行 编辑 编译 测试 打包 部署 等一系列流程 称之为项目构建。 ​ 行业主流的项目构建工具：apache ant(200年)········apache maven(2004年)········Gradle(2012年) 什么是Gradle​ Gradle是一个基于Apache Ant和Apache Maven概念的项目自动化构建开源工具。它使用一种基于Groovy语言进行编写的，主要面向Java应用为主，目前也增加了基于Kotlin语言以及Scala语言的支持，目的是为了抛弃基于XML的各种繁琐配置。 为什么是Gradle 简化了Maven中繁琐的XML配置 强大的支持多工程的构建 基于groovy脚本构建，其build脚本使用groovy语言编写 Gradle的安装环境准备安装前准备环境： windows7+、macOS Sierra+、Linux... JDK8+ 下载Gradle官方网站：https://gradle.org Gradle安装包目录结构 bin：用来存放Gradle的相关脚本文件 init.d：用户日后可以自定义脚本的目录 lib：依赖的jar包 配置环境变量Mac 下载到指定目录并解压做 12$ pwd/Users/buubiu/gradle/gradle-6.2 配置环境变量 123456# 在最后追加$ vim ~/.bash_profileexport GRADLE_HOME=/Users/buubiu/gradle/gradle-6.2export PATH=$PATH:$GRADLE_HOME/bin# 生效配置$ source ~/.bash_profile 查看配置是否成功 1234567891011121314151617181920212223$ gradle -versionWelcome to Gradle 6.2!Here are the highlights of this release: - Dependency checksum and signature verification - Documentation links in deprecation messages - Shareable read-only dependency cacheFor more details see https://docs.gradle.org/6.2/release-notes.html------------------------------------------------------------Gradle 6.2------------------------------------------------------------Build time: 2020-02-17 08:32:01 UTCRevision: 61d3320259a1a0d31519bf208eb13741679a742fKotlin: 1.3.61Groovy: 2.5.8Ant: Apache Ant(TM) version 1.10.7 compiled on September 1 2019JVM: 1.8.0_281 (Oracle Corporation 25.281-b09)OS: Mac OS X 10.16 x86_64 windows 下载到指定位置解压缩 配置环境变量 打开cmd测试环境变量配置是否成功 1$ gradle -version linux 下载到指定目录并解压缩 配置环境变量 vim /etc/profile配置文件 查看配置是否成功","link":"/Gradle%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%89%E8%A3%85/"},{"title":"Groovy仓库配置","text":"仓库介绍 Gradle支持下面三种不同类型的仓库： 下图是配置不同仓库对应的Gradle API： 下面以Maven仓库来介绍，Maven仓库是Java项目中使用最为广泛的一个仓库，库文件一般是以JAR文件的形式存在，用XML(POM文件)来来描述库的元数据和它的传递依赖。所有的库文件都存储在仓库的指定位置，当你在构建脚本中声明了依赖时，这些属性用来找到库文件在仓库中的准确位置。group属性标识了Maven仓库中的一个子目录，下图展示了Cargo依赖属性是怎么对应到仓库中的文件的： RepositoryHandler接口提供了两个方法来定义Maven仓库，mavenCentral方法添加一个指向仓库列表的引用，mavenLocal方法引用你文件系统中的本地Maven仓库。 添加Maven仓库要使用远程的官方Maven仓库你只需要调用mavenCentral方法，如下所示： 123repositories { mavenCentral()} 添加本地仓库本地仓库默认在 /.m2/repository目录下，只需要添加如下脚本来引用它： 如果配置了环境变量M2_HOME，则会从指定的maven配置 setting.xml中寻找本地仓库 123repositories { mavenLocal()} 添加自定义Maven仓库如果指定的依赖不存在与Maven仓库或者你想通过建立自己的企业仓库来确保可靠性，你可以使用自定义的仓库。仓库管理器允许你使用Maven布局来配置一个仓库，这意味着你要遵守artifact的存储模式。你也可以添加验证凭证来提供访问权限，Gradle的API提供两种方法配置自定义的仓库：maven()和mavenRepo()。下面这段代码添加了一个自定义的仓库，如果Maven仓库中不存在相应的库会从自定义仓库中查找： 1234567891011121314151617181920212223repositories { mavenLocal() maven { url '/Users/xxxx/maven/repository_3_6_3' } maven { name 'aliyun-maven2' url 'https://maven.aliyun.com/repository/central' } maven { name 'aliyun-spring' url 'https://maven.aliyun.com/repository/spring' } maven { name 'maven2' url 'https://repo1.maven.org/maven2/' } maven { name 'spring' url 'https://repo.spring.io/libs-milestone' } mavenCentral() } 上面配置顺序表示拉取仓库的顺序","link":"/Groovy%E4%BB%93%E5%BA%93%E9%85%8D%E7%BD%AE/"},{"title":"Groovy语言的基本入门","text":"基本语法输出语句123456789101112//1.括号，分号可不写//2.不区分单双引号println(&quot;Hello Groovy&quot;);println(&quot;Hello Gradle&quot;)println &quot;Hello Maven&quot;println 'Hello'=============Hello GroovyHello GradleHello MavenHello 定义变量1234567891011121314151617181920212223242526272829303132int a = 23println adef aa = 24println aadef s = 'hello'println sdef k = 23.23println kdef sex = trueprintln sexprintln a.classprintln aa.classprintln s.classprintln k.classprintln sex.class=============2324hello23.23trueclass java.lang.Integerclass java.lang.Integerclass java.lang.Stringclass java.math.BigDecimalclass java.lang.Boolean 注意： 在groovy语言中，可以定义任意java类型，也可以不指定类型，用def，由值类决定类型 groovy语言中的基本类型（Java中的int,float,double,byte,char,long,short）和对象类型（String等），最终都是对象类型 定义方法123456789//定义方法def play(def str) { println str + &quot;: hello maven&quot;}//调用方法play(&quot;Gradle is good&quot;)==========Gradle is good: hello maven 判断语句1234567891011def plays(def b) { if (b) { println &quot;hello world&quot; } else { println &quot;hello groovy&quot; }}plays(true)============hello world list 和 map 集合list12345678910111213141516//定义listdef lists = ['zhangsan', 'lisi', 'wangwu']//根据下标获取集合元素println lists[1]//遍历集合for (name in lists) { println name}==========lisizhangsanlisiwangwu map12345678910111213141516//定义mapdef map = ['zhangsan': '张三', '李四': 'lisi', '王五': '王五']//直接通过key获取map集合中的元素println map.get(&quot;zhangsan&quot;)//遍历map集合for (entry in map) { println &quot;key:&quot; + entry.getKey() + &quot;value:&quot; + entry.getValue()}==========张三key:zhangsanvalue:张三key:李四value:lisikey:王五value:王五 Grovvy的闭包闭包：就是Groovy中一段代码块，主要是用来作为参数在方法之间传递使用 基础闭包语法1234567891011121314//闭包定义def m1 = { println &quot;hello Groovy&quot;}//定义一个带有闭包参数的方法def play(Closure closure) { closure()}//调用方法传递参数play(m1)==========hello Groovy 定义带有参数的闭包1234567891011121314151617181920212223242526272829//定义一个接收参数的闭包def m2 = { v -&gt; println &quot;hello Groovy &quot; + v}def m3 = { v,m,n -&gt; println &quot;hello Groovy &quot; + v println &quot;hello Groovy &quot; + m println &quot;hello Groovy &quot; + n}//在方法中调用闭包传递参数def play1(Closure closure) { closure(&quot;Java&quot;)}def play2(Closure closure) { closure(&quot;Py&quot;, &quot;JS&quot;, &quot;node&quot;)}//调用方法play1(m2)play2(m3)===========hello Groovy Javahello Groovy Pyhello Groovy JShello Groovy node","link":"/Groovy%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%85%A5%E9%97%A8/"},{"title":"Hystrix组件使用","text":"In a distributed environment, inevitably some of the many service dependencies will fail. Hystrix is a library that helps you control the interactions between these distributed services by adding latency tolerance and fault tolerance logic. Hystrix does this by isolating points of access between the services, stopping cascading failures across them, and providing fallback options, all of which improve your system’s overall resiliency. –[摘自官方] 介绍官方：https://github.com/Netflix/Hystrix 翻译: 在分布式环境中，许多服务依赖项不可避免地会失败。Hystrix是一个库，它通过添加延迟容忍和容错逻辑来帮助您控制这些分布式服务之间的交互。Hystrix通过隔离服务之间的访问点、停止它们之间的级联故障以及提供后备选项来实现这一点，所有这些都可以提高系统的整体弹性。 通俗定义: Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统中，许多依赖不可避免的会调用失败，超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障(服务雪崩现象)，提高分布式系统的弹性。 服务雪崩定义在微服务之间进行服务调用是由于某一个服务故障，导致级联服务故障的现象，称为雪崩效应。雪崩效应描述的是提供方不可用，导致消费方不可用并将不可用逐渐放大的过程。 图解雪崩效应如存在如下图调用链路： 而此时，Service A的流量波动很大，流量经常会突然性增加！那么在这种情况下，就算Service A能扛得住请求，Service B和Service C未必能扛得住这突发的请求。此时，如果Service C因为抗不住请求，变得不可用。那么Service B的请求也会阻塞，慢慢耗尽Service B的线程资源，Service B就会变得不可用。紧接着，Service A也会不可用，这一过程如下图所示 解决方法服务熔断定义“熔断器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控，某个异常条件被触发，直接熔断整个服务。向调用方法返回一个符合预期的、可处理的备选响应(FallBack),而不是长时间的等待或者抛出调用方法无法处理的异常，就保证了服务调用方的线程不会被长时间占用，避免故障在分布式系统中蔓延，乃至雪崩。如果目标服务情况好转则恢复调用。服务熔断是解决服务雪崩的重要手段。 服务熔断图示 服务降级定义服务压力剧增的时候根据当前的业务情况及流量对一些服务和页面有策略的降级，以此环节服务器的压力，以保证核心任务的进行。同时保证部分甚至大部分任务客户能得到正确的相应。也就是当前的请求处理不了了或者出错了，给一个默认的返回。 通俗: 关闭系统中边缘服务 保证系统核心服务的正常运行 称之为服务降级 服务降级图示 熔断和降级总结共同点 目的很一致，都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段； 最终表现类似，对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用； 粒度一般都是服务级别，当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改）； 自治性要求很高，熔断模式一般都是服务基于策略的自动触发，降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段； 异同点 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑； 管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 总结 熔断必会触发降级,所以熔断也是降级一种,区别在于熔断是对调用链路的保护,而降级是对系统过载的一种保护处理 服务熔断的实现（在服务提供者实现）项目中引入hystrix依赖12345&lt;!--引入hystrix依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 修改启动类开启断路器123456789@SpringBootApplication@EnableCircuitBreaker //用来开启断路器public class Springcloud05Products9998Application { public static void main(String[] args) { SpringApplication.run(Springcloud05Products9998Application.class, args); }} 使用HystrixCommand注解实现断路在服务提供者的业务类中添加： 12345678910111213141516171819202122/** * @author buubiu **/@RestController@Slf4jpublic class ProductController { //模拟熔断器 @GetMapping(&quot;/product/break&quot;) @HystrixCommand(fallbackMethod = &quot;testBreakFall&quot;) public String testBreak(Integer productId) { log.info(&quot;接收的商品productId为：[{}]&quot;, productId); if (productId &lt; 0) { throw new RuntimeException(&quot;数据不合法&quot;); } return &quot;当前接收商品productId为：&quot;+ productId; } public String testBreakFall(Integer productId){ return &quot;当前数据不合法: &quot;+productId; }} 访问测试 正常参数访问 错误参数访问 断路器打开条件从上面演示过程中会发现如果触发一定条件断路器会自动打开,过了一点时间正常之后又会关闭。那么断路器打开条件是什么呢？ 官方：https://cloud.spring.io/spring-cloud-netflix/2.2.x/reference/html/#circuit-breaker-spring-cloud-circuit-breaker-with-hystrix A service failure in the lower level of services can cause cascading failure all the way up to the user. When calls to a particular service exceed circuitBreaker.requestVolumeThreshold (default: 20 requests) and the failure percentage is greater than circuitBreaker.errorThresholdPercentage (default: &gt;50%) in a rolling window defined by metrics.rollingStats.timeInMilliseconds (default: 10 seconds), the circuit opens and the call is not made. In cases of error and an open circuit, a fallback can be provided by the developer. –摘自官方 原文翻译之后,总结打开关闭的条件: 当满足一定的阀值的时候（默认10秒内超过20个请求次数） 当失败率达到一定的时候（默认10秒内超过50%的请求失败） 到达以上阀值，断路器将会开启 当开启的时候，所有请求都不会进行转发 一段时间之后（默认是5秒），这个时候断路器是半开状态，会让其中一个请求进行转发。如果成功，断路器会关闭，若失败，继续开启。重复4和5。 默认的服务FallBack处理方法如果为每一个服务方法开发一个降级,对于我们来说,可能会出现大量的代码的冗余,不利于维护,这个时候就需要加入默认服务降级处理方法 1234567891011121314151617181920212223/** * @author buubiu **/@RestController@Slf4jpublic class ProductController { //模拟熔断器 @GetMapping(&quot;/product/break&quot;) //@HystrixCommand(fallbackMethod = &quot;testBreakFall&quot;) @HystrixCommand(defaultFallback = &quot;defaultBreakFall&quot;) public String testBreak(Integer productId) { log.info(&quot;接收的商品productId为：[{}]&quot;, productId); if (productId &lt; 0) { throw new RuntimeException(&quot;数据不合法&quot;); } return &quot;当前接收商品productId为：&quot;+ productId; } public String defaultBreakFall() { return &quot;当前服务已被熔断，暂时不可用！&quot;; }} 服务降级的实现（在服务消费者实现）引入h ystrix依赖12345&lt;!--引入hystrix依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件开启feign支持hystrix12#开启feign支持hystrixfeign.hystrix.enabled=true 开发fallback处理类必须要实现OpenFeign客户端接口 1234567891011/** * @author buubiu **/@Componentpublic class ProductClientFallBack implements ProductClient { @Override public String testBreak(Integer productId) { return &quot;当前根据查询所有不可用，服务已被降级！&quot;; }} 在OpenFeign客户端中加入Hystrixfallback = ProductClientFallBack.class 1234567891011/** * @author buubiu **///用来标识当前接口是一个 feign 组件//value:书写调用服务serviceId(服务名称)//fallback:用来指定服务降级的客户端实现类@FeignClient(value = &quot;products&quot;,fallback = ProductClientFallBack.class)public interface ProductClient { @GetMapping(&quot;/product/break&quot;) String testBreak(Integer productId);} 访问测试 正常参数访问 错误参数访问 注意： 1. 如果服务端降级和客户端降级同时开启,要求服务端降级方法的返回值必须与客户端方法降级的返回值一致!! 2. 如果服务端降级和客户端降级同时开启,熔断的优先级高于降级的优先级，所以上面错误返回的数据是服务熔断的!! Hystrix Dashboard使用介绍Hystrix Dashboard的一个主要优点是它收集了关于每个HystrixCommand的一组度量。Hystrix仪表板以高效的方式显示每个断路器的运行状况。 使用方法新建项目引入hystrix dashboard 依赖12345&lt;!--引入 hystrix dashboard 依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; 入口类中开启hystrix dashboard123456789@SpringBootApplication@EnableHystrixDashboard //开启监控面板public class Springcloud07Hystrixdashboard9990Application { public static void main(String[] args) { SpringApplication.run(Springcloud07Hystrixdashboard9990Application.class, args); }} 启动hystrix dashboard 应用，并访问http://localhost:9990/hystrix 修改仪表盘项目的配置文件12#允许监控的白名单，这里代表全部监控hystrix.dashboard.proxy-stream-allow-list=* 修改被监控项目的配置文件12#熔断监控配置management.endpoints.web.exposure.include=* 通过监控界面监控 填写监控路径：http://localhost:9998/actuator/hystrix.stream 点击 Monitor Stream 查看控制台 当发起服务调用时，控制台就会显示结果： Hystrix 和 Hystrix Dashboard停止维护官方：https://github.com/Netflix/Hystrix Hystrix is no longer in active development, and is currently in maintenance mode. Hystrix (at version 1.5.18) is stable enough to meet the needs of Netflix for our existing applications. Meanwhile, our focus has shifted towards more adaptive implementations that react to an application’s real time performance rather than pre-configured settings (for example, through adaptive concurrency limits). For the cases where something like Hystrix makes sense, we intend to continue using Hystrix for existing applications, and to leverage open and active projects like resilience4j for new internal projects. We are beginning to recommend others do the same. –[官方说明] **翻译:**Hystrix（版本1.5.18）足够稳定，可以满足Netflix对我们现有应用的需求。同时，我们的重点已经转移到对应用程序的实时性能作出反应的更具适应性的实现，而不是预先配置的设置（例如，通过自适应并发限制）。对于像Hystrix这样的东西有意义的情况，我们打算继续在现有的应用程序中使用Hystrix，并在新的内部项目中利用诸如resilience4j这样的开放和活跃的项目。我们开始建议其他人也这样做。 The hystrix-dashboard component of this project has been deprecated and moved to Netflix-Skunkworks/hystrix-dashboard. Please see the README there for more details including important security considerations. —[官方说明] 翻译：该项目的hystrix-dashboard组件已被弃用，并移至Netflix-Skunkworks / hystrix-dashboard。请参阅自述文件以获取更多详细信息，包括重要的安全注意事项。","link":"/Hystrix%E7%BB%84%E4%BB%B6%E4%BD%BF%E7%94%A8/"},{"title":"IK分词器","text":"IK分词器介绍默认ES中采用标准分词器进行分词,这种方式并不适用于中文网站,因此需要修改ES对中文友好分词,从而达到更佳的搜索的效果。 安装IK分词器 ES 在v5.5.1版本后开始支持在线安装分词插件 IK分词插件版本一定要和ES的版本一致 IK分词器下载地址：https://github.com/medcl/elasticsearch-analysis-ik 在线安装 将es服务器中原始数据删除 进入es安装目录中将data目录数据删除 1rm -rf data 在es安装目录中执行安装命令 12345678910111213elasticsearch/elasticsearch-6.8.0/bin➜ ./elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.8.0/elasticsearch-analysis-ik-6.8.0.zip-&gt; Downloading https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.8.0/elasticsearch-analysis-ik-6.8.0.zip[=================================================] 100%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: plugin requires additional permissions @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@* java.net.SocketPermission * connect,resolveSee http://docs.oracle.com/javase/8/docs/technotes/guides/security/permissions.htmlfor descriptions of what these permissions allow and the associated risks.Continue with installation? [y/N]y-&gt; Installed analysis-ik IK分词配置文件和字典位置为 /XXX/elasticsearch/elasticsearch-6.8.0/config/analysis-ik/IKAnalyzer.cfg.xml 重启ES生效 测试ik安装成功 12345GET /_analyze{ &quot;text&quot;:&quot;中华人民共和国国歌&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;} 离线安装 将es服务器中原始数据删除 进入es安装目录中将data目录数据删除 1rm -rf data 下载对应IK分词器版本 https://github.com/medcl/elasticsearch-analysis-ik/releases 解压缩到plugins目录中命名为analysis-ik IK分词配置文件和字典位置为 /xxxx/elasticsearch/elasticsearch-6.8.0/plugins/analysis-ik/config/IKAnalyzer.cfg.xml 重启ES生效 测试ik安装成功 12345GET /_analyze{ &quot;text&quot;:&quot;中华人民共和国国歌&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;} 测试IK分词器IK分词器提供了两种mapping类型用来做文档的分词分别是 ik_max_word 和 ik_smart ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合； ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”。 测试数据12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061DELETE /buubiuPUT /buubiu{ &quot;mappings&quot;:{ &quot;user&quot;:{ &quot;properties&quot;:{ &quot;name&quot;:{ &quot;type&quot;:&quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot; }, &quot;age&quot;:{ &quot;type&quot;:&quot;integer&quot; }, &quot;bir&quot;:{ &quot;type&quot;:&quot;date&quot; }, &quot;content&quot;:{ &quot;type&quot;:&quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot; }, &quot;address&quot;:{ &quot;type&quot;:&quot;keyword&quot; } } } }}PUT /buubiu/user/_bulk {&quot;index&quot;:{}} {&quot;name&quot;:&quot;小黑&quot;,&quot;age&quot;:23,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;为开发团队选择一款优秀的MVC框架是件难事儿，在众多可行的方案中决择需要很高的经验和水平&quot;,&quot;address&quot;:&quot;北京&quot;} {&quot;index&quot;:{}} {&quot;name&quot;:&quot;王小黑&quot;,&quot;age&quot;:24,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;Spring 框架是一个分层架构，由 7 个定义良好的模块组成。Spring 模块构建在核心容器之上，核心容器定义了创建、配置和管理 bean 的方式&quot;,&quot;address&quot;:&quot;上海&quot;} {&quot;index&quot;:{}} {&quot;name&quot;:&quot;张小五&quot;,&quot;age&quot;:8,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;Spring Cloud 作为Java 语言的微服务框架，它依赖于Spring Boot，有快速开发、持续交付和容易部署等特点。Spring Cloud 的组件非常多，涉及微服务的方方面面，井在开源社区Spring 和Netflix 、Pivotal 两大公司的推动下越来越完善&quot;,&quot;address&quot;:&quot;无锡&quot;} {&quot;index&quot;:{}} {&quot;name&quot;:&quot;win7&quot;,&quot;age&quot;:9,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;Spring的目标是致力于全方位的简化Java开发。 这势必引出更多的解释， Spring是如何简化Java开发的？&quot;,&quot;address&quot;:&quot;南京&quot;} {&quot;index&quot;:{}} {&quot;name&quot;:&quot;梅超风&quot;,&quot;age&quot;:43,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API&quot;,&quot;address&quot;:&quot;杭州&quot;} {&quot;index&quot;:{}} {&quot;name&quot;:&quot;张无忌&quot;,&quot;age&quot;:59,&quot;bir&quot;:&quot;2012-12-12&quot;,&quot;content&quot;:&quot;ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口&quot;,&quot;address&quot;:&quot;北京&quot;}GET /buubiu/user/_search{ &quot;query&quot;:{ &quot;term&quot;:{ &quot;content&quot;:&quot;框架&quot; } }, &quot;highlight&quot;: { &quot;pre_tags&quot;: [&quot;&lt;span style='color:red'&gt;&quot;], &quot;post_tags&quot;: [&quot;&lt;/span&gt;&quot;], &quot;fields&quot;: { &quot;*&quot;:{} } }} 配置扩展词IK支持自定义扩展词典和停用词典,所谓**扩展词典就是有些词并不是关键词,但是也希望被ES用来作为检索的关键词,可以将这些词加入扩展词典。停用词典**就是有些词是关键词,但是出于业务场景不想使用这些关键词被检索到，可以将这些词放入停用词典。 定义扩展词典和停用词典 可以修改IK分词器中config目录中IKAnalyzer.cfg.xml这个文件。 NOTE：词典的编码必须为UTF-8，否则无法生效 修改vim IKAnalyzer.cfg.xml 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=&quot;ext_dict&quot;&gt;&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;&lt;/entry&gt;&lt;/properties&gt; 在ik分词器目录下config目录中创建ext_dict.dic文件 编码一定要为UTF-8才能生效 1vim ext_dict.dic #加入扩展词即可 在ik分词器目录下config目录中创建ext_stopword.dic文件 1vim ext_stopword.dic #加入停用词即可 重启es生效 定义远程扩展词典和停用词典 开发Spring Boot项目提供远程字典URL接口 修改vim IKAnalyzer.cfg.xml 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置远程扩展字典 --&gt; &lt;entry key=&quot;remote_ext_dict&quot;&gt;http://localhsot:8080/springboot/es/ext_dict.txt&lt;/entry&gt; &lt;!--用户可以在这里配置远程扩展停止词字典--&gt; &lt;entry key=&quot;remote_ext_stopwords&quot;&gt;http://localhsot:8080/springboot/es/ext_stopword.txt&lt;/entry&gt;&lt;/properties&gt; 重启es生效","link":"/IK%E5%88%86%E8%AF%8D%E5%99%A8/"},{"title":"JVM-001-整体介绍","text":"","link":"/JVM-001-%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D/"},{"title":"JVM-002-类加载子系统","text":"介绍 类加载器子系统负责从文件系统或者网络中加载 Class 文件，class 文件在文件开头有特定的文件标识。 ClassLoader 只负责 class 文件的加载，至于它是否可以运行，则有 ExecutionEngine 决定。 加载的类信息存放于一块称为方法区的内存空间。除了类的信息外，方法区中还会存放运行时常量池信息。可能还包括字符串字面量和数字常量（这部分常量信息是Class文件中常量池部分的内存映射）。 类的加载过程 加载（Loading） 通过一个类的全限定名获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口 字节码文件的来源，或者说 加载 .class文件的方式： 从本地系统中直接加载 通过网络获取，典型场景：Web Applet 从 zip 压缩包中读取，成为日后 jar 、war 格式的基础 运行时计算生成，使用最多的是：动态代理技术 由其他文件生成，典型场景：JSP 应用 从加密文件中获取，典型的防 Class 文件被反编译的保护措施 链接（Linking）验证（Verify） 目的在于确保 Class 文件的字节流中包含的信息符合当前虚拟机要求，保证被加载类的正确性，不会危害虚拟机自身安全。 主要包括四种验证：文件格式验证，元数据验证，字节码验证，符号引用验证。 比如：字节码二进制文件开头都是以 cafe babe 开头的 .class 文件，否则就会报错 Verify Error 准备（Prepare） 为类变量分配内存并且设置该变量的默认初始值 private static int a=1; //这里a在准备阶段赋值为0，在后续的初始化阶段才会赋值为 1 数值型赋值为 0 浮点型赋值为 0.0 char 型赋值为 -u0000 布尔型赋值为 false 引用类型赋值为 null 这里不包含用 final 修饰的 static，因为 final 在编译的时候就会分配了，准备阶段会显式初始化，直接初始化为代码指定的值 这里不会为实例变量分配初始化（因为变量还没创建），类变量会分配在方法区中，而实例变量是会随着对象一起分配的 Java 堆中。 解析（Resolve） 将常量池内的符号引用转化为直接引用的过程。 事实上，解析操作往往会伴随着 JVM 在执行完初始化之后再执行。 符号引用就是一组符号来描述所引用的目标。符号引用的字面量形式明确定义在《java虚拟机规范》的 Class 文件格式中。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。对应常量池中的 CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTRANT_Methordref_info 等。 初始化（Initialization） 初始化阶段就是执行类构造器方法&lt;clinit&gt;()的过程。 此方法不需要定义，是 javac 编译器自动收集类中的所有类变量（static修饰的变量）的赋值动作和静态代码块中的语句合并而来。 构造器方法中指令按语句在源文件中出现的顺序执行。 &lt;clinit&gt;()不同与类的构造器。（构造器是虚拟机视角下的&lt;init&gt;()） 若该类具有父类，JVM会保证子类的&lt;clinit&gt;()执行前，父类的&lt;clinit&gt;()已经执行完毕。 虚拟机必须保证一个类的&lt;clinit&gt;()方法在多线程下被同步加锁。（即：说明类加载到内存中只需要加载一次就行了，放在了方法区，并缓存起来，jdk8叫作原空间） 类加载器分类JVM支持两种类型的类加载器，分别为引导类加载器（Bootstrap ClassLoader)和自定义类加载器（UserDefined ClassLoader)-将所有派生与抽象类ClassLoader的类加载器都划分为自定义类加载器。 在程序中常见的类加载器始终只有3个，如下所示： 这里的四者之间的关系是包含关系。不是上层下层，也不是子父类的继承关系。 1234567891011121314151617181920212223242526272829303132package com.buubiu;/** * @comment: * @author: buubiu * @create: 2022/5/25 13:48 */public class ClassLoaderTest { public static void main(String[] args) { //获取系统类加载器 ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); System.out.println(systemClassLoader);//sun.misc.Launcher$AppClassLoader@18b4aac2 //获取其上层：扩展类加载器 ClassLoader extClassLoader = systemClassLoader.getParent(); System.out.println(extClassLoader);//sun.misc.Launcher$ExtClassLoader@75b84c92 //获取其上层：结果获取不到引导类加载器 ClassLoader bootstrapClassLoad = extClassLoader.getParent(); System.out.println(bootstrapClassLoad);//null //对于用户自定义类来说：默认使用系统类加载器进行加载 ClassLoader classLoader = ClassLoaderTest.class.getClassLoader(); System.out.println(classLoader);//sun.misc.Launcher$AppClassLoader@18b4aac2 //String类使用引导类加载器进行加载的。由此得出----&gt; Java的核心类库都是使用引导类加载器进行加载的。 ClassLoader classLoader1 = String.class.getClassLoader(); System.out.println(classLoader1);//null }} 虚拟机自带的加载器引导类加载器（启动类加载器，Bootstrap ClassLoader） 这个类加载使用 C/C++ 语言实现的，嵌套在JVM内部。 它用来加载 Java 的核心库（JAVA_HOME/jre/lib/rt.jar、resources.jar 或sun.boot.class.path路径下的内容），用户提供 JVM 自身需要的类。 并不继承自 java.lang.ClassLoader，没有父加载器。 加载扩展类和应用程序类加载器，并指定为他们的父类加载器。 出于安全考虑，Bootstrap 启动类加载器只加载包名为 java、javax、sun 等开头的类。 扩展类加载器（Extension ClassLoader） Java 语言编写，由 sun.misc.Launcher$ExtClassLoader 实现 派生于 ClassLoader 类 父类加载器为启动类加载器（引导类加载器，Bootstrap ClassLoader） 从 java.ext.dirs 系统属性所指定的目录中加载类库，或从JDK的安装目录 jar/lib/ext 子目录（扩展目录）下加载类库。如果用户创建的 JAR 放在此目录下，也会自动由扩展类加载器加载。 系统类加载器（应用程序类加载器，AppClassLoader） Java 语言编写，由 sun.misc.Launcher$AppClassLoader 实现 派生于 ClassLoader 类 父类加载器为扩展类加载器 它负责加载环境变量 classpath 或系统属性 java.class.path 指定路径下的类库 该类加载器是程序中默认的类加载器，一般来说，Java 应用的类都是由它来完成加载。 通过 ClassLoader.getSystemClassLoader() 方法可以获取到该类加载器。 用户自定义类加载器在Java的日常应用程序开发中，类的加载几乎是由上述3种类加载器相互配合执行的，在必要时，我们还可以自定义类加载器，来定制类的加载方式。 为什么要自定义类加载器？在什么场景下需要自定义类加载器呢？ 隔离加载类 比如说假设现在Spring框架，和RocketMQ有包名路径完全一样的类，类名也一样，这个时候类就冲突了，这个时候就需要自定义类加载器。不过一般的主流框架和中间件都会自定义类加载器，实现不同的框架，中间价之间是隔离的 修改类加载的方式 在某些时候，我们只需要引导类加载器就可以了，这时候，可以更改虚拟机自带的类加载器，让它们按需加载。 扩展加载源 可以考虑从数据库中加载类，机顶盒等等不同的地方 防止源码泄漏 对字节码文件进行加密防篡改，自己用的时候需要通过自定义类加载器来对其进行解密。 如何自定义类加载器？ 通过继承抽象类java.lang.ClassLoader类的方式，实现自己的类加载器，以满足一些特殊的需求 在JDK1.2之前，在自定义类加载器时，总会去继承ClassLoader类并重写loadClass()方法，从而实现自定义的类加载类，但是在JDK1.2之后已不再建议用户去覆盖loadClass()方法，而是建议把自定义的类加载逻辑写在findclass()方法中 在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承URIClassLoader类，这样就可以避免自己去编写findclass()方法及其获取字节码流的方式，使自定义类加载器编写更加简洁。 123456789101112131415161718192021222324252627282930313233343536public class CustomClassLoader extends ClassLoader { @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { try { byte[] result = getClassFromCustomPath(name); if (result == null) { throw new FileNotFoundException(); } else { //defineClass和findClass搭配使用 return defineClass(name, result, 0, result.length); } } catch (FileNotFoundException e) { e.printStackTrace(); } throw new ClassNotFoundException(name); } //自定义流的获取方式 private byte[] getClassFromCustomPath(String name) { //从自定义路径中加载指定类:细节略 //如果指定路径的字节码文件进行了加密，则需要在此方法中进行解密操作。 return null; } public static void main(String[] args) { CustomClassLoader customClassLoader = new CustomClassLoader(); try { Class&lt;?&gt; clazz = Class.forName(&quot;One&quot;, true, customClassLoader); Object obj = clazz.newInstance(); System.out.println(obj.getClass().getClassLoader()); } catch (Exception e) { e.printStackTrace(); } }} ClassLoader的使用说明介绍ClassLoader 类是一个抽象类，其后所有的类加载器都继承自 ClassLoader（不包括启动类加载器） 继承关系sun.misc.Launcher 是一个java虚拟机的入口应用 获取ClassLoader的方式 序号 途径 方法 1 获取当前类的ClassLoader clazz.getClassoader() 2 获取当前线程上下文的ClassLoader Thread.currentThread().getContextClassLoader() 3 获取系统的ClassLoader ClassLoader.getSystemClassLoader() 4 获取调用者的ClassLoader DriverManager.getCallerClassLoader() 示例： 12345678910111213141516171819202122232425262728package com.buubiu;/** * @comment: * @author: buubiu * @create: 2022/5/25 16:36 */public class GetClassLoaderTest { public static void main(String[] args) { try { //1.获取当前类的ClassLoader ClassLoader classLoader = Class.forName(&quot;java.lang.String&quot;).getClassLoader(); System.out.println(classLoader);//null //2.获取当前线程上下文的ClassLoader ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader(); System.out.println(contextClassLoader);//sun.misc.Launcher$AppClassLoader@18b4aac2 //3.获取系统的ClassLoader ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); System.out.println(systemClassLoader);//sun.misc.Launcher$AppClassLoader@18b4aac2 } catch (ClassNotFoundException e) { e.printStackTrace(); } }} 双亲委派机制介绍Java虚拟机对class文件采用的是按需加载的方式，也就是说当需要使用该类时才会将它的class文件加载到内存生成class对象。而且加载某个类的class文件时，Java虚拟机采用的是双亲委派模式，即把请求交由父类处理，它是一种任务委派模式。 工作原理 如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器区执行； 如果父类加载器还存在父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器； 如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己区加载，这就是双亲委派模式。 举例验证一： 首先建立一个包为 java.lang的String类，并写上 static 代码块 1234567891011121314package java.lang;/** * @comment: * @author: buubiu * @create: 2022/5/25 17:03 */public class String { static { System.out.println(&quot;我是自定义的String类的静态代码块&quot;); }} 在其他类里面去加载这个 String 类，观察加载的String类是JDK自带的String类，还是自己编写的String类 123456789101112131415package com.buubiu;/** * @comment: * @author: buubiu * @create: 2022/5/25 17:05 */public class StringTest { public static void main(String[] args) { java.lang.String s = new java.lang.String(); System.out.println(&quot;hello,buubiu&quot;); }} 结果：hello,buubiu解释： 程序并没有输出我们静态代码块中的内容，可见仍然加载的是 JDK 自带的 String 类，由于双亲委派机制一直找父类，所以最后找到了Bootstrap ClassLoader，Bootstrap ClassLoader找到的是 JDK 自带的 String 类 举例验证二：还是刚刚第一个String，修改一下： 1234567891011121314151617package java.lang;/** * @comment: * @author: buubiu * @create: 2022/5/25 17:03 */public class String { static { System.out.println(&quot;我是自定义的String类的静态代码块&quot;); } public static void main(String[] args) { System.out.println(&quot;hello String&quot;); }} 执行报错： 123错误: 在类 java.lang.String 中找不到 main 方法, 请将 main 方法定义为: public static void main(String[] args)否则 JavaFX 应用程序类必须扩展javafx.application.Application 解释： 由于双亲委派机制一直找父类，所以最后找到了Bootstrap ClassLoader，Bootstrap ClassLoader找到的是 JDK 自带的 String 类，在那个String类中并没有 main() 方法，所以就报了上面的错误。 举例验证三： 当我们加载jdbc.jar 用于实现数据库连接的时候： 我们现在程序中需要用到SPI接口，而SPI接口属于rt.jar包中Java核心api 然后使用双亲委派机制，引导类加载器把rt.jar包加载进来，而rt.jar包中的SPI只存在一些接口，没有具体的实现类 具体的实现类就涉及到了某些第三方的jar包了，比如我们加载SPI的实现类jdbc.jar包【首先我们需要知道的是 jdbc.jar是基于SPI接口进行实现的】 这时候就会反向委托线程上下文类加载器加载jdbc.jar，而线程上下文类加载器就是系统类加载器 这样一个完整的调用就实现了 从上面可以说明： SPI核心接口由引导类加载器来加载，SPI具体实现类由系统类加载器来加载 优势 避免类的重复加载（因为类加载器是由层次关系的） 保护程序安全，防止核心API被随意篡改 例如上面的例子一，自定义类：java.lang.String，创建同包名同名的类无效（沙箱安全机制） 禁止使用核心类的包名创建自定义类，比如： 创建一个包名为 java.lang 下面的 buubiu 类： 12345678910111213package java.lang;/** * @comment: * @author: buubiu * @create: 2022/5/25 17:32 */public class buubiu { public static void main(String[] args) { System.out.println(&quot;hello&quot;); }} 结果报错：不允许在核心类的包下创建类 123456789101112131415Error: A JNI error has occurred, please check your installation and try againException in thread &quot;main&quot; java.lang.SecurityException: Prohibited package name: java.lang at java.lang.ClassLoader.preDefineClass(ClassLoader.java:655) at java.lang.ClassLoader.defineClass(ClassLoader.java:754) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:473) at java.net.URLClassLoader.access$100(URLClassLoader.java:74) at java.net.URLClassLoader$1.run(URLClassLoader.java:369) at java.net.URLClassLoader$1.run(URLClassLoader.java:363) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:362) at java.lang.ClassLoader.loadClass(ClassLoader.java:418) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352) at java.lang.ClassLoader.loadClass(ClassLoader.java:351) at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:601) 沙箱安全机制自定义String类时：在加载自定义String类的时候会率先使用引导类加载器加载，而引导类加载器在加载的过程中会先加载jdk自带的文件（rt.jar包中java.lang.String.class），报错信息说没有main方法，就是因为加载的是rt.jar包中的String类。这样可以保证对java核心源代码的保护，这就是沙箱安全机制。 其他问题判断Class对象是否相同在JVM中表示两个class对象是否为同一个类需要满足两个条件： 类的完整类名必须一致，包括包名 加载这个类的ClassLoader（指ClassLoader实例对象）必须相同 换句话说，在JVM中，即使这两个类对象（class对象）来源同一个Class文件，被同一个虚拟机所加载，但只要加载它们的ClassLoader实例对象不同，那么这两个类对象也是不相等的 对类加载器的引用 JVM必须知道一个类型是由启动加载器加载的还是由用户类加载器加载的 如果一个类型是由用户类加载器加载的，那么JVM会将这个类加载器的一个引用作为类型信息的一部分保存在方法区中 当解析一个类型到另一个类型的引用的时候，JVM需要保证这两个类型的类加载器是相同的 类的主动使用和被动使用Java程序对类的使用方式分为：主动使用和被动使用。区别在于会不会导致类的初始化。 主动使用会进行类的初始化，分为七种情况： 创建类的实例 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射（比如：Class.forName(“com.buubiu.Test”)） 初始化一个类的子类 Java虚拟机启动的时候被标明为启动类的类 JDK 7 开始提供的动态语言支持： java.lang.invoke.MethodHandle实例的解析结果 REF_getStatic、REF_putStatic、REF_invokeStatic句柄对应的类没有初始化，则初始化 被动使用除了以上七种情况，其他使用Java类的方式都是对类的 被动使用，都 不会导致类的初始化","link":"/JVM-002-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F/"},{"title":"JVM-003-运行时数据区概述及线程","text":"引言在类加载完成后进入运行时数据区阶段。 类的加载 –&gt; 验证 –&gt; 准备 –&gt; 解析 –&gt; 初始化，这几个阶段完成后，就会用到执行引擎对编写的类进行使用，同时执行引擎将会使用到运行时数据区 内存的概念内存是非常重要的系统资源，是硬盘和CPU的中间仓库及桥梁，承载着操作系统和应用程序的实时运行。JVM内存布局规定了Java在运行过程中内存申请、分配、管理的策略，保证了JVM的高效稳定运行。不同的JVM对于内存的划分方式和管理机制存在着部分差异。 整体分析下图为阿里巴巴JDK8手册的图： 虚拟机内的线程和进程 Java虚拟机定义了若干种程序运行期间会使用到的运行时数据区：其中有一些会随着虚拟机启动而创建，随着虚拟机退出而销毁。另外一些则是与线程一一对应的，这些与线程对应的数据区域会随着线程开始和结束而创建和销毁。 上图分析得出： 红色部分为：一个进程对应着一份，或者理解成一个虚拟机实例对应着一份 灰色部分为：一个线程对应着一份 进程包括线程，比如1个进程对应着5个线程，这5个线程共用这1个进程的方法区和堆空间 上图分析得出： 灰色的为单独线程私有的，红色的为多个线程共享的。即： 每个线程：独立包括程序计数器（PC）、栈（VMS）、本地栈（NMS）。 线程间共享：堆（Heap）、堆外内存或者叫方法区（永久代或元空间、代码缓存）（Method Area） Class Runtime 每个JVM只有一个Runtime实例，是单例的，即为运行时环境，相当于JVM内存结构中的运行时数据区。 线程简介 线程是一个程序里的运行单元。JVM允许一个应用有多个线程并行的执行 在Hotspot JVM里，每个线程都与操作系统的本地线程直接映射 当一个Java线程准备好执行以后，此时一个操作系统的本地线程也同时创建。Java线程执行终止后，本地线程也会回收 Java线程执行终止后，JVM是否一并执行终止取决于： 正常终止：没有异常，或者有异常但是被捕获了。 非正常终止：有异常，没有捕获，若当前程序中只剩下守护线程了，则JVM也一并终止，若是非守护线程（普通线程），但是此线程是最后一个，JVM也是一并终止退出，其他情况JVM不会终止。 操作系统负责将线程安排调度到任何一个可用的CPU上。一旦本地线程初始化成功，它就会调用Java线程中的run()方法 JVM后台线程 如果你使用jconsole或者是任何一个调试工具，都能看到在后台有许多线程在运行。这些后台线程不包括调用public static void main(String[])的main线程以及所有这个main线程自己创建的线程。 这些主要的后台系统线程在Hotspot JVM里主要是以下几个： 虚拟机线程：这种线程的操作是需要JVM达到安全点才会出现。这些操作必须在不同的线程中发生的原因是他们都需要JVM达到安全点，这样堆才不会变化。这种线程的执行类型括”stop-the-world”的垃圾收集，线程栈收集，线程挂起以及偏向锁撤销. 周期任务线程：这种线程是时间周期事件的体现（比如中断），他们一般用于周期性操作的调度执行 GC线程：这种线程对在JVM里不同种类的垃圾收集行为提供了支持 编译线程：这种线程在运行时会将字节码编译成到本地代码 信号调度线程：这种线程接收信号并发送给JVM，在它内部通过调用适当的方法进行处理","link":"/JVM-003-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E6%A6%82%E8%BF%B0%E5%8F%8A%E7%BA%BF%E7%A8%8B/"},{"title":"JVM-004-运行时数据区-程序计数器(PC寄存器)","text":"介绍 官方地址：https://docs.oracle.com/javase/specs/jvms/se8/html/index.html JVM中的程序计数寄存器（Program Counter Register）中，Register 的命名源于CPU的寄存器，寄存器存储指令相关的现场信息。CPU只有把数据装载到寄存器才能够运行。 这里，并非是广义上所指的物理寄存器，或许将其翻译为PC计数器（或指令计数器）会更加贴切（也称为程序钩子），并且也不容易引起一些不必要的误会。JVM中的PC寄存器是对物理PC寄存器的一种抽象模拟。 作用 PC寄存器用来存储指向下一条指令的地址，也即将要执行的指令代码。由执行引擎读取下一条指令。 它是一块很小的内存空间，几乎可以忽略不记。也是运行速度最快的存储区域。 在JVM规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期保持一致。 任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。程序计数器会存储当前线程正在执行的Java方法的JVM指令地址；或者，如果是在执行native（本地方法栈，调用c/c++的时候）方法，则地址是未指定值（undefined）。 它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令 它是唯一一个在Java虚拟机规范中没有规定任何OutofMemoryError情况，也没有 GC 情况的区域。 扩展：GC（垃圾回收）、OOM（内存溢出） 存在GC的地方有：Heap Area（堆）、Method Area（方法区） 存在OOM的地方由：Heap Area（堆）、Method Area（方法区）、Stack-栈（Stack Area-虚拟机栈、Native Mehtod Stack-本地方法栈） 举例说明PCRegisterTest.java1234567891011121314151617181920package com.buubiu;/** * @comment: * @author: buubiu * @create: 2022/5/26 13:31 */public class PCRegisterTest { public static void main(String[] args) { int i = 10; int j = 20; int k = i + j; String s = &quot;abc&quot;; System.out.println(i); System.out.println(k); }} 查看字节码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103$ javap -verbose PCRegisterTest.classClassfile /com/buubiu/PCRegisterTest.class Last modified 2022-5-26; size 663 bytes MD5 checksum 2b77dd6af5bf87b0f434bc3d9cc35e0b Compiled from &quot;PCRegisterTest.java&quot;public class com.buubiu.PCRegisterTest minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #6.#26 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = String #27 // abc #3 = Fieldref #28.#29 // java/lang/System.out:Ljava/io/PrintStream; #4 = Methodref #30.#31 // java/io/PrintStream.println:(I)V #5 = Class #32 // com/buubiu/PCRegisterTest #6 = Class #33 // java/lang/Object #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Lcom/buubiu/PCRegisterTest; #14 = Utf8 main #15 = Utf8 ([Ljava/lang/String;)V #16 = Utf8 args #17 = Utf8 [Ljava/lang/String; #18 = Utf8 i #19 = Utf8 I #20 = Utf8 j #21 = Utf8 k #22 = Utf8 s #23 = Utf8 Ljava/lang/String; #24 = Utf8 SourceFile #25 = Utf8 PCRegisterTest.java #26 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #27 = Utf8 abc #28 = Class #34 // java/lang/System #29 = NameAndType #35:#36 // out:Ljava/io/PrintStream; #30 = Class #37 // java/io/PrintStream #31 = NameAndType #38:#39 // println:(I)V #32 = Utf8 com/buubiu/PCRegisterTest #33 = Utf8 java/lang/Object #34 = Utf8 java/lang/System #35 = Utf8 out #36 = Utf8 Ljava/io/PrintStream; #37 = Utf8 java/io/PrintStream #38 = Utf8 println #39 = Utf8 (I)V{ public com.buubiu.PCRegisterTest(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 8: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/buubiu/PCRegisterTest; public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=5, args_size=1 0: bipush 10 2: istore_1 3: bipush 20 5: istore_2 6: iload_1 7: iload_2 8: iadd 9: istore_3 10: ldc #2 // String abc 12: astore 4 14: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 17: iload_1 18: invokevirtual #4 // Method java/io/PrintStream.println:(I)V 21: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 24: iload_3 25: invokevirtual #4 // Method java/io/PrintStream.println:(I)V 28: return LineNumberTable: line 11: 0 line 12: 3 line 13: 6 line 15: 10 line 16: 14 line 17: 21 line 18: 28 LocalVariableTable: Start Length Slot Name Signature 0 29 0 args [Ljava/lang/String; 3 26 1 i I 6 23 2 j I 10 19 3 k I 14 15 4 s Ljava/lang/String;}SourceFile: &quot;PCRegisterTest.java&quot; 主要看 main 方法： 两个问题使用PC寄存器存储字节码指令有什么用？或者问：为什么使用PC寄存器记录当前线程的执行地址？ 因为CPU需要不停的切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行。 JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。 PC寄存器为什么会被设定为线程私有？为了能够准确地记录各个线程正在执行的当前字节码指令地址，最好的办法自然是为每一个线程都分配一个PC寄存器，这样一来各个线程之间便可以进行独立计算，从而不会出现相互干扰的情况。 CPU时间片 CPU时间片即CPU分配给各个程序的时间，每个线程被分配一个时间段，称作它的时间片 在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。 但在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，每个程序轮流执行。 这边要区分并行和并发： 并行是与串行相比较的 串行是线程排队执行 并行是线程同时执行 并发在CPU处理JVM线程的时候，由于CPU交换处理频率非常快，让人感觉线程是并行似的，其实它们是并发的。","link":"/JVM-004-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8-PC%E5%AF%84%E5%AD%98%E5%99%A8/"},{"title":"JVM-005-运行时数据区-虚拟机栈","text":"概述官方：https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5.2 背景由于跨平台性的设计，Java的指令都是根据栈来设计的。不同平台CPU架构不同，所以不能设计为基于寄存器的。 优点是跨平台，指令集小，编译器容易实现，缺点是性能下降，实现同样的功能需要更多的指令。 内存中的栈与堆栈是运行时的单位，而堆是存储的单位。 栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。 堆解决的是数据存储的问题，即数据怎么放、放在哪里。 虚拟机栈基本内容Java虚拟机栈是什么？ Java虚拟机栈（Java Virtual Machine Stack），早期也叫Java栈。 每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧（Stack Frame），对应着一次次的Java方法调用。 Java虚拟机栈和PC寄存器一样，是线程私有的。 生命周期生命周期和线程一致，线程结束了，该虚拟机栈也就销毁了 作用主管Java程序的运行，它保存方法的局部变量（8 种基本数据类型、引用数据类型对象的引用地址）、部分结果，并参与方法的调用和返回。 扩展： 局部变量是与成员变量（或属性）进行比较的 基本数据变量是与引用类型变量（类、数组、接口）进行比较的 栈的特点 栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器。 JVM直接对Java栈的操作只有两个： 每个方法执行，伴随着进栈（入栈、压栈） 执行结束后的出栈操作 对于栈来说不存在垃圾回收（GC）问题，但是会有内存溢出（OOM）问题 栈中可能出现的异常Java 虚拟机规范允许Java栈的大小是动态的或者是固定不变的。 如果采用固定大小的Java虚拟机栈，那每一个线程的Java虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过Java虚拟机栈允许的最大容量，Java虚拟机将会抛出一个StackoverflowError（内存溢出） 异常。 如果Java虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那Java虚拟机将会抛出一个 OutofMemoryError（内存溢出） 异常。 设置栈内存的大小官方：https://docs.oracle.com/en/java/javase/11/tools/java.html#GUID-3B1CE181-CD30-4178-9602-230B800D4FAE 可以使用参数 -Xss 选项来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度。 123-Xss1m-Xss1024k-Xss1048576 例如： 12345678910111213141516171819package com.buubiu;/** * @comment: * @author: buubiu * @create: 2022/5/26 16:06 * * 默认情况下： count：10824 * 设置栈的大小：-Xss256k : count: 1875 */public class StackErrorTest { private static int count = 1; public static void main(String[] args) { System.out.println(count); count++; main(args); }} 栈的存储单位栈中存储什么？ 每个线程都有自己的栈，栈中的数据都是以栈帧（Stack Frame）的格式存在，或者说栈帧是栈中的基本单位。 在这个线程上正在执行的每个方法都是各自对应一个栈帧，或者说 方法和栈帧是一一对应的关系。 栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息。 栈运行原理 JVM 直接对 Java 栈的操作只有两个，就是对栈的 压栈和出栈，遵循“先进后出”或者“后进先出”原则。 在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧（栈顶栈帧）是有效的，这个栈帧被称为当前栈帧（Current Frame），与当前栈帧相对应的方法就是当前方法（Current Method），定义这个方法的类就是当前类（Current Class）。 执行引擎运行的所有字节码指令只针对当前栈帧进行操作。 如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，成为新的当前栈帧。 不同线程中所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧中引用另外一个线程的栈帧。 如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为当前栈帧。 Java 方法有两种返回函数的方式，不管使用哪种方式，都会导致栈帧被弹出。 一种是正常的函数返回，使用return 指令，详见正常完成出口 另一种是抛出异常，详见异常完成出口 栈帧的内部结构每个栈帧中存储着： 局部变量表（Local Variables） 操作数栈（Operand Stack）（或表达式栈） 动态链接（Dynamic Linking)（或指向运行时常量池的方法引用） 方法返回地址（Return Address）（或方法正常退出或者异常退出的定义） 一些附加信息 有时候 把 方法返回地址、动态链接、一些附加信息 统称为 帧数据区","link":"/JVM-005-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/"},{"title":"JVM-006-运行时数据区-虚拟机栈-局部变量表（Local Variables）","text":"定义 局部变量表也被称之为局部变量数组或本地变量表 定义为一个数字数组，主要用于存储方法参数和定义在方法体内的局部变量，这些数据类型包括各类基本数据类型、对象引用（reference），以及returnAddress返回值类型。 由于局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题 局部变量表所需的容量大小是在编译期确定下来的，并保存在方法的Code属性的maximum local variables数据项中。在方法运行期间是不会改变局部变量表的大小的。 可以通过反编译（javap -v XXX.class）或者 jclasslib 插件看到： 方法嵌套调用的次数由栈的大小决定。一般来说，栈越大，方法嵌套调用次数越多。对一个函数而言，它的参数和局部变量越多，使得局部变量表越膨胀，它的栈帧就越大，以满足方法调用所需传递的信息增大的需求。进而函数调用就会占用更多的栈空间，导致其嵌套调用次数就会减少。 局部变量表中的变量只在当前方法调用中有效。在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁。 举例java源码： LocalVariablesTest.java123456789101112131415package com.buubiu;/** * @comment: * @author: buubiu * @create: 2022/5/30 13:50 */public class LocalVariablesTest { public static void main(String[] args) { LocalVariablesTest test = new LocalVariablesTest(); int num = 0; System.out.println(num); }} 反编译后的字节码（只看main方法）： 12345678910111213141516171819202122232425public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: new #2 // class com/buubiu/LocalVariablesTest 3: dup 4: invokespecial #3 // Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: iconst_0 9: istore_2 10: getstatic #4 // Field java/lang/System.out:Ljava/io/PrintStream; 13: iload_2 14: invokevirtual #5 // Method java/io/PrintStream.println:(I)V 17: return LineNumberTable: line 11: 0 line 12: 8 line 13: 10 line 14: 17 LocalVariableTable: Start Length Slot Name Signature 0 18 0 args [Ljava/lang/String; 8 10 1 test Lcom/buubiu/LocalVariablesTest; 10 8 2 num I 插件jclasslib显示（只看main方法）： main方法 code LineNumberTable（行号表）：字节码指令的行号与java源码的行号对应关系 LocalVariableTable（局部变量表） Start PC 与 Length 一起组成了参数作用域范围： ​ 1. 一般当这个参数定义好后，从下一行开始就是作用域的开始 ​ 2. Start PC：字节码指令起始行号 ​ 3. Length：从字节码起始行号开始算，字节码指令的长度 4. Start PC + Length = 字节码总行数（18） 比如：参数 num ​ 1. 定义num参数后的下一行字节码指令行号是10，所以Start PC 为 10 ​ 2. 由于方法总共长度为18，所以 Length = 18-10 = 8 槽 Slot概念与使用 参数值的存放总是从局部变量数组索引 0 的位置开始，到数组长度-1的索引结束。 局部变量表，最基本的存储单元是Slot（变量槽） 局部变量表中存放编译期可知的各种基本数据类型（8种），引用类型（reference），returnAddress类型的变量。 在局部变量表里，32位以内的类型只占用一个 slot（包括引用类型和returnAddress类型），64位的类型（long和double）占有两个slot。 byte、short、char、float 在存储前被转换为int，boolean 也被转换为 int，0表示false，非0表示true。 long 和 double 则占用两个 slot JVM会为局部变量表中的每一个Slot都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值 当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会 按照顺序被复制 到局部变量表中的每一个 Slot 上 如果需要访问局部变量表中一个64bit的局部变量值时，只需要使用前一个索引即可。（比如下图：访问long或double类型变量时，使用索引为 1 或 4，而不是 2 或 5 如果当前栈帧是由构造方法（或者叫构造器init()，方法名是类名）或者实例方法（非静态的方法）创建的，那么 该对象中引用的 this 将会存放在 index 为 0 的 slot 处，其余的参数按照参数表顺序继续排列赋值。 由上述可得，为什么static静态方法中无法使用this变量 因为：this 变量不存在于 static 修饰的方法的局部变量表中！ Slot 的重复利用栈帧中的局部变量表中的槽位（Slot）是可以重复利用的 如果一个局部变量过了其作用域，那么在其作用域之后声明的新的局部变量就很可能会复用过期局部变量的槽位，从而 达到节省资源的目的。 123456789public void test4() { int a = 0; { int b = 0; b = a + 1; } //变量c使用之前已经销毁的变量b占据的slot的位置 int c = a + 1; } 静态变量与局部变量的对比 参数表分配完毕之后，再根据方法体内定义的变量的顺序和作用域分配。 我们知道类变量有两次初始化的机会，第一次是在“准备阶段”，执行系统初始化，对类变量设置零值，另一次则是在“初始化”阶段，赋予程序员在代码中定义的初始值。 和类变量初始化不同的是，局部变量表不存在系统初始化的过程，这意味着一旦定义了局部变量则必须人为的初始化，否则无法使用。 变量的分类与赋值变量的分类与赋值： 按照数据类型分 基本数据类型（8种byte、short、int、long、float、double、char、boolean） 引用数据类型（类、数组、接口、枚举） 按照在类中声明的位置分 成员变量（在方法外面的变量），在使用前，都经历过默认初始化赋值。 类变量（静态变量，static修饰的） 赋值操作：在类加载阶段中 linking 的 prepare 阶段，给类变量默认赋值，然后在 initial 阶段，给类变量显示赋值即静态代码块赋值 实例变量（非静态变量），归具体的实例对象所有，所以叫实例变量 赋值操作：随着对象的创建，会在堆空间中分配实例变量空间，并进行默认赋值 局部变量（在方法里面的变量） 赋值操作：在使用前，必须要进行显示赋值，否则，编译不通过。 例如： 1234public void test(){ int num; System.out.println(num);//报错：变量num未进行初始化。} 扩展说明 在栈帧中，与性能调优关系最为密切的部分就是前面提到的局部变量表。在方法执行时，虚拟机使用局部变量表完成方法的传递。 局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收。","link":"/JVM-006-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88-%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E8%A1%A8%EF%BC%88Local-Variables%EF%BC%89/"},{"title":"JVM-007-运行时数据区-虚拟机栈-操作数栈（Operand Stack）","text":"定义 栈的含义：先进后出，可以使用数组或链表来实现，但不具有数组或链表的特性（任意位置增删改等） 而操作数栈的含义：只是使用了数组来存储实现的栈，即按照顺序存放，有索引，但是并非采用访问索引的方式来进行数据访问的，只能通过入栈和出栈来操作数据 每一个独立的栈帧中除了包含局部变量表以外，还包含一个后进先出(Last-In-First-Out)的操作数栈，也可以称为 表达式栈(Expression Stack) 原理 操作数栈，在方法执行过程中，根据字节码指令，往栈中写入数据或者提取数据，即入栈（push）/ 出栈（pop）。 某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈， 比如：执行复制、交换、求和等操作 特点 操作数栈，主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间。 操作数栈就是JVM执行引擎的一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来，此时这个方法的操作数栈是空的。 每一个操作数栈都会拥有一个明确的栈深度用于存储数值，其所需的最大深度在编译期就定义好了(因为数组一旦创建，其长度就是确定的），保存在方法的 Code 属性中，为 max_stack 的值。 栈中的任何一个元素都可以是任意的Java数据类型 32bit的类型占用一个栈单位深度 64bit的类型占用两个栈单位深度 操作数栈并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈和出栈操作来完成一次数据访问。只不过操作数栈是用数组这个结构来实现的而已 如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中，并更新PC寄存器中下一条需要执行的字节码指令。 操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译器期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次验证。 另外，我们说Java虚拟机的解释引擎是基于栈的执行引擎，其中的栈指的就是操作数栈。 执行流程java代码： 123456public void testAddOperation() { //byte、short、char、boolean：都以int型来保存 byte i = 15; int j = 8; int k = i + j;} 字节码： 123456789 0 bipush 15 2 istore_1 3 bipush 8 5 istore_2 6 iload_1 7 iload_2 8 iadd 9 istore_310 return 执行流程 首先执行第一条语句，PC寄存器指向的是0，也就是指令地址为0，然后使用bipush让操作数15入操作数栈。 执行完后，PC寄存器往下移，指向下一行代码，下一行代码就是将操作数栈的元素存储到局部变量表1的位置（istore_1），我们可以看到局部变量表的已经增加了一个元素。并且操作数栈为空了 解释为什么局部变量表索引从 1 开始，因为该方法为实例方法，局部变量表索引为 0 的位置存放的是 this 然后PC下移，指向的是下一行。让操作数8也入栈，同时执行store操作，存入局部变量表中 然后从局部变量表中，依次将数据放在操作数栈中，等待执行 add 操作 iload_1：取出局部变量表中索引为1的数据入操作数栈 iload_2：取出局部变量表中索引为2的数据入操作数栈 然后将操作数栈中的两个元素出栈让执行引擎通过CPU执行相加操作，并存储在操作数栈中 然后在把操作数栈中的23执行store操作，并存储在局部变量表索引未3的位置 类型转换问题 因为 8 可以存放在 byte 类型中，所以压入操作数栈的类型为 byte ，而不是 int ，所以执行的字节码指令为 bipush 8，但是存储在局部变量的时候，会转成 int 类型的变量：istore_4。 m改成800之后，byte存储不了，就成了short型，sipush 800 带有返回值的方法如果被调用的方法带有返回值，返回值入操作数栈 getSum() 方法字节码指令：最后带着个 ireturn testGetSum() 方法字节码指令：一上来就加载 getSum() 方法的返回值() 栈顶缓存技术（Top Of Stack Cashing）背景基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派（instruction dispatch）次数（也就是你会发现指令很多）和导致内存读/写次数多，效率不高。 方案由于操作数是存储在内存中的，因此频繁地执行内存读/写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM的设计者们提出了栈顶缓存（Tos，Top-of-Stack Cashing）技术，将栈顶元素全部缓存在物理CPU的寄存器中，以此降低对内存的读/写次数，提升执行引擎的执行效率。 优点寄存器的主要优点：指令更少，执行速度快，但是指令集（也就是指令种类）很多","link":"/JVM-007-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88-%E6%93%8D%E4%BD%9C%E6%95%B0%E6%A0%88%EF%BC%88Operand-Stack%EF%BC%89/"},{"title":"JVM-008-运行时数据区-虚拟机栈-动态链接（Dynamic Linking）","text":"定义 动态链接，又叫指向运行时常量池的方法引用 每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用。包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接（Dynamic Linking），比如：invokedynamic 指令 作用在Java源文件被编译到字节码文件中时，所有的变量和方法引用都作为符号引用（Symbolic Reference）保存在class文件的常量池里。比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用 为什么要用常量池呢常量池的作用：就是为了提供一些符号和常量，便于指令的识别 方法的调用两种链接方式在JVM中，将符号引用转换为调用方法的直接引用与方法的绑定机制相关 静态链接当一个字节码文件被装载进JVM内部时，如果被调用的目标方法在编译期确定，且运行期保持不变时，这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接 动态链接如果被调用的方法在编译期无法被确定下来，也就是说，只能够在程序运行期将调用的方法的符号转换为直接引用，由于这种引用转换过程具备动态性，因此也被称之为动态链接。 两种方法的绑定机制对应的方法的绑定机制为：早期绑定（Early Binding）和晚期绑定（Late Binding）。绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次。 静态链接与动态链接针对的是方法。早期绑定和晚期绑定范围更广，包括字段、方法、类 早期绑定早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时（即：静态链接），即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用。 晚期绑定如果被调用的方法在编译期无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法（即：动态链接），这种绑定方式也就被称之为晚期绑定。 虚方法与非虚方法背景随着高级语言的横空出世，类似于Java一样的基于面向对象的编程语言如今越来越多，尽管这类编程语言在语法风格上存在一定的差别，但是它们彼此之间始终保持着一个共性，那就是都支持封装、继承和多态等面向对象特性，既然这一类的编程语言具备多态特性，那么自然也就具备早期绑定和晚期绑定两种绑定方式。 Java中任何一个普通的方法其实都具备虚函数的特征，它们相当于C++语言中的虚函数（C++中则需要使用关键字virtual来显式定义）。如果在Java程序中不希望某个方法拥有虚函数的特征时，则可以使用关键字final来标记这个方法。 概念非虚方法 如果方法在编译期就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为非虚方法。 静态方法、私有方法、final方法、实例构造器、父类方法都是非虚方法。 虚方法其他方法（包括自定义的方法）称为虚方法。 子类对象的多态性的使用前提： 类的继承关系 方法的重写（父类的静态方法、私有方法、final方法、实例构造器都不允许重写） 调用指令虚拟机中提供了以下几条调用指令： 普通调用指令 非虚方法 invokestatic ：调用静态方法，解析阶段确定唯一方法版本 invokespecial ：调用方法（实例构造器）、私有及父类方法，解析阶段确定唯一方法版本 虚方法 invokevirtual：调用所有虚方法（除 final 修饰的） invokeinterface：调用接口方法 动态调用指令 invokedynamic:动态解析出需要调用的方法，然后执行 前四条指令固化在虚拟机内部，方法的调用执行不可人为干预。而invokedynamic指令则支持由用户确定方法版本。其中invokestatic指令和invokespecial指令调用的方法称为非虚方法，其余的（final修饰的除外）称为虚方法。 invokedynamic说明 JVM字节码指令集一直比较稳定，一直到Java7中才增加了一个invokedynamic指令，这是Java为了实现【动态类型语言】支持而做的一种改进。 但是在Java7中并没有提供直接生成invokedynamic指令的方法，需要借助ASM这种底层字节码工具来产生invokedynamic指令。直到Java8的Lambda表达式的出现，invokedynamic指令的生成，在Java中才有了直接的生成方式。 Java7中增加的动态语言类型支持的本质是对Java虚拟机规范的修改，而不是对Java语言规则的修改，这一块相对来讲比较复杂，增加了虚拟机中的方法调用，最直接的受益者就是运行在Java平台的动态语言的编译器。 动态类型语言和静态类型语言 动态类型语言和静态类型语言两者的区别就在于对类型的检查是在编译期还是在运行期，满足前者就是静态类型语言，反之是动态类型语言。 说的再直白一点就是，静态类型语言是判断变量自身的类型信息；动态类型语言是判断变量值的类型信息，变量没有类型信息，变量值才有类型信息，这是动态语言的一个重要特征。 所以，Java是静态类型语言的，会先编译就进行类型检查，而JS，python是动态类型语言。 方法重写的本质Java语言中方法重写的本质 先找到操作数栈顶的第一个元素所执行的对象的实际类型，记作C（即把调用的对象先压入栈，再去找重写方法） 如果在类型C中找到与常量中的描述符和简单名称都相符的方法（即在入栈的对象类中找到了要重写方法），则进行访问权限校验。 如果通过则返回这个方法的直接引用，查找过程结束（即找到了重写方法） 如果不通过，则返回java.lang.IllegalAccessError 异常（非法访问，即调用了父类不能重写的方法） 否则，按照继承关系从下往上依次对C的各个父类进行第2步的搜索和验证过程。 如果始终没有找到合适的方法，则抛出java.lang.AbstractMethodError异常。（说明调用的这个方法没有被重写，即这个方法肯定是个抽象方法） IllegalAccessError介绍程序试图访问或修改一个属性或调用一个方法，这个属性或方法，你没有权限访问。一般的，这个会引起编译器异常。这个错误如果发生在运行时，就说明一个类发生了不兼容的改变。 虚方法表 在面向对象的编程中，会很频繁的使用到动态分派（即：上面的方法重写的本质），如果在每次动态分派的过程中都要重新在类的方法元数据中搜索合适的目标的话就可能影响到执行效率。因此，为了提高性能，JVM采用在类的方法区建立一个虚方法表（virtual method table）来实现，非虚方法不会出现在表中。使用索引表来代替查找。 每个类中都有一个虚方法表，表中存放着各个方法的实际入口。 虚方法表是什么时候被创建的呢？ 虚方法表会在类加载的链接阶段被创建并开始初始化，类的变量初始值准备完成之后，JVM会把该类的虚方法表也初始化完毕。","link":"/JVM-008-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88-%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%EF%BC%88Dynamic-Linking%EF%BC%89/"},{"title":"Java基础知识 Java概述篇","text":"何为编程编程就是让计算机为解决某个问题而使用某种程序设计语言编写程序代码,并最终得到结果的过程。 为了使计算机能够理解人的意图,人类就必须要将需解决的问题的思路、方法、和手段通过计算机能够理解的形式告诉计算机,使得计算机能够根据人的指令一步一步去工作,完成某种特定的任务。这种人和计算机之间交流的过程就是编程。 什么是 JavaJava 是一门面向对象编程语言,不仅吸收了 C++ 语言的各种优点,还摒弃了 C++ 里难以理解的多继承、指针等概念,因此 Java 语言具有功能强大和简单易用两个特征。 Java 语言作为静态面向对象编程语言的代表,极好地实现了面向对象理论,允许程序员以优雅的思维方式进行复杂的编程。 jdk1.5 之后的三大版本 Java SE(J2SE,Java 2 Platform Standard Edition,标准版)Java SE 以前称为 J2SE。它允许开发和部署在桌面、服务器、嵌入式环境和实时环境中使用的 Java 应用程序。Java SE 包含了支持 Java Web 服务开发的类,并为 Java EE 和 Java ME 提供基础。 Java EE(J2EE,Java 2 Platform Enterprise Edition,企业版)Java EE以前称为J2EE。企业版本帮助开发和部署可移植、健壮、可伸缩且安全的服务器端Java应用程序。Java EE是在Java SE的基础上构建的,它提供Web服务、组件模型、管理和通信 API,可以用来实现企业级的面向服务体系结构(service-oriented architecture,SOA)和Web2.0应用程序。2018 年 2 月,Eclipse宣布正式将JavaEE更名为JakartaEE. Java ME(J2ME,Java 2 Platform Micro Edition,微型版)Java ME以前称为 J2ME。Java ME为在移动设备和嵌入式设备(比如手机、PDA、电视机顶盒和打印机)上运行的应用程序提供一个健壮且灵活的环境。Java ME包括灵活的用户界面、健壮的安全模型、许多内置的网络协议以及对可以动态下载的连网和离线应用程序的丰富支持。基于Java ME规范的应用程序只需编写一次,就可以用于许多设备,而且可以利用每个设备的本机功能。 JVM、JRE 和 JDK 的关系JVMJava Virtual Machine是 Java 虚拟机,Java 程序需要运行在虚拟机上,不同的平台有自己的虚拟机,因此 Java 语言可以实现跨平台。 JREJava Runtime Environment 包括 Java 虚拟机和 Java 程序所需的核心类库等。核心类库主要是 java.lang 包:包含了运行 Java 程序必不可少的系统类,如基本数据类型、基本数学函数、字符串处理、线程、异常处理类等,系统缺省加载这个包。 如果想要运行一个开发好的 Java 程序,计算机中只需要安装 JRE 即可。 JDKJava Development Kit 是提供给 Java 开发人员使用的,其中包含了 Java 的开发工具,也包括了 JRE。所以安装了 JDK,就无需再单独安装 JRE 了。其中的开发工具:编译工具(javac.exe),打包工具(jar.exe)等。 JVM&amp;JRE&amp;JDK 关系图 什么是跨平台性？原理是什么所谓跨平台性,是指 java 语言编写的程序,一次编译后,可以在多个系统平台上运行。 实现原理: Java 程序是通过 java 虚拟机在系统平台上运行的,只要该系统可以安装相应的 java 虚拟机,该系统就可以运行 java 程序。 Java 语言有哪些特点 简单易学(Java 语言的语法与 C 语言和 C++语言很接近) 面向对象(封装,继承,多态) 平台无关性(Java 虚拟机实现平台无关性) 支持网络编程并且很方便(Java 语言诞生本身就是为简化网络编程设计的) 支持多线程(多线程机制使应用程序在同一时间并行执行多项任务) 健壮性(Java 语言的强类型机制、异常处理、垃圾的自动收集等) 安全性 什么是字节码？采用字节码的最大好处是什么?字节码: Java 源代码经过虚拟机编译器编译后产生的文件(即扩展为.class的文件),它不面向任何特定的处理器,只面向虚拟机。 采用字节码的好处:Java 语言通过字节码的方式,在一定程度上解决了传统解释型语言执行效率低的问题,同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效,而且,由于字节码并不专对一种特定的机器,因此,Java 程序无须重新编译便可在多种不同的计算机上运行。 java 中的编译器和解释器:Java 中引入了虚拟机的概念,即在机器和编译程序之间加入了一层抽象的虚拟机器。这台虚拟的机器在任何平台上都提供给编译程序一个的共同的接口。编译程序只需要面向虚拟机,生成虚拟机能够理解的代码,然后由解释器来将虚拟机代码转换为特定系统的机器码执行。在 Java 中,这种供虚拟机理解的代码叫做字节码(即扩展为.class 的文件),它不面向任何特定的处理器,只面向虚拟机。每一种平台的解释器是不同的,但是实现的虚拟机是相同的。Java 源程序经过编译器编译后变成字节码,字节码由虚拟机解释执行,虚拟机将每一条要执行的字节码送给解释器,解释器将其翻译成特定机器上的机器码,然后在特定的机器上运行,这就是上面提到的 Java 的特点的编译与解释并存的解释。 1Java源代码----&gt;编译器----&gt;jvm可执行的Java字节码(即虚拟指令)----&gt;jvm----&gt;jvm中解释器-----&gt;机器可执行的二进制机器码----&gt;程序运行。 什么是 Java 程序的主类？应用程序和小程序的主类有何不同？一个程序中可以有多个类,但只能有一个类是主类。在 Java 应用程序中,这个主类是指包含main()方法的类。而在 Java 小程序中,这个主类是一个继承自系统类 JApplet 或 Applet 的子类。应用程序的主类不一定要求是 public 类,但小程序的主类要求必须是 public 类。主类是 Java 程序执行的入口点。 Java 应用程序与小程序之间有那些差别？简单说应用程序是从主线程启动(也就是 main()方法)。applet 小程序没有 main 方法,主要是嵌在浏览器页面上运行(调用 init()线程或者 run()来启动),嵌入浏览器这点跟 flash 的小游戏类似。 Java 和 C++的区别我知道很多人没学过 C++,但是面试官就是没事喜欢拿咱们 Java 和 C++比呀!没办法!!!就算没学过 C++,也要记下来！ 都是面向对象的语言,都支持封装、继承和多态 Java 不提供指针来直接访问内存,程序内存更加安全 Java 的类是单继承的,C++支持多重继承；虽然 Java 的类不可以多继承,但是接口可以多继承。 Java 有自动内存管理机制,不需要程序员手动释放无用内存 Oracle JDK 和 OpenJDK 的对比 Oracle JDK版本将每三年发布一次,而OpenJDK版本每三个月发布一次； OpenJDK是一个参考模型并且是完全开源的,而Oracle JDK是OpenJDK的一个实现,并不是完全开源的； Oracle JDK比OpenJDK更稳定。OpenJDK和Oracle JDK的代码几乎相同,但Oracle JDK有更多的类和一些错误修复。因此,如果您想开发企业/商业软件,我建议您选择Oracle JDK,因为它经过了彻底的测试和稳定。某些情况下,有些人提到在使用OpenJDK可能会遇到了许多应用程序崩溃的问题,但是,只需切换到Oracle JDK就可以解决问题； 在响应性和JVM性能方面,Oracle JDK与OpenJDK相比提供了更好的性能； Oracle JDK不会为即将发布的版本提供长期支持,用户每次都必须通过更新到最新版本获得支持来获取最新版本； Oracle JDK根据二进制代码许可协议获得许可,而OpenJDK根据GPL v2许可获得许可。 参考：https://blog.csdn.net/ThinkWon","link":"/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-Java%E6%A6%82%E8%BF%B0%E7%AF%87/"},{"title":"Java基础知识 基础语法-IO流","text":"java 中 IO 流分为几种? 按照流的流向分，可以分为输入流和输出流； 按照操作单元划分，可以划分为字节流和字符流； 按照流的角色划分为节点流和处理流。 Java IO 流共涉及 40 多个类，这些类看上去很杂乱，但实际上很有规则，而且彼此之间存在非常紧密的联系， Java IO 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。 InputStream/Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。 OutputStream/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。 按操作方式分类结构图： 按操作对象分类结构图： BIO,NIO,AIO 有什么区别?简答 BIO： Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力低。 NIO： Non IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路复用。 AIO： Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调机制。 详细回答 BIO (Blocking I/O): 同步阻塞 I/O 模式，数据的读取写入必须阻塞在一个线程内等待其完成。在活动连接数不是特别高（小于单机 1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。 NIO (New I/O): NIO 是一种同步非阻塞的 I/O 模型，在 Java 1.4 中引入了 NIO 框架，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它支持面向缓冲的，基于通道的 I/O 操作方法。 NIO 提供了与传统 BIO 模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞 I/O 来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发 AIO (Asynchronous I/O): AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的 IO 模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。AIO 是异步 IO 的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO 操作本身是同步的。查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。 Files 的常用方法都有哪些？ Files.exists()：检测文件路径是否存在。 Files.createFile()：创建文件。 Files.createDirectory()：创建文件夹。 Files.delete()：删除一个文件或目录。 Files.copy()：复制文件。 Files.move()：移动文件。 Files.size()：查看文件个数。 Files.read()：读取文件。 Files.write()：写入文件。 参考：https://blog.csdn.net/ThinkWon","link":"/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95-IO%E6%B5%81/"},{"title":"Java基础知识 基础语法-反射","text":"什么是反射机制？JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 java 语言的反射机制。 静态编译和动态编译 静态编译： 在编译时确定类型，绑定对象 动态编译： 运行时确定类型，绑定对象 反射机制优缺点 优点： 运行期类型的判断，动态加载类，提高代码灵活度。 缺点： 性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的 java 代码要慢很多。 反射机制的应用场景有哪些？反射是框架设计的灵魂。 在我们平时的项目开发过程中，基本上很少会直接使用到反射机制，但这不能说明反射机制没有用，实际上有很多设计、开发都与反射机制有关，例如模块化的开发，通过反射去调用对应的字节码；动态代理设计模式也采用了反射机制，还有我们日常使用的 Spring／Hibernate 等框架也大量使用到了反射机制。 举例： 我们在使用 JDBC 连接数据库时使用 Class.forName()通过反射加载数据库的驱动程序； Spring 框架也用到很多反射机制，最经典的就是 xml 的配置模式。Spring 通过 XML 配置模式装载 Bean 的过程： 将程序内所有 XML 或 Properties 配置文件加载入内存中; Java 类里面解析 xml 或 properties 里面的内容，得到对应实体类的字节码字符串以及相关的属性信息; 使用反射机制，根据这个字符串获得某个类的 Class 实例; 动态配置实例的属性 Java 获取反射的三种方法 通过 new 对象实现反射机制 通过路径实现反射机制 通过类名实现反射机制 123456public class Student { private int id; String name; protected boolean sex; public float score;} 123456789101112131415public class Get { //获取反射机制三种方式 public static void main(String[] args) throws ClassNotFoundException { //方式一(通过建立对象) Student stu = new Student(); Class classobj1 = stu.getClass(); System.out.println(classobj1.getName()); //方式二（所在通过路径-相对路径） Class classobj2 = Class.forName(&quot;fanshe.Student&quot;); System.out.println(classobj2.getName()); //方式三（通过类名） Class classobj3 = Student.class; System.out.println(classobj3.getName()); }} 参考：https://blog.csdn.net/ThinkWon","link":"/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95-%E5%8F%8D%E5%B0%84/"},{"title":"Java基础知识 基础语法-常用API","text":"String 相关字符型常量和字符串常量的区别 形式上: 字符常量是单引号引起的一个字符 字符串常量是双引号引起的若干个字符 含义上: 字符常量相当于一个整形值(ASCII 值),可以参加表达式运算 字符串常量代表一个地址值(该字符串在内存中存放位置) 占内存大小 字符常量只占一个字节 字符串常量占若干个字节(至少一个字符结束标志) 什么是字符串常量池？ 字符串常量池位于堆内存中，专门用来存储字符串常量，可以提高内存的使用率，避免开辟多块空间存储相同的字符串，在创建字符串时 JVM 会首先检查字符串常量池，如果该字符串已经存在池中，则返回它的引用，如果不存在，则实例化一个字符串放到池中，并返回其引用。 String 是最基本的数据类型吗 不是。Java 中的基本数据类型只有 8 个 ：byte、short、int、long、float、double、char、boolean；除了基本类型（primitive type），剩下的都是引用类型（referencetype），Java 5 以后引入的枚举类型也算是一种比较特殊的引用类型。 这是很基础的东西，但是很多初学者却容易忽视，Java 的 8 种基本数据类型中不包括 String，基本数据类型中用来描述文本数据的是 char，但是它只能表示单个字符，比如 ‘a’,‘好’ 之类的，如果要描述一段文本，就需要用多个 char 类型的变量，也就是一个 char 类型数组，比如“你好” 就是长度为 2 的数组 char[] chars = {‘你’,‘好’}; 但是使用数组过于麻烦，所以就有了 String，String 底层就是一个 char 类型的数组，只是使用的时候开发者不需要直接操作底层数组，用更加简便的方式即可完成对字符串的使用。 String 有哪些特性 不变性： String 是只读字符串，是一个典型的 immutable 对象，对它进行任何操作，其实都是创建一个新的对象，再把引用指向该对象。不变模式的主要作用在于当一个对象需要被多线程共享并频繁访问时，可以保证数据的一致性。 常量池优化： String 对象创建之后，会在字符串常量池中进行缓存，如果下次创建同样的对象时，会直接返回缓存的引用。 final： 使用 final 来定义 String 类，表示 String 类不能被继承，提高了系统的安全性。 String 为什么是不可变的吗？ 简单来说就是 String 类利用了 final 修饰的 char 类型数组存储字符，源码如下图所以： 12/** The value is used for character storage. */private final char value[]; String 真的是不可变的吗？ 我觉得如果别人问这个问题的话，回答不可变就可以了。 下面只是给大家看两个有代表性的例子： 1) String 不可变但不代表引用不可以变 123String str = &quot;Hello&quot;;str = str + &quot; World&quot;;System.out.println(&quot;str=&quot; + str); 结果： 1str=Hello World 解析： 实际上，原来 String 的内容是不变的，只是 str 由原来指向”Hello”的内存地址转为指向”Hello World”的内存地址而已，也就是说多开辟了一块内存区域给”Hello World”字符串。 2) 通过反射是可以修改所谓的“不可变”对象 123456789101112131415161718// 创建字符串&quot;Hello World&quot;， 并赋给引用sString s = &quot;Hello World&quot;;System.out.println(&quot;s = &quot; + s); // Hello World// 获取String类中的value字段Field valueFieldOfString = String.class.getDeclaredField(&quot;value&quot;);// 改变value属性的访问权限valueFieldOfString.setAccessible(true);// 获取s对象上的value属性的值char[] value = (char[]) valueFieldOfString.get(s);// 改变value所引用的数组中的第5个字符value[5] = '_';System.out.println(&quot;s = &quot; + s); // Hello_World 结果： 12s = Hello Worlds = Hello_World 解析： 用反射可以访问私有成员， 然后反射出 String 对象中的 value 属性， 进而改变通过获得的 value 引用改变数组的结构。但是一般我们不会这么做，这里只是简单提一下有这个东西。 是否可以继承 String 类 String 类是 final 类，不可以被继承。 String str=”i”与 String str=new String(“i”)一样吗？ 不一样，因为内存的分配方式不一样。String str=”i”的方式，java 虚拟机会将其分配到常量池中；而 String str=new String(“i”) 则会被分到堆内存中。 String s = new String(“xyz”);创建了几个字符串对象 两个对象，一个是静态区的”xyz”，一个是用 new 创建在堆上的对象。 123456789101112String str1 = &quot;hello&quot;; //str1指向静态区String str2 = new String(&quot;hello&quot;); //str2指向堆上的对象String str3 = &quot;hello&quot;;String str4 = new String(&quot;hello&quot;);System.out.println(str1.equals(str2)); //trueSystem.out.println(str2.equals(str4)); //trueSystem.out.println(str1 == str3); //trueSystem.out.println(str1 == str2); //falseSystem.out.println(str2 == str4); //falseSystem.out.println(str2 == &quot;hello&quot;); //falsestr2 = str1;System.out.println(str2 == &quot;hello&quot;); //true 如何将字符串反转？ 使用 StringBuilder 或者 stringBuffer 的 reverse() 方法。 示例代码： 12345678// StringBuffer reverseStringBuffer stringBuffer = new StringBuffer();stringBuffer. append(&quot;abcdefg&quot;);System. out. println(stringBuffer. reverse()); // gfedcba// StringBuilder reverseStringBuilder stringBuilder = new StringBuilder();stringBuilder. append(&quot;abcdefg&quot;);System. out. println(stringBuilder. reverse()); // gfedcba 数组有没有 length()方法？String 有没有 length()方法 数组没有 length()方法 ，有 length 的属性。String 有 length()方法。JavaScript 中，获得字符串的长度是通过 length 属性得到的，这一点容易和 Java 混淆。 String 类的常用方法都有那些？ indexOf()：返回指定字符的索引。 charAt()：返回指定索引处的字符。 replace()：字符串替换。 trim()：去除字符串两端空白。 split()：分割字符串，返回一个分割后的字符串数组。 getBytes()：返回字符串的 byte 类型数组。 length()：返回字符串长度。 toLowerCase()：将字符串转成小写字母。 toUpperCase()：将字符串转成大写字符。 substring()：截取字符串。 equals()：字符串比较。 在使用 HashMap 的时候，用 String 做 key 有什么好处？ HashMap 内部实现是通过 key 的 hashcode 来确定 value 的存储位置，因为字符串是不可变的，所以当创建字符串时，它的 hashcode 被缓存下来，不需要再次计算，所以相比于其他对象更快。 String 和 StringBuffer、StringBuilder 的区别是什么？String 为什么是不可变的 可变性 String 类中使用字符数组保存字符串，private final char value[]，所以 string 对象是不可变的。StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串，char[] value，这两种对象都是可变的。 线程安全性 String 中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder 是 StringBuilder 与 StringBuffer 的公共父类，定义了一些字符串的基本操作，如 expandCapacity、append、insert、indexOf 等公共方法。StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。 性能 每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StirngBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 对于三者使用的总结 如果要操作少量的数据用 = String 单线程操作字符串缓冲区 下操作大量数据 = StringBuilder 多线程操作字符串缓冲区 下操作大量数据 = StringBuffer Date 相关 待补充 包装类相关自动装箱与拆箱 装箱： 将基本类型用它们对应的引用类型包装起来； 拆箱： 将包装类型转换为基本数据类型； int 和 Integer 有什么区别 Java 是一个近乎纯洁的面向对象编程语言，但是为了编程的方便还是引入了基本数据类型，但是为了能够将这些基本数据类型当成对象操作，Java 为每一个基本数据类型都引入了对应的包装类型（wrapper class），int 的包装类就是 Integer，从 Java 5 开始引入了自动装箱/拆箱机制，使得二者可以相互转换。 Java 为每个原始类型提供了包装类型： 原始类型: boolean，char，byte，short，int，long，float，double 包装类型：Boolean，Character，Byte，Short，Integer，Long，Float，Double Integer a= 127 与 Integer b = 127 相等吗 对于对象引用类型：==比较的是对象的内存地址。对于基本数据类型：==比较的是值。 如果整型字面量的值在-128 到 127 之间，那么自动装箱时不会 new 新的 Integer 对象，而是直接引用常量池中的 Integer 对象。 123456789101112131415public static void main(String[] args) { Integer a = new Integer(3); Integer b = 3; // 将3自动装箱成Integer类型 int c = 3; System.out.println(a == b); // false 两个引用没有引用同一对象 System.out.println(a == c); // true a自动拆箱成int类型再和c比较 System.out.println(b == c); // true Integer a1 = 128; Integer b1 = 128; System.out.println(a1 == b1); // false Integer a2 = 127; Integer b2 = 127; System.out.println(a2 == b2); // true 解析： 因为 a1、b1 超过范围，所以 a1==b1 的结果是 false 参考：https://blog.csdn.net/ThinkWon","link":"/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95-%E5%B8%B8%E7%94%A8API/"},{"title":"Java基础知识 基础语法-数据类型","text":"Java 有哪些数据类型定义： Java 语言是强类型语言，对于每一种数据都定义了明确的具体的数据类型，在内存中分配了不同大小的内存空间。 分类 基本数据类型 数值型 整数类型(byte,short,int,long) 浮点类型(float,double) 字符型(char) 布尔型(boolean) 引用数据类型 类(class) 接口(interface) 数组([]) Java 基本数据类型图 switch 是否能作用在 byte 上，是否能作用在 long 上，是否能作用在 String 上 在 Java 5 以前，switch(expr)中，expr 只能是 byte、short、char、int。从 Java5 开始，Java 中引入了枚举类型，expr 也可以是 enum 类型，从 Java 7 开始，expr 还可以是字符串（String），但是长整型（long）在目前所有的版本中都是不可以的。 用最有效率的方法计算 2 乘以 8 2 &lt;&lt; 3（左移 3 位相当于乘以 2 的 3 次方，右移 3 位相当于除以 2 的 3 次方）。 Math.round(11.5) 等于多少？Math.round(-11.5)等于多少 Math.round(11.5)的返回值是 12，Math.round(-11.5)的返回值是-11。四舍五入的原理是在参数上加 0.5 然后进行下取整。 float f=3.4;是否正确 不正确。3.4 是双精度数，将双精度型（double）赋值给浮点型（float）属于下转型（down-casting，也称为窄化）会造成精度损失，因此需要强制类型转换 float f =(float)3.4; 或者写成 float f =3.4F;。 short s1 = 1; s1 = s1 + 1;有错吗?short s1 = 1; s1 += 1;有错吗 对于 short s1 = 1; s1 = s1 + 1;由于 1 是 int 类型，因此 s1+1 运算结果也是 int 型，需要强制转换类型才能赋值给 short 型。 而 short s1 = 1; s1 += 1;可以正确编译，因为 s1+= 1;相当于 s1 = (short(s1 + 1);其中有隐含的强制类型转换。 编码Java 语言采用何种编码方案？有何特点？ Java 语言采用 Unicode 编码标准，Unicode（标准码），它为每个字符制订了一个唯一的数值，因此在任何的语言，平台，程序都可以放心的使用。 注释什么是 Java 注释 定义： 用于解释说明程序的文字 分类 单行注释格式： // 注释文字 多行注释格式： /* 注释文字 */ 文档注释格式：/** 注释文字 */ 作用 在程序中，尤其是复杂的程序中，适当地加入注释可以增加程序的可读性，有利于程序的修改、调试和交流。注释的内容在程序编译的时候会被忽视，不会产生目标代码，注释的部分不会对程序的执行结果产生任何影响。 注意事项：多行和文档注释都不能嵌套使用。 访问修饰符访问修饰符 public,private,protected,以及不写（默认）时的区别 定义： Java 中，可以使用访问修饰符来保护对类、变量、方法和构造方法的访问。Java 支持 4 种不同的访问权限。 分类 private : 在同一类内可见。使用对象：变量、方法。 注意：不能修饰类（外部类） default (即缺省，什么也不写，不使用任何关键字）: 在同一包内可见，不使用任何修饰符。使用对象：类、接口、变量、方法。 protected : 对同一包内的类和所有子类可见。使用对象： 变量、方法。 注意：不能修饰类（外部类）。 public : 对所有类可见。使用对象：类、接口、变量、方法 访问修饰符图 运算符&amp;和&amp;&amp;的区别 &amp;运算符有两种用法：(1)按位与；(2)逻辑与。 &amp;&amp;运算符是短路与运算。逻辑与跟短路与的差别是非常巨大的，虽然二者都要求运算符左右两端的布尔值都是 true 整个表达式的值才是 true。&amp;&amp;之所以称为短路运算，是因为如果&amp;&amp;左边的表达式的值是 false，右边的表达式会被直接短路掉，不会进行运算。 注意：逻辑或运算符（|）和短路或运算符（||）的差别也是如此。 关键字Java 有没有 goto goto 是 Java 中的保留字，在目前版本的 Java 中没有使用。 final 有什么用？ 用于修饰类、属性和方法； 被 final 修饰的类不可以被继承 被 final 修饰的方法不可以被重写 被 final 修饰的变量不可以被改变，被 final 修饰不可变的是变量的引用，而不是引用指向的内容，引用指向的内容是可以改变的 final finally finalize 区别 final 可以修饰类、变量、方法，修饰类表示该类不能被继承、修饰方法表示该方法不能被重写、修饰变量表示该变量是一个常量不能被重新赋值。 finally 一般作用在 try-catch 代码块中，在处理异常的时候，通常我们将一定要执行的代码方法 finally 代码块中，表示不管是否出现异常，该代码块都会执行,一般用来存放一些关闭资源的代码。 finalize 是一个方法，属于 Object 类的一个方法，而 Object 类是所有类的父类，该方法一般由垃圾回收器来调用，当我们调用 System.gc() 方法的时候，由垃圾回收器调用 finalize()回收垃圾，一个对象是否可回收的最后判断。 this 关键字的用法 this 是自身的一个对象，代表对象本身，可以理解为：指向对象本身的一个指针。 this 的用法在 java 中大体可以分为 3 种： 普通的直接引用，this 相当于是指向当前对象本身。 形参与成员名字重名，用 this 来区分： 1234public Person(String name, int age) { this.name = name; this.age = age;} 引用本类的构造函数 123456789101112131415class Person{ private String name; private int age; public Person() { } public Person(String name) { this.name = name; } public Person(String name, int age) { this(name); this.age = age; }} super 关键字的用法 super 可以理解为是指向自己超（父）类对象的一个指针，而这个超类指的是离自己最近的一个父类。 super 也有三种用法： 普通的直接引用 与 this 类似，super 相当于是指向当前对象的父类的引用，这样就可以用 super.xxx 来引用父类的成员。 子类中的成员变量或方法与父类中的成员变量或方法同名时，用 super 进行区分 12345678910111213141516171819202122232425262728293031class Person{ protected String name; public Person(String name) { this.name = name; }}class Student extends Person{ private String name; public Student(String name, String name1) { super(name); this.name = name1; } public void getInfo(){ System.out.println(this.name); //Child System.out.println(super.name); //Father }}public class Test { public static void main(String[] args) { Student s1 = new Student(&quot;Father&quot;,&quot;Child&quot;); s1.getInfo(); }} 引用父类构造函数 super（参数）：调用父类中的某一个构造函数（应该为构造函数中的第一条语句）。 this（参数）：调用本类中另一种形式的构造函数（应该为构造函数中的第一条语句） this 与 super 的区别 super:它引用当前对象的直接父类中的成员（用来访问直接父类中被隐藏的父类中成员数据或函数，基类与派生类中有相同成员定义时如：super.变量名 super.成员函数数据名（实参） this:它代表当前对象名（在程序中易产生二义性之处，应使用 this 来指明当前对象；如果函数的形参与类中的成员数据同名，这时需用 this 来指明成员变量名） super()和 this()类似,区别是，super()在子类中调用父类的构造方法，this()在本类内调用本类的其它构造方法。 super()和 this()均需放在构造方法内第一行。 尽管可以用 this 调用一个构造器，但却不能调用两个。 this 和 super 不能同时出现在一个构造函数里面，因为 this 必然会调用其它的构造函数，其它的构造函数必然也会有 super 语句的存在，所以在同一个构造函数里面有相同的语句，就失去了语句的意义，编译器也不会通过。 this()和 super()都指的是对象，所以，均不可以在 static 环境中使用。包括：static 变量,static 方法，static 语句块。 从本质上讲，this 是一个指向本对象的指针, 然而 super 是一个 Java 关键字。 static 存在的主要意义 static 的主要意义是在于创建独立于具体对象的域变量或者方法。以致于即使没有创建对象，也能使用属性和调用方法！ static 关键字还有一个比较关键的作用就是 用来形成静态代码块以优化程序性能。static 块可以置于类中的任何地方，类中可以有多个 static 块。在类初次被加载的时候，会按照 static 块的顺序来执行每个 static 块，并且只会执行一次。 为什么说 static 块可以用来优化程序性能，是因为它的特性:只会在类加载的时候执行一次。因此，很多时候会将一些只需要进行一次的初始化操作都放在 static 代码块中进行。 static 的独特之处 被 static 修饰的变量或者方法是独立于该类的任何对象，也就是说，这些变量和方法不属于任何一个实例对象，而是被类的实例对象所共享。 怎么理解 “被类的实例对象所共享” 这句话呢？就是说，一个类的静态成员，它是属于大伙的【大伙指的是这个类的多个对象实例，我们都知道一个类可以创建多个实例！】，所有的类对象共享的，不像成员变量是自个的【自个指的是这个类的单个实例对象】…我觉得我已经讲的很通俗了，你明白了咩？ 在该类被第一次加载的时候，就会去加载被 static 修饰的部分，而且只在类第一次使用时加载并进行初始化，注意这是第一次用就要初始化，后面根据需要是可以再次赋值的。 static 变量值在类加载的时候分配空间，以后创建类对象的时候不会重新分配。赋值的话，是可以任意赋值的！ 被 static 修饰的变量或者方法是优先于对象存在的，也就是说当一个类加载完毕之后，即便没有创建对象，也可以去访问。 static 应用场景 因为 static 是被类的实例对象所共享，因此如果某个成员变量是被所有对象所共享的，那么这个成员变量就应该定义为静态变量。 因此比较常见的 static 应用场景有： 修饰成员变量 修饰成员方法 静态代码块 修饰类【只能修饰内部类也就是静态内部类】 静态导包 static 注意事项 静态只能访问静态。 非静态既可以访问非静态的，也可以访问静态的。 流程控制语句break ,continue ,return 的区别及作用 break 跳出总上一层循环，不再执行循环(结束当前的循环体) continue 跳出本次循环，继续执行下次循环(结束正在执行的循环 进入下一个循环条件) return 程序返回，不再执行下面的代码(结束当前的方法 直接返回) 在 Java 中，如何跳出当前的多重嵌套循环 在 Java 中，要想跳出多重循环，可以在外面的循环语句前定义一个标号，然后在里层循环体的代码中使用带有标号的 break 语句，即可跳出外层循环。例如： 123456789101112public static void main(String[] args) { ok: for (int i = 0; i &lt; 10; i++) { for (int j = 0; j &lt; 10; j++) { System.out.println(&quot;i=&quot; + i + &quot;,j=&quot; + j); if (j == 5) { break ok; } } }} 参考：https://blog.csdn.net/ThinkWon","link":"/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"title":"Java基础知识 基础语法-网络编程","text":"计算机网络体系结构在计算机网络的基本概念中，分层次的体系结构是最基本的。计算机网络体系结构的抽象概念较多，在学习时要多思考。这些概念对后面的学习很有帮助。 网络协议是什么？在计算机网络要做到有条不紊地交换数据，就必须遵守一些事先约定好的规则，比如交换数据的格式、是否需要发送一个应答信息。这些规则被称为网络协议。 为什么要对网络协议分层？ 简化问题难度和复杂度。由于各层之间独立，我们可以分割大问题为小问题。 灵活性好。当其中一层的技术变化时，只要层间接口关系保持不变，其他层不受影响。 易于实现和维护。 促进标准化工作。分开后，每层功能可以相对简单地被描述。 网络协议分层的缺点： 功能可能出现在多个层里，产生了额外开销。 为了使不同体系结构的计算机网络都能互联，国际标准化组织 ISO 于 1977 年提出了一个试图使各种计算机在世界范围内互联成网的标准框架，即著名的开放系统互联基本参考模型 OSI/RM，简称为 OSI。 OSI 的七层协议体系结构的概念清楚，理论也较完整，但它既复杂又不实用，TCP/IP 体系结构则不同，但它现在却得到了非常广泛的应用。TCP/IP 是一个四层体系结构，它包含应用层，运输层，网际层和网络接口层（用网际层这个名字是强调这一层是为了解决不同网络的互连问题），不过从实质上讲，TCP/IP 只有最上面的三层，因为最下面的网络接口层并没有什么具体内容，因此在学习计算机网络的原理时往往采用折中的办法，即综合 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚，有时为了方便，也可把最底下两层称为网络接口层。 四层协议，五层协议和七层协议的关系如下： TCP/IP 是一个四层的体系结构，主要包括：应用层、运输层、网际层和网络接口层。 五层协议的体系结构主要包括：应用层、运输层、网络层，数据链路层和物理层。 OSI 七层协议模型主要包括是：应用层（Application）、表示层（Presentation）、会话层（Session）、运输层（Transport）、网络层（Network）、数据链路层（Data Link）、物理层（Physical）。 注：五层协议的体系结构只是为了介绍网络原理而设计的，实际应用还是 TCP/IP 四层体系结构。 TCP/IP 协议族应用层应用层( application layer）的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。 对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统 DNS，支持万维网应用的 HTTP 协议，支持电子邮件的 SMTP 协议等等。 运输层运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。 运输层主要使用一下两种协议 传输控制协议-TCP：提供面向连接的，可靠的数据传输服务。 用户数据协议-UDP：提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。 UDP TCP 是否连接 无连接 面向连接 是否可靠 不可靠传输，不使用流量控制和拥塞控制 可靠传输，使用流量控制和拥塞控制 连接对象个数 支持一对一，一对多，多对一和多对多交互通信 只能是一对一通信 传输方式 面向报文 面向字节流 首部开销 首部开销小，仅 8 字节 首部最小 20 字节，最大 60 字节 场景 适用于实时应用（IP 电话、视频会议、直播等） 适用于要求可靠传输的应用，例如文件传输 每一个应用层（TCP/IP 参考模型的最高层）协议一般都会使用到两个传输层协议之一： 运行在 TCP 协议上的协议： HTTP（Hypertext Transfer Protocol，超文本传输协议），主要用于普通浏览。 HTTPS（HTTP over SSL，安全超文本传输协议）,HTTP 协议的安全版本。 FTP（File Transfer Protocol，文件传输协议），用于文件传输。 POP3（Post Office Protocol, version 3，邮局协议），收邮件用。 SMTP（Simple Mail Transfer Protocol，简单邮件传输协议），用来发送电子邮件。 TELNET（Teletype over the Network，网络电传），通过一个终端（terminal）登陆到网络。 SSH（Secure Shell，用于替代安全性差的 TELNET），用于加密安全登陆用。 运行在 UDP 协议上的协议： BOOTP（Boot Protocol，启动协议），应用于无盘设备。 NTP（Network Time Protocol，网络时间协议），用于网络同步。 DHCP（Dynamic Host Configuration Protocol，动态主机配置协议），动态配置 IP 地址。 运行在 TCP 和 UDP 协议上： DNS（Domain Name Service，域名服务），用于完成地址查找，邮件转发等工作。 网络层网络层的任务就是选择合适的网间路由和交换结点，确保计算机通信的数据及时传送。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称数据报。 互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Prococol）和许多路由选择协议，因此互联网的网络层也叫做网际层或 IP 层。 数据链路层数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。 在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。 在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。 一般的 web 应用的通信传输流是这样的： 发送端在层与层之间传输数据时，每经过一层时会被打上一个该层所属的首部信息。反之，接收端在层与层之间传输数据时，每经过一层时会把对应的首部信息去除。 物理层在物理层上所传送的数据单位是比特。 物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。 TCP/IP 协议族在互联网使用的各种协议中最重要和最著名的就是 TCP/IP 两个协议。现在人们经常提到的 TCP/IP 并不一定是单指 TCP 和 IP 这两个具体的协议，而往往是表示互联网所使用的整个 TCP/IP 协议族。 互联网协议套件（英语：Internet Protocol Suite，缩写 IPS）是一个网络通讯模型，以及一整个网络传输协议家族，为网际网络的基础通讯架构。它常被通称为 TCP/IP 协议族（英语：TCP/IP Protocol Suite，或 TCP/IP Protocols），简称 TCP/IP。因为该协定家族的两个核心协定：TCP（传输控制协议）和 IP（网际协议），为该家族中最早通过的标准。 划重点： TCP（传输控制协议）和 IP（网际协议） 是最先定义的两个核心协议，所以才统称为 TCP/IP 协议族 TCP 的三次握手四次挥手TCP 是一种面向连接的、可靠的、基于字节流的传输层通信协议，在发送数据前，通信双方必须在彼此间建立一条连接。所谓的“连接”，其实是客户端和服务端保存的一份关于对方的信息，如 ip 地址、端口号等。 TCP 可以看成是一种字节流，它会处理 IP 层或以下的层的丢包、重复以及错误问题。在连接的建立过程中，双方需要交换一些连接的参数。这些参数可以放在 TCP 头部。 一个 TCP 连接由一个 4 元组构成，分别是两个 IP 地址和两个端口号。一个 TCP 连接通常分为三个阶段：连接、数据传输、退出（关闭）。 通过三次握手建立一个链接，通过四次挥手来关闭一个连接。 当一个连接被建立或被终止时，交换的报文段只包含 TCP 头部，而没有数据。 TCP 报文的头部结构在了解 TCP 连接之前先来了解一下 TCP 报文的头部结构。 上图中有几个字段需要重点介绍下： 序号：seq 序号，占 32 位，用来标识从 TCP 源端向目的端发送的字节流，发起方发送数据时对此进行标记。 确认序号：ack 序号，占 32 位，只有 ACK 标志位为 1 时，确认序号字段才有效，ack=seq+1。 标志位：共 6 个，即 URG、ACK、PSH、RST、SYN、FIN 等，具体含义如下： ACK：确认序号有效。 FIN：释放一个连接。 PSH：接收方应该尽快将这个报文交给应用层。 RST：重置连接。 SYN：发起一个新连接。 URG：紧急指针（urgent pointer）有效。 需要注意的是： 不要将确认序号 ack 与标志位中的 ACK 搞混了。 确认方 ack=发起方seq+1，两端配对。 三次握手 三次握手的本质是确认通信双方收发数据的能力 首先，我让信使运输一份信件给对方，对方收到了，那么他就知道了我的发件能力和他的收件能力是可以的。 于是他给我回信，我若收到了，我便知我的发件能力和他的收件能力是可以的，并且他的发件能力和我的收件能力是可以。 然而此时他还不知道他的发件能力和我的收件能力到底可不可以，于是我最后回馈一次，他若收到了，他便清楚了他的发件能力和我的收件能力是可以的。 这，就是三次握手，这样说，你理解了吗？ 第一次握手： 客户端要向服务端发起连接请求，首先客户端随机生成一个起始序列号 ISN(比如是 100)，那客户端向服务端发送的报文段包含 SYN 标志位(也就是 SYN=1)，序列号 seq=100。 第二次握手： 服务端收到客户端发过来的报文后，发现 SYN=1，知道这是一个连接请求，于是将客户端的起始序列号 100 存起来，并且随机生成一个服务端的起始序列号(比如是 300)。然后给客户端回复一段报文，回复报文包含 SYN 和 ACK 标志(也就是 SYN=1,ACK=1)、序列号 seq=300、确认号 ack=101(客户端发过来的序列号+1)。 第三次握手： 客户端收到服务端的回复后发现 ACK=1 并且 ack=101,于是知道服务端已经收到了序列号为 100 的那段报文；同时发现 SYN=1，知道了服务端同意了这次连接，于是就将服务端的序列号 300 给存下来。然后客户端再回复一段报文给服务端，报文包含 ACK 标志位(ACK=1)、ack=301(服务端序列号+1)、seq=101(第一次握手时发送报文是占据一个序列号的，所以这次 seq 就从 101 开始，需要注意的是不携带数据的 ACK 报文是不占据序列号的，所以后面第一次正式发送数据时 seq 还是 101)。当服务端收到报文后发现 ACK=1 并且 ack=301，就知道客户端收到序列号为 300 的报文了，就这样客户端和服务端通过 TCP 建立了连接。 四次挥手 四次挥手的目的是关闭一个连接 比如客户端初始化的序列号 ISA=100，服务端初始化的序列号 ISA=300。TCP 连接成功后客户端总共发送了 1000 个字节的数据，服务端在客户端发 FIN 报文前总共回复了 2000 个字节的数据。 第一次挥手： 当客户端的数据都传输完成后，客户端向服务端发出连接释放报文(当然数据没发完时也可以发送连接释放报文并停止发送数据)，释放连接报文包含 FIN 标志位(FIN=1)、序列号 seq=1101(100+1+1000，其中的 1 是建立连接时占的一个序列号)。需要注意的是客户端发出 FIN 报文段后只是不能发数据了，但是还可以正常收数据；另外 FIN 报文段即使不携带数据也要占据一个序列号。 第二次挥手： 服务端收到客户端发的 FIN 报文后给客户端回复确认报文，确认报文包含 ACK 标志位(ACK=1)、确认号 ack=1102(客户端 FIN 报文序列号 1101+1)、序列号 seq=2300(300+2000)。此时服务端处于关闭等待状态，而不是立马给客户端发 FIN 报文，这个状态还要持续一段时间，因为服务端可能还有数据没发完。 第三次挥手： 服务端将最后数据(比如 50 个字节)发送完毕后就向客户端发出连接释放报文，报文包含 FIN 和 ACK 标志位(FIN=1,ACK=1)、确认号和第二次挥手一样 ack=1102、序列号 seq=2350(2300+50)。 第四次挥手： 客户端收到服务端发的 FIN 报文后，向服务端发出确认报文，确认报文包含 ACK 标志位(ACK=1)、确认号 ack=2351、序列号 seq=1102。注意客户端发出确认报文后不是立马释放 TCP 连接，而是要经过 2MSL(最长报文段寿命的 2 倍时长)后才释放 TCP 连接。而服务端一旦收到客户端发出的确认报文就会立马释放 TCP 连接，所以服务端结束 TCP 连接的时间要比客户端早一些。 常见面试题为什么 TCP 连接的时候是 3 次？2 次不可以吗？因为需要考虑连接时丢包的问题，如果只握手 2 次，第二次握手时如果服务端发给客户端的确认报文段丢失，此时服务端已经准备好了收发数(可以理解服务端已经连接成功)据，而客户端一直没收到服务端的确认报文，所以客户端就不知道服务端是否已经准备好了(可以理解为客户端未连接成功)，这种情况下客户端不会给服务端发数据，也会忽略服务端发过来的数据。 如果是三次握手，即便发生丢包也不会有问题，比如如果第三次握手客户端发的确认 ack 报文丢失，服务端在一段时间内没有收到确认 ack 报文的话就会重新进行第二次握手，也就是服务端会重发 SYN 报文段，客户端收到重发的报文段后会再次给服务端发送确认 ack 报文。 为什么 TCP 连接的时候是 3 次，关闭的时候却是 4 次？因为只有在客户端和服务端都没有数据要发送的时候才能断开 TCP。而客户端发出 FIN 报文时只能保证客户端没有数据发了，服务端还有没有数据发客户端是不知道的。而服务端收到客户端的 FIN 报文后只能先回复客户端一个确认报文来告诉客户端我服务端已经收到你的 FIN 报文了，但我服务端还有一些数据没发完，等这些数据发完了服务端才能给客户端发 FIN 报文(所以不能一次性将确认报文和 FIN 报文发给客户端，就是这里多出来了一次)。 为什么客户端发出第四次挥手的确认报文后要等 2MSL 的时间才能释放 TCP 连接？这里同样是要考虑丢包的问题，如果第四次挥手的报文丢失，服务端没收到确认 ack 报文就会重发第三次挥手的报文，这样报文一去一回最长时间就是 2MSL，所以需要等这么长时间来确认服务端确实已经收到了。 如果已经建立了连接，但是客户端突然出现故障了怎么办？TCP 设有一个保活计时器，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为 2 小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔 75 秒钟发送一次。若一连发送 10 个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 什么是 HTTP，HTTP 与 HTTPS 的区别HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范 区别 HTTP HTTPS 协议 运行在 TCP 之上，明文传输，客户端与服务器端都无法验证对方的身份 身披 SSL( Secure Socket Layer )外壳的 HTTP，运行于 SSL 上，SSL 运行于 TCP 之上， 是添加了加密和认证机制的 HTTP。 端口 80 443 资源消耗 较少 由于加解密处理，会消耗更多的 CPU 和内存资源 开销 无需证书 需要证书，而证书一般需要向认证机构购买 加密机制 无 共享密钥加密和公开密钥加密并用的混合加密机制 安全性 弱 由于加密机制，安全性强 常用 HTTP 状态码HTTP 状态码表示客户端 HTTP 请求的返回结果、标识服务器处理是否正常、表明请求出现的错误等。 状态码的类别： 类别 原因短语 1XX Informational（信息性状态码） 接受的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 常用 HTTP 状态码： 2XX 成功（这系列表明请求被正常处理了） 200 OK，表示从客户端发来的请求在服务器端被正确处理 204 No content，表示请求成功，但响应报文不含实体的主体部分 206 Partial Content，进行范围请求成功 3XX 重定向（表明浏览器要执行特殊处理） 301 moved permanently，永久性重定向，表示资源已被分配了新的 URL 302 found，临时性重定向，表示资源临时被分配了新的 URL 303 see other，表示资源存在着另一个 URL，应使用 GET 方法获取资源（对于 301/302/303 响应，几乎所有浏览器都会删除报文主体并自动用 GET 重新请求） 304 not modified，表示服务器允许访问资源，但请求未满足条件的情况（与重定向无关） 307 temporary redirect，临时重定向，和 302 含义类似，但是期望客户端保持请求方法不变向新的地址发出请求 4XX 客户端错误 400 bad request，请求报文存在语法错误 401 unauthorized，表示发送的请求需要有通过 HTTP 认证的认证信息 403 forbidden，表示对请求资源的访问被服务器拒绝，可在实体主体部分返回原因描述 404 not found，表示在服务器上没有找到请求的资源 5XX 服务器错误 500 internal sever error，表示服务器端在执行请求时发生了错误 501 Not Implemented，表示服务器不支持当前请求所需要的某个功能 503 service unavailable，表明服务器暂时处于超负载或正在停机维护，无法处理请求 GET 和 POST 区别说到 GET 和 POST，就不得不提 HTTP 协议，因为浏览器和服务器的交互是通过 HTTP 协议执行的，而 GET 和 POST 也是 HTTP 协议中的两种方法。 HTTP 全称为 Hyper Text Transfer Protocol，中文翻译为超文本传输协议，目的是保证浏览器与服务器之间的通信。HTTP 的工作方式是客户端与服务器之间的请求-应答协议。 HTTP 协议中定义了浏览器和服务器进行交互的不同方法，基本方法有 4 种，分别是 GET，POST，PUT，DELETE。这四种方法可以理解为，对服务器资源的查，改，增，删。 GET： 从服务器上获取数据，也就是所谓的查，仅仅是获取服务器资源，不进行修改。 POST： 向服务器提交数据，这就涉及到了数据的更新，也就是更改服务器的数据。 PUT： 英文含义是放置，也就是向服务器新添加数据，就是所谓的增。 DELETE： 从字面意思也能看出，这种方式就是删除服务器数据的过程。 GET 和 POST 区别 Get 是不安全的，因为在传输过程，数据被放在请求的 URL 中；Post 的所有操作对用户来说都是不可见的。 但是这种做法也不是绝对的，大部分人的做法也是按照上面的说法来的，但是也可以在 get 请求加上 request body，给 post 请求带上 URL 参数。 Get 请求提交的 url 中的数据最多只能是 2048 字节，这个限制是浏览器或者服务器给添加的，http 协议并没有对 url 长度进行限制，目的是为了保证服务器和浏览器能够正常运行，防止有人恶意发送请求。Post 请求则没有大小限制。 Get 限制 Form 表单的数据集的值必须为 ASCII 字符；而 Post 支持整个 ISO10646 字符集。 Get 执行效率却比 Post 方法好。Get 是 form 提交的默认方法。 GET 产生一个 TCP 数据包；POST 产生两个 TCP 数据包。 对于 GET 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）； 而对于 POST，浏览器先发送 header，服务器响应 100 continue，浏览器再发送 data，服务器响应 200 ok（返回数据）。 什么是对称加密与非对称加密对称密钥加密是指加密和解密使用同一个密钥的方式，这种方式存在的最大问题就是密钥发送问题，即如何安全地将密钥发给对方； 而非对称加密是指使用一对非对称密钥，即公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密。由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性；但是和对称加密比起来，非常的慢 什么是 HTTP2HTTP2 可以提高了网页的性能。 在 HTTP1 中浏览器限制了同一个域名下的请求数量（Chrome 下一般是六个），当在请求很多资源的时候，由于队头阻塞当浏览器达到最大请求数量时，剩余的资源需等待当前的六个请求完成后才能发起请求。 HTTP2 中引入了多路复用的技术，这个技术可以只通过一个 TCP 连接就可以传输所有的请求数据。多路复用可以绕过浏览器限制同一个域名下的请求数量的问题，进而提高了网页的性能。 Session、Cookie 和 Token 的主要区别HTTP 协议本身是无状态的。什么是无状态呢，即服务器无法判断用户身份。 什么是 cookie cookie 是由 Web 服务器保存在用户浏览器上的小文件（key-value 格式），包含用户相关的信息。客户端向服务器发起请求，如果服务器需要记录该用户状态，就使用 response 向客户端浏览器颁发一个 Cookie。客户端浏览器会把 Cookie 保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该 Cookie 一同提交给服务器。服务器检查该 Cookie，以此来辨认用户身份。 什么是 session session 是依赖 Cookie 实现的。session 是服务器端对象 session 是浏览器和服务器会话过程中，服务器分配的一块储存空间。服务器默认为浏览器在 cookie 中设置 sessionid，浏览器在向服务器请求过程中传输 cookie 包含 sessionid ，服务器根据 sessionid 获取出会话中存储的信息，然后确定会话的身份信息。 cookie 与 session 区别 存储位置与安全性： cookie 数据存放在客户端上，安全性较差，session 数据放在服务器上，安全性相对更高； 存储空间： 单个 cookie 保存的数据不能超过 4K，很多浏览器都限制一个站点最多保存 20 个 cookie，session 无此限制 占用服务器资源： session 一定时间内保存在服务器上，当访问增多，占用服务器性能，考虑到服务器性能方面，应当使用 cookie。 什么是 Token Token 的引入： Token 是在客户端频繁向服务端请求数据，服务端频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，并作出相应提示，在这样的背景下，Token 便应运而生。 Token 的定义： Token 是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个 Token 便将此 Token 返回给客户端，以后客户端只需带上这个 Token 前来请求数据即可，无需再次带上用户名和密码。 使用 Token 的目的： Token 的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮。 Token 是在服务端产生的。如果前端使用用户名/密码向服务端请求认证，服务端认证成功，那么在服务端会返回 Token 给前端。前端可以在每次请求的时候带上 Token 证明自己的合法地位 session 与 token 区别 session 机制存在服务器压力增大，CSRF 跨站伪造请求攻击，扩展性不强等问题； session 存储在服务器端，token 存储在客户端 token 提供认证和授权功能，作为身份认证，token 安全性比 session 好； session 这种会话存储方式方式只适用于客户端代码和服务端代码运行在同一台服务器上，token 适用于项目级的前后端分离（前后端代码运行在不同的服务器下） Servlet 是线程安全的吗Servlet 不是线程安全的，多线程并发的读写会导致数据不同步的问题。 解决的办法是尽量不要定义 name 属性，而是要把 name 变量分别定义在 doGet()和 doPost()方法内。虽然使用 synchronized(name){}语句块可以解决问题，但是会造成线程的等待，不是很科学的办法。 注意：多线程的并发的读写 Servlet 类属性会导致数据不同步。但是如果只是并发地读取属性而不写入，则不存在数据不同步的问题。因此 Servlet 里的只读属性最好定义为 final 类型的。 Servlet 接口中有哪些方法及 Servlet 生命周期探秘在 Java Web 程序中，Servlet 主要负责接收用户请求 HttpServletRequest，在 doGet()，doPost()中做相应的处理，并将回应 HttpServletResponse 反馈给用户。Servlet 可以设置初始化参数，供 Servlet 内部使用。 Servlet 接口定义了 5 个方法，其中前三个方法与 Servlet 生命周期相关： void init(ServletConfig config) throws ServletException void service(ServletRequest req, ServletResponse resp) throws ServletException, java.io.IOException void destory() java.lang.String getServletInfo() ServletConfig getServletConfig() 生命周期： Web 容器加载 Servlet 并将其实例化后，Servlet 生命周期开始， 容器运行其 init()方法进行 Servlet 的初始化； 请求到达时调用 Servlet 的 service()方法，service()方法会根据需要调用与请求对应的 doGet 或 doPost 等方法； 当服务器关闭或项目被卸载时服务器会将 Servlet 实例销毁，此时会调用 Servlet 的 destroy()方法。 init 方法和 destory 方法只会执行一次，service 方法客户端每次请求 Servlet 都会执行。 Servlet 中有时会用到一些需要初始化与销毁的资源，因此可以把初始化资源的代码放入 init 方法中，销毁资源的代码放入 destroy 方法中，这样就不需要每次处理客户端的请求都要初始化与销毁资源。 如果客户端禁止 cookie 能实现 session 还能用吗？Cookie 与 Session，一般认为是两个独立的东西，Session 采用的是在服务器端保持状态的方案，而 Cookie 采用的是在客户端保持状态的方案。 但为什么禁用 Cookie 就不能得到 Session 呢？因为 Session 是用 Session ID 来确定当前对话所对应的服务器 Session，而 Session ID 是通过 Cookie 来传递的，禁用 Cookie 相当于失去了 Session ID，也就得不到 Session 了。 假定用户关闭 Cookie 的情况下使用 Session，其实现途径有以下几种： 手动通过 URL 传值、隐藏表单传递 Session ID。 用文件、数据库等形式保存 Session ID，在跨页过程中手动调用。 参考：https://blog.csdn.net/ThinkWon","link":"/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"title":"Java基础知识 基础语法-面向对象","text":"面向对象概述面向对象和面向过程的区别 面向过程： 优点： 性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;比如单片机、嵌入式开发、Linux/Unix 等一般采用面向过程开发，性能是最重要的因素。 缺点： 没有面向对象易维护、易复用、易扩展 面向对象： 优点： 易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统更加灵活、更加易于维护 缺点： 性能比面向过程低 面向过程是具体化的，流程化的，解决一个问题，你需要一步一步的分析，一步一步的实现。 面向对象是模型化的，你只需抽象出一个类，这是一个封闭的盒子，在这里你拥有数据也拥有解决问题的方法。需要什么功能直接使用就可以了，不必去一步一步的实现，至于这个功能是如何实现的，管我们什么事？我们会用就可以了。 面向对象的底层其实还是面向过程，把面向过程抽象成类，然后封装，方便我们使用的就是面向对象了。 面向对象三大特性面向对象的特征有哪些方面 面向对象的特征主要有以下几个方面： 抽象： 抽象是将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象两方面。抽象只关注对象有哪些属性和行为，并不关注这些行为的细节是什么。 封装： 封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。 继承： 继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便地复用以前的代码。 多态： 所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。 其中 Java 面向对象编程三大特性： 封装 继承 多态 封装： 隐藏对象的属性和实现细节，仅对外提供公共访问方式，将变化隔离，便于使用，提高复用性和安全性。 继承： 继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承可以提高代码复用性。继承是多态的前提。 关于继承如下 3 点请记住： 子类拥有父类非 private 的属性和方法。 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。 子类可以用自己的方式实现父类的方法。 多态性： 父类或接口定义的引用变量可以指向子类或具体实现类的实例对象。提高了程序的拓展性。 在 Java 中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。 方法重载（overload）实现的是编译时的多态性（也称为前绑定），而方法重写（override）实现的是运行时的多态性（也称为后绑定）。 一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。运行时的多态是面向对象最精髓的东西，要实现多态需要做两件事： 方法重写（子类继承父类并重写父类中已有的或抽象的方法）； 对象造型（用父类型引用子类型对象，这样同样的引用调用同样的方法就会根据子类对象的不同而表现出不同的行为）。 什么是多态机制？Java 语言是如何实现多态的？ 所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。 多态分为编译时多态和运行时多态。其中编辑时多态是静态的，主要是指方法的重载，它是根据参数列表的不同来区分不同的函数，通过编辑之后会变成两个不同的函数，在运行时谈不上多态。而运行时多态是动态的，它是通过动态绑定来实现的，也就是我们所说的多态性。 多态的实现 Java 实现多态有三个必要条件：继承、重写、向上转型。 继承： 在多态中必须存在有继承关系的子类和父类。 重写： 子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法。 向上转型： 在多态中需要将子类的引用赋给父类对象，只有这样该引用才能够具备技能调用父类的方法和子类的方法。 只有满足了上述三个条件，我们才能够在同一个继承结构中使用统一的逻辑实现代码处理不同的对象，从而达到执行不同的行为。 对于 Java 而言，它多态的实现机制遵循一个原则：当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。 面向对象五大基本原则是什么（可选） 单一职责原则 SRP(Single Responsibility Principle)类的功能要单一，不能包罗万象，跟杂货铺似的。 开放封闭原则 OCP(Open－Close Principle) 一个模块对于拓展是开放的，对于修改是封闭的，想要增加功能热烈欢迎，想要修改，哼，一万个不乐意。 里式替换原则 LSP(the Liskov Substitution Principle LSP)子类可以替换父类出现在父类能够出现的任何地方。比如你能代表你爸去你姥姥家干活。哈哈~~ 依赖倒置原则 DIP(the Dependency Inversion Principle DIP)高层次的模块不应该依赖于低层次的模块，他们都应该依赖于抽象。抽象不应该依赖于具体实现，具体实现应该依赖于抽象。就是你出国要说你是中国人，而不能说你是哪个村子的。比如说中国人是抽象的，下面有具体的 xx 省，xx 市，xx 县。你要依赖的抽象是中国人，而不是你是 xx 村的。 接口分离原则 ISP(the Interface Segregation Principle ISP)设计时采用多个与特定客户类有关的接口比采用一个通用的接口要好。就比如一个手机拥有打电话，看视频，玩游戏等功能，把这几个功能拆分成不同的接口，比在一个接口里要好的多。 类与接口抽象类和接口的对比 抽象类是用来捕捉子类的通用特性的。接口是抽象方法的集合。 从设计层面来说，抽象类是对类的抽象，是一种模板设计，接口是行为的抽象，是一种行为的规范。 相同点 接口和抽象类都不能实例化 都位于继承的顶端，用于被其他实现或继承 都包含抽象方法，其子类都必须覆写这些抽象方法 不同点 参数 抽象类 接口 声明 抽象类使用 abstract 关键字声明 接口使用 interface 关键字声明 实现 子类使用 extends 关键字来继承抽象类。如果子类不是抽象类的话，它需要提供抽象类中所有声明的方法的实现 子类使用 implements 关键字来实现接口。它需要提供接口中所有声明的方法的实现 构造器 抽象类可以有构造器 接口不能有构造器 访问修饰符 抽象类中的方法可以是任意访问修饰符 接口方法默认修饰符是 public 。并且不允许定义为 private 或者 protected 多继承 一个类最多只能继承一个抽象类 一个类可以实现多个接口 字段声明 抽象类的字段声明可以是任意的 接口的字段默认都是 static 和 final 的 备注： Java8 中接口中引入默认方法和静态方法，以此来减少抽象类和接口之间的差异。 现在，我们可以为接口提供默认实现的方法了，并且不用强制子类来实现它。 接口和抽象类各有优缺点，在接口和抽象类的选择上，必须遵守这样一个原则： 行为模型应该总是通过接口而不是抽象类定义，所以通常是优先选用接口，尽量少用抽象类。 选择抽象类的时候通常是如下情况：需要定义子类的行为，又要为子类提供通用的功能。 普通类和抽象类有哪些区别？ 普通类不能包含抽象方法，抽象类可以包含抽象方法。 抽象类不能直接实例化，普通类可以直接实例化。 抽象类能使用 final 修饰吗？ 不能，定义抽象类就是让其他类继承的，如果定义为 final 该类就不能被继承，这样彼此就会产生矛盾，所以 final 不能修饰抽象类 创建一个对象用什么关键字？对象实例与对象引用有何不同？ new 关键字，new 创建对象实例（对象实例在堆内存中），对象引用指向对象实例（对象引用存放在栈内存中）。一个对象引用可以指向 0 个或 1 个对象（一根绳子可以不系气球，也可以系一个气球）;一个对象可以有 n 个引用指向它（可以用 n 条绳子系住一个气球） 变量与方法成员变量与局部变量的区别有哪些 变量： 在程序执行的过程中，在某个范围内其值可以发生改变的量。从本质上讲，变量其实是内存中的一小块区域 成员变量： 方法外部，类内部定义的变量 局部变量： 类的方法中的变量。 成员变量和局部变量的区别： 作用域 成员变量：针对整个类有效。局部变量：只在某个范围内有效。(一般指的就是方法,语句体内) 存储位置 成员变量：随着对象的创建而存在，随着对象的消失而消失，存储在堆内存中。局部变量：在方法被调用，或者语句被执行的时候存在，存储在栈内存中。当方法调用完，或者语句结束后，就自动释放。 生命周期 成员变量：随着对象的创建而存在，随着对象的消失而消失局部变量：当方法调用完，或者语句结束后，就自动释放。 初始值 成员变量：有默认初始值。 局部变量：没有默认初始值，使用前必须赋值。 使用原则 在使用变量时需要遵循的原则为：就近原则首先在局部范围找，有就使用；接着在成员位置找。 在 Java 中定义一个不做事且没有参数的构造方法的作用 Java 程序在执行子类的构造方法之前，如果没有用 super()来调用父类特定的构造方法，则会调用父类中“没有参数的构造方法”。因此，如果父类中只定义了有参数的构造方法，而在子类的构造方法中又没有用 super()来调用父类中特定的构造方法，则编译时将发生错误，因为 Java 程序在父类中找不到没有参数的构造方法可供执行。解决办法是在父类里加上一个不做事且没有参数的构造方法。 在调用子类构造方法之前会先调用父类没有参数的构造方法，其目的是？ 帮助子类做初始化工作。 一个类的构造方法的作用是什么？若一个类没有声明构造方法，改程序能正确执行吗？为什么？ 主要作用是完成对类对象的初始化工作。可以执行。因为一个类即使没有声明构造方法也会有默认的不带参数的构造方法。 构造方法有哪些特性？ 名字与类名相同； 没有返回值，但不能用 void 声明构造函数； 生成类的对象时自动执行，无需调用。 静态变量和实例变量区别 静态变量： 静态变量由于不属于任何实例对象，属于类的，所以在内存中只会有一份，在类的加载过程中，JVM 只为静态变量分配一次内存空间。 实例变量： 每次创建对象，都会为每个对象分配成员变量内存空间，实例变量是属于实例对象的，在内存中，创建几次对象，就有几份成员变量。 静态变量与普通变量区别 static 变量也称作静态变量，静态变量和非静态变量的区别是：静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。而非静态变量是对象所拥有的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响。 还有一点就是 static 成员变量的初始化顺序按照定义的顺序进行初始化。 静态方法和实例方法有何不同？ 静态方法和实例方法的区别主要体现在两个方面： 在外部调用静态方法时，可以使用”类名.方法名“的方式，也可以使用”对象名.方法名“的方式。而实例方法只有后面这种方式。也就是说，调用静态方法可以无需创建对象。 静态方法在访问本类的成员时，只允许访问静态成员（即静态成员变量和静态方法），而不允许访问实例成员变量和实例方法；实例方法则无此限制 在一个静态方法内调用一个非静态成员为什么是非法的？ 由于静态方法可以不通过对象进行调用，因此在静态方法里，不能调用其他非静态变量，也不可以访问非静态变量成员。 什么是方法的返回值？返回值的作用是什么？ 方法的返回值是指我们获取到的某个方法体中的代码执行后产生的结果！（前提是该方法可能产生结果）。返回值的作用:接收出结果，使得它可以用于其他的操作！ 内部类什么是内部类 在 Java 中，可以将一个类的定义放在另外一个类的定义内部，这就是内部类。内部类本身就是类的一个属性，与其他属性定义方式一致。 内部类的分类有哪些 内部类可以分为四种：静态内部类、成员内部类、局部内部类和匿名内部类。 静态内部类 定义在类内部的静态类，就是静态内部类。 12345678910public class Outer { private static int radius = 1; static class StaticInner { public void visit() { System.out.println(&quot;visit outer static variable:&quot; + radius); } }} 静态内部类可以访问外部类所有的静态变量，而不可访问外部类的非静态变量；静态内部类的创建方式，new 外部类.静态内部类()，如下： 12Outer.StaticInner inner = new Outer.StaticInner();inner.visit(); 成员内部类 定义在类内部，成员位置上的非静态类，就是成员内部类。 123456789101112public class Outer { private static int radius = 1; private int count =2; class Inner { public void visit() { System.out.println(&quot;visit outer static variable:&quot; + radius); System.out.println(&quot;visit outer variable:&quot; + count); } }} 成员内部类可以访问外部类所有的变量和方法，包括静态和非静态，私有和公有。成员内部类依赖于外部类的实例，它的创建方式，new 外部类实例().new 内部类()，如下： 12Outer.Inner inner = new Outer().new Inner();inner.visit(); 局部内部类 定义在方法中的内部类，就是局部内部类。 123456789101112131415161718192021222324252627282930public class Outer { private int out_a = 1; private static int STATIC_b = 2; public void testFunctionClass(){ int inner_c =3; class Inner { private void fun(){ System.out.println(out_a); System.out.println(STATIC_b); System.out.println(inner_c); } } Inner inner = new Inner(); inner.fun(); } public static void testStaticFunctionClass(){ int d =3; class Inner { private void fun(){ // System.out.println(out_a); 编译错误，定义在静态方法中的局部类不可以访问外部类的实例变量 System.out.println(STATIC_b); System.out.println(d); } } Inner inner = new Inner(); inner.fun(); }} 定义在实例方法中的局部类可以访问外部类的所有变量和方法，定义在静态方法中的局部类只能访问外部类的静态变量和方法。局部内部类的创建方式，在对应方法内，new 内部类()，如下： 12345public static void testStaticFunctionClass(){ class Inner { } Inner inner = new Inner(); } 匿名内部类 匿名内部类就是没有名字的内部类，日常开发中使用的比较多。 12345678910111213141516public class Outer { private void test(final int i) { new Service() { public void method() { for (int j = 0; j &lt; i; j++) { System.out.println(&quot;匿名内部类&quot; ); } } }.method(); } } //匿名内部类必须继承或实现一个已有的接口 interface Service{ void method();} 除了没有名字，匿名内部类还有以下特点： 匿名内部类必须继承一个抽象类或者实现一个接口。 匿名内部类不能定义任何静态成员和静态方法。 当所在的方法的形参需要被匿名内部类使用时，必须声明为 final。 匿名内部类不能是抽象的，它必须要实现继承的类或者实现的接口的所有抽象方法。 匿名内部类创建方式： 123new 类/接口{ //匿名内部类实现部分} 内部类的优点 我们为什么要使用内部类呢？因为它有以下优点： 一个内部类对象可以访问创建它的外部类对象的内容，包括私有数据！ 内部类不为同一包的其他类所见，具有很好的封装性； 内部类有效实现了“多重继承”，优化 java 单继承的缺陷。 匿名内部类可以很方便的定义回调。 内部类有哪些应用场景 一些多算法场合 解决一些非面向对象的语句块。 适当使用内部类，使得代码更加灵活和富有扩展性。 当某个类除了它的外部类，不再被其他的类使用时。 局部内部类和匿名内部类访问局部变量的时候，为什么变量必须要加上 final？ 局部内部类和匿名内部类访问局部变量的时候，为什么变量必须要加上 final 呢？它内部原理是什么呢？ 先看这段代码： 123456789101112public class Outer { void outMethod(){ final int a =10; class Inner { void innerMethod(){ System.out.println(a); } } }} 以上例子，为什么要加 final 呢？是因为生命周期不一致， 局部变量直接存储在栈中，当方法执行结束后，非 final 的局部变量就被销毁。而局部内部类对局部变量的引用依然存在，如果局部内部类要调用局部变量时，就会出错。加了 final，可以确保局部内部类使用的变量与外层的局部变量区分开，解决了这个问题。 内部类相关，看程序说出运行结果 12345678910111213141516171819public class Outer { private int age = 12; class Inner { private int age = 13; public void print() { int age = 14; System.out.println(&quot;局部变量：&quot; + age); System.out.println(&quot;内部类变量：&quot; + this.age); System.out.println(&quot;外部类变量：&quot; + Outer.this.age); } } public static void main(String[] args) { Outer.Inner in = new Outer().new Inner(); in.print(); }} 运行结果： 123局部变量：14内部类变量：13外部类变量：12 重写与重载构造器（constructor）是否可被重写（override） 构造器不能被继承，因此不能被重写，但可以被重载。 重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？ 方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。 重载： 发生在同一个类中，方法名相同参数列表不同（参数类型不同、个数不同、顺序不同），与方法返回值和访问修饰符无关，即重载的方法不能根据返回类型进行区分 重写： 发生在父子类中，方法名、参数列表必须相同，返回值小于等于父类，抛出的异常小于等于父类，访问修饰符大于等于父类（里氏代换原则）；如果父类方法访问修饰符为 private 则子类中就不是重写。 对象相等判断== 和 equals 的区别是什么 == : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。(基本数据类型 == 比较的是值，引用数据类型 == 比较的是内存地址) equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况： 情况 1：类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。 情况 2：类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来两个对象的内容相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。 举个例子： 1234567891011121314151617public class test1 { public static void main(String[] args) { String a = new String(&quot;ab&quot;); // a 为一个引用 String b = new String(&quot;ab&quot;); // b为另一个引用,对象的内容一样 String aa = &quot;ab&quot;; // 放在常量池中 String bb = &quot;ab&quot;; // 从常量池中查找 if (aa == bb) // true System.out.println(&quot;aa==bb&quot;); if (a == b) // false，非同一对象 System.out.println(&quot;a==b&quot;); if (a.equals(b)) // true System.out.println(&quot;aEQb&quot;); if (42 == 42.0) { // true System.out.println(&quot;true&quot;); } }} 说明： String 中的 equals 方法是被重写过的，因为 object 的 equals 方法是比较的对象的内存地址，而 String 的 equals 方法比较的是对象的值。 当创建 String 类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个 String 对象。 hashCode 与 equals (重要) HashSet 如何检查重复 两个对象的 hashCode() 相同，则 equals() 也一定为 true，对吗？ hashCode 和 equals 方法的关系 面试官可能会问你：“你重写过 hashcode 和 equals 么，为什么重写 equals 时必须重写 hashCode 方法？” hashCode()介绍 hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个 int 整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 定义在 JDK 的 Object.java 中，这就意味着 Java 中的任何类都包含有 hashCode()函数。 散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象） 为什么要有 hashCode 我们以“HashSet 如何检查重复”为例子来说明为什么要有 hashCode： 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的 Java 启蒙书《Head first java》第二版）。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。 hashCode()与 equals()的相关规定 如果两个对象相等，则 hashcode 一定也是相同的 两个对象相等，对两个对象分别调用 equals 方法都返回 true 两个对象有相同的 hashcode 值，它们也不一定是相等的 因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖 hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） 对象的相等与指向他们的引用相等，两者有什么不同？ 对象的相等 比的是内存中存放的内容是否相等而 引用相等 比较的是他们指向的内存地址是否相等。 值传递当一个对象被当作参数传递到一个方法后，此方法可改变这个对象的属性，并可返回变化后的结果，那么这里到底是值传递还是引用传递 是值传递。Java 语言的方法调用只支持参数的值传递。当一个对象实例作为一个参数被传递到方法中时，参数的值就是对该对象的引用。对象的属性可以在被调用过程中被改变，但对对象引用的改变是不会影响到调用者的 为什么 Java 中只有值传递 首先回顾一下在程序设计语言中有关将参数传递给方法（或函数）的一些专业术语。按值调用(call by value)表示方法接收的是调用者提供的值，而按引用调用（call by reference)表示方法接收的是调用者提供的变量地址。一个方法可以修改传递引用所对应的变量值，而不能修改传递值调用所对应的变量值。 它用来描述各种程序设计语言（不只是 Java)中方法参数传递方式。 Java 程序设计语言总是采用按值调用。也就是说，方法得到的是所有参数值的一个拷贝，也就是说，方法不能修改传递给它的任何参数变量的内容。 下面通过 3 个例子来给大家说明 example 1 123456789101112131415161718public static void main(String[] args) { int num1 = 10; int num2 = 20; swap(num1, num2); System.out.println(&quot;num1 = &quot; + num1); System.out.println(&quot;num2 = &quot; + num2);}public static void swap(int a, int b) { int temp = a; a = b; b = temp; System.out.println(&quot;a = &quot; + a); System.out.println(&quot;b = &quot; + b);} 结果 1234a = 20b = 10num1 = 10num2 = 20 解析 在 swap 方法中，a、b 的值进行交换，并不会影响到 num1、num2。因为，a、b 中的值，只是从 num1、num2 的复制过来的。也就是说，a、b 相当于 num1、num2 的副本，副本的内容无论怎么修改，都不会影响到原件本身。 通过上面例子，我们已经知道了一个方法不能修改一个基本数据类型的参数，而对象引用作为参数就不一样，请看 example2. example2 1234567891011public static void main(String[] args) { int[] arr = { 1, 2, 3, 4, 5 }; System.out.println(arr[0]); change(arr); System.out.println(arr[0]);}public static void change(int[] array) { // 将数组的第一个元素变为0 array[0] = 0;} 结果： 1210 解析 array 被初始化 arr 的拷贝也就是一个对象的引用，也就是说 array 和 arr 指向的时同一个数组对象。 因此，外部对引用对象的改变会反映到所对应的对象上。 通过 example2 我们已经看到，实现一个改变对象参数状态的方法并不是一件难事。理由很简单，方法得到的是对象引用的拷贝，对象引用及其他的拷贝同时引用同一个对象。 很多程序设计语言（特别是，C++和 Pascal)提供了两种参数传递的方式：值调用和引用调用。有些程序员（甚至本书的作者）认为 Java 程序设计语言对对象采用的是引用调用，实际上，这种理解是不对的。由于这种误解具有一定的普遍性，所以下面给出一个反例来详细地阐述一下这个问题。 example 3 12345678910111213141516171819public class Test { public static void main(String[] args) { // TODO Auto-generated method stub Student s1 = new Student(&quot;小张&quot;); Student s2 = new Student(&quot;小李&quot;); Test.swap(s1, s2); System.out.println(&quot;s1:&quot; + s1.getName()); System.out.println(&quot;s2:&quot; + s2.getName()); } public static void swap(Student x, Student y) { Student temp = x; x = y; y = temp; System.out.println(&quot;x:&quot; + x.getName()); System.out.println(&quot;y:&quot; + y.getName()); }} 结果 1234x:小李y:小张s1:小张s2:小李 解析 交换之前： 交换之后： 通过上面两张图可以很清晰的看出： 方法并没有改变存储在变量 s1 和 s2 中的对象引用。swap 方法的参数 x 和 y 被初始化为两个对象引用的拷贝，这个方法交换的是这两个拷贝 总结 Java 程序设计语言对对象采用的不是引用调用，实际上，对象引用是按值传递的。 下面再总结一下 Java 中方法参数的使用情况： 一个方法不能修改一个基本数据类型的参数（即数值型或布尔型》 一个方法可以改变一个对象参数的状态。 一个方法不能让对象参数引用一个新的对象。 值传递和引用传递有什么区别 值传递： 指的是在方法调用时，传递的参数是按值的拷贝传递，传递的是值的拷贝，也就是说传递后就互不相关了。 引用传递： 指的是在方法调用时，传递的参数是按引用进行传递，其实传递的引用的地址，也就是变量所对应的内存空间的地址。传递的是值的引用，也就是说传递前和传递后都指向同一个引用（也就是同一个内存空间）。 Java 包JDK 中常用的包有哪些 java.lang：这个是系统的基础类； java.io：这里面是所有输入输出有关的类，比如文件操作等； java.nio：为了完善 io 包中的功能，提高 io 包中性能而写的一个新包； java.net：这里面是与网络有关的类； java.util：这个是系统辅助类，特别是集合类； java.sql：这个是数据库操作的类。 import java 和 javax 有什么区别 刚开始的时候 JavaAPI 所必需的包是 java 开头的包，javax 当时只是扩展 API 包来说使用。然而随着时间的推移，javax 逐渐的扩展成为 Java API 的组成部分。但是，将扩展从 javax 包移动到 java 包将是太麻烦了，最终会破坏一堆现有的代码。因此，最终决定 javax 包将成为标准 API 的一部分。 所以，实际上 java 和 javax 没有区别。这都是一个名字。 参考：https://blog.csdn.net/ThinkWon","link":"/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"title":"Java操作ElasticSearch","text":"Java操作ES检索和索引思路分析 引入maven依赖12345678910111213141516&lt;!--引入elasticsearch客户端依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;6.8.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;6.8.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.plugin&lt;/groupId&gt; &lt;artifactId&gt;transport-netty4-client&lt;/artifactId&gt; &lt;version&gt;6.8.0&lt;/version&gt;&lt;/dependency&gt; 创建索引和类型创建客户端操作对象12345678910111213141516private TransportClient transportClient;@Beforepublic void before() throws UnknownHostException { //创建ES客户端对象 this.transportClient = new PreBuiltTransportClient(Settings.EMPTY); //设置操作ES服务主机和端口 transportClient .addTransportAddress(new TransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;), 9300));}@Afterpublic void after() { transportClient.close(); }} 创建索引123456789//创建索引@Testpublic void testCreateIndex() { //创建一个索引 前提：保证创建的索引不存在 CreateIndexResponse createIndexResponse = transportClient.admin().indices().prepareCreate(&quot;buubiu&quot;).get(); //获取响应信息 boolean acknowledged = createIndexResponse.isAcknowledged(); System.out.println(&quot;acknowledged = &quot; + acknowledged);} 删除对象12345678910//删除索引@Testpublic void testDeleteIndex() { //删除索引 AcknowledgedResponse acknowledgedResponse = transportClient.admin().indices().prepareDelete(&quot;buubiu&quot;) .get(); //获取响应信息 boolean acknowledged = acknowledgedResponse.isAcknowledged(); System.out.println(&quot;acknowledged = &quot; + acknowledged);} 创建索引和类型1234567891011121314//[了解]创建索引 类型 mapping@Testpublic void testCreateIndexAndTypeMaping() throws ExecutionException, InterruptedException { //创建一个索引请求对象 CreateIndexRequest buubiuIndex = new CreateIndexRequest(&quot;buubiu&quot;); //索引设置类型 //参数1：类型名 参数2：映射的json格式数据 参数3：映射格式类型 buubiuIndex.mapping(&quot;user&quot;, &quot;{\\&quot;properties\\&quot;:{\\&quot;name\\&quot;:{\\&quot;type\\&quot;:\\&quot;text\\&quot;,\\&quot;analyzer\\&quot;:\\&quot;ik_max_word\\&quot;,\\&quot;search_analyzer\\&quot;:\\&quot;ik_max_word\\&quot;},\\&quot;age\\&quot;:{\\&quot;type\\&quot;:\\&quot;integer\\&quot;},\\&quot;bir\\&quot;:{\\&quot;type\\&quot;:\\&quot;date\\&quot;},\\&quot;content\\&quot;:{\\&quot;type\\&quot;:\\&quot;text\\&quot;,\\&quot;analyzer\\&quot;:\\&quot;ik_max_word\\&quot;,\\&quot;search_analyzer\\&quot;:\\&quot;ik_max_word\\&quot;},\\&quot;address\\&quot;:{\\&quot;type\\&quot;:\\&quot;keyword\\&quot;}}}&quot;, XContentType.JSON); //创建索引 CreateIndexResponse createIndexResponse = transportClient.admin().indices() .create(buubiuIndex).get(); boolean acknowledged = createIndexResponse.isAcknowledged(); System.out.println(&quot;acknowledged = &quot; + acknowledged);} 操作索引记录指定id生成索引记录123456789101112//添加一个记录 指定id@Testpublic void testCreateOptionId() { User user = new User(&quot;1&quot;, &quot;张三&quot;, 23, new Date(), &quot;今天晴转多云&quot;, &quot;上海&quot;); //转为json String json = JSONObject.toJSONStringWithDateFormat(user,&quot;yyyy-MM-dd&quot;); //创建一条记录 IndexResponse indexResponse = transportClient.prepareIndex(&quot;buubiu&quot;, &quot;user&quot;, user.getId()) .setSource(json, XContentType.JSON).get(); RestStatus status = indexResponse.status(); System.out.println(&quot;status = &quot; + status);} 自动生成id索引记录123456789101112//添加一个记录 自动id@Testpublic void testCreateAutoId() { User user = new User(null, &quot;张三2&quot;, 23, new Date(), &quot;今天晴转多云2&quot;, &quot;上海&quot;); //转为json String json = JSONObject.toJSONStringWithDateFormat(user,&quot;yyyy-MM-dd&quot;); //创建一条记录 IndexResponse indexResponse = transportClient.prepareIndex(&quot;buubiu&quot;, &quot;user&quot;) .setSource(json, XContentType.JSON).get(); RestStatus status = indexResponse.status(); System.out.println(&quot;status = &quot; + status);} 更新一条记录1234567891011121314//更新一条记录@Testpublic void testUpdate() { User user = new User(); user.setName(&quot;王武&quot;) .setContent(&quot;今天樱桃&quot;) .setBir(new Date()); //转为json String json = JSONObject.toJSONStringWithDateFormat(user,&quot;yyyy-MM-dd&quot;); UpdateResponse updateResponse = transportClient.prepareUpdate(&quot;buubiu&quot;, &quot;user&quot;, &quot;1&quot;) .setDoc(json, XContentType.JSON).get(); RestStatus status = updateResponse.status(); System.out.println(&quot;status = &quot; + status);} 删除一条记录1234567//删除记录@Testpublic void testDelete() { DeleteResponse deleteResponse = transportClient.prepareDelete(&quot;buubiu&quot;, &quot;user&quot;, &quot;1&quot;).get(); RestStatus status = deleteResponse.status(); System.out.println(&quot;status = &quot; + status);} 批量更新记录1234567891011121314151617181920212223242526//批量更新记录@Testpublic void testBulk() throws IOException { //添加一条记录 IndexRequest indexRequest1 = new IndexRequest(&quot;buubiu&quot;, &quot;user&quot;, &quot;12&quot;); User user1 = new User(&quot;1&quot;,&quot;刘能1&quot;, 22, new Date(), &quot;男&quot;, &quot;这是好人&quot;); indexRequest1.source(JSONObject.toJSONStringWithDateFormat(user1,&quot;yyyy-MM-dd&quot;), XContentType.JSON); //添加第二条记录 IndexRequest indexRequest2 = new IndexRequest(&quot;buubiu&quot;, &quot;user&quot;, &quot;13&quot;); User user2 = new User(&quot;2&quot;,&quot;刘能2&quot;, 24, new Date(), &quot;男&quot;, &quot;这是好人&quot;); indexRequest2.source(JSONObject.toJSONStringWithDateFormat(user2,&quot;yyyy-MM-dd&quot;), XContentType.JSON); //更新一条记录 UpdateRequest updateRequest = new UpdateRequest(&quot;buubiu&quot;, &quot;user&quot;, &quot;12&quot;); User user = new User().setName(&quot;中国厉害&quot;); updateRequest.doc(JSONObject.toJSONString(user), XContentType.JSON); //删除一条记录 DeleteRequest deleteRequest = new DeleteRequest(&quot;buubiu&quot;, &quot;user&quot;, &quot;13&quot;); BulkResponse bulkItemResponses = transportClient.prepareBulk().add(indexRequest1) .add(indexRequest2).add(updateRequest).add(deleteRequest).get(); BulkItemResponse[] items = bulkItemResponses.getItems(); for (BulkItemResponse item : items) { System.out.println(&quot;item = &quot; + item.status()); }} 检索记录查询一条记录123456789101112//查询一条记录@Testpublic void testFindOne() throws ParseException { GetResponse getResponse = transportClient.prepareGet(&quot;buubiu&quot;, &quot;user&quot;, &quot;1&quot;).get(); String sourceAsString = getResponse.getSourceAsString(); System.out.println(&quot;sourceAsString = &quot; + sourceAsString); Map&lt;String, Object&gt; sourceAsMap = getResponse.getSourceAsMap(); User user = new User(); user.setId(sourceAsMap.get(&quot;id&quot;).toString()); user.setBir(new SimpleDateFormat(&quot;yyyy-MM-dd&quot;).parse(sourceAsMap.get(&quot;bir&quot;).toString())); System.out.println(&quot;user = &quot; + user);} 查询所有12345678910111213141516171819//查询所有@Testpublic void testMatchAllQuery() { //查询条件 MatchAllQueryBuilder matchAllQueryBuilder = QueryBuilders.matchAllQuery(); SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(matchAllQueryBuilder)//指定查询条件 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} 高级检索分页查询12345678910111213141516171819202122232425/** * 分页查询 * From 从那条记录开始 默认从0 开始 form = (pageNow-1)*size * Size 每次返回多少条符合条件的结果 默认10 */@Testpublic void testMatchAllQueryFormAndSize() { //查询条件 MatchAllQueryBuilder matchAllQueryBuilder = QueryBuilders.matchAllQuery(); SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(matchAllQueryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(2)//设置每页展示记录数 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} 排序查询1234567891011121314151617181920212223242526272829/** * 排序查询 * From 从那条记录开始 默认从0 开始 form = (pageNow-1)*size * Size 每次返回多少条符合条件的结果 默认10 * ASC 升序 DESC 降序 * addSort(&quot;age&quot;, SortOrder.ASC) 指定排序字段以及使用哪种方式排序 * addSort(&quot;age&quot;, SortOrder.DESC) 指定排序字段以及使用哪种方式排序 */@Testpublic void testMatchAllQueryFormAndSizeAndSort() { //查询条件 MatchAllQueryBuilder matchAllQueryBuilder = QueryBuilders.matchAllQuery(); SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(matchAllQueryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(20)//设置每页展示记录数，默认10条 .addSort(&quot;age&quot;, SortOrder.DESC)//设置排序 desc降序 asc升序 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} term关键字查询1234567891011121314151617181920212223242526//term关键字查询@Testpublic void testTermQuery() { TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(&quot;content&quot;, &quot;今天&quot;); testResult(termQueryBuilder);}private void testResult(QueryBuilder queryBuilder) { SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(queryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(20)//设置每页展示记录数，默认10条 .addSort(&quot;age&quot;, SortOrder.ASC)//设置排序 desc降序 asc升序 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} range范围查询12345678910111213141516171819202122232425262728293031/** * rang查询 * lt 小于 * lte 小于等于 * gt 大于 * gte 大于等于 */@Testpublic void testRangeQuery() { RangeQueryBuilder rangeQueryBuilder = QueryBuilders.rangeQuery(&quot;age&quot;).gte(0).lte(22); testResult(rangeQueryBuilder);}private void testResult(QueryBuilder queryBuilder) { SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(queryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(20)//设置每页展示记录数，默认10条 .addSort(&quot;age&quot;, SortOrder.ASC)//设置排序 desc降序 asc升序 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} wildcard通配符查询12345678910111213141516171819202122232425//wildcardQuery 通配符查询 ? 一个 * 0到多个@Testpublic void testWildcardQuery() { WildcardQueryBuilder wildcardQueryBuilder = QueryBuilders.wildcardQuery(&quot;name&quot;, &quot;张*&quot;); testResult(wildcardQueryBuilder);}private void testResult(QueryBuilder queryBuilder) { SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(queryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(20)//设置每页展示记录数，默认10条 .addSort(&quot;age&quot;, SortOrder.ASC)//设置排序 desc降序 asc升序 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} prefix前缀查询123456789101112131415161718192021222324252627/** * prefix 前缀查询 */@Testpublic void testPrefixQuery() { PrefixQueryBuilder prefixQueryBuilder = QueryBuilders.prefixQuery(&quot;name&quot;, &quot;中&quot;); testResult(prefixQueryBuilder);}private void testResult(QueryBuilder queryBuilder) { SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(queryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(20)//设置每页展示记录数，默认10条 .addSort(&quot;age&quot;, SortOrder.ASC)//设置排序 desc降序 asc升序 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} ids查询123456789101112131415161718192021222324252627/** * ids查询 */@Testpublic void testIdsQuery() { IdsQueryBuilder idsQueryBuilder = QueryBuilders.idsQuery().addIds(&quot;U1q9k3YBZ23tdxk-z2eh&quot;, &quot;1&quot;); testResult(idsQueryBuilder);}private void testResult(QueryBuilder queryBuilder) { SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(queryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(20)//设置每页展示记录数，默认10条 .addSort(&quot;age&quot;, SortOrder.ASC)//设置排序 desc降序 asc升序 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} fuzzy模糊查询123456789101112131415161718192021222324252627/** * fuzzy模糊查询 字符数：0-2 不允许模糊 3-5 可以出现一个模糊 &gt;5最多出现两个模糊 */@Testpublic void testFuzzyQuery() { FuzzyQueryBuilder fuzzyQueryBuilder = QueryBuilders.fuzzyQuery(&quot;name&quot;, &quot;厉害&quot;); testResult(fuzzyQueryBuilder);}private void testResult(QueryBuilder queryBuilder) { SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(queryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(20)//设置每页展示记录数，默认10条 .addSort(&quot;age&quot;, SortOrder.ASC)//设置排序 desc降序 asc升序 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} bool查询12345678910111213141516171819202122232425262728/** * bool查询 */@Testpublic void testBoolQuery() { BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery() .must(QueryBuilders.termQuery(&quot;name&quot;, &quot;张三&quot;)); testResult(boolQueryBuilder);}private void testResult(QueryBuilder queryBuilder) { SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(queryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(20)//设置每页展示记录数，默认10条 .addSort(&quot;age&quot;, SortOrder.ASC)//设置排序 desc降序 asc升序 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} 指定返回字段查询123456789101112131415161718192021222324/** * 指定返回字段查询 */@Testpublic void testMatchAllQuerySource() { //查询条件 MatchAllQueryBuilder matchAllQueryBuilder = QueryBuilders.matchAllQuery(); SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(matchAllQueryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(2)//设置每页展示记录数，默认10条 .setSource(SearchSourceBuilder.searchSource().fetchSource(&quot;*&quot;, &quot;age&quot;))//执行结果中返回哪些字段 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} multiMatch多字段查询12345678910111213141516171819202122232425262728/** * multiMatch 多字段查询 */@Testpublic void testMultiMatchQuery() { MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders .multiMatchQuery(&quot;2&quot;, &quot;name&quot;, &quot;content&quot;); testResult(multiMatchQueryBuilder);}private void testResult(QueryBuilder queryBuilder) { SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(queryBuilder)//指定查询条件 .setFrom(0)//起始条数 默认从0开始（当前页-1）*size .setSize(20)//设置每页展示记录数，默认10条 .addSort(&quot;age&quot;, SortOrder.ASC)//设置排序 desc降序 asc升序 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { System.out.println(&quot;hit.getSourceAsString() = &quot; + hit.getSourceAsString()); }} 高亮查询123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 高亮查询 */@Testpublic void testHighlight() throws ParseException { List&lt;User&gt; users = new ArrayList&lt;&gt;(); //创建highlightBuilder HighlightBuilder highlightBuilder = new HighlightBuilder() .field(&quot;*&quot;) .requireFieldMatch(false) .preTags(&quot;&lt;span style='color:red;'&gt;&quot;) .postTags(&quot;&lt;/span&gt;&quot;); SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;)//指定类型 .setQuery(QueryBuilders.termQuery(&quot;name&quot;, &quot;张三&quot;))//指定查询条件 .highlighter(highlightBuilder)//高亮处理 .get(); SearchHits hits = searchResponse.getHits(); System.out.println(&quot;总条数 = &quot; + hits.getTotalHits()); System.out.println(&quot;最大得分 = &quot; + hits.getMaxScore()); SearchHit[] hits1 = hits.getHits(); for (SearchHit hit : hits1) { User user = new User(); //封装原始结果 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); user.setId(hit.getId()); user.setName(sourceAsMap.get(&quot;name&quot;).toString()); user.setAge(Integer.valueOf(sourceAsMap.get(&quot;age&quot;).toString())); //user.setBir(new SimpleDateFormat(&quot;yyyy-MM-dd&quot;).parse(sourceAsMap.get(&quot;bir&quot;).toString())); user.setContent(sourceAsMap.get(&quot;content&quot;).toString()); user.setAddress(sourceAsMap.get(&quot;address&quot;).toString()); //高亮处理 Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields(); if (highlightFields.containsKey(&quot;name&quot;)) { user.setName(highlightFields.get(&quot;name&quot;).fragments()[0].toString()); } if (highlightFields.containsKey(&quot;content&quot;)) { user.setContent(highlightFields.get(&quot;content&quot;).fragments()[0].toString()); } users.add(user); } //遍历集合 users.forEach(user -&gt; System.out.println(&quot;user = &quot; + user));} 过滤查询12345678910111213141516/** * 过滤查询 主要用在查询执行之前对大量数据进行过滤 */@Testpublic void testHighlight() { RangeQueryBuilder rangeQueryBuilder = QueryBuilders.rangeQuery(&quot;name&quot;).gte(0).lte(23); SearchResponse searchResponse = transportClient.prepareSearch(&quot;buubiu&quot;) .setTypes(&quot;user&quot;) .setPostFilter(rangeQueryBuilder)//过滤条件 .setQuery(QueryBuilders.matchAllQuery()) .get(); SearchHit[] hits = searchResponse.getHits().getHits(); for (SearchHit hit : hits) { System.out.println(&quot;hit.toString() = &quot; + hit.toString()); }}","link":"/Java%E6%93%8D%E4%BD%9CElasticSearch/"},{"title":"Java虚拟机(JVM)问题总结","text":"Java 内存区域说一下 JVM 的主要组成部分及其作用？ JVM包含两个子系统和两个组件，两个子系统为Class loader(类装载)、Execution engine(执行引擎)；两个组件为Runtime data area(运行时数据区)、Native Interface(本地接口)。 Class loader(类装载)：根据给定的全限定名类名(如：java.lang.Object)来装载class文件到Runtime data area中的method area。 Execution engine（执行引擎）：执行classes中的指令。 Native Interface(本地接口)：与native libraries交互，是其它编程语言交互的接口。 Runtime data area(运行时数据区域)：这就是我们常说的JVM的内存。 作用 ：首先通过编译器把 Java 代码转换成字节码，类加载器（ClassLoader）再把字节码加载到内存中，将其放在运行时数据区（Runtime data area）的方法区内，而字节码文件只是 JVM 的一套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解析器执行引擎（Execution Engine），将字节码翻译成底层系统指令，再交由 CPU 去执行，而这个过程中需要调用其他语言的本地库接口（Native Interface）来实现整个程序的功能。 下面是Java程序运行机制详细说明 Java程序运行机制步骤 首先利用IDE集成开发工具编写Java源代码，源文件的后缀为.java； 再利用编译器(javac命令)将源代码编译成字节码文件，字节码文件的后缀名为.class； 运行字节码的工作是由解释器(java命令)来完成的。 从上图可以看，java文件通过编译器变成了.class文件，接下来类加载器又将这些.class文件加载到JVM中。其实可以一句话来解释：类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个 java.lang.Class对象，用来封装类在方法区内的数据结构。 说一下 JVM 运行时数据区Java 虚拟机在执行 Java 程序的过程中会把它所管理的内存区域划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有些区域随着虚拟机进程的启动而存在，有些区域则是依赖线程的启动和结束而建立和销毁。Java 虚拟机所管理的内存被划分为如下几个区域： 不同虚拟机的运行时数据区可能略微有所不同，但都会遵从 Java 虚拟机规范， Java 虚拟机规范规定的区域分为以下 5 个部分： 程序计数器（Program Counter Register）：当前线程所执行的字节码的行号指示器，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成； Java 虚拟机栈（Java Virtual Machine Stacks）：用于存储局部变量表、操作数栈、动态链接、方法出口等信息； 本地方法栈（Native Method Stack）：与虚拟机栈的作用是一样的，只不过虚拟机栈是服务 Java 方法的，而本地方法栈是为虚拟机调用 Native 方法服务的； Java 堆（Java Heap）：Java 虚拟机中内存最大的一块，是被所有线程共享的，几乎所有的对象实例都在这里分配内存； 方法区（Methed Area）：用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据。 深拷贝和浅拷贝浅拷贝（shallowCopy）只是增加了一个指针指向已存在的内存地址， 深拷贝（deepCopy）是增加了一个指针并且申请了一个新的内存，使这个增加的指针指向这个新的内存， 使用深拷贝的情况下，释放内存的时候不会因为出现浅拷贝时释放同一个内存的错误。 浅复制：仅仅是指向被复制的内存地址，如果原地址发生改变，那么浅复制出来的对象也会相应的改变。 深复制：在计算机中开辟一块新的内存地址用于存放复制的对象。 说一下堆栈的区别？物理地址 堆的物理地址分配对对象是不连续的。因此性能慢些。在GC的时候也要考虑到不连续的分配，所以有各种算法。比如，标记-消除，复制，标记-压缩，分代（即新生代使用复制算法，老年代使用标记——压缩） 栈使用的是数据结构中的栈，先进后出的原则，物理地址分配是连续的。所以性能快。 内存分别 堆因为是不连续的，所以分配的内存是在运行期确认的，因此大小不固定。一般堆大小远远大于栈。 栈是连续的，所以分配的内存大小要在编译期就确认，大小是固定的。 存放的内容 堆存放的是对象的实例和数组。因此该区更关注的是数据的存储 栈存放：局部变量，操作数栈，返回结果。该区更关注的是程序方法的执行。 PS： 静态变量放在方法区 静态的对象还是放在堆。 程序的可见度 堆对于整个应用程序都是共享、可见的。 栈只对于线程是可见的。所以也是线程私有。他的生命周期和线程相同。 队列和栈是什么？有什么区别？队列和栈都是被用来预存储数据的。 操作的名称不同。队列的插入称为入队，队列的删除称为出队。栈的插入称为进栈，栈的删除称为出栈。 可操作的方式不同。队列是在队尾入队，队头出队，即两边都可操作。而栈的进栈和出栈都是在栈顶进行的，无法对栈底直接进行操作。 操作的方法不同。队列是先进先出（FIFO），即队列的修改是依先进先出的原则进行的。新来的成员总是加入队尾（不能从中间插入），每次离开的成员总是队列头上（不允许中途离队）。而栈为后进先出（LIFO）,即每次删除（出栈）的总是当前栈中最新的元素，即最后插入（进栈）的元素，而最先插入的被放在栈的底部，要到最后才能删除。 HotSpot虚拟机对象探秘对象的创建说到对象的创建，首先让我们看看 Java 中提供的几种对象创建方式： Header 解释 使用new关键字 调用了构造函数 使用Class的newInstance方法 调用了构造函数 使用Constructor类的newInstance方法 调用了构造函数 使用clone方法 没有调用构造函数 使用反序列化 没有调用构造函数 下面是对象创建的主要流程: 虚拟机遇到一条new指令时，先检查常量池是否已经加载相应的类，如果没有，必须先执行相应的类加载。类加载通过后，接下来分配内存。若Java堆中内存是绝对规整的，使用“指针碰撞“方式分配内存；如果不是规整的，就从空闲列表中分配，叫做”空闲列表“方式。划分内存时还需要考虑一个问题-并发，也有两种方式: CAS同步处理，或者本地线程分配缓冲(Thread Local Allocation Buffer, TLAB)。然后内存空间初始化操作，接着是做一些必要的对象设置(元信息、哈希码…)，最后执行&lt;init&gt;方法。 为对象分配内存类加载完成后，接着会在Java堆中划分一块内存分配给对象。内存分配根据Java堆是否规整，有两种方式： 指针碰撞：如果Java堆的内存是规整，即所有用过的内存放在一边，而空闲的的放在另一边。分配内存时将位于中间的指针指示器向空闲的内存移动一段与对象大小相等的距离，这样便完成分配内存工作。 空闲列表：如果Java堆的内存不是规整的，则需要由虚拟机维护一个列表来记录那些内存是可用的，这样在分配的时候可以从列表中查询到足够大的内存分配给对象，并在分配后更新列表记录。 选择哪种分配方式是由 Java 堆是否规整来决定的，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 处理并发安全问题对象的创建在虚拟机中是一个非常频繁的行为，哪怕只是修改一个指针所指向的位置，在并发情况下也是不安全的，可能出现正在给对象 A 分配内存，指针还没来得及修改，对象 B 又同时使用了原来的指针来分配内存的情况。解决这个问题有两种方案： 对分配内存空间的动作进行同步处理（采用 CAS + 失败重试来保障更新操作的原子性）； 把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在 Java 堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer, TLAB）。哪个线程要分配内存，就在哪个线程的 TLAB 上分配。只有 TLAB 用完并分配新的 TLAB 时，才需要同步锁。通过-XX:+/-UserTLAB参数来设定虚拟机是否使用TLAB。 对象的访问定位Java程序需要通过 JVM 栈上的引用访问堆中的具体对象。对象的访问方式取决于 JVM 虚拟机的实现。目前主流的访问方式有 句柄 和 直接指针 两种方式。 指针： 指向对象，代表一个对象在内存中的起始地址。 句柄： 可以理解为指向指针的指针，维护着对象的指针。句柄不直接指向对象，而是指向对象的指针（句柄不发生变化，指向固定内存地址），再由对象的指针指向对象的真实内存地址。 句柄访问Java堆中划分出一块内存来作为句柄池，引用中存储对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息，具体构造如下图所示： 优势：引用中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而引用本身不需要修改。 直接指针如果使用直接指针访问，引用 中存储的直接就是对象地址，那么Java堆对象内部的布局中就必须考虑如何放置访问类型数据的相关信息。 优势：速度更快，节省了一次指针定位的时间开销。由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是非常可观的执行成本。HotSpot 中采用的就是这种方式。 内存溢出异常Java会存在内存泄漏吗？请简单描述内存泄漏是指不再被使用的对象或者变量一直被占据在内存中。理论上来说，Java是有GC垃圾回收机制的，也就是说，不再被使用的对象，会被GC自动回收掉，自动从内存中清除。 但是，即使这样，Java也还是存在着内存泄漏的情况，java导致内存泄露的原因很明确：长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这就是java中内存泄露的发生场景。 垃圾收集器简述Java垃圾回收机制在java中，程序员是不需要显示的去释放一个对象的内存的，而是由虚拟机自行执行。在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫面那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收。 GC是什么？为什么要GCGC 是垃圾收集的意思（Gabage Collection）,内存处理是编程人员容易出现问题的地方，忘记或者错误的内存 回收会导致程序或系统的不稳定甚至崩溃，Java 提供的 GC 功能可以自动监测对象是否超过作用域从而达到自动 回收内存的目的，Java 语言没有提供释放已分配内存的显示操作方法。 垃圾回收的优点和原理。并考虑2种回收机制java语言最显著的特点就是引入了垃圾回收机制，它使java程序员在编写程序时不再考虑内存管理的问题。 由于有这个垃圾回收机制，java中的对象不再有“作用域”的概念，只有引用的对象才有“作用域”。 垃圾回收机制有效的防止了内存泄露，可以有效的使用可使用的内存。 垃圾回收器通常作为一个单独的低级别的线程运行，在不可预知的情况下对内存堆中已经死亡的或很长时间没有用过的对象进行清除和回收。 程序员不能实时的对某个对象或所有对象调用垃圾回收器进行垃圾回收。 垃圾回收有分代复制垃圾回收、标记垃圾回收、增量垃圾回收。 垃圾回收器的基本原理是什么？垃圾回收器可以马上回收内存吗？有什么办法主动通知虚拟机进行垃圾回收？对于GC来说，当程序员创建对象时，GC就开始监控这个对象的地址、大小以及使用情况。 通常，GC采用有向图的方式记录和管理堆(heap)中的所有对象。通过这种方式确定哪些对象是”可达的”，哪些对象是”不可达的”。当GC确定一些对象为”不可达”时，GC就有责任回收这些内存空间。 可以。程序员可以手动执行System.gc()，通知GC运行，但是Java语言规范并不保证GC一定会执行。 Java 中都有哪些引用类型？ 强引用：发生 gc 的时候不会被回收。 软引用：有用但不是必须的对象，在发生内存溢出之前会被回收。 弱引用：有用但不是必须的对象，在下一次GC时会被回收。 虚引用（幽灵引用/幻影引用）：无法通过虚引用获得对象，用 PhantomReference 实现虚引用，虚引用的用途是在 gc 时返回一个通知。 怎么判断对象是否可以被回收？垃圾收集器在做垃圾回收的时候，首先需要判定的就是哪些内存是需要被回收的，哪些对象是「存活」的，是不可以被回收的；哪些对象已经「死掉」了，需要被回收。 一般有两种方法来判断： 引用计数器法：为每个对象创建一个引用计数，有对象引用时计数器 +1，引用被释放时计数 -1，当计数器为 0 时就可以被回收。它有一个缺点不能解决循环引用的问题； 可达性分析算法：从 GC Roots 开始向下搜索，搜索所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是可以被回收的。 在Java中，对象什么时候可以被垃圾回收当对象对当前使用这个对象的应用程序变得不可触及的时候，这个对象就可以被回收了。垃圾回收不会发生在永久代，如果永久代满了或者是超过了临界值，会触发完全垃圾回收(Full GC)。如果你仔细查看垃圾收集器的输出信息，就会发现永久代也是被回收的。这就是为什么正确的永久代大小对避免Full GC是非常重要的原因。 JVM中的永久代中会发生垃圾回收吗垃圾回收不会发生在永久代，如果永久代满了或者是超过了临界值，会触发完全垃圾回收(Full GC)。如果你仔细查看垃圾收集器的输出信息，就会发现永久代也是被回收的。这就是为什么正确的永久代大小对避免Full GC是非常重要的原因。请参考下Java8：从永久代到元数据区(译者注：Java8中已经移除了永久代，新加了一个叫做元数据区的native内存区) 说一下 JVM 有哪些垃圾回收算法？ 标记-清除算法：标记无用对象，然后进行清除回收。缺点：效率不高，无法清除垃圾碎片。 复制算法：按照容量划分二个大小相等的内存区域，当一块用完的时候将活着的对象复制到另一块上，然后再把已使用的内存空间一次清理掉。缺点：内存使用率不高，只有原来的一半。 标记-整理算法：标记无用对象，让所有存活的对象都向一端移动，然后直接清除掉端边界以外的内存。 分代算法：根据对象存活周期的不同将内存划分为几块，一般是新生代和老年代，新生代基本采用复制算法，老年代采用标记整理算法。 标记-清除算法标记无用对象，然后进行清除回收。 标记-清除算法（Mark-Sweep）是一种常见的基础垃圾收集算法，它将垃圾收集分为两个阶段： 标记阶段：标记出可以回收的对象。 清除阶段：回收被标记的对象所占用的空间。 标记-清除算法之所以是基础的，是因为后面讲到的垃圾收集算法都是在此算法的基础上进行改进的。 优点：实现简单，不需要对象进行移动。 缺点：标记、清除过程效率低，产生大量不连续的内存碎片，提高了垃圾回收的频率。 标记-清除算法的执行的过程如下图所示 复制算法为了解决标记-清除算法的效率不高的问题，产生了复制算法。它把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾收集时，遍历当前使用的区域，把存活对象复制到另外一个区域中，最后将当前使用的区域的可回收的对象进行回收。 优点：按顺序分配内存即可，实现简单、运行高效，不用考虑内存碎片。 缺点：可用的内存大小缩小为原来的一半，对象存活率高时会频繁进行复制。 复制算法的执行过程如下图所示 标记-整理算法在新生代中可以使用复制算法，但是在老年代就不能选择复制算法了，因为老年代的对象存活率会较高，这样会有较多的复制操作，导致效率变低。标记-清除算法可以应用在老年代中，但是它效率不高，在内存回收后容易产生大量内存碎片。因此就出现了一种标记-整理算法（Mark-Compact）算法，与标记-整理算法不同的是，在标记可回收的对象后将所有存活的对象压缩到内存的一端，使他们紧凑的排列在一起，然后对端边界以外的内存进行回收。回收后，已用和未用的内存都各自一边。 优点：解决了标记-清理算法存在的内存碎片问题。 缺点：仍需要进行局部对象移动，一定程度上降低了效率。 标记-整理算法的执行过程如下图所示 分代收集算法当前商业虚拟机都采用分代收集的垃圾收集算法。分代收集算法，顾名思义是根据对象的存活周期将内存划分为几块。一般包括年轻代、老年代 和 永久代，如图所示： 说一下 JVM 有哪些垃圾回收器？如果说垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。下图展示了7种作用于不同分代的收集器，其中用于回收新生代的收集器包括Serial、PraNew、Parallel Scavenge，回收老年代的收集器包括Serial Old、Parallel Old、CMS，还有用于回收整个Java堆的G1收集器。不同收集器之间的连线表示它们可以搭配使用。 Serial收集器（复制算法): 新生代单线程收集器，标记和清理都是单线程，优点是简单高效； ParNew收集器 (复制算法): 新生代收并行集器，实际上是Serial收集器的多线程版本，在多核CPU环境下有着比Serial更好的表现； Parallel Scavenge收集器 (复制算法): 新生代并行收集器，追求高吞吐量，高效利用 CPU。吞吐量 = 用户线程时间/(用户线程时间+GC线程时间)，高吞吐量可以高效率的利用CPU时间，尽快完成程序的运算任务，适合后台应用等对交互相应要求不高的场景； Serial Old收集器 (标记-整理算法): 老年代单线程收集器，Serial收集器的老年代版本； Parallel Old收集器 (标记-整理算法)： 老年代并行收集器，吞吐量优先，Parallel Scavenge收集器的老年代版本； CMS(Concurrent Mark Sweep)收集器（标记-清除算法）： 老年代并行收集器，以获取最短回收停顿时间为目标的收集器，具有高并发、低停顿的特点，追求最短GC回收停顿时间。 G1(Garbage First)收集器 (标记-整理算法)： Java堆并行收集器，G1收集器是JDK1.7提供的一个新收集器，G1收集器基于“标记-整理”算法实现，也就是说不会产生内存碎片。此外，G1收集器不同于之前的收集器的一个重要特点是：G1回收的范围是整个Java堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老年代。 详细介绍一下 CMS 垃圾回收器？CMS 是英文 Concurrent Mark-Sweep 的简称，是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。在启动 JVM 的参数加上“-XX:+UseConcMarkSweepGC”来指定使用 CMS 垃圾回收器。 CMS 使用的是标记-清除的算法实现的，所以在 gc 的时候回产生大量的内存碎片，当剩余内存不能满足程序运行要求时，系统将会出现 Concurrent Mode Failure，临时 CMS 会采用 Serial Old 回收器进行垃圾清除，此时的性能将会被降低。 新生代垃圾回收器和老年代垃圾回收器都有哪些？有什么区别？ 新生代回收器：Serial、ParNew、Parallel Scavenge 老年代回收器：Serial Old、Parallel Old、CMS 整堆回收器：G1 新生代垃圾回收器一般采用的是复制算法，复制算法的优点是效率高，缺点是内存利用率低；老年代回收器一般采用的是标记-整理的算法进行垃圾回收。 简述分代垃圾回收器是怎么工作的？分代回收器有两个分区：老生代和新生代，新生代默认的空间占比总空间的 1/3，老生代的默认占比是 2/3。 新生代使用的是复制算法，新生代里有 3 个分区：Eden、To Survivor、From Survivor，它们的默认占比是 8:1:1，它的执行流程如下： 把 Eden + From Survivor 存活的对象放入 To Survivor 区； 清空 Eden 和 From Survivor 分区； From Survivor 和 To Survivor 分区交换，From Survivor 变 To Survivor，To Survivor 变 From Survivor。 每次在 From Survivor 到 To Survivor 移动时都存活的对象，年龄就 +1，当年龄到达 15（默认配置是 15）时，升级为老生代。大对象也会直接进入老生代。 老生代当空间占用到达某个值之后就会触发全局垃圾收回，一般使用标记整理的执行算法。以上这些循环往复就构成了整个分代垃圾回收的整体执行流程。 内存分配策略简述java内存分配与回收策率以及Minor GC和Major GC所谓自动内存管理，最终要解决的也就是内存分配和内存回收两个问题。前面我们介绍了内存回收，这里我们再来聊聊内存分配。 对象的内存分配通常是在 Java 堆上分配（随着虚拟机优化技术的诞生，某些场景下也会在栈上分配，后面会详细介绍），对象主要分配在新生代的 Eden 区，如果启动了本地线程缓冲，将按照线程优先在 TLAB 上分配。少数情况下也会直接在老年代上分配。总的来说分配规则不是百分百固定的，其细节取决于哪一种垃圾收集器组合以及虚拟机相关参数有关，但是虚拟机对于内存的分配还是会遵循以下几种「普世」规则： 对象优先在 Eden 区分配多数情况，对象都在新生代 Eden 区分配。当 Eden 区分配没有足够的空间进行分配时，虚拟机将会发起一次 Minor GC。如果本次 GC 后还是没有足够的空间，则将启用分配担保机制在老年代中分配内存。 这里我们提到 Minor GC，如果你仔细观察过 GC 日常，通常我们还能从日志中发现 Major GC/Full GC。 Minor GC 是指发生在新生代的 GC，因为 Java 对象大多都是朝生夕死，所有 Minor GC 非常频繁，一般回收速度也非常快； Major GC/Full GC 是指发生在老年代的 GC，出现了 Major GC 通常会伴随至少一次 Minor GC。Major GC 的速度通常会比 Minor GC 慢 10 倍以上。 大对象直接进入老年代所谓大对象是指需要大量连续内存空间的对象，频繁出现大对象是致命的，会导致在内存还有不少空间的情况下提前触发 GC 以获取足够的连续空间来安置新对象。 前面我们介绍过新生代使用的是标记-清除算法来处理垃圾回收的，如果大对象直接在新生代分配就会导致 Eden 区和两个 Survivor 区之间发生大量的内存复制。因此对于大对象都会直接在老年代进行分配。 长期存活对象将进入老年代虚拟机采用分代收集的思想来管理内存，那么内存回收时就必须判断哪些对象应该放在新生代，哪些对象应该放在老年代。因此虚拟机给每个对象定义了一个对象年龄的计数器，如果对象在 Eden 区出生，并且能够被 Survivor 容纳，将被移动到 Survivor 空间中，这时设置对象年龄为 1。对象在 Survivor 区中每「熬过」一次 Minor GC 年龄就加 1，当年龄达到一定程度（默认 15） 就会被晋升到老年代。 虚拟机类加载机制简述java类加载机制?虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验，解析和初始化，最终形成可以被虚拟机直接使用的java类型。 描述一下JVM加载Class文件的原理机制Java中的所有类，都需要由类加载器装载到JVM中才能运行。类加载器本身也是一个类，而它的工作就是把class文件从硬盘读取到内存中。在写程序的时候，我们几乎不需要关心类的加载，因为这些都是隐式装载的，除非我们有特殊的用法，像是反射，就需要显式的加载所需要的类。 类装载方式，有两种 ： 1.隐式装载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中， 2.显式装载， 通过class.forname()等方法，显式加载需要的类 Java类的加载是动态的，它并不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类(像是基类)完全加载到jvm中，至于其他类，则在需要的时候才加载。这当然就是为了节省内存开销。 什么是类加载器，类加载器有哪些?实现通过类的权限定名获取该类的二进制字节流的代码块叫做类加载器。 主要有一下四种类加载器: 启动类加载器(Bootstrap ClassLoader)用来加载java核心类库，无法被java程序直接引用。 扩展类加载器(extensions class loader):它用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。 系统类加载器（system class loader）：它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。 用户自定义类加载器，通过继承 java.lang.ClassLoader类的方式实现。 说一下类装载的执行过程？类装载分为以下 5 个步骤： 加载：根据查找路径找到相应的 class 文件然后导入； 验证：检查加载的 class 文件的正确性； 准备：给类中的静态变量分配内存空间； 解析：虚拟机将常量池中的符号引用替换成直接引用的过程。符号引用就理解为一个标示，而在直接引用直接指向内存中的地址； 初始化：对静态变量和静态代码块执行初始化工作。 什么是双亲委派模型？在介绍双亲委派模型之前先说下类加载器。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立在 JVM 中的唯一性，每一个类加载器，都有一个独立的类名称空间。类加载器就是根据指定全限定名称将 class 文件加载到 JVM 内存，然后再转化为 class 对象。 类加载器分类： 启动类加载器（Bootstrap ClassLoader），是虚拟机自身的一部分，用来加载Java_HOME/lib/目录中的，或者被 -Xbootclasspath 参数所指定的路径中并且被虚拟机识别的类库； 其他类加载器： 扩展类加载器（Extension ClassLoader）：负责加载\\lib\\ext目录或Java. ext. dirs系统变量指定的路径中的所有类库； 应用程序类加载器（Application ClassLoader）。负责加载用户类路径（classpath）上的指定类库，我们可以直接使用这个类加载器。一般情况，如果我们没有自定义类加载器默认就是用这个加载器。 双亲委派模型：如果一个类加载器收到了类加载的请求，它首先不会自己去加载这个类，而是把这个请求委派给父类加载器去完成，每一层的类加载器都是如此，这样所有的加载请求都会被传送到顶层的启动类加载器中，只有当父加载无法完成加载请求（它的搜索范围中没找到所需的类）时，子加载器才会尝试去加载类。 当一个类收到了类加载请求时，不会自己先去加载这个类，而是将其委派给父类，由父类去加载，如果此时父类不能加载，反馈给子类，由子类去完成类的加载。 JVM调优说一下 JVM 调优的工具？JDK 自带了很多监控工具，都位于 JDK 的 bin 目录下，其中最常用的是 jconsole 和 jvisualvm 这两款视图监控工具。 jconsole：用于对 JVM 中的内存、线程和类等进行监控； jvisualvm：JDK 自带的全能分析工具，可以分析：内存快照、线程快照、程序死锁、监控内存的变化、gc 变化等。 常用的 JVM 调优的参数都有哪些？ -Xms2g：初始化推大小为 2g； -Xmx2g：堆最大内存为 2g； -XX:NewRatio=4：设置年轻的和老年代的内存比例为 1:4； -XX:SurvivorRatio=8：设置新生代 Eden 和 Survivor 比例为 8:2； –XX:+UseParNewGC：指定使用 ParNew + Serial Old 垃圾回收器组合； -XX:+UseParallelOldGC：指定使用 ParNew + ParNew Old 垃圾回收器组合； -XX:+UseConcMarkSweepGC：指定使用 CMS + Serial Old 垃圾回收器组合； -XX:+PrintGC：开启打印 gc 信息； -XX:+PrintGCDetails：打印 gc 详细信息。 参考：https://blog.csdn.net/ThinkWon","link":"/Java%E8%99%9A%E6%8B%9F%E6%9C%BAJVM%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"},{"title":"Jenkins Pipeline使用","text":"什么是Jenkins的流水线Jenkins Pipeline（或简称为带有大写“P”的“Pipeline”）是一套插件，支持将持续交付管道实现和集成到 Jenkins 中。 一个持续交付（CD）管道是一直到你的用户和客户的过程正从版本控制软件的自动化表达。对您的软件（在源代码控制中提交）的每一次更改在发布之前都经历了一个复杂的过程。此过程涉及以可靠且可重复的方式构建软件，以及通过多个测试和部署阶段推进构建的软件（称为“构建”）。 Pipeline 提供了一组可扩展的工具，用于通过Pipeline 域特定语言 (DSL) 语法对从简单到复杂的交付管道“作为代码”进行建模 创建Pipeline项目的三种方式Pipeline的定义对Jenkins 流水线的定义被写在一个文本文件中 (称为 Jenkinsfile)，该文件可以被提交到项目的源代码的控制仓库。这是”流水线即代码”的基础; 将CD 流水线作为应用程序的一部分，像其他代码一样进行版本化和审查。 Jenkinsfile 能使用两种语法进行编写 - 声明式和脚本化。 声明式和脚本化的流水线从根本上是不同的。 声明式流水线相较于脚本化的流水线： 声明式流水线提供更丰富的语法特性, 声明式流水线是为了使编写和读取流水线代码更容易而设计的。 脚本化流水线是用Groovy 语法编写的 不过，许多写入 的单个语法组件（或“步骤”） Jenkinsfile对于声明式管道和脚本式管道都是通用的 通过Blue Ocean创建在 Blue Ocean 中设置一个流水线项目后，Blue Ocean UI 会帮你编写流水线的 Jenkinsfile 文件并提交到源代码管理系统。 通过经典UI创建（推荐）使用经典 UI 创建的 Jenkinsfile 由 Jenkins 自己保存（在 Jenkins 的主目录下）。 登录成功后，从Jenkins 主页（即 Jenkins 经典 UI 的工作台），点击左上的 新建Item。 输入名称，点击 流水线，并确认 注意： Jenkins 使用此项目名称在磁盘上创建目录。建议避免在项目名称中使用空格，因为这样做可能会发现脚本中未正确处理目录路径中的空格的错误。 点击页面顶部 流水线选项卡，确保 定义字段是 Pipeline script选项，并写入流水线代码，保存 12345678910pipeline { agent any stages { stage('Stage 1') { steps { echo 'Hello world!' } } }} agent 指 Jenkins 为整个流水线分配一个执行器（在 Jenkins 环境中的任何可用代理/节点上）和工作区。 echo 写一个简单的字符串到控制台输出。 node 与上面的 agent 做了同样的事情。 在该页面, 点击左侧的 立即构建 运行流水线 在左侧的 Build History 下面，点击 #1 来访问这个特定流水线运行的详细信息。 点击 Console Output 来查看流水线运行的全部输出。下面的输出显示你的流水线已成功运行。 通过SCM(源代码管理系统)创建复杂的流水线如果 通过经典UI创建 ，很麻烦和复杂 为简化操作，流水线的 Jenkinsfile 可以在文本编辑器或集成开发环境（IDE）中进行编写并提交到源码管理系统 （可选择性地与需要 Jenkins 构建的应用程序代码放在一起）。然后 Jenkins 从源代码管理系统中检出 Jenkinsfile 文件作为流水线项目构建过程的一部分并接着执行你的流水线。 操作步骤： 按照 通过经典UI创建 上面的步骤定义你的流水线直到第3步（在流水线配置页面访问流水线部分） 从 定义 字段选择 Pipeline script from SCM 选项。 从 SCM 字段，选择包含 Jenkinsfile 文件的仓库的源代码管理系统的类型。 填充对应仓库的源代码管理系统的字段。 在 脚本路径 字段，指定你的 Jenkinsfile 文件的位置（和名称）。这个位置是 Jenkins 检出/克隆包括 Jenkinsfile 文件的仓库的位置，它应该与仓库的文件结构匹配。该字段的默认值采取名称为 “Jenkinsfile” 的 Jenkinsfile 文件并位于仓库的根路径。 创建Pipeline对于目前最新版本的 Jenkins 来说，存在两种语法格式的 Pipeline：脚本式 Pipeline（Scripted Pipeline）和声明式 Pipeline(Declarative Pipeline)。 脚本式 Pipeline脚本式 Pipeline 是早期编写 Pipelien 的语法，开发人员通过编写自己的 Groovy 脚本来定义 Pipeline，虽然这为我们提供了很强的灵活性，但需要开发者有较好的 Groovy 编程经验。 格式1234567891011121314node { stage(&quot;CodeStyle Check&quot;) { echo &quot;Checking...&quot; } stage(&quot;Build&quot;) { echo &quot;Building...&quot; } stage(&quot;Test&quot;) { echo &quot;Testing...&quot; } stage(&quot;Deploy&quot;) { echo &quot;Deploying...&quot; }} 特点 最外层有node{}包裹 可直接使用groovy语句 声明式 Pipeline（重点核心）声明式 Pipeline 是在 Pipeline 2.5 版本中新引入的语法格式，相对于 脚本式 Pipeline 来说，声明式 Pipelien 提供了更加简洁和灵活的语法，新增了更丰富的功能，在大大降低了 Pipeline 编写难度的同时，又不失其灵活性。无论你之前是否了解过 Pipeline，声明式 Pipeline 都是你以后在编写 Pipeline 道路上的的首选方案。 格式12345678910111213141516171819202122232425pipeline { agent any stages { stage(&quot;CodeStyle Check&quot;) { steps { echo &quot;Checking...&quot; } } stage(&quot;Build&quot;) { steps { echo &quot;Building&quot; } } stage(&quot;Test&quot;) { steps { echo &quot;Testing&quot; } } stage(&quot;Deploy&quot;) { steps { echo &quot;Deploying&quot; } } }} pipeline 用于定义 Pipeline 块，所有有关 Pipeline 定义的部分必须全部被定义在该语句块内，除了 Groovy 定义的类，方法，变量等。 agent 指定要执行 Pipeline 的 Jenkins 节点。 stages 用来包括所有的 stage。 stage 用来包括具体所要执行的操作。 steps 用来包括要执行的指令。 echo 打印字符串。 特点 最外层必须由pipline{ //do something }来进行包裹 不需要分号作为分隔符，每个语句必须在一行内 不能直接使用groovy语句（例如循环判断等），需要被script {}包裹 Pipeline 语法主要是介绍 声明式 Pipeline 中的语法 pipeline应用于全局最外层，表明该脚本为声明式pipeline agent当我们要执行某个 Pipeline 时，必须指定执行该 Pipelien 的 Jenkins 节点，只有指定了运行节点的 Pipeline 才可以被执行。指定执行节点是通过 agent 来定义的。agent 必须被定义在 pipeline{} 块的最顶端，我们可以称之为全局 agent，用来为整个 Pipeline 指定一个要执行的节点。可选的，也可以在某个 stage 块中定义 agent，表明为当前 stage 指定一个执行节点，我们会在讲解 stage 时在具体介绍。 参数列表any 表明 Pipeline 可以在任意一个 Jenkins 节点中运行，包括 master 节点。当使用该参数时，Jenkins 会在当前空闲的节点中随意选择一个节点来运行 Pipeline。 示例： 123pipeline { agent any} label通过 Jenkins 节点的 Label 属性选择节点。 示例： 12345pipeline { agent { label 'Linux' }} 该示例表明将在所有 Label 为 Linux 的节点中随机选择一个空闲的节点来执行 Pipeline。 注意：如果指定了一个不存在的 Label，Jenkins 会像处理离线节点那样，Job将一直等待节点上线，而并不会报出任何异常。 nodenode 是在 label 参数的基础上，添加了一些附加的选项。它是一个语句块，语句块中可以定义以下参数： label：必选参数，与 agent 的 label 参数功能一样，通过 Jenkins 节点的 Label 属性来选择适当的节点 customWorkspace：可选参数，指定当前节点上执行 Pipeline 或是 Stage（在 stage 中设置了 agent）时的目录。默认情况下，当运行 Pipeline 时，Jenkins 会在工作节点机器上的默认工作目录（通过节点配置页面的 Remote root directory 选项指定）下创建一个与所运行 Job 同名的子目录作为 Pipeline 的执行目录。customWorkspace 选项可以让我们手动选择一个自定义。其值可以是一个绝对路径，也可以是一个以该节点默认的工作目录为根路径的相对路径。 示例： 12345678pipeline { agent { node { label 'Linux' customWorkspace '/tmp/Jenkins' } }} 在这个示例中，除了我们额外使用绝对路径指定了 Pipeline 的工作目录为 /tmp/Jenkins 之外，其功能与使用 label 的示例功能完全相同。 none只有 Pipeline 最顶端的 agent 可以指定为 none 参数，该参数表明不为当前整体 Pipeline 分配任何节点，相应地，必须在每个 stage 块中单独配置一个 Jenkins 节点，这样不同的 stage 可以运行在不同的 Jenkins 节点中。 示例： 1234567891011121314151617pipeline { //没有为当前 Pipeline 分配任何执行节点 agent none stages { //指定 stage1 可以运行在任何一个节点中 stage(&quot;stage1&quot;) { agent any ... } //指定 stage2 只能运行在 Label 是 Linux 的节点上 stage(&quot;stage2&quot;) { agent { label &quot;Linux&quot; } } }} stagesstages 是一个用来包含一个或多个 stage 指令的序列块，它无需任何参数。每个 Pipeline 必须有且只能有一个 stages 块，而且每个 stages 中至少需要包含一个 stage 指令。 而 stage 是用来包裹那些真正执行某些操作的指令的。每个 stage 应当包含用于去完成某个 比如构建代码，执行测试用例，部署到生产环境中去等，而这些步骤一般都被封装在各自的 stage 中。一个 stages 块中必须至少包含一个 stage 指令。在整个 Pipeline 中，应当有且仅有一个 stages 块。stages 在使用时不接受任何参数。 stage在编写一个 Pipeline 时，我们应当按照不同的阶段或是不同的功能，将 Pipeline 拆分成不同的阶段，比如在整个 CD 流程中，一般都至少包括 打包代码、运行自动化测试脚本以及部署等流程。stage 就是用来封装这些流程的，我们应当将这些流程分别定义在各自的 stage 中，当运行 Pipeline 时，Jenkins 会按照定义时的顺序依次执行这些流程。同时，最终生成的可视化页面也是按照 stage 为单位显示的。 stage 必须被包含在 stages 中，并且至少包含一个。而在每个 stage 中，必须包含其只能包含一个 steps 来执行具体的指令，或是一个 parallel 指令来定义需要并行执行的 stage，以及一些可选的如 agent、environment、options、tool 等其他指令。 参数列表stage 接收一个字符串参数，用来给当前 stage 命名。 示例： 123456789101112131415161718192021222324pipeline { agent { label 'Linux' } stages { //定义一个名为 build 的 stage stage(&quot;build&quot;) { //在该 stage 内部定义 agent，指明运行当前 stage 时所在的 Jenkins 节点 agent { label 'Linux2' } //定义一个 step，这是该 stage 真正执行操作的地方。在这个示例中，通过 sh step 在节点中执行 mvn clean install 命令 steps { sh 'mvn clean install' } } //定义一个名为 test 的 stage，该 stage 会运行在 Pipeline 中指定的节点中 stage(&quot;test&quot;) { steps { sh &quot;mvn test&quot; } } }} stepssteps 被定义在 stage 中，每个 stage 必须包含且只能包含一个 steps， 用于调用 Jenkins 中的特定指令，比如在前面的例子所中使用的 sh 指令。 steps 中除了可以调用 Jenkins 中定义的指令外，还支持 script 指令，在 script 中，我们可以定义并执行脚本式 Pipeline。 示例： 12345678910111213141516171819pipeline { agent any stages { stage('Example') { steps { //调用 echo 指令来输出 “Hello World” 字符串 echo 'Hello World' //9-14行：通过 script 指令执行 Groovy 脚本 script { def browsers = ['chrome', 'firefox'] for (int i = 0; i &lt; browsers.size(); ++i) { echo &quot;Testing the ${browsers[i]} browser&quot; } } } } }} environmentenvironment 指令可以帮助我们定义环境变量，当在指定的 Jenkins 节点中在执行 stage 中的指令时，定义的环境变量会被添加到节点机器的系统环境变量中去。该指令既可以被定义在 pipeline 最外层中来定义环境变量，这样定义的环境变量对所有 stage 都有效，也可有定义在某个特定的 stage 中，这样定义的环境变量仅仅会应用到当前 stage 执行时所在的节点。 credentials 方法credentials 是 environment 指令提供了一个附加的 helper 方法，通过将我们在 Jenkins 中定义的 credentials 时指定的 ID 作为参数传递给该方法，可以获取到该 credential 的值，并将该值赋值给指定的环境变量。使用 credentials 方法获取到的 credential 的值仍然是加密过的，因此用户不必担心敏感信息的泄漏问题。如果我们不想将这些 credentials 以环境变量的形式获取，还可以使用 Jenkins 还提供的 withCredentials 方法。 示例： 123456789101112131415161718192021pipeline { agent any //4-6 行，在 Pipeline 最外层定义了一个环境变量 CC，这个环境变量可以被该 Pipeline 中的所有 stage 所引用 environment { CC = 'clang' } stages { stage('Example') { //10-12行，在 stage 中定义的环境变量 AN_ACCESS_KEY，并将系统中预定义好的 ID 为 my-prefined-secret-text 的 credential 的值。该环境变量仅对当前 stage 有效 environment { AN_ACCESS_KEY = credentials('my-prefined-secret-text') } steps { //通过执行系统的 printenv 命令里获取所有系统中所有环境变量，可以在输出中同时看到我们上面定义的 CC 和 AN_ACCESS_KEY 两个环境变量，并且 AN_ACCESS_KEY 的值是以 **** 的形式展现出来的 sh 'printenv' //通过 Jenkins 中的 env 系统变量来获取指定的环境变量 echo &quot;${env.AN_ACCESS_KEY}&quot; } } }} optionsoptions 指令可以让我们为当前的 Pipeline 或某个特定的 stage 设置一些附加选项。 如果该指令出现在 pipeline 块的最外层，则这些选项对整个 Pipeline 生效； 如果该指令出现在某个 stage 内，则这些选项设置仅对当前的 stage 生效。 options 指令中可用的选项，一部分来自于 Jenkins 自身定义好的，一部分来自于某些插件。并且对整体 Pipeline 范围来说可用的选项和 stage 范围可用的选项也不尽相同，下面让分别介绍一下在 Pipeline 级别中和 stage 级别中一些比较常用的选项。 Pipeline 中的可用选项123456789101112131415161718192021222324pipeline { agent any options { //表示只保留最近执行的 5 个 Job 的日志和归档信息 buildDiscarder(logRotator(numToKeepStr: '5')) //关闭 Pipeline 并行执行的能力 disableConcurrentBuilds() //当某个 stage 执行结果状态变为 UNSTABLE 时，将跳过余下的所有 stage skipStagesAfterUnstable() //指定该 Pipeline 最多可执行 1 小时 timeout(time: 1, unit: 'HOURS') //当 Pipeline 执行失败后，指定尝试重新执行该 Pipeline 的次数 retry(3) //当日志信息打印到 Jenkins Job 的控制台输出页面时，同时打印出日志的时间戳信息 timestamps() } stages { stage('Example') { steps { ...... } } }} buildDiscarder每当 Jenkins Job 被执行一次，都会产生一些日志文件，或是一些由 Job 生成的归档文件，当 Job 被执行的次数越多，生成的日志和归档文件就越多，数以千计的日志文件和归档文件不但会占用大量的系统磁盘资源，还会影响到 Jenkins 性能。因此定期清理这些无用的日志和归档文件非常重要。buildDiscarder 选项可以让我们选择保留该 Pipeline 最近执行的多少个 Job 的日志信息，超过这个数量的 Job 日志信息和归档文件将被自动清除。 如：options { buildDiscarder(logRotator(numToKeepStr: '5')) }，表示只保留最近执行的 5 个 Job 的日志和归档信息。 我们还可以直接在 Jenkins Job 的配置页面中，通过配置 Discard old builds 来达到同样的目的。 disableConcurrentBuilds默认情况下，Pipeline 支持并行运行，即同一个 Pipeline 可以同时被执行多次（前提是执行 Pipeline 的 agent 设置正确）。当有些时候，我们并不希望 Pipeline 被并行执行，disableConcurrentBuilds 方法可以帮助我们关闭 Pipeline 并行执行的能力，如: options { disableConcurrentBuilds() } skipStagesAfterUnstable如果设定了 skipStagesAfterUnstable 选项，则当某个 stage 执行结果状态变为 UNSTABLE 时，将跳过余下的所有 stage。如：options { skipStagesAfterUnstable() }。 timeouttimeout 选项可用于设置 Pipeline 的最大执行时间，当超过指定时间后，Pipeline 将被自动终止。如：options { timeout(time: 1, unit: 'HOURS') } 指定该 Pipeline 最多可执行 1 小时。 retry就像该参数名字的含义一样，当 Pipeline 执行失败后，我们可以通过 retry 参数指定尝试重新执行该 Pipeline 的次数，当尝试过指定次数后仍然失败，则 Pipeline 状态设置为失败并退出执行。如：options { retry(3) }。 timestamps当日志信息打印到 Jenkins Job 的控制台输出页面时，同时打印出日志的时间戳信息。如：options { timestamps() }。 stage 中的可用的选项这些选项在 stage 中的使用方式与在 Pipeline 中的使用方式一样，只是在 stage 中定义的选项仅对当前的 stage 有效。 timeout设置当前 stage 的最大执行时间。 retry设置当前 stage 执行失败后可以自动尝试重新执行的次数。 timestamps仅为当前 stage 中的日志输出设置时间戳信息。 parameters虽然在创建 Jenkins job 时可以在 Job 配置页面指定执行 Job 时所需的参数，Pipeline 额外还提供了 parameters 指令，用于声明执行 Pipeline 时所需要的参数列表。parameters 指令只能被包含在 pipeline 块的最外层，并且在整个 Pipeline 块中只能定义一个 parameters 指令。 在 parameters 指令中支持调用两个方法：string() 和 booleanParam()， 分别用于定义一个字符串类型的参数和一个布尔值类型的参数，每个方法都可以接收一下参数： 参数列表name必选参数，指定参数的名字。 defaultValue指定参数的默认值，该参数为可选参数，对于字符串类型的参数来说，如果没有指定该参数，默认值为 null；对于布尔值类型的参数来说，如果没有指定改制，默认是为 false。 description可选参数，为该参数添加描述信息，方法其他开发人员参考。 示例1234567891011121314151617181920pipeline { agent any //6-9行中，我们使用 parameters 指令定义了两个参数： //- 参数名为 PERSON 的字符串类型的，该参数默认值为 Mr Jenkins。 //- 参数名为 DEBUG_BUILD 的布尔值类型参数，该参数默认为 true。 parameters { string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?') booleanParam(name: 'DEBUG_BUILD', defaultValue: true, description: '') } stages { stage('Example') { steps { //通过 Jenkins 内置的 params 变量来获取这两个参数的值 echo &quot;Hello ${params.PERSON}&quot; echo &quot;${params.DEBUG_BUILD}&quot; } } }} whenwhen 指令可以帮助我们编写条件式 stage，即只有某些条件符合时，才会执行指定的 stage 指令，它必须定义在 stage 中。Jenkins 内置了许多条件表达式，让我们简单介绍一下常见的表达式。 常见的表达式allOf至少包含一个表达式，并且当所有的表达式都为真时，才会执行该 stage。 anyOf至少包含一个表达式，并且只要有一个条件为真，就会执行该 stage。 not只能包含一个表达式，当该表达式为假时，就会执行该 stage。 environment如果存在指定的环境变量，并且其值等于给定的值，则执行该 stage。 expression当给定的 Groovy 脚本返回真时，则执行该 stage。 branch如果当前使用的分支名与指定的分支名相同，则执行该 stage。注意，只有在多分支的 Pipeline 中才可以使用该选项。 beforeAgent 行为默认情况下，当执行某个带有 when 指令的 stage 时，Jenkins 首先会进入到当前 stage 要执行的节点服务器中，然后在判断 when 指令中指定的条件。 如果指定 beforeAgent 为 true，则在进入到节点之前就开始进行判断，只有条件符合后才会进入到节点中执行该 stage。 示例123456789101112131415161718192021222324pipeline { agent any stages { stage('Example Deploy') { //定义 when 指令，该指令中共包含 3 个条件，when 指令默认使用 allOf，因此，只有定义的 3 个条件全部为真时，当前 stage Example Deploy 才会被执行 when { //指定先对 when 中的条件进行判断，只有所有条件符合后，才会进入到某个节点中执行 steps 操作 beforeAgent true //当前所操作的分支名应当为 production branch 'production' //通过 expression 指定的该表达式返回应当返回真 expression { BRANCH_NAME ==~ /(production|staging)/ } //14-17行，在 anyOf 块中定义了两个表达式：执行的节点系统中存在环境变量 DEPLOY_TO，并且该值必须是 production 或 staging 中的一个值 anyOf { environment name: 'DEPLOY_TO', value: 'production' environment name: 'DEPLOY_TO', value: 'staging' } } steps { echo 'Deploying' } } }} Parallel在 Pipeline 中，默认同时只能执行一个 stage 块，但有些时候某些 stage 之间没有互相依赖关系，我们通常希望可以并行执行这些互相没有任何依赖的 stage，来加速整个 Pipeline 的构建速度。我们可以通过 Pipeline 提供的 parallel 指令来实现，该指令必须被包含在 stage 块中，parallel 中不能在嵌套其他的 parallel。注意，在定义了 parallel 的 stage 中，不能够在使用任何 agent 或 tool 等指令，如果有必须，需要在 parallel 中的每个 stage 中进行各自的定义。 同时，我们还可以指定，当并行执行的多个 stage 中，只要有任意一个 stage 执行失败，就可以终止所有其他并行执行的 stage，这通过设置 failFast true 来实现。 示例12345678910111213141516171819202122232425262728293031323334353637pipeline { agent any stages { stage('Non-Parallel Stage') { steps { echo 'This stage will be executed first.' } } stage('Parallel Stage') { when { branch 'master' } //指定了 failFast true，表明 parallel 中定义的 Branch A stage 和 Branch B stage 中的任意一个执行失败，另一个则会马上停止 failFast true //定义了 parralel，并在其内部定义了两个可以同时并行执行的 stage：Branch A 和 Branch B parallel { stage('Branch A') { //19-21行，为 ‘Branch A’ stage 指定了要执行的节点 agent { label &quot;for-branch-a&quot; } steps { echo &quot;On Branch A&quot; } } stage('Branch B') { agent { label &quot;for-branch-b&quot; } steps { echo &quot;On Branch B&quot; } } } } }} tools用于引用配置好的工具，需要提前在 系统管理-&gt;全局工具配置里面配置过 示例12345678910111213pipeline { agent any tools { maven 'apache-maven-3.0.1' } stages { stage('Example') { steps { sh 'mvn --version' } } }} inputinput指令允许暂时中断pipeline执行，等待用户输入，根据用户输入进行下一步动作 示例123456789101112131415161718pipeline { agent any stages { stage('Example') { input { message &quot;Should we continue?&quot; ok &quot;Yes, we should.&quot; submitter &quot;alice,bob&quot; parameters { string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?') } } steps { echo &quot;Hello, ${PERSON}, nice to meet you.&quot; } } }} post执行构建后的操作，根据构建结果来执行对应的操作，作用在pipeline结束后或者stage结束后。 参数列表 always 无论pipeline或stage的完成状态如何，都允许在 post 部分运行该步骤。 changed 只有当前pipeline或stage的完成状态与它之前的运行不同时，才允许在 post 部分运行该步骤。 failure 只有当前pipeline或stage的完成状态为”failure”，才允许在 post 部分运行该步骤, 通常web UI是红色。 success 只有当前pipeline或stage的完成状态为”success”，才允许在 post 部分运行该步骤, 通常web UI是蓝色或绿色。 unstable 只有当前pipeline或stage的完成状态为”unstable”，才允许在 post 部分运行该步骤, 通常由于测试失败,代码违规等造成。通常web UI是黄色。 aborted 只有当前pipeline或stage的完成状态为”aborted”，才允许在 post 部分运行该步骤, 通常由于pipeline被手动的aborted。通常web UI是灰色。 示例123456789101112131415pipeline{ agent any stages{ stage(&quot;first stage&quot;){ steps(&quot;first steps&quot;){ echo &quot;this is first step&quot; } } } post{ always{ echo &quot;this is ending...&quot; } }} 完整示例123456789101112131415161718192021222324252627282930313233343536373839404142434445class myname{ public get() { print('name') }}public get() { print('name')}String name = 'zzl'pipeline { agent { label 'Linux' } environment { GIT_COMMITTER_NAME = 'jenkins' } options { timeout(6, HOURS) } stages { stage('Build') { steps { sh 'mvn clean install' } } stage('Archive') { when { branch '*/master' } steps { archive '*/target/**/*' junit '*/target/surefire-reports/*.xml' } } } post { always { deleteDir() } }}","link":"/Jenkins-Pipeline%E4%BD%BF%E7%94%A8/"},{"title":"Jenkins 在Pipeline中使用Docker","text":"pipeline插件从2.5版本开始就内置了Docker插件，与之前不同的，在agent部分我们将node换成了docker。 安装docker插件在插件仓库安装插件 Docker Pipeline，会自动安装依赖插件。 使用方法在Pipeline中操作Docker，既可以用作全局环境，也可以每个stage的环境。 在镜像中执行命令参数docker：表示使用docker image：指定镜像 示例123456789101112131415161718192021222324252627282930pipeline { //在全局环境中使用docker agent { docker { image 'node:7-alpine' }//定义镜像 } stages { stage('Test') { steps { // 在镜像 node:7-alpine 中执行该命令 sh 'node --version' } } }}//或者pipeline { agent any stages { stage('Test') { //在每个stage中使用docker agent { docker { image 'node:7-alpine' } } steps { sh 'node --version' } } }} 执行结果 为容器添加运行参数这个功能也可以实现 Jenkins 缓存数据。 参数args：字符串类型，Jenkins执行docker run命令时所带的参数，如 -v -e 等 示例1234567891011121314151617pipeline { agent { docker { image 'maven:3-alpine' //// 为容器添加运行参数 把宿主机的maven的仓库挂载容器中 args '-v $HOME/.m2:/root/.m2' } } stages { stage('Build') { steps { // 在容器中执行该命令 sh 'mvn --version' } } }} 在多个容器中执行命令示例1234567891011121314151617181920212223pipeline { agent none stages { stage('Back-end') { agent { docker { image 'maven:3-alpine' }// 定义镜像一 } steps { // 在容器一中执行命令 sh 'mvn --version' } } stage('Front-end') { agent { docker { image 'node:7-alpine' }// 定义镜像二 } steps { // 在容器二中执行命令 sh 'node --version' } } }} 使用Dockerfile参数dockerfile true：表示用从 Dockerfile 中构建一个新的镜像而不是从 Docker Hub中拉取一个 示例需要将流水线定义成SCM模式 首先新建一个Dockerfile Dockerfile123FROM node:7-alpineRUN apk add -U subversion 然后在编写pipeline Jenkinsfile1234567891011pipeline { agent { dockerfile true } stages { stage('Test') { steps { sh 'node --version' sh 'svn --version' } } }} 执行结果 指定Docker标签（暂时没搞懂）默认情况下，Pipeline 假定任何配置的 代理都能够运行基于 Docker 的 Pipelines。对于具有 macOS、Windows 或其他代理的 Jenkins 环境，无法运行 Docker 守护程序，此默认设置可能有问题。Pipeline 在Manage Jenkins页面和 文件夹 级别提供了一个全局选项，用于指定使用哪些代理（通过 Label）来运行基于 Docker 的管道。 配置路径：系统管理--系统配置-- Declarative Pipeline（Docker） Docker Label：当 pipeline 中的 agent 部分没有指定 label 选项时，就会使用此配置。如docker {image’maven：3-alpine’}。 Docker registry URL：Docker私有仓库地址，或其他地址 Registry credentials：登录Docker私有仓库的凭证。 高级用法运行sidecar容器在 Pipeline 中使用 Docker 是运行构建或一组测试可能依赖的服务的有效方法。与sidecar 模式类似 ，Docker Pipeline 可以“在后台”运行一个容器，同时在容器中执行工作。利用这种 sidecar 方法， Pipeline 可以为每个 Pipeline 运行提供一个“干净”的容器。 举例一假设有一个集成测试套件，它依赖于要运行的本地 MySQL 数据库。使用withRun在Docker Pipeline插件支持 Scripted Pipeline 中实现的方法， Jenkinsfile可以将 MySQL 作为 sidecar 运行： 1234567891011121314node { checkout scm /* * In order to communicate with the MySQL server, this Pipeline explicitly * maps the port (`3306`) to a known port on the host machine. * 将这个镜像的3306端口映射到主机了，这样就可以为jenkins提供测试环境了，而无需在本地安装mysql了 */ docker.image('mysql:5').withRun('-e &quot;MYSQL_ROOT_PASSWORD=my-secret-pw&quot; -p 3306:3306') { c -&gt; /* Wait until mysql service is up */ sh 'while ! mysqladmin ping -h0.0.0.0 --silent; do sleep 1; done' /* Run some tests which require MySQL */ sh 'make check' }} 举例二这个例子可以更进一步，同时使用两个容器。一个运行 MySQL 的“sidecar”，另一个通过使用 Docker 容器链接提供执行环境。 123456789101112131415161718192021222324node { checkout scm //最外面跑的容器是提供本次构建的测试环境的 docker.image('mysql:5').withRun('-e &quot;MYSQL_ROOT_PASSWORD=my-secret-pw&quot;') { c -&gt; //这个容器是在内部执行了一个命令 //inside表示在容器内部运行命令 // link 表示创建链接 // c.id 是容器的ID，通过方法withRun的返回值c获取的 docker.image('mysql:5').inside(&quot;--link ${c.id}:db&quot;) { /* Wait until mysql service is up */ sh 'while ! mysqladmin ping -hdb --silent; do sleep 1; done' //在退出 pipeline之前可以通过ID查看docker容器日志 sh &quot;docker logs ${c.id}&quot; } //这个容器在内部执行了一个需要mysql服务的命令 docker.image('centos:7').inside(&quot;--link ${c.id}:db&quot;) { /* * Run some tests which require MySQL, and assume that it is * available on the host name `db` */ sh 'make check' } }} 构建镜像docker.build()Docker pipeline 插件提供了一个 build()方法，用于在流水线运行期间从存储库的 Dockerfile中创建一个新的镜像。 用法一docker.build(&quot;my-image-name&quot;) 在默认情况下， build() 方法使用当前目录（Jenkinsfile文件）下的 Dockerfile。 使用该语法的一个主要好处是脚本pipeline可以使用返回值进行后续 Docker pipeline调用，例如： 12345678910node { checkout scm def customImage = docker.build(&quot;my-image:${env.BUILD_ID}&quot;) customImage.inside { //在构建好的镜像内部执行测试命令 sh 'make test' }} 用法二若想使用其他路径的 Dockerfile，可传入第二个参数，该参数是包含 Dockerfile文件的路径，仅是相对路径，例如，若想使用./dockerfiles/test/Dockerfile，则： 12345678node { checkout scm def testImage = docker.build(&quot;test-image&quot;, &quot;./dockerfiles/test&quot;) testImage.inside { sh 'make test' }} 用法三若build()中有若干个参数，需要保证参数最后的字符串必须是以 所用到的Dockerfile的路径，比如，现在要是用这个文件构建：./dockerfiles/Dockerfile.test: 12345node { checkout scm def dockerfile = 'Dockerfile.test' def customImage = docker.build(&quot;my-image:${env.BUILD_ID}&quot;, &quot;-f ${dockerfile} ./dockerfiles&quot;) } 上传镜像到仓库push()该返回值也可以用于通过 push() 方法将Docker 镜像发布到 Docker Hub, 或 custom Registry,比如: 12345node { checkout scm def customImage = docker.build(&quot;my-image:${env.BUILD_ID}&quot;) customImage.push()} 参数push() 方法接受可选的 tag 参数, 允许pipeline使用不同的标签 push customImage , 比如: 12345678node { checkout scm def customImage = docker.build(&quot;my-image:${env.BUILD_ID}&quot;) //customImage.push() //也可以指定上传不同的标签 customImage.push('latest')} 调用远程的docker默认情况下，Docker Pipeline插件是与本地的Docker守护线程通过/var/run/docker.sock进行通信的，也就是说操作的docker都是本地的；要想操作远程服务器上的docker，比如 Docker 集群，要使用方法 withServer()。 1234567891011node { checkout scm //调用远程的docker服务来跑容器 //第二个参数是在jenkins中设置好的认证id，填上去就可以了 docker.withServer('tcp://swarm.example.com:2376', 'swarm-certs') { //跑这个镜像来提供本次测试的运行环境 docker.image('mysql:5').withRun('-p 3306:3306') { /* do things */ } }} 使用自定义的docker仓库默认情况下，Docker Pipeline集成采用Docker Hub的默认 Docker Registry 。 为了使用自定义 Docker Registry，Scripted Pipeline 的用户可以使用该withRegistry()方法包装步骤，传入自定义 Registry URL，例如： 无身份验证的docker仓库12345678910node { checkout scm //自定义的docker仓库 docker.withRegistry('https://registry.example.com') { //提供运行环境并执行命令 docker.image('my-custom-image').inside { sh 'make test' } }} 有身份验证的docker仓库对于需要身份验证的 Docker Registry，从 Jenkins 主页添加“用户名/密码”凭据项，并使用凭据 ID 作为第二个参数withRegistry()： 123456789101112node { checkout scm //设置自定义仓库的认证 //第二个参数是在jenkins中设置好的认证id，填上去就可以了 docker.withRegistry('https://registry.example.com', 'credentials-id') { //构建镜像 def customImage = docker.build(&quot;my-image:${env.BUILD_ID}&quot;) //上传镜像 /* Push the container to the custom Registry */ customImage.push() }}","link":"/Jenkins-%E5%9C%A8Pipeline%E4%B8%AD%E4%BD%BF%E7%94%A8Docker/"},{"title":"Jenkins创建多分支pipeline","text":"介绍Multibranch Pipeline 项目类型能够 在同一个项目的不同分支上实现不同的Jenkinsfile。 在多分支流水线项目中, Jenkins 自动的发现, 管理和执行在源代码控制中包含Jenkinsfile的分支的流水线。 这消除了手动创建和管理流水线的需要。 操作步骤 点击新建任务 选择多分支流水线 添加 分支源 (比如, Git) 并输入仓库的位置 默认情况下， Jenkins 不会自动的重新索引分支添加或删除的仓库(除非使用 组织文件夹), 所以周期性地重新索引有助于配置多分支流水线： 点击保存，等待系统自动创建多分支job","link":"/Jenkins%E5%88%9B%E5%BB%BA%E5%A4%9A%E5%88%86%E6%94%AFpipeline/"},{"title":"Jenkins的介绍与安装","text":"Jenkins是什么Jenkins是一款开源 CI&amp;CD 软件，用于自动化各种任务，包括构建、测试和部署软件。 Jenkins 支持各种运行方式，可通过系统包、Docker 或者通过一个独立的 Java 程序。 安装JenkinsDocker方式12345678910111213141516# 8080：控制台端口 # 50000：基于JNLP的Jenkins代理通过TCP端口50000与Jenkins主站进行通信# root：用root用户执行，否则服务挂载目录，提示copy失败，无权限# /var/jenkins_home：jenkins的工作目录# /var/run/docker.sock：若想Jenkins支持控制docker,挂载这个(只有Linux支持)# /usr/bin/docker：本地docker命令所在目录挂载出来，否则jenkins不能支持docker命令(只有Linux支持)$ docker run \\ -u root \\ -d \\ -p 8080:8080 \\ -p 50000:50000 \\ -v /opt/jenkins/jenkins_home:/var/jenkins_home \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /usr/bin/docker:/usr/bin/docker \\ --name jenkins \\ jenkins/jenkins:latest-jdk8 可通过查看日志查看初始密码： 1234567891011121314151617181920212223242526272829$ docker logs -f jenkins***************************************************************************************************************************************************************************************Jenkins initial setup is required. An admin user has been created and a password generated.Please use the following password to proceed to installation:7c227bb4453b411c8db81a31116d56aeThis may also be found at: /var/jenkins_home/secrets/initialAdminPassword***************************************************************************************************************************************************************************************2021-12-20 07:42:39.909+0000 [id=34] INFO jenkins.InitReactorRunner$1#onAttained: Completed initialization2021-12-20 07:42:40.484+0000 [id=21] INFO hudson.WebAppMain$3#run: Jenkins is fully up and running WAR包方式Jenkins的Web应用程序ARchive（WAR）文件版本可以安装在任何支持Java的操作系统或平台上。 要下载并运行Jenkins的WAR文件版本，请执行以下操作: 将最新的稳定Jenkins WAR包 下载到您计算机上的相应目录。 在下载的目录内打开一个终端/命令提示符窗口到。 运行命令java -jar jenkins.war，也可以指定端口：java -jar jenkins.war --httpPort=9090 浏览http://localhost:8080并等到*Unlock Jenkins*页面出现。 Notes: 不像在Docker中下载和运行有Blue Ocean的Jenkins，这个过程不会自动安装Blue Ocean功能， 这将分别需要在jenkins上通过 Manage Jenkins &gt; Manage Plugins安装。 在Getting started with Blue Ocean有关于安装Blue Ocean的详细信息 。. 您可以通过--httpPort在运行java -jar jenkins.war命令时指定选项来更改端口。例如，要通过端口9090访问Jenkins，请使用以下命令运行Jenkins： java -jar jenkins.war --httpPort=9090 Linux二进制Debian/Ubuntu在基于Debian的发行版（如Ubuntu）上，您可通过apt安装Jenkins 每 12 周从常规版本流中选择一个LTS（长期支持）版本作为该时间段的稳定版本。它可以从debian-stableapt 存储库安装。 1234567$ curl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo tee \\ /usr/share/keyrings/jenkins-keyring.asc &gt; /dev/null$ echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \\ https://pkg.jenkins.io/debian-stable binary/ | sudo tee \\ /etc/apt/sources.list.d/jenkins.list &gt; /dev/null$ sudo apt-get update$ sudo apt-get install jenkins 安装这个软件包将会： 将Jenkins设置为启动时启动的守护进程。查看/etc/init.d/jenkins获取更多细节 创建一个’jenkins‘用户来运行此服务 直接将控制台日志输出到文件/var/log/jenkins/jenkins.log。如果您正在解决Jenkins问题，请检查此文件 /etc/default/jenkins为启动填充配置参数，例如JENKINS_HOME 将Jenkins设置为在端口8080上进行监听。使用浏览器访问此端口以开始配置 如果你的/etc/init.d/jenkins文件无法启动Jenkins，编辑/etc/default/jenkins， 修改 ----HTTP_PORT=8080----为----HTTP_PORT=8081---- 在这里，“8081”也可被换为其他可用端口。 Fedora1234567sudo wget -O /etc/yum.repos.d/jenkins.repo \\ https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keysudo dnf upgrade# Add required dependencies for the jenkins packagesudo dnf install chkconfig java-develsudo dnf install jenkins Start JenkinsRegister the Jenkins service with the command: 1sudo systemctl daemon-reload You can start the Jenkins service with the command: 1sudo systemctl start jenkins You can check the status of the Jenkins service using the command: 1sudo systemctl status jenkins If everything has been set up correctly, you should see an output like this: 12Loaded: loaded (/etc/rc.d/init.d/jenkins; generated)Active: active (running) since Tue 2018-11-13 16:19:01 +03; 4min 57s ago Red Hat / CentOS每 12 周从常规版本流中选择一个LTS（长期支持）版本作为该时间段的稳定版本。它可以从debian-stableapt 存储库安装。 1234567sudo wget -O /etc/yum.repos.d/jenkins.repo \\ https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keysudo yum upgradesudo yum install epel-release java-11-openjdk-develsudo yum install jenkinssudo systemctl daemon-reload Start JenkinsYou can start the Jenkins service with the command: 1sudo systemctl start jenkins You can check the status of the Jenkins service using the command: 1sudo systemctl status jenkins If everything has been set up correctly, you should see an output like this: 123Loaded: loaded (/etc/rc.d/init.d/jenkins; generated)Active: active (running) since Tue 2018-11-13 16:19:01 +03; 4min 57s ago... 简单的初始配置 浏览器访问http://localhost:8080/，并输入安装后得到的密码 紧接着有两个选项 安装建议的插件 - 安装推荐的一组插件，这些插件基于最常见的用例.（新手推荐） 选择要安装的插件 - 选择安装的插件集。当你第一次访问插件选择页面时，默认选择建议的插件。 创建第一个管理员用户安装好插件后，会提示创建用户：","link":"/Jenkins%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%89%E8%A3%85/"},{"title":"Keytool创建证书","text":"简介keytool 是java 用于管理密钥和证书的工具，官方文档其功能包括： 创建并管理密钥 创建并管理证书 作为CA 为证书授权 导入导出证书 主要格式keytool 采用 keystore 文件来存储密钥及证书，其中可包括私钥、信任证书；keystore 文件主要使用 JKS格式(也可支持其他格式)，带密钥存储；其中私钥的存储也有独立的密码；其他格式 keytool工具帮助命令1234567891011121314151617181920212223$ keytool -help密钥和证书管理工具命令: -certreq 生成证书请求 -changealias 更改条目的别名 -delete 删除条目 -exportcert 导出证书 -genkeypair 生成密钥对 -genseckey 生成密钥 -gencert 根据证书请求生成证书 -importcert 导入证书或证书链 -importpass 导入口令 -importkeystore 从其他密钥库导入一个或所有条目 -keypasswd 更改条目的密钥口令 -list 列出密钥库中的条目 -printcert 打印证书内容 -printcertreq 打印证书请求的内容 -printcrl 打印 CRL 文件的内容 -storepasswd 更改密钥库的存储口令使用 &quot;keytool -command_name -help&quot; 获取 command_name 的用法 生成私钥和证书keytool -genkey 帮助命令1234567891011121314151617181920212223242526272829$ keytool -genkey -helpkeytool -genkeypair [OPTION]...生成密钥对选项: -alias &lt;alias&gt; 要处理的条目的别名 -keyalg &lt;keyalg&gt; 密钥算法名称 -keysize &lt;keysize&gt; 密钥位大小 -groupname &lt;name&gt; Group name. For example, an Elliptic Curve name. -sigalg &lt;sigalg&gt; 签名算法名称 -destalias &lt;destalias&gt; 目标别名 -dname &lt;dname&gt; 唯一判别名 -startdate &lt;startdate&gt; 证书有效期开始日期/时间 -ext &lt;value&gt; X.509 扩展 -validity &lt;valDays&gt; 有效天数 -keypass &lt;arg&gt; 密钥口令 -keystore &lt;keystore&gt; 密钥库名称 -storepass &lt;arg&gt; 密钥库口令 -storetype &lt;storetype&gt; 密钥库类型 支持：JKS(默认)和 PKCS12 -providername &lt;providername&gt; 提供方名称 -providerclass &lt;providerclass&gt; 提供方类名 -providerarg &lt;arg&gt; 提供方参数 -providerpath &lt;pathlist&gt; 提供方类路径 -v 详细输出 -protected 通过受保护的机制的口令使用 &quot;keytool -help&quot; 获取所有可用命令 生成证书默认生成 jks 格式的证书1234567891011121314151617181920212223$ keytool -genkeypair -alias serverkey -keystore server.keystore输入密钥库口令:再次输入新口令:它们不匹配。请重试输入密钥库口令:再次输入新口令:您的名字与姓氏是什么? [Unknown]: bu您的组织单位名称是什么? [Unknown]: buubiu您的组织名称是什么? [Unknown]: dev您所在的城市或区域名称是什么? [Unknown]: SZ您所在的省/市/自治区名称是什么? [Unknown]: JS该单位的双字母国家/地区代码是什么? [Unknown]: CNCN=bu, OU=buubiu, O=buubiu, L=SZ, ST=JS, C=CN是否正确? [否]:y输入 &lt;serverkey&gt; 的密钥口令 (如果和密钥库口令相同, 按回车): 按提示 输入keystore 存储密码、私钥密码、个人信息，之后会生成 server.keystore文件若不想输入参数，可提供参数： 1234# keysize 密钥长度(DSA算法对应的默认算法是sha1withDSA，不支持2048长度，此时需指定RSA)$ keytool -genkeypair -alias serverkey -keypass 123456 -storepass 123456 \\-dname &quot;C=CN,ST=JS,L=SZ,O=buubiu,OU=dev,CN=bu&quot; \\-keyalg RSA -keysize 2048 -validity 365 -keystore server.keystore 生成 pkcs12 格式的证书跟上面同理，多了个指定证书的类型： 123$ keytool -genkeypair -storetype PKCS12 -alias serverkey -keypass 123456 -storepass 123456 \\-dname &quot;C=CN,ST=JS,L=SZ,O=buubiu,OU=dev,CN=bu&quot; \\-keyalg RSA -keysize 2048 -validity 365 -keystore server.p12 查看keystore详情keytool -list帮助命令1234567891011121314151617181920$ keytool -list -helpkeytool -list [OPTION]...列出密钥库中的条目选项: -rfc 以 RFC 样式输出 -alias &lt;alias&gt; 要处理的条目的别名 -keystore &lt;keystore&gt; 密钥库名称 -storepass &lt;arg&gt; 密钥库口令 -storetype &lt;storetype&gt; 密钥库类型 -providername &lt;providername&gt; 提供方名称 -providerclass &lt;providerclass&gt; 提供方类名 -providerarg &lt;arg&gt; 提供方参数 -providerpath &lt;pathlist&gt; 提供方类路径 -v 详细输出 -protected 通过受保护的机制的口令使用 &quot;keytool -help&quot; 获取所有可用命令 查看详情命令12345678$ keytool -list -storepass 123456 -keystore server.keystore密钥库类型: jks密钥库提供方: SUN您的密钥库包含 1 个条目serverkey, 2021-12-9, PrivateKeyEntry,证书指纹 (SHA-256): CA:18:CD:D1:45:13:9F:86:07:4F:B4:42:89:9D:5C:EE:30:4F:85:09:7E:15:EA:3E:2A:53:AF:E3:BD:C1:9C:F7 查看更详细数据加上-v 12345678910111213141516171819202122232425262728293031323334353637$ keytool -list -v -storepass 123456 -keystore server.keystore密钥库类型(Keystore type): jks密钥库提供方(Keystore provider): SUN您的密钥库包含 1 个条目别名: serverkey创建日期: 2021-12-9条目类型(Entry type): PrivateKeyEntry证书链长度: 1证书[1]:所有者: C=CN, ST=JS, L=SZ, O=buubiu, OU=dev, CN=bu发布者: C=CN, ST=JS, L=SZ, O=buubiu, OU=dev, CN=bu序列号: 51cb8ed1生效时间: Thu Dec 09 09:56:38 CST 2021, 失效时间: Fri Dec 09 09:56:38 CST 2022证书指纹: SHA1: 45:58:60:6B:69:82:D6:B0:E6:A9:80:24:B4:ED:91:2B:35:89:81:A3 SHA256: CA:18:CD:D1:45:13:9F:86:07:4F:B4:42:89:9D:5C:EE:30:4F:85:09:7E:15:EA:3E:2A:53:AF:E3:BD:C1:9C:F7签名算法名称: SHA256withRSA主体公共密钥算法: 2048 位 RSA 密钥版本: 3扩展:#1: ObjectId: 2.5.29.14 Criticality=falseSubjectKeyIdentifier [KeyIdentifier [0000: 6A 6D BF 1B 1D 14 E2 AC 5C 76 F5 B6 A4 0B D5 5E jm......\\v.....^0010: A1 E4 5F D5 .._.]]************************************************************************************** 证书导出keytool -exportcert 帮助命令123456789101112131415161718192021$ keytool -exportcert -helpkeytool -exportcert [OPTION]...导出证书选项: -rfc 以 RFC 样式输出 -alias &lt;alias&gt; 要处理的条目的别名 -file &lt;filename&gt; 输出文件名 -keystore &lt;keystore&gt; 密钥库名称 -storepass &lt;arg&gt; 密钥库口令 -storetype &lt;storetype&gt; 密钥库类型 -providername &lt;providername&gt; 提供方名称 -providerclass &lt;providerclass&gt; 提供方类名 -providerarg &lt;arg&gt; 提供方参数 -providerpath &lt;pathlist&gt; 提供方类路径 -v 详细输出 -protected 通过受保护的机制的口令使用 &quot;keytool -help&quot; 获取所有可用命令 导出证书12$ keytool -exportcert -alias serverkey -keystore server.keystore -storepass 123456 -file server.cer存储在文件 &lt;server.cer&gt; 中的证书 此时导出的证书为DER编码格式，使用openssl 可以输出 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253$ openssl x509 -in server.cer -inform der -noout -textCertificate: Data: Version: 3 (0x2) Serial Number: 1372294865 (0x51cb8ed1) Signature Algorithm: sha256WithRSAEncryption Issuer: CN=bu, OU=dev, O=buubiu, L=SZ, ST=JS, C=CN Validity Not Before: Dec 9 01:56:38 2021 GMT Not After : Dec 9 01:56:38 2022 GMT Subject: CN=bu, OU=dev, O=buubiu, L=SZ, ST=JS, C=CN Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:82:69:72:34:fb:83:3a:b9:8d:75:d7:22:76:e1: bc:8c:d7:d5:8d:a2:45:b2:2b:74:7d:42:95:6b:00: d1:47:eb:67:fc:b8:f1:12:33:8a:8c:2b:e6:f2:8b: 8e:2b:14:6e:c7:c9:39:e5:5e:6b:68:b4:fe:3e:d5: a0:a8:e7:84:65:93:93:79:77:fb:6b:d3:9c:14:87: 24:9e:2e:6f:72:c1:c3:ec:dc:9c:44:29:f2:d2:25: 7a:58:c6:0e:9e:1d:34:f6:9f:14:89:4a:4d:4a:e5: 7a:47:14:38:bf:4e:3d:0c:77:f7:0d:bc:c4:f8:7c: fc:21:1d:29:f8:85:ac:11:94:9e:c1:3a:2a:22:8c: ea:52:b5:30:04:69:8f:52:d7:e9:83:e4:91:1a:39: 98:e0:95:fa:6e:93:6d:ab:88:45:44:69:78:c2:32: c3:ee:a1:c9:64:05:21:7b:23:7b:fc:fc:44:06:a2: 21:cf:ed:c6:88:9b:e5:a9:72:4f:6b:c0:10:10:6b: 0d:41:64:45:5b:48:8e:1c:50:f5:2b:ad:ab:e4:1a: bb:d4:38:cc:4b:e3:87:e2:8d:a6:d2:19:71:b1:88: 99:f0:64:23:8b:05:50:c4:f1:85:8f:75:43:1a:38: 93:f4:2b:b1:4d:17:40:2d:81:fa:7c:75:c5:5f:18: 4d:cf Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Subject Key Identifier: 6A:6D:BF:1B:1D:14:E2:AC:5C:76:F5:B6:A4:0B:D5:5E:A1:E4:5F:D5 Signature Algorithm: sha256WithRSAEncryption 78:98:a7:58:0c:e2:01:34:31:c0:e0:63:50:16:fb:ae:d2:a4: 88:63:3f:1b:3c:f7:e7:de:5b:81:30:30:0d:9c:06:3e:56:10: 9e:fd:fb:f5:fa:7e:02:78:fb:07:15:4d:b6:e4:77:2e:76:a5: 76:33:87:45:9a:bc:1d:4e:b3:4e:92:02:98:e2:d2:c6:5a:5d: 1d:dc:bb:e3:0f:73:ce:7f:c3:6c:90:84:99:97:c0:76:a9:d9: e3:ec:68:65:38:62:34:c6:64:a1:5f:11:07:af:e5:16:2c:4d: 33:91:91:52:bc:c0:1e:9d:6e:a2:2e:92:e0:f8:ce:47:45:cb: ab:9c:20:0d:b3:ab:e5:5e:8a:63:5d:d7:23:0d:d9:34:e9:25: e9:8d:63:e5:ed:76:06:3e:c2:37:63:0a:43:68:d1:08:9b:92: e1:43:d5:83:b0:a1:f2:66:68:16:42:e0:86:88:8d:21:38:d4: 9e:e8:47:9c:54:f7:b5:a9:f4:45:6a:69:59:44:f4:36:a7:88: c9:fd:9d:7a:e6:40:b7:ab:10:87:0c:52:ff:98:86:9a:29:70: 39:5e:cc:f2:ac:46:3c:30:4e:60:d2:68:07:95:d2:58:60:70: 44:7c:18:2b:d3:9c:76:8d:20:94:ff:eb:82:7b:38:13:a2:cb: 58:e8:08:8c 加上 -rfc选项，可输出PEM编码格式的证书 1234567891011121314151617181920212223$ keytool -exportcert -alias serverkey -keystore server.keystore -storepass 123456 -rfc -file server.cer存储在文件 &lt;server.cer&gt; 中的证书$ cat server.cer-----BEGIN CERTIFICATE-----MIIDRTCCAi2gAwIBAgIEUcuO0TANBgkqhkiG9w0BAQsFADBTMQswCQYDVQQDEwJidTEMMAoGA1UECxMDZGV2MQ8wDQYDVQQKEwZidXViaXUxCzAJBgNVBAcTAlNaMQswCQYDVQQIEwJKUzELMAkGA1UEBhMCQ04wHhcNMjExMjA5MDE1NjM4WhcNMjIxMjA5MDE1NjM4WjBTMQswCQYDVQQDEwJidTEMMAoGA1UECxMDZGV2MQ8wDQYDVQQKEwZidXViaXUxCzAJBgNVBAcTAlNaMQswCQYDVQQIEwJKUzELMAkGA1UEBhMCQ04wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCCaXI0+4M6uY111yJ24byM19WNokWyK3R9QpVrANFH62f8uPESM4qMK+byi44rFG7HyTnlXmtotP4+1aCo54Rlk5N5d/tr05wUhySeLm9ywcPs3JxEKfLSJXpYxg6eHTT2nxSJSk1K5XpHFDi/Tj0Md/cNvMT4fPwhHSn4hawRlJ7BOioijOpStTAEaY9S1+mD5JEaOZjglfpuk22riEVEaXjCMsPuoclkBSF7I3v8/EQGoiHP7caIm+Wpck9rwBAQaw1BZEVbSI4cUPUrravkGrvUOMxL44fijabSGXGxiJnwZCOLBVDE8YWPdUMaOJP0K7FNF0Atgfp8dcVfGE3PAgMBAAGjITAfMB0GA1UdDgQWBBRqbb8bHRTirFx29bakC9VeoeRf1TANBgkqhkiG9w0BAQsFAAOCAQEAeJinWAziATQxwOBjUBb7rtKkiGM/Gzz3595bgTAwDZwGPlYQnv379fp+Anj7BxVNtuR3LnaldjOHRZq8HU6zTpICmOLSxlpdHdy74w9zzn/DbJCEmZfAdqnZ4+xoZThiNMZkoV8RB6/lFixNM5GRUrzAHp1uoi6S4PjOR0XLq5wgDbOr5V6KY13XIw3ZNOkl6Y1j5e12Bj7CN2MKQ2jRCJuS4UPVg7Ch8mZoFkLghoiNITjUnuhHnFT3tan0RWppWUT0NqeIyf2deuZAt6sQhwxS/5iGmilwOV7M8qxGPDBOYNJoB5XSWGBwRHwYK9Ocdo0glP/rgns4E6LLWOgIjA==-----END CERTIFICATE----- 导入证书keytool -importcert帮助命令1234567891011121314151617181920212223$ keytool -importcert -helpkeytool -importcert [OPTION]...导入证书或证书链选项: -noprompt 不提示 -trustcacerts 信任来自 cacerts 的证书 -protected 通过受保护的机制的口令 -alias &lt;alias&gt; 要处理的条目的别名 -file &lt;filename&gt; 输入文件名 -keypass &lt;arg&gt; 密钥口令 -keystore &lt;keystore&gt; 密钥库名称 -storepass &lt;arg&gt; 密钥库口令 -storetype &lt;storetype&gt; 密钥库类型 -providername &lt;providername&gt; 提供方名称 -providerclass &lt;providerclass&gt; 提供方类名 -providerarg &lt;arg&gt; 提供方参数 -providerpath &lt;pathlist&gt; 提供方类路径 -v 详细输出使用 &quot;keytool -help&quot; 获取所有可用命令 导入证书一般为导入信任证书(SSL客户端使用) 1234$ keytool -importcert -file server.cer -alias client_trust_server -keystore client_trust.keystore -storepass 123456 -noprompt证书已添加到密钥库中$ lsclient_trust.keystore server.cer server.keystore 导入后的证书为 trustedCertEntry 实体类型，而私钥证书为 PrivateKeyEntry 打印证书keytool -printcert 帮助命令1234567891011121314$ keytool -printcert -helpkeytool -printcert [OPTION]...打印证书内容选项: -rfc 以 RFC 样式输出 -file &lt;filename&gt; 输入文件名 -sslserver &lt;server[:port]&gt; SSL 服务器主机和端口 -jarfile &lt;filename&gt; 已签名的 jar 文件 -v 详细输出使用 &quot;keytool -help&quot; 获取所有可用命令 打印证书123456789101112131415161718192021$ keytool -printcert -file server.cer所有者: C=CN, ST=JS, L=SZ, O=buubiu, OU=dev, CN=bu发布者: C=CN, ST=JS, L=SZ, O=buubiu, OU=dev, CN=bu序列号: 51cb8ed1生效时间: Thu Dec 09 09:56:38 CST 2021, 失效时间: Fri Dec 09 09:56:38 CST 2022证书指纹: SHA1: 45:58:60:6B:69:82:D6:B0:E6:A9:80:24:B4:ED:91:2B:35:89:81:A3 SHA256: CA:18:CD:D1:45:13:9F:86:07:4F:B4:42:89:9D:5C:EE:30:4F:85:09:7E:15:EA:3E:2A:53:AF:E3:BD:C1:9C:F7签名算法名称: SHA256withRSA主体公共密钥算法: 2048 位 RSA 密钥版本: 3扩展:#1: ObjectId: 2.5.29.14 Criticality=falseSubjectKeyIdentifier [KeyIdentifier [0000: 6A 6D BF 1B 1D 14 E2 AC 5C 76 F5 B6 A4 0B D5 5E jm......\\v.....^0010: A1 E4 5F D5 .._.]] 转换格式keytool -importkeystore 帮助命令123456789101112131415161718192021222324252627$ keytool -importkeystore -helpkeytool -importkeystore [OPTION]...从其他密钥库导入一个或所有条目选项: -srckeystore &lt;srckeystore&gt; 源密钥库名称 -destkeystore &lt;destkeystore&gt; 目标密钥库名称 -srcstoretype &lt;srcstoretype&gt; 源密钥库类型 -deststoretype &lt;deststoretype&gt; 目标密钥库类型 -srcstorepass &lt;arg&gt; 源密钥库口令 -deststorepass &lt;arg&gt; 目标密钥库口令 -srcprotected 受保护的源密钥库口令 -srcprovidername &lt;srcprovidername&gt; 源密钥库提供方名称 -destprovidername &lt;destprovidername&gt; 目标密钥库提供方名称 -srcalias &lt;srcalias&gt; 源别名 -destalias &lt;destalias&gt; 目标别名 -srckeypass &lt;arg&gt; 源密钥口令 -destkeypass &lt;arg&gt; 目标密钥口令 -noprompt 不提示 -providerclass &lt;providerclass&gt; 提供方类名 -providerarg &lt;arg&gt; 提供方参数 -providerpath &lt;pathlist&gt; 提供方类路径 -v 详细输出使用 &quot;keytool -help&quot; 获取所有可用命令 jks 格式转 pkcs12123456$ keytool -importkeystore -srckeystore server.keystore -destkeystore server.p12 \\-srcalias serverkey -destalias serverkey \\-srcstoretype jks -deststoretype pkcs12 \\-srcstorepass 123456 -deststorepass 123456 \\-noprompt正在将密钥库 server.keystore 导入到 server.p12... pkcs12 格式转 jks与上面同理 123456$ keytool -importkeystore -srckeystore server.p12 -destkeystore server.keystore \\-srcalias serverkey -destalias serverkey \\-srcstoretype pkcs12 -deststoretype jks \\-srcstorepass 123456 -deststorepass 123456 \\-noprompt正在将密钥库 server.p12 导入到 server.keystore... 场景示例制作 Java SSL 双向证书12345678910111213141516171819202122storepass=123456keypass=123456server_dname=&quot;C=CN,ST=JS,L=SZ,O=buubiu,OU=dev,CN=bu&quot;client_dname=&quot;C=CN,ST=JS,L=SZ,O=buubiu,OU=dev,CN=buc&quot;echo &quot;generate server keystore&quot;keytool -genkeypair -alias serverkey -keypass $keypass -storepass $storepass \\ -dname $server_dname \\ -keyalg RSA -keysize 2048 -validity 3650 -keystore server.keystoreecho &quot;generate client keystore&quot;keytool -genkeypair -alias clientkey -keypass $keypass -storepass $storepass \\ -dname $client_dname \\ -keyalg RSA -keysize 2048 -validity 3650 -keystore client.keystoreecho &quot;export server certificate&quot;keytool -exportcert -keystore server.keystore -file server.cer -alias serverkey -storepass $storepassecho &quot;export client certificate&quot;keytool -exportcert -keystore client.keystore -file client.cer -alias clientkey -storepass $storepassecho &quot;add server cert to client trust keystore&quot;keytool -importcert -keystore client_trust.keystore -file server.cer -alias client_trust_server \\ -storepass $storepass -nopromptecho &quot;add client cert to server trust keystore&quot;keytool -importcert -keystore server_trust.keystore -file client.cer -alias server_trust_client \\ -storepass $storepass -noprompt Java 证书与 nginx 证书互转Java通常使用JKS作为证书存储格式，而Nginx往往采用PEM证书格式，如何实现互转？ JKS 证书转 Nginx 证书 第一步：jks 证书转 p12 12345678$ keytool -importkeystore -srckeystore server.keystore -destkeystore server.p12 \\-srcalias serverkey -destalias serverkey \\-srcstoretype jks -deststoretype pkcs12 \\-srcstorepass 123456 -deststorepass 123456 \\-noprompt正在将密钥库 server.keystore 导入到 server.p12...$ lsserver.keystore server.p12 第二步：p12 证书提取pem证书和私钥 12345678$ openssl pkcs12 -in server.p12 -clcerts -nokeys -password pass:123456 -out server.crtMAC verified OK$ lsserver.crt server.keystore server.p12$ openssl pkcs12 -in server.p12 -nocerts -password pass:123456 -passout pass:123456 -out server.keyMAC verified OK$ lsserver.crt server.key server.keystore server.p12 其中得到的私钥文件为PKCS#8 加密格式，证书和密钥均为PEM文件编码。 Nginx 证书转 JKS 第一步：pem证书和私钥合成p12 12345$ lsserver.crt server.key$ openssl pkcs12 -export -in server.crt -inkey server.key -passin pass:123456 -password pass:123456 -name serverkey -out server.p12$ lsserver.crt server.key server.p12 注意定义-name 选项，这将作为keystore识别实体的参数 第二步：p12 证书转jks 证书 12345678$ keytool -importkeystore -srckeystore server.p12 -destkeystore server.keystore \\-srcalias serverkey -destalias serverkey \\-srcstoretype pkcs12 -deststoretype jks \\-srcstorepass 123456 -deststorepass 123456 \\-noprompt正在将密钥库 server.p12 导入到 server.keystore...$ lsserver.crt server.key server.keystore server.p12 如果p12 文件中未指定实体名称，使用keytool转换时则不需提供srcalias/destalias参数，而输出的keystore实体名称默认为1 其他已有的Nginx证书，如何快速在Java中添加信任通过keytool -importcert 命令可直接导入信任证书 keytool 通用格式为 jks，如何获取私钥通过程序读取，参考stackoverflowJavaSE样例","link":"/Keytool%E5%88%9B%E5%BB%BA%E8%AF%81%E4%B9%A6/"},{"title":"Kibana的安装与基本操作","text":"介绍Kibana是一个针对Elasticsearch的开源分析及可视化平台，使用Kibana可以查询、查看并与存储在ES索引的数据进行交互操作，使用Kibana能执行高级的数据分析，并能以图表、表格和地图的形式查看数据。 安装下载Kibanahttps://www.elastic.co/downloads/kibana 编辑kibana配置文件config/kibana.yml 修改如下配置，若es有用户名密码，还需要追加后两行： 1234567server.host: &quot;127.0.0.1&quot; #ES服务器主机地址elasticsearch.hosts: [&quot;http://127.0.0.1:9200&quot;] #ES服务器地址elasticsearch.username: &quot;kibana&quot;elasticsearch.password: &quot;Aa000000&quot;xpack.security.enabled: true#32位以上的随机数即可，用作信息的加密xpack.security.encryptionKey: &quot;4297f44b13955235245b2497399d7a93&quot; 启动kibana1../bin/kibana 关闭kibana12$ ps -ef|grep node $ kill -9 4444 访问kibana的web界面http://127.0.0.1:5601/ #kibana默认端口为5601 使用主机:端口直接访问即可 登录kibana的时候，输入的用户名和密码是:elastic/Aa000000 kibana的基本操作索引(Index)的基本操作创建索引规则：PUT /索引 1PUT /buubiu 删除索引规则：DELETE /索引 123DELETE /buubiu#删除所有DELETE /* 查看索引信息规则：GET /_cat/indices?v 1GET /_cat/indices?_v 类型(Type)的基本操作创建类型规则： PUT /索引 {} 注意：这种方式创建类型要求索引不能存在，否则创建的时候报错 1234567891011121314#创建 /buubiu索引并创建（user）类型PUT /buubiu{ &quot;mappings&quot;: { &quot;user&quot;:{ &quot;properties&quot;:{ &quot;id&quot;:{&quot;type&quot;:&quot;keyword&quot;}, &quot;name&quot;:{&quot;type&quot;:&quot;text&quot;}, &quot;age&quot;:{&quot;type&quot;:&quot;integer&quot;}, &quot;bir&quot;:{&quot;type&quot;:&quot;date&quot;} } } }} Mpping Type类型有： text , keyword , date ,integer, long , double , boolean or ip** 查看类型规则：GET /索引/_mapping 1GET /buubiu/_mapping 文档(document)的基本操作添加文档规则：PUT /索引/类型/_id 12345678910111213141516#1.手动生成文档idPUT /buubiu/user/1{ &quot;id&quot;:1, &quot;name&quot;:&quot;buubiu&quot;, &quot;age&quot;:23, &quot;bir&quot;:&quot;2020-12-12&quot;}#2.自动生成文档idPOST /buubiu/user{ &quot;id&quot;:2, &quot;name&quot;:&quot;buubiu2&quot;, &quot;age&quot;:24, &quot;bir&quot;:&quot;2020-12-14&quot;} 查看文档规则：PUT /索引/类型/_id 1GET /buubiu/user/1 删除文档规则：DELETE /索引/类型/_id 1DELETE /buubiu/user/1 更新文档 规则：POST /索引/文档id {} 注意：此方法不保留未修改的数据（先删除后插入） 1234POST /buubiu/user/8GLxiHYBsfluacNe6SjK{ &quot;name&quot;:&quot;小明&quot;} 规则：POST /索引/文档id/_update {&quot;doc&quot;} 说明：保留未修改的数据，更新时若有新字段会自动生成相应的类型mapping 12345678POST /buubiu/user/8mIFiXYBsfluacNevCho/_update{ &quot;doc&quot;: { &quot;name&quot;:&quot;校长&quot;, &quot;age&quot;:33, &quot;dept&quot;:&quot;软件开发部&quot; }} 规则：POST /索引/文档id/_update {&quot;script&quot;} 说明：脚本更新数据 12345#例如：把年龄自增3岁POST /buubiu/user/8mIFiXYBsfluacNevCho/_update{ &quot;script&quot;: &quot;ctx._source.age+=3&quot;} 批量操作文档规则：PUT /索引/类型/_bulk 注意:批量时不会因为一个失败而全部失败,而是继续执行后续操作,批量在返回时按照执行的状态开始返回 1234567#index:添加 delete：删除 update：更新PUT /buubiu/user/_bulk{&quot;index&quot;:{&quot;_id&quot;:&quot;5&quot;}} {&quot;name&quot;:&quot;buubiu5&quot;,&quot;age&quot;:44,&quot;bir&quot;:&quot;2020-02-22&quot;}{&quot;delete&quot;:{&quot;_id&quot;:&quot;4&quot;}}{&quot;update&quot;:{&quot;_id&quot;:&quot;1&quot;}} {&quot;doc&quot;:{&quot;name&quot;:&quot;buubiu11&quot;,&quot;age&quot;:55}}","link":"/Kibana%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"title":"Kubernetes-ConfigMap与Secret的使用","text":"ConfigMap数据库连接地址，这种可能根据部署环境变化的，我们不应该写死在代码里。Kubernetes 为我们提供了 ConfigMap，可以方便的配置一些变量。文档 创建 yaml configmap.yaml123456apiVersion: v1kind: ConfigMapmetadata: name: mongo-configdata: mongoHost: mongodb-0.mongodb 部署 yaml 123456789101112131415161718192021222324$ kubectl apply -f configmap.yamlconfigmap/mongo-config created# 查看所有的 configmap$ kubectl get configmapNAME DATA AGEkube-root-ca.crt 1 5d7hmongo-config 1 8s# 以 yaml 查看configmap$ kubectl get configmap mongo-config -o yamlapiVersion: v1data: mongoHost: mongodb-0.mongodbkind: ConfigMapmetadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;data&quot;:{&quot;mongoHost&quot;:&quot;mongodb-0.mongodb&quot;},&quot;kind&quot;:&quot;ConfigMap&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;mongo-config&quot;,&quot;namespace&quot;:&quot;default&quot;}} creationTimestamp: &quot;2022-01-12T08:29:46Z&quot; name: mongo-config namespace: default resourceVersion: &quot;48470&quot; uid: 8cfaa997-0e6c-4290-b620-cd9db02d9a16 Secret一些重要数据，例如密码、TOKEN，我们可以放到 secret 中。文档，配置证书 注意，数据要进行 Base64 编码 创建 yaml secret.yaml12345678910apiVersion: v1kind: Secretmetadata: name: mongo-secret# Opaque 用户定义的任意数据，更多类型介绍 https://kubernetes.io/zh/docs/concepts/configuration/secret/#secret-typestype: Opaquedata: # 数据要 base64。https://tools.fun/base64.html mongo-username: bW9uZ291c2Vy mongo-password: bW9uZ29wYXNz 部署 yaml 1234567891011121314151617181920212223242526$ kubectl apply -f secret.yamlsecret/mongo-secret created# 查看所有 secret$ kubectl get secretNAME TYPE DATA AGEdefault-token-m2x8s kubernetes.io/service-account-token 3 5d7hmongo-secret Opaque 2 9s# 以 yaml 方式查看 secret$ kubectl get secret mongo-secret -o yamlapiVersion: v1data: mongo-password: bW9uZ29wYXNz mongo-username: bW9uZ291c2Vykind: Secretmetadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;data&quot;:{&quot;mongo-password&quot;:&quot;bW9uZ29wYXNz&quot;,&quot;mongo-username&quot;:&quot;bW9uZ291c2Vy&quot;},&quot;kind&quot;:&quot;Secret&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;mongo-secret&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;type&quot;:&quot;Opaque&quot;} creationTimestamp: &quot;2022-01-12T09:05:51Z&quot; name: mongo-secret namespace: default resourceVersion: &quot;49988&quot; uid: a2e1f7e5-c5b8-4814-928a-5422c78f8678type: Opaque 使用方法作为环境变量使用举例一：自定义的镜像之前的 deployment类型的 test-k8s，若镜像里面要使用环境变量，则可以在 yaml 文件中加入 env 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556apiVersion: apps/v1kind: Deploymentmetadata: # 部署名字 name: test-k8sspec: replicas: 2 # 用来查找关联的 Pod，所有标签都匹配才行 selector: matchLabels: app: test-k8s # 定义 Pod 相关数据 template: metadata: labels: app: test-k8s spec: # 等待 mongodb 起来后才启动 initContainers: - name: wait-mongo image: busybox:1.28 command: ['sh', '-c', &quot;until nslookup mongodb; do echo waiting for mongo; sleep 2; done&quot;] # 定义容器，可以多个 containers: - name: test-k8s # 容器名字 image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v4-configmap # 镜像 env: - name: MONGO_USERNAME # 定义一个环境变量名：MONGO_USERNAME 供镜像里面的程序使用 valueFrom: # 环境变量的值的来源 secretKeyRef: # 环境变量的值来自 secret 类型的 yaml 中 name: mongo-secret # 环境变量的值来自 serect 中的 metadata.name=mongo-secret 的配置文件 key: mongo-username # 环境变量的值来自 metadata.name=mongo-secret 中的 data.mongo-username - name: MONGO_PASSWORD valueFrom: secretKeyRef: name: mongo-secret key: mongo-password - name: MONGO_ADDRESS valueFrom: configMapKeyRef: # 环境变量的值来自 configmap 类型的 yaml 中 name: mongo-config # 环境变量的值来自 configmap 中的 metadata.name=mongo-config 的配置文件 key: mongoHost # 环境变量的值来自 metadata.name=mongo-config 中的 data.mongoHost---apiVersion: v1kind: Servicemetadata: name: test-k8sspec: selector: app: test-k8s # 默认 ClusterIp 集群内可访问，NodePort 节点可访问，LoadBalancer 负载均衡模式（需要负载均衡器才可用） type: NodePort ports: - nodePort: 31000 # 节点端口，范围固定 30000 ~ 32767 port: 8080 # 本 Service 的端口 targetPort: 8080 # 容器端口 举例二：公共镜像之前 statefulset类型的 mongodb 加上用户名和密码 mongo.yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051apiVersion: apps/v1kind: StatefulSetmetadata: name: mongodbspec: serviceName: mongodb replicas: 1 selector: matchLabels: app: mongodb serviceName: mongodb template: metadata: labels: app: mongodb spec: containers: - name: mongo image: mongo:4.4 # IfNotPresent 仅本地没有镜像时才远程拉，Always 永远都是从远程拉，Never 永远只用本地镜像，本地没有则报错 imagePullPolicy: IfNotPresent env: - name: MONGO_INITDB_ROOT_USERNAME # 官方镜像规定的数据库用户名环境变量名称 valueFrom: secretKeyRef: name: mongo-secret key: mongo-username - name: MONGO_INITDB_ROOT_PASSWORD # 官方镜像规定的数据库密码环境变量名称 valueFrom: secretKeyRef: name: mongo-secret key: mongo-password # Secret 的所有数据定义为容器的环境变量，Secret 中的键名称为 Pod 中的环境变量名称 # envFrom: # - secretRef: # name: mongo-secret---apiVersion: v1kind: Servicemetadata: name: mongodbspec: selector: app: mongodb type: ClusterIP # HeadLess clusterIP: None ports: - port: 27017 protocol: TCP targetPort: 27017 挂载为文件（更适合证书文件）挂载后，会在容器中对应路径生成文件，一个 key 一个文件，内容就是 value，文档 pod.yaml12345678910111213141516apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: &quot;/etc/foo&quot; readOnly: true volumes: - name: foo secret: secretName: mysecret","link":"/Kubernetes-ConfigMap%E4%B8%8ESecret%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Kubernetes-Helm的使用","text":"介绍Helm类似 maven, npm，pip，docker hub, 可以理解为是一个软件库，可以方便快速的为我们的集群安装一些第三方软件。使用 Helm 我们可以非常方便的就搭建出来 MongoDB / MySQL 副本集群，YAML 文件别人都给我们写好了，直接使用。官网，应用中心 安装 Helm安装 文档 12345678$ curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 11156 100 11156 0 0 13136 0 --:--:-- --:--:-- --:--:-- 13140Downloading https://get.helm.sh/helm-v3.7.2-linux-amd64.tar.gzVerifying checksum... Done.Preparing to install helm into /usr/local/binhelm installed into /usr/local/bin/helm 常用命令安装源（添加仓库）helm repo add 源的名称 源的地址 如：helm repo add bitnami https://charts.bitnami.com/bitnami 安装服务helm install 自定义的服务名 服务名 如：helm install my-mongo bitnami/mongodb 查看已安装helm ls 删除已安装helm delete 自定义的服务名 或者 helm uninstall 自定义的服务名 如：helm delete my-mongo 或者 helm uninstall my-mongo 更新已安装helm upgrade 自定义的服务名 --install 如：helm upgrade my-mongo --install 安装 MongoDB 示例单机安装1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 安装源$ helm repo add bitnami https://charts.bitnami.com/bitnami&quot;bitnami&quot; has been added to your repositories# 安装 MongoDB$ helm install my-mongo bitnami/mongodbNAME: my-mongoLAST DEPLOYED: Thu Jan 13 09:45:55 2022NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:CHART NAME: mongodbCHART VERSION: 10.31.3APP VERSION: 4.4.11** Please be patient while the chart is being deployed **MongoDB&amp;reg; can be accessed on the following DNS name(s) and ports from within your cluster: # 提示已安装的 mongodb 的连接地址 my-mongo-mongodb.default.svc.cluster.localTo get the root password run: # 提示你如何获得密码 export MONGODB_ROOT_PASSWORD=$(kubectl get secret --namespace default my-mongo-mongodb -o jsonpath=&quot;{.data.mongodb-root-password}&quot; | base64 --decode)To connect to your database, create a MongoDB&amp;reg; client container: kubectl run --namespace default my-mongo-mongodb-client --rm --tty -i --restart='Never' --env=&quot;MONGODB_ROOT_PASSWORD=$MONGODB_ROOT_PASSWORD&quot; --image docker.io/bitnami/mongodb:4.4.11-debian-10-r12 --command -- bashThen, run the following command: mongo admin --host &quot;my-mongo-mongodb&quot; --authenticationDatabase admin -u root -p $MONGODB_ROOT_PASSWORDTo connect to your database from outside the cluster execute the following commands: # 提示你怎么连接 mongodb kubectl port-forward --namespace default svc/my-mongo-mongodb 27017:27017 &amp; mongo --host 127.0.0.1 --authenticationDatabase admin -p $MONGODB_ROOT_PASSWORD # 查看 pod$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmy-mongo-mongodb-798559bb5d-jhzx9 1/1 Running 0 5m32s 172.17.0.4 minikube &lt;none&gt; &lt;none&gt;# 查看所有$ kubectl get allNAME READY STATUS RESTARTS AGEpod/my-mongo-mongodb-798559bb5d-jhzx9 1/1 Running 0 5m55sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 6dservice/my-mongo-mongodb ClusterIP 10.103.169.139 &lt;none&gt; 27017/TCP 5m55sNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/my-mongo-mongodb 1/1 1 1 5m55sNAME DESIRED CURRENT READY AGEreplicaset.apps/my-mongo-mongodb-798559bb5d 1 1 1 5m55s 集群安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# 安装源$ helm repo add bitnami https://charts.bitnami.com/bitnami&quot;bitnami&quot; has been added to your repositories# 安装 MongoDB，安装前删除一下$ helm lsNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSIONmy-mongo default 1 2022-01-13 09:45:55.138740938 +0800 CST deployed mongodb-10.31.3 4.4.11$ helm delete my-mongorelease &quot;my-mongo&quot; uninstalled$ kubectl get allNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 6d# 指定架构(集群)和密码$ helm install my-mongo bitnami/mongodb --set architecture=&quot;replicaset&quot;,auth.rootPassword=&quot;mongopass&quot;NAME: my-mongoLAST DEPLOYED: Thu Jan 13 10:01:32 2022NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:CHART NAME: mongodbCHART VERSION: 10.31.3APP VERSION: 4.4.11** Please be patient while the chart is being deployed **MongoDB&amp;reg; can be accessed on the following DNS name(s) and ports from within your cluster: # 提示已安装的 mongodb 的连接地址 my-mongo-mongodb-0.my-mongo-mongodb-headless.default.svc.cluster.local:27017 my-mongo-mongodb-1.my-mongo-mongodb-headless.default.svc.cluster.local:27017To get the root password run: export MONGODB_ROOT_PASSWORD=$(kubectl get secret --namespace default my-mongo-mongodb -o jsonpath=&quot;{.data.mongodb-root-password}&quot; | base64 --decode)To connect to your database, create a MongoDB&amp;reg; client container: kubectl run --namespace default my-mongo-mongodb-client --rm --tty -i --restart='Never' --env=&quot;MONGODB_ROOT_PASSWORD=$MONGODB_ROOT_PASSWORD&quot; --image docker.io/bitnami/mongodb:4.4.11-debian-10-r12 --command -- bashThen, run the following command: mongo admin --host &quot;my-mongo-mongodb-0.my-mongo-mongodb-headless.default.svc.cluster.local:27017,my-mongo-mongodb-1.my-mongo-mongodb-headless.default.svc.cluster.local:27017&quot; --authenticationDatabase admin -u root -p $MONGODB_ROOT_PASSWORD # 查看 pod$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmy-mongo-mongodb-0 1/1 Running 0 2m50s 172.17.0.4 minikube &lt;none&gt; &lt;none&gt;my-mongo-mongodb-1 1/1 Running 0 2m38s 172.17.0.5 minikube &lt;none&gt; &lt;none&gt;my-mongo-mongodb-arbiter-0 1/1 Running 0 2m50s 172.17.0.3 minikube &lt;none&gt; &lt;none&gt;# 查看所有$ kubectl get allNAME READY STATUS RESTARTS AGEpod/my-mongo-mongodb-0 1/1 Running 0 3m10spod/my-mongo-mongodb-1 1/1 Running 0 2m58spod/my-mongo-mongodb-arbiter-0 1/1 Running 0 3m10sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 6dservice/my-mongo-mongodb-arbiter-headless ClusterIP None &lt;none&gt; 27017/TCP 3m10sservice/my-mongo-mongodb-headless ClusterIP None &lt;none&gt; 27017/TCP 3m10sNAME READY AGEstatefulset.apps/my-mongo-mongodb 2/2 3m10sstatefulset.apps/my-mongo-mongodb-arbiter 1/1 3m10s# 查看 pv pvc sc $ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpvc-6680772f-8205-4af3-a8e5-ef661f05a350 8Gi RWO Delete Bound default/datadir-my-mongo-mongodb-0 standard 25mpvc-b8bdec22-3b62-4f27-9f1b-aababc804e2b 8Gi RWO Delete Bound default/datadir-my-mongo-mongodb-1 standard 25m$ kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEdatadir-my-mongo-mongodb-0 Bound pvc-6680772f-8205-4af3-a8e5-ef661f05a350 8Gi RWO standard 25mdatadir-my-mongo-mongodb-1 Bound pvc-b8bdec22-3b62-4f27-9f1b-aababc804e2b 8Gi RWO standard 25m$ kubectl get scNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGEstandard (default) k8s.io/minikube-hostpath Delete Immediate false 6d1h 连接 MongoDB123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118# 查看密码 然后在用 base64 解码 ,bW9uZ29wYXNz=mongopass$ kubectl get secret my-mongo-mongodb -o json# 或者输出为 yaml 查看$ kubectl get secret my-mongo-mongodb -o yaml &gt; secret.yamlapiVersion: v1data: mongodb-replica-set-key: T3MzMjVIYms2Tg== mongodb-root-password: bW9uZ29wYXNz kind: Secretmetadata: annotations: meta.helm.sh/release-name: my-mongo meta.helm.sh/release-namespace: default creationTimestamp: &quot;2022-01-13T02:01:32Z&quot; labels: app.kubernetes.io/component: mongodb app.kubernetes.io/instance: my-mongo app.kubernetes.io/managed-by: Helm app.kubernetes.io/name: mongodb helm.sh/chart: mongodb-10.31.3 name: my-mongo-mongodb namespace: default resourceVersion: &quot;52760&quot; uid: d35f498f-4bb7-43cb-a1b4-fadc6446648ftype: Opaque# 临时运行一个包含 mongo client 的 debian 系统$ kubectl run mongodb-client --rm --tty -i --restart='Never' --image docker.io/bitnami/mongodb:4.4.10-debian-10-r20 --command -- bashIf you don't see a command prompt, try pressing enter.# 进去 mongodb 这个是主节点，可以读写I have no name!@mongodb-client:/$ mongo --host my-mongo-mongodb-0.my-mongo-mongodb-headless.default.svc.cluster.local:27017 -u root -p mongopassMongoDB shell version v4.4.10connecting to: mongodb://my-mongo-mongodb-0.my-mongo-mongodb-headless.default.svc.cluster.local:27017/?compressors=disabled&amp;gssapiServiceName=mongodbImplicit session: session { &quot;id&quot; : UUID(&quot;fdece2d2-01de-4b14-a326-ed7923a3d32e&quot;) }MongoDB server version: 4.4.11---The server generated these startup warnings when booting: 2022-01-13T02:01:42.564+00:00: /sys/kernel/mm/transparent_hugepage/enabled is 'always'. We suggest setting it to 'never' 2022-01-13T02:01:42.564+00:00: /sys/kernel/mm/transparent_hugepage/defrag is 'always'. We suggest setting it to 'never'------ Enable MongoDB's free cloud-based monitoring service, which will then receive and display metrics about your deployment (disk utilization, CPU, operation statistics, etc). The monitoring data will be available on a MongoDB website with a unique URL accessible to you and anyone you share the URL with. MongoDB may use this information to make product improvements and to suggest MongoDB products and deployment options to you. To enable free monitoring, run the following command: db.enableFreeMonitoring() To permanently disable this reminder, run the following command: db.disableFreeMonitoring()---rs0:PRIMARY&gt; show dbsadmin 0.000GBconfig 0.000GBlocal 0.000GBrs0:PRIMARY&gt; exitbye# 进去 mongodb 这个是从节点，只读节点I have no name!@mongodb-client:/$ mongo --host my-mongo-mongodb-1.my-mongo-mongodb-headless.default.svc.cluster.local:27017 -u root -p mongopassMongoDB shell version v4.4.10connecting to: mongodb://my-mongo-mongodb-1.my-mongo-mongodb-headless.default.svc.cluster.local:27017/?compressors=disabled&amp;gssapiServiceName=mongodbImplicit session: session { &quot;id&quot; : UUID(&quot;bf4c9990-abfa-47e6-88e6-b49ce70a5c04&quot;) }MongoDB server version: 4.4.11---The server generated these startup warnings when booting: 2022-01-13T02:02:01.245+00:00: /sys/kernel/mm/transparent_hugepage/enabled is 'always'. We suggest setting it to 'never' 2022-01-13T02:02:01.245+00:00: /sys/kernel/mm/transparent_hugepage/defrag is 'always'. We suggest setting it to 'never' 2022-01-13T02:02:01.370+00:00: 2022-01-13T02:02:01.370+00:00: ** WARNING: This replica set has a Primary-Secondary-Arbiter architecture, but readConcern:majority is enabled 2022-01-13T02:02:01.370+00:00: ** for this node. This is not a recommended configuration. Please see 2022-01-13T02:02:01.370+00:00: ** https://dochub.mongodb.org/core/psa-disable-rc-majority 2022-01-13T02:02:01.371+00:00:------ Enable MongoDB's free cloud-based monitoring service, which will then receive and display metrics about your deployment (disk utilization, CPU, operation statistics, etc). The monitoring data will be available on a MongoDB website with a unique URL accessible to you and anyone you share the URL with. MongoDB may use this information to make product improvements and to suggest MongoDB products and deployment options to you. To enable free monitoring, run the following command: db.enableFreeMonitoring() To permanently disable this reminder, run the following command: db.disableFreeMonitoring()---rs0:SECONDARY&gt; show dbsuncaught exception: Error: listDatabases failed:{ &quot;topologyVersion&quot; : { &quot;processId&quot; : ObjectId(&quot;61df8818d1bd992fb7d6ff94&quot;), &quot;counter&quot; : NumberLong(3) }, &quot;operationTime&quot; : Timestamp(1642040662, 1), &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;not master and slaveOk=false&quot;, &quot;code&quot; : 13435, &quot;codeName&quot; : &quot;NotPrimaryNoSecondaryOk&quot;, &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1642040662, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;Q9kV+ODHLfyTrw1sN4d8momJPnw=&quot;), &quot;keyId&quot; : NumberLong(&quot;7052505087951765510&quot;) } }} :_getErrorWithCode@src/mongo/shell/utils.js:25:13Mongo.prototype.getDBs/&lt;@src/mongo/shell/mongo.js:147:19Mongo.prototype.getDBs@src/mongo/shell/mongo.js:99:12shellHelper.show@src/mongo/shell/utils.js:937:13shellHelper@src/mongo/shell/utils.js:819:15@(shellhelp2):1:1rs0:SECONDARY&gt; exitbye# 也可以转发集群里的端口到宿主机访问 mongodb$ kubectl port-forward service/my-mongo-mongodb-headless 27017:27017Forwarding from 127.0.0.1:27017 -&gt; 27017Forwarding from [::1]:27017 -&gt; 2701","link":"/Kubernetes-Helm%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Kubernetes-Ingress的使用","text":"介绍官方文档：Ingress Ingress 为外部访问集群提供了一个 统一 入口，避免了对外暴露集群端口；功能类似 Nginx，可以根据域名、路径把请求转发到不同的 Service。可以配置 https 跟 LoadBalancer 有什么区别？ LoadBalancer 需要对外暴露端口，不安全； 无法根据域名、路径转发流量到不同 Service，多个 Service 则需要开多个 LoadBalancer； 功能单一，无法配置 https 使用要使用 Ingress，需要一个负载均衡器 + Ingress Controller 如果是裸机（bare metal) 搭建的集群，你需要自己安装一个负载均衡插件，可以安装 MetalLB 如果是云服务商，会自动给你配置，否则你的外部 IP 会是 “pending” 状态，无法使用。 裸机搭建准备好 LoadBalancer 类型的Servicetest-k8s.yaml12345678910111213141516171819202122232425262728293031323334353637383940414243apiVersion: apps/v1# 定义以 Deployment 方式管理kind: Deploymentmetadata: # Deployment 的名称 name: test-k8sspec: # 运行的 pod 副本数量 replicas: 2 # 用来查找关联的 Pod，所有标签都匹配才行 selector: matchLabels: app: test-k8s # 定义 Pod 相关数据 template: metadata: labels: app: test-k8s spec: # 定义容器，可以多个 containers: - name: test-k8s # 容器名字 image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1 # 镜像---apiVersion: v1# 制定类型为 Servicekind: Servicemetadata: # 服务的名称 name: test-k8sspec: # 标签 ，要与 pod的标签对应上，否则关联不起来 selector: app: test-k8s # ClusterIP：集群内可访问 （默认） # NodePort：节点可访问 # LoadBalancer：负载均衡模式（需要负载均衡才可用） type: LoadBalancer ports: - port: 8080 # 本 Service 的端口 targetPort: 8080 # 容器端口 # nodePort: 31000 # 节点端口，范围固定 30000 ～ 32767 12345678910111213141516171819$ kubectl apply -f deployment.yamldeployment.apps/test-k8s createdservice/test-k8s created# service 的 EXTERNAL-IP一直是pending状态$ kubectl get allNAME READY STATUS RESTARTS AGEpod/test-k8s-7f8b7548fc-289cv 1/1 Running 0 14spod/test-k8s-7f8b7548fc-qxjgd 1/1 Running 0 14sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 6d7hservice/test-k8s LoadBalancer 10.111.43.66 &lt;pending&gt; 8080:31000/TCP 14sNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/test-k8s 2/2 2 2 14sNAME DESIRED CURRENT READY AGEreplicaset.apps/test-k8s-7f8b7548fc 2 2 2 14s 安装负载均衡器(MetalLB)开源地址：GitHub 下载 yaml 文件安装 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 创建命名空间 $ kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/namespace.yaml# 直接运行 yaml 文件# 后续想要卸载的话，可以执行# kubectl delete -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/metallb.yaml$ kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/metallb.yamlWarning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+podsecuritypolicy.policy/controller createdpodsecuritypolicy.policy/speaker createdserviceaccount/controller createdserviceaccount/speaker createdclusterrole.rbac.authorization.k8s.io/metallb-system:controller createdclusterrole.rbac.authorization.k8s.io/metallb-system:speaker createdrole.rbac.authorization.k8s.io/config-watcher createdrole.rbac.authorization.k8s.io/pod-lister createdrole.rbac.authorization.k8s.io/controller createdclusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller createdclusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker createdrolebinding.rbac.authorization.k8s.io/config-watcher createdrolebinding.rbac.authorization.k8s.io/pod-lister createdrolebinding.rbac.authorization.k8s.io/controller createddaemonset.apps/speaker createddeployment.apps/controller created# 会生成一个 namespace metallb-system$ kubectl get nsNAME STATUS AGEdefault Active 6d7hkube-node-lease Active 6d7hkube-public Active 6d7hkube-system Active 6d7hmetallb-system Active 39m# 查看所有$ kubectl get all -n metallb-systemNAME READY STATUS RESTARTS AGE# 负责IP地址的分配，以及service和endpoint的监听pod/controller-7dcc8764f4-58fs4 1/1 Running 0 119s# 负责保证service地址可达pod/speaker-jfb7w 1/1 Running 0 119sNAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGEdaemonset.apps/speaker 1 1 1 1 1 kubernetes.io/os=linux 119sNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/controller 1/1 1 1 119sNAME DESIRED CURRENT READY AGEreplicaset.apps/controller-7dcc8764f4 1 1 1 119s 地址分配 MetalLB会为用户的load balancer类型service分配IP地址，该IP地址不是凭空产生的，需要用户预先分配。 外部声明 地址分配后还需要通知到网络中的其他主机。MetalLB支持两种声明模式，都是通过 ConfigMap来进行配置的 Layer 2模式：ARP/NDP BGP模式 Layer 2模式部署 yaml 文件，官方：YAML metallb-config-layer2.yaml123456789101112apiVersion: v1kind: ConfigMapmetadata: namespace: metallb-system name: metallb-config-layer2data: config: | address-pools: - name: my-ip-space protocol: layer2 addresses: - 192.168.1.240/28 部署 ConfigMap 12$ kubectl apply -f metallb-config-layer2.yamlconfigmap/metallb-config-layer2 configured 检查是否成功（暂时没验证成功，不知道原因） 12$ kubectl get all BGP模式部署（推荐） yaml 文件，官方：YAML metallb-config-bgp.yaml1234567891011121314151617181920212223apiVersion: v1kind: ConfigMapmetadata: namespace: metallb-system name: configdata: config: | peers: - my-asn: 64512 peer-asn: 64512 peer-address: 10.96.0.100 - my-asn: 64512 peer-asn: 64512 peer-address: 10.96.0.101 - my-asn: 64512 peer-asn: 64512 peer-address: 10.96.0.102 address-pools: - name: my-ip-space protocol: bgp avoid-buggy-ips: true addresses: - 198.51.100.0/24 avoid-buggy-ips: true：代表 Load Balancer 在分配 IP 的时候，会从 .1 开始分配，而不会从 .0 开始 198.51.100.0/24：Load Balancer 能分配的 IP 池 部署 ConfigMap 12$ kubectl apply -f metallb-config-bgp.yamlconfigmap/metallb-config-bgp configured 检查是否成功 发现 service/test-k8s，EXTERNAL-IP 不在是 pending ，而是分配了一个 IP 12345678910111213141516171819$ kubectl get allNAME READY STATUS RESTARTS AGEpod/test-k8s-7f8b7548fc-289cv 1/1 Running 0 25mpod/test-k8s-7f8b7548fc-qxjgd 1/1 Running 0 25mNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 6d7hservice/test-k8s LoadBalancer 10.111.43.66 198.51.100.1 8080:31000/TCP 25mNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/test-k8s 2/2 2 2 25mNAME DESIRED CURRENT READY AGEreplicaset.apps/test-k8s-7f8b7548fc 2 2 2 25m$ curl http://198.51.100.1:8080index pageIP lo10.244.2.2, hostname: test-k8s-8598bbb8c6-rx5tn 安装 Ingress ControllerMinikube 中部署 Ingress Controller官方文档：ingress ingress.yaml12345678910111213141516apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: example-ingressspec: rules: - host: hello-world.info http: paths: - path: / pathType: Prefix backend: service: name: web port: number: 8080 Helm 安装官方文档：ingress-nginx 12345678910$ helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx&quot;ingress-nginx&quot; has been added to your repositories$ helm repo updateHang tight while we grab the latest from your chart repositories......Successfully got an update from the &quot;ingress-nginx&quot; chart repository...Successfully got an update from the &quot;bitnami&quot; chart repositoryUpdate Complete. ⎈Happy Helming!⎈$ helm install my-ingress-nginx ingress-nginx/ingress-nginx 腾讯云搭建","link":"/Kubernetes-Ingress%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Kubernetes(K8S)简介","text":"Kubernetes (K8S) 是什么它是一个为 容器化 应用提供集群部署和管理的开源工具，由 Google 开发。Kubernetes 这个名字源于希腊语，意为“舵手”或“飞行员”。k8s 这个缩写是因为 k 和 s 之间有八个字符的关系。 Google 在 2014 年开源了 Kubernetes 项目 主要特性： 高可用，不宕机，自动灾难恢复 灰度更新，不影响业务正常运转 一键回滚到历史版本 方便的伸缩扩展（应用伸缩，机器加减）、提供负载均衡 有一个完善的生态 不同的应用部署方案 传统部署方式：应用直接在物理机上部署，机器资源分配不好控制，出现Bug时，可能机器的大部分资源被某个应用占用，导致其他应用无法正常运行，无法做到应用隔离。 虚拟机部署在单个物理机上运行多个虚拟机，每个虚拟机都是完整独立的系统，性能损耗大。 容器部署所有容器共享主机的系统，轻量级的虚拟机，性能损耗小，资源隔离，CPU和内存可按需分配 什么时候需要 Kubernetes当你的应用只是跑在一台机器，直接一个 docker + docker-compose 就够了，方便轻松；当你的应用需要跑在 3，4 台机器上，你依旧可以每台机器单独配置运行环境 + 负载均衡器；当你应用访问数不断增加，机器逐渐增加到十几台、上百台、上千台时，每次加机器、软件更新、版本回滚，都会变得非常麻烦、痛不欲生，再也不能好好的摸鱼了，人生浪费在那些没技术含量的重复性工作上。 这时候，Kubernetes 就可以一展身手了，让你轻松管理百万千万台机器的集群。“谈笑间，樯橹灰飞烟灭”，享受着一手掌控所有，年薪百万指日可待。 Kubernates 可以为你提供集中式的管理集群机器和应用，加机器、版本升级、版本回滚，那都是一个命令就搞定的事，不停机的灰度更新，确保高可用、高性能、高扩展。 Kubernetes 集群架构 master主节点，控制平台，不需要很高性能，不跑任务，通常一个就行了，也可以开多个主节点来提高集群可用度。 worker工作节点，可以是虚拟机或物理计算机，任务都在这里跑，机器性能需要好点；通常都有很多个，可以不断加机器扩大集群；每个工作节点由主节点管理 重要概念 Pod豆荚，K8S 调度、管理的最小单位，一个 Pod 可以包含一个或多个容器，每个 Pod 有自己的虚拟IP。一个工作节点可以有多个 pod，主节点会考量负载自动调度 pod 到哪个节点运行。 Kubernetes 组件kube-apiserver API 服务器，公开了 Kubernetes APIetcd 键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库kube-scheduler 调度 Pod 到哪个节点运行kube-controller 集群控制器cloud-controller 与云服务商交互 如果你想要了解更多 K8S 组成细节，主节点、工作节点分别有哪些程序，各有什么作用，可以查看 官网详细介绍","link":"/Kubernetes-K8S-%E7%AE%80%E4%BB%8B/"},{"title":"Kubernetes-Pod的实现原理以及设计模式","text":"为什么我们会需要 PodPod，是 Kubernetes 项目中最小的 API 对象。如果换一个更专业的说法，我们可以这样描述：Pod，是 Kubernetes 项目的原子调度单位。 容器的本质是进程，容器镜像就是这个系统里的“.exe”安装包，Kubernetes 就是操作系统！ 而 Kubernetes 项目所做的，其实就是将“进程组”的概念映射到了容器技术中，并使其成为了这个云计算“操作系统”里的“一等公民”。 Kubernetes 项目之所以要这么做的原因，我在前面介绍 Kubernetes 和 Borg 的关系时曾经提到过：在 Borg 项目的开发和实践过程中，Google 公司的工程师们发现，他们部署的应用，往往都存在着类似于“进程和进程组”的关系。更具体地说，就是这些应用之间有着密切的协作关系，使得它们必须部署在同一台机器上。 而如果事先没有“组”的概念，像这样的运维关系就会非常难以处理。 容器间的紧密协作，我们可以称为“超亲密关系”。这些具有“超亲密关系”容器的典型特征包括但不限于： 互相之间会发生直接的文件交换 使用 localhost 或者 Socket 文件进行本地通信 会发生非常频繁的远程调用 需要共享某些 Linux Namespace（比如，一个容器要加入另一个容器的 Network Namespace）等等。 这也就意味着，并不是所有有“关系”的容器都属于同一个 Pod。比如，PHP 应用容器和 MySQL 虽然会发生访问关系，但并没有必要、也不应该部署在同一台机器上，它们更适合做成两个 Pod Pod 的实现原理首先，关于 Pod 最重要的一个事实是：它只是一个逻辑概念。 也就是说，Kubernetes 真正处理的，还是宿主机操作系统上 Linux 容器的 Namespace 和 Cgroups，而并不存在一个所谓的 Pod 的边界或者隔离环境。 Pod，其实是一组共享了某些资源的容器。Pod 里的所有容器，共享的是同一个 Network Namespace，并且可以声明共享同一个 Volume。 在 Kubernetes 项目里，Pod 的实现需要使用一个中间容器，这个容器叫作 Infra 容器。在这个 Pod 中，Infra 容器永远都是第一个被创建的容器，而其他用户定义的容器，则通过 Join Network Namespace 的方式，与 Infra 容器关联在一起。这样的组织关系，可以用下面这样一个示意图来表达： 如上图所示，这个 Pod 里有两个用户容器 A 和 B，还有一个 Infra 容器。很容易理解，在 Kubernetes 项目里，Infra 容器一定要占用极少的资源，所以它使用的是一个非常特殊的镜像，叫作：k8s.gcr.io/pause。这个镜像是一个用汇编语言编写的、永远处于“暂停”状态的容器，解压后的大小也只有 100~200 KB 左右。 而在 Infra 容器“Hold 住”Network Namespace 后，用户容器就可以加入到 Infra 容器的 Network Namespace 当中了。所以，如果你查看这些容器在宿主机上的 Namespace 文件（这个 Namespace 文件的路径），它们指向的值一定是完全一样的。 这也就意味着，对于 Pod 里的容器 A 和容器 B 来说： 它们可以直接使用 localhost 进行通信； 它们看到的网络设备跟 Infra 容器看到的完全一样； 一个 Pod 只有一个 IP 地址，也就是这个 Pod 的 Network Namespace 对应的 IP 地址； 当然，其他的所有网络资源，都是一个 Pod 一份，并且被该 Pod 中的所有容器共享； Pod 的生命周期只跟 Infra 容器一致，而与容器 A 和 B 无关。 而对于同一个 Pod 里面的所有用户容器来说，它们的进出流量，也可以认为都是通过 Infra 容器完成的 容器设计模式sidecarsidecar 指的就是我们可以在一个 Pod 中，启动一个辅助容器，来完成一些独立于主进程（主容器）之外的工作 最典型的例子是：WAR 包与 Web 服务器 我们现在有一个 Java Web 应用的 WAR 包，它需要被放在 Tomcat 的 webapps 目录下运行起来。 假如，你现在只能用 Docker 来做这件事情，那该如何处理这个组合关系呢？ 一种方法是，把 WAR 包直接放在 Tomcat 镜像的 webapps 目录下，做成一个新的镜像运行起来。可是，这时候，如果你要更新 WAR 包的内容，或者要升级 Tomcat 镜像，就要重新制作一个新的发布镜像，非常麻烦。 另一种方法是，你压根儿不管 WAR 包，永远只发布一个 Tomcat 容器。不过，这个容器的 webapps 目录，就必须声明一个 hostPath 类型的 Volume，从而把宿主机上的 WAR 包挂载进 Tomcat 容器当中运行起来。不过，这样你就必须要解决一个问题，即：如何让每一台宿主机，都预先准备好这个存储有 WAR 包的目录呢？这样来看，你只能独立维护一套分布式存储系统了。 实际上，有了 Pod 之后，这样的问题就很容易解决了。我们可以把 WAR 包和 Tomcat 分别做成镜像，然后把它们作为一个 Pod 里的两个容器“组合”在一起。这个 Pod 的配置文件如下所示： 12345678910111213141516171819202122232425apiVersion: v1kind: Podmetadata: name: javaweb-2spec: initContainers: - image: geektime/sample:v2 name: war command: [&quot;cp&quot;, &quot;/sample.war&quot;, &quot;/app&quot;] volumeMounts: - mountPath: /app name: app-volume containers: - image: geektime/tomcat:7.0 name: tomcat command: [&quot;sh&quot;,&quot;-c&quot;,&quot;/root/apache-tomcat-7.0.42-v2/bin/start.sh&quot;] volumeMounts: - mountPath: /root/apache-tomcat-7.0.42-v2/webapps name: app-volume ports: - containerPort: 8080 hostPort: 8001 volumes: - name: app-volume emptyDir: {} 在这个 Pod 中，我们定义了两个容器，第一个容器使用的镜像是 geektime/sample:v2，这个镜像里只有一个 WAR 包（sample.war）放在根目录下。而第二个容器则使用的是一个标准的 Tomcat 镜像。 不过，你可能已经注意到，WAR 包容器的类型不再是一个普通容器，而是一个 Init Container 类型的容器。 在 Pod 中，所有 Init Container 定义的容器，都会比 spec.containers 定义的用户容器先启动。并且，Init Container 容器会按顺序逐一启动，而直到它们都启动并且退出了，用户容器才会启动。 所以，这个 Init Container 类型的 WAR 包容器启动后，我执行了一句”cp /sample.war /app”，把应用的 WAR 包拷贝到 /app 目录下，然后退出。 而后这个 /app 目录，就挂载了一个名叫 app-volume 的 Volume。 接下来就很关键了。Tomcat 容器，同样声明了挂载 app-volume 到自己的 webapps 目录下。 所以，等 Tomcat 容器启动时，它的 webapps 目录下就一定会存在 sample.war 文件：这个文件正是 WAR 包容器启动时拷贝到这个 Volume 里面的，而这个 Volume 是被这两个容器共享的。 像这样，我们就用一种“组合”方式，解决了 WAR 包与 Tomcat 容器之间耦合关系的问题。 实际上，这个所谓的“组合”操作，正是容器设计模式里最常用的一种模式，它的名字叫：sidecar。 第二个例子，则是容器的日志收集。 比如，我现在有一个应用，需要不断地把日志文件输出到容器的 /var/log 目录中。 这时，我就可以把一个 Pod 里的 Volume 挂载到应用容器的 /var/log 目录上。 然后，在这个 Pod 里同时运行一个 sidecar 容器，它也声明挂载同一个 Volume 到自己的 /var/log 目录上。 这样，接下来 sidecar 容器就只需要做一件事儿，那就是不断地从自己的 /var/log 目录里读取日志文件，转发到 MongoDB 或者 Elasticsearch 中存储起来。这样，一个最基本的日志收集工作就完成了。 跟第一个例子一样，这个例子中的 sidecar 的主要工作也是使用共享的 Volume 来完成对文件的操作。 但不要忘记，Pod 的另一个重要特性是，它的所有容器都共享同一个 Network Namespace。这就使得很多与 Pod 网络相关的配置和管理，也都可以交给 sidecar 完成，而完全无须干涉用户容器。这里最典型的例子莫过于 Istio 这个微服务治理项目了。","link":"/Kubernetes-Pod%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"Kubernetes-Service的使用","text":"特性 Service 通过 label 关联对应的 Pod Servcie 生命周期不跟 Pod 绑定，不会因为 Pod 重创改变 IP 提供了负载均衡功能，自动转发流量到不同 Pod 可对集群外部提供访问端口 集群内部可通过服务名字访问 创建Service创建 一个 Service，通过标签test-k8s跟对应的 Pod 关联上service.yaml service.yaml12345678910111213141516171819apiVersion: v1# 制定类型为 Servicekind: Servicemetadata: # 服务的名称 name: test-k8sspec: # 标签 ，要与 pod的标签对应上，否则关联不起来 selector: app: test-k8s # ClusterIP：集群内可访问 （默认） # NodePort：节点可访问 # LoadBalance：负载均衡模式（需要负载均衡才可用） type: NodePort ports: - port: 8090 # 本 Service 的端口 targetPort: 8080 # 容器端口 nodePort: 31000 # 节点端口，范围固定 30000 ～ 32767 部署 Service12345678910111213# 首先创建 deployment$ kubectl apply -f deployment.yamldeployment.apps/test-k8s created# 查看 pod$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-8598bbb8c6-l9dp7 1/1 Running 0 3m38s 10.244.0.32 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-xgvn8 1/1 Running 0 3m38s 10.244.0.35 node1 &lt;none&gt; &lt;none&gt;# 创建 Service$ kubectl apply -f service.yamlservice/test-k8s created 查看 Service1234567891011# 查看 service# kubectl get service 或者 kubectl get svc$ kubectl get serviceNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 66mtest-k8s NodePort 10.107.238.211 &lt;none&gt; 8090:31000/TCP 36s$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 66mtest-k8s NodePort 10.107.238.211 &lt;none&gt; 8090:31000/TCP 41s 查看 Service 详情12345678910111213141516171819# kubectl describe svc SERVICE-NAME$ kubectl describe svc test-k8sName: test-k8sNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Selector: app=test-k8sType: NodePortIP Family Policy: SingleStackIP Families: IPv4IP: 10.107.238.211IPs: 10.107.238.211Port: &lt;unset&gt; 8090/TCPTargetPort: 8080/TCPNodePort: &lt;unset&gt; 31000/TCPEndpoints: 10.244.0.32:8080,10.244.0.35:8080Session Affinity: NoneExternal Traffic Policy: ClusterEvents: &lt;none&gt; 解释说明： Endpoints：可以发现 Endpoints 是各个 Pod 的 IP，也就是他会把流量转发到这些节点。 Type：服务的类型，可以为 ClusterIP NodePort LoadBalancer 对外暴露服务ClusterIP服务的默认类型是ClusterIP，只能在集群内部访问ClusterIP： 修改一下 service.yaml中的 type ，并且去掉 最后一行 nodePort service.yaml12345678910111213141516171819apiVersion: v1# 制定类型为 Servicekind: Servicemetadata: # 服务的名称 name: test-k8sspec: # 标签 ，要与 pod的标签对应上，否则关联不起来 selector: app: test-k8s # ClusterIP：集群内可访问 （默认） # NodePort：节点可访问 # LoadBalance：负载均衡模式（需要负载均衡才可用） type: ClusterIP ports: - port: 8090 # 本 Service 的端口 targetPort: 8080 # 容器端口 # nodePort: 31000 # 节点端口，范围固定 30000 ～ 32767 重新部署一下 123456789101112131415161718192021222324$ kubectl apply -f service.yamlservice/test-k8s configured$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 85mtest-k8s ClusterIP 10.107.238.211 &lt;none&gt; 8090/TCP 19m$ kubectl describe svc test-k8sName: test-k8sNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Selector: app=test-k8sType: ClusterIPIP Family Policy: SingleStackIP Families: IPv4IP: 10.107.238.211IPs: 10.107.238.211Port: &lt;unset&gt; 8090/TCPTargetPort: 8080/TCPEndpoints: 10.244.0.32:8080,10.244.0.35:8080Session Affinity: NoneEvents: &lt;none&gt; 可以进入到 Pod 里面访问： 12345678# kubectl exec -it POD-NAME -- bash$ kubectl exec -it test-k8s-8598bbb8c6-smxnw -- bashroot@test-k8s-8598bbb8c6-smxnw:/app$ curl http://test-k8s:8090暂时不通--不知道为什么...root@test-k8s-8598bbb8c6-smxnw:/app$ curl http://10.107.238.211:8090index pageIP lo10.244.0.34, hostname: test-k8s-8598bbb8c6-smxnw 如果要在集群外部访问，可以通过端口转发实现（只适合临时测试用）： 123456789$ kubectl port-forward service/test-k8s 8888:8090Forwarding from 127.0.0.1:8888 -&gt; 8080Forwarding from [::1]:8888 -&gt; 8080# 在主节点上，可以 curl http://127.0.0.1:8888 访问到应用$ curl http://127.0.0.1:8888/index pageIP lo10.244.0.34, hostname: test-k8s-8598bbb8c6-smxnw 如果你用 minikube，也可以这样minikube service test-k8s来转发服务到本机 NodePort上面我们是通过端口转发的方式可以在外面访问到集群里的服务，如果想要直接把集群服务暴露出来，我们可以使用NodePort 和 Loadbalancer 类型的 Service 修改 yaml 文件，修改 type 为 NodePort ，并且加上 nodePort 转发端口 service.yaml12345678910111213apiVersion: v1kind: Servicemetadata: name: test-k8sspec: selector: app: test-k8s # 默认 ClusterIP 集群内可访问，NodePort 节点可访问，LoadBalancer 负载均衡模式（需要负载均衡器才可用） type: NodePort ports: - port: 8090 # 本 Service 的端口 targetPort: 8080 # 容器端口 nodePort: 31000 # 节点端口，范围固定 30000 ~ 32767 重新部署 12345678910111213141516171819$ kubectl apply -f service.yamlservice/test-k8s configured# 在节点上，我们可以 curl http://localhost:31000/hello/easydoc 访问到应用# 并且是有负载均衡的，网页的信息可以看到被转发到了不同的 Pod$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2afb7bcea2f8 kicbase/stable:v0.0.28 &quot;/usr/local/bin/entr…&quot; 4 days ago Up 3 minutes 127.0.0.1:49157-&gt;22/tcp, 127.0.0.1:49156-&gt;2376/tcp, 127.0.0.1:49155-&gt;5000/tcp, 127.0.0.1:49154-&gt;8443/tcp, 127.0.0.1:49153-&gt;32443/tcp minikube$ docker exec -it minikube bashroot@minikube:/$ curl http://localhost:31000/hello/easydochello easydocIP lo172.17.0.8, hostname: test-k8s-68bb74d654-ztg6hroot@minikube:/$ curl http://localhost:31000/hello/easydochello easydocIP lo172.17.0.9, hostname: test-k8s-68bb74d654-xnxkc 如果你是用 minikube，因为是模拟集群，你的电脑并不是节点，节点是 minikube 模拟出来的，所以你并不能直接在电脑上访问到服务 LoadbalancerLoadbalancer 也可以对外提供服务，这需要一个负载均衡器的支持，因为它需要生成一个新的 IP 对外服务，否则状态就一直是 pendding，这个很少用了，后面我们会讲更高端的 Ingress 来代替它。 1234$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 4d4htest-k8s LoadBalancer 10.98.202.206 &lt;pending&gt; 8090:31000/TCP 23m 多端口多端口时必须配置 name， 文档 service.yaml1234567891011121314151617apiVersion: v1kind: Servicemetadata: name: test-k8sspec: selector: app: test-k8s type: NodePort ports: - port: 8080 # 本 Service 的端口 name: test-k8s # 必须配置 targetPort: 8080 # 容器端口 nodePort: 31000 # 节点端口，范围固定 30000 ~ 32767 - port: 8090 name: test-other targetPort: 8090 nodePort: 32000 总结ClusterIP默认的，仅在集群内可用 NodePort暴露端口到节点，提供了集群外部访问的入口端口范围固定 30000 ~ 32767 LoadBalancer需要负载均衡器（通常都需要云服务商提供，裸机可以安装 METALLB 测试）会额外生成一个 IP 对外服务K8S 支持的负载均衡器：负载均衡器 Headless适合数据库clusterIp 设置为 None 就变成 Headless 了，不会再分配 IP，后面会再讲到具体用法官网文档","link":"/Kubernetes-Service%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Kubernetes-StatefuSet的使用","text":"什么是 StatefulSetStatefulSet 是用来管理有状态的应用，例如数据库。 deployment 部署的应用，都是不需要存储数据，不需要记住状态的，可以随意扩充副本，每个副本都是一样的，可替代的。而像数据库、Redis 这类有状态的，则不能随意扩充副本。StatefulSet 会固定每个 Pod 的名字 下面以部署 Mongodb为例讲解： 部署 StatefulSet 类型的 Mongodb 编写 yaml 文件 mongo.yaml12345678910111213141516171819202122232425262728293031323334apiVersion: apps/v1kind: StatefulSetmetadata: name: mongodbspec: serviceName: mongodb replicas: 3 selector: matchLabels: app: mongodb template: metadata: labels: app: mongodb spec: containers: - name: mongo image: mongo:4.4 # IfNotPresent 仅本地没有镜像时才远程拉，Always 永远都是从远程拉，Never 永远只用本地镜像，本地没有则报错 imagePullPolicy: IfNotPresent---apiVersion: v1kind: Servicemetadata: name: mongodbspec: selector: app: mongodb type: ClusterIP # HeadLess clusterIP: None ports: - port: 27017 targetPort: 27017 执行 yaml 123456789101112131415$ kubectl apply -f mongo.yamlstatefulset.apps/mongodb createdservice/mongodb created# 查看 statefulset$ kubectl get statefulsetNAME READY AGEmongodb 3/3 4m37s# 查看 pod$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmongodb-0 1/1 Running 0 2m28s 172.17.0.4 minikube &lt;none&gt; &lt;none&gt;mongodb-1 1/1 Running 0 75s 172.17.0.3 minikube &lt;none&gt; &lt;none&gt;mongodb-2 1/1 Running 0 72s 172.17.0.5 minikube &lt;none&gt; &lt;none&gt; StatefulSet 特性 Service 的 CLUSTER-IP 是空的，Pod 名字也是固定的。 12345# 查看 service$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 4d8hmongodb ClusterIP None &lt;none&gt; 27017/TCP 4m1s Pod 创建和销毁是有序的，创建是顺序的，销毁是逆序的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# 首先修改 yaml ，副本数量改为10，然后在执行 yaml$ kubectl apply -f mongo.yamlstatefulset.apps/mongodb configuredservice/mongodb unchanged# 查看 pod 的变化，发现 ID的创建 是有顺序的$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmongodb-0 1/1 Running 0 7m48s 172.17.0.4 minikube &lt;none&gt; &lt;none&gt;mongodb-1 1/1 Running 0 6m35s 172.17.0.3 minikube &lt;none&gt; &lt;none&gt;mongodb-2 1/1 Running 0 6m32s 172.17.0.5 minikube &lt;none&gt; &lt;none&gt;mongodb-3 1/1 Running 0 17s 172.17.0.2 minikube &lt;none&gt; &lt;none&gt;mongodb-4 1/1 Running 0 14s 172.17.0.7 minikube &lt;none&gt; &lt;none&gt;mongodb-5 1/1 Running 0 13s 172.17.0.8 minikube &lt;none&gt; &lt;none&gt;mongodb-6 1/1 Running 0 11s 172.17.0.9 minikube &lt;none&gt; &lt;none&gt;mongodb-7 1/1 Running 0 9s 172.17.0.10 minikube &lt;none&gt; &lt;none&gt;mongodb-8 1/1 Running 0 5s 172.17.0.11 minikube &lt;none&gt; &lt;none&gt;mongodb-9 1/1 Running 0 3s 172.17.0.12 minikube &lt;none&gt; &lt;none&gt;# 然后在修改 ymal，副本改为3，然后执行 yaml$ kubectl apply -f mongo.yamlstatefulset.apps/mongodb configuredservice/mongodb unchanged# 查看 pod 的变化，发现 ID的删除也是有顺序的，是创建的逆序$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmongodb-0 1/1 Running 0 9m55s 172.17.0.4 minikube &lt;none&gt; &lt;none&gt;mongodb-1 1/1 Running 0 8m42s 172.17.0.3 minikube &lt;none&gt; &lt;none&gt;mongodb-2 1/1 Running 0 8m39s 172.17.0.5 minikube &lt;none&gt; &lt;none&gt;# 通过输出 yaml 来查看,会多一个 hostname$ kubectl get endpoints mongodb -o yamlapiVersion: v1kind: Endpointsmetadata: creationTimestamp: &quot;2022-01-11T09:32:08Z&quot; labels: service.kubernetes.io/headless: &quot;&quot; name: mongodb namespace: default resourceVersion: &quot;29984&quot; uid: fa3a0607-61dc-4b7d-b566-d8c026cf4e94subsets:- addresses: # 会多一个 hostname - hostname: mongodb-1 ip: 172.17.0.3 nodeName: minikube targetRef: kind: Pod name: mongodb-1 namespace: default resourceVersion: &quot;29433&quot; uid: 776c156e-c3d7-44ed-8822-b5dbdabaf5ec # 会多一个 hostname - hostname: mongodb-0 ip: 172.17.0.4 nodeName: minikube targetRef: kind: Pod name: mongodb-0 namespace: default resourceVersion: &quot;29420&quot; uid: 7c1dff67-14d7-4bd5-b5f1-ee1e733beba4 # 会多一个 hostname - hostname: mongodb-2 ip: 172.17.0.5 nodeName: minikube targetRef: kind: Pod name: mongodb-2 namespace: default resourceVersion: &quot;29446&quot; uid: 5a6c3dc5-9a33-4c89-bef0-05073fa29b43 ports: - port: 27017 protocol: TCP Pod 重建不会改变名字，除了IP，所以不要用IP直连 访问时，如果直接使用 Service 名字连接，会随机转发请求 要连接指定 Pod，可以这样pod-name.service-name 运行一个临时 Pod 连接数据测试下： 123456789101112131415161718192021222324252627282930313233343536373839404142# mongodb-client： pod 名称# --rm：表示 临时的，退出即删除# --image: 使用的镜像地址# --command -- bash：进入容器内命令行$ kubectl run mongodb-client --rm --tty -i --restart='Never' --image docker.io/bitnami/mongodb:4.4.10-debian-10-r20 --command -- bashIf you don't see a command prompt, try pressing enter.# 使用 'mongodb-0.mongodb'连接其中一个I have no name!@mongodb-client:/$ $ mongo --host mongodb-0.mongodbMongoDB shell version v4.4.10connecting to: mongodb://mongodb-0.mongodb:27017/?compressors=disabled&amp;gssapiServiceName=mongodbImplicit session: session { &quot;id&quot; : UUID(&quot;4e965766-ac5b-4e81-aaba-c78f404fed68&quot;) }MongoDB server version: 4.4.11---The server generated these startup warnings when booting: 2022-01-11T10:10:12.341+00:00: Access control is not enabled for the database. Read and write access to data and configuration is unrestricted 2022-01-11T10:10:12.342+00:00: /sys/kernel/mm/transparent_hugepage/enabled is 'always'. We suggest setting it to 'never' 2022-01-11T10:10:12.342+00:00: /sys/kernel/mm/transparent_hugepage/defrag is 'always'. We suggest setting it to 'never'------ Enable MongoDB's free cloud-based monitoring service, which will then receive and display metrics about your deployment (disk utilization, CPU, operation statistics, etc). The monitoring data will be available on a MongoDB website with a unique URL accessible to you and anyone you share the URL with. MongoDB may use this information to make product improvements and to suggest MongoDB products and deployment options to you. To enable free monitoring, run the following command: db.enableFreeMonitoring() To permanently disable this reminder, run the following command: db.disableFreeMonitoring()---&gt; show dbsadmin 0.000GBconfig 0.000GBlocal 0.000GB&gt; use testswitched to db test&gt; db.users.save({'_id':'buubiu', 'name':'buubiu_k8s'})WriteResult({ &quot;nMatched&quot; : 0, &quot;nUpserted&quot; : 1, &quot;nModified&quot; : 0, &quot;_id&quot; : &quot;buubiu&quot; })&gt; db.user.find()&gt; db.users.find(){ &quot;_id&quot; : &quot;buubiu&quot;, &quot;name&quot; : &quot;buubiu_k8s&quot; }&gt; Web 应用连接 Mongodb在集群内部，我们可以通过服务名字访问到不同的服务指定连接第一个：mongodb-0.mongodb 通过 deployment 启动 web 镜像 deployment.yaml12345678910111213141516171819202122232425262728293031323334353637383940apiVersion: apps/v1kind: Deploymentmetadata: # 部署名字 name: test-k8sspec: replicas: 2 # 用来查找关联的 Pod，所有标签都匹配才行 selector: matchLabels: app: test-k8s # 定义 Pod 相关数据 template: metadata: labels: app: test-k8s spec: # 定义容器，可以多个 containers: - name: test-k8s # 容器名字 image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v3-mongo # 镜像 # 等待 mongodb 起来后才启动 initContainers: - name: wait-mongo image: busybox:1.28 command: ['sh', '-c', &quot;until nslookup mongodb; do echo waiting for mongo; sleep 2; done&quot;]---apiVersion: v1kind: Servicemetadata: name: test-k8sspec: selector: app: test-k8s # 默认 ClusterIp 集群内可访问，NodePort 节点可访问，LoadBalancer 负载均衡模式（需要负载均衡器才可用） type: NodePort ports: - nodePort: 31000 # 节点端口，范围固定 30000 ~ 32767 port: 8080 # 本 Service 的端口 targetPort: 8080 # 容器端口 部署 yaml 1234567891011121314151617$ kubectl apply -f deployment.yamldeployment.apps/test-k8s createdservice/test-k8s created$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmongodb-0 1/1 Running 1 (27m ago) 51m 172.17.0.3 minikube &lt;none&gt; &lt;none&gt;mongodb-1 1/1 Running 1 (27m ago) 50m 172.17.0.2 minikube &lt;none&gt; &lt;none&gt;mongodb-2 1/1 Running 1 (27m ago) 50m 172.17.0.4 minikube &lt;none&gt; &lt;none&gt;test-k8s-7f8b7548fc-22cxs 1/1 Running 0 26s 172.17.0.6 minikube &lt;none&gt; &lt;none&gt;test-k8s-7f8b7548fc-6pv6c 1/1 Running 0 26s 172.17.0.7 minikube &lt;none&gt; &lt;none&gt;$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 4d9hmongodb ClusterIP None &lt;none&gt; 27017/TCP 52mtest-k8s NodePort 10.104.13.44 &lt;none&gt; 8080:31000/TCP 50s 端口转发 1234567891011121314151617181920212223242526272829303132$ kubectl port-forward service/test-k8s 8090:8080Forwarding from 127.0.0.1:8090 -&gt; 8080Forwarding from [::1]:8090 -&gt; 8080Handling connection for 8090# 在 minikube 本机器 访问$ curl http://localhost:8090index pageIP lo172.17.0.6, hostname: test-k8s-7f8b7548fc-22cxs$ kubectl get allNAME READY STATUS RESTARTS AGEpod/mongodb-0 1/1 Running 2 (6m23s ago) 62mpod/mongodb-1 1/1 Running 2 (6m24s ago) 60mpod/mongodb-2 1/1 Running 2 (6m24s ago) 60mpod/test-k8s-7f8b7548fc-22cxs 1/1 Running 1 (3m1s ago) 10mpod/test-k8s-7f8b7548fc-6pv6c 1/1 Running 1 (3m1s ago) 10mNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 4d9hservice/mongodb ClusterIP None &lt;none&gt; 27017/TCP 62mservice/test-k8s NodePort 10.104.13.44 &lt;none&gt; 8080:31000/TCP 10mNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/test-k8s 2/2 2 2 10mNAME DESIRED CURRENT READY AGEreplicaset.apps/test-k8s-7f8b7548fc 2 2 2 10mNAME READY AGEstatefulset.apps/mongodb 3/3 62m pod 重建后，数据库的内容丢失了,这时候需要进行 数据持久化 12# 重新部署 statefulset$ kubectl rollout restart statefulset mongodb","link":"/Kubernetes-StatefuSet%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Kubernetes-命名空间的使用","text":"介绍如果一个集群中部署了多个应用，所有应用都在一起，就不太好管理，也可以导致名字冲突等。我们可以使用 namespace 把应用划分到不同的命名空间，跟代码里的 namespace 是一个概念，只是为了划分空间。 官方文档 使用命名空间创建12$ kubectl create namespace testappnamespace/testapp created 查看12345678910111213141516171819202122232425262728293031323334353637383940# 查看命名空间# 或者 kubectl get namespace$ kubectl get nsNAME STATUS AGEdefault Active 6d1hkube-node-lease Active 6d1hkube-public Active 6d1hkube-system Active 6d1htestapp Active 90s# 一般在查看所有 all 的时候，默认查看的是 default 的命名空间$ kubectl get all -n defaultNAME READY STATUS RESTARTS AGEpod/mongodb-client 1/1 Running 0 35mpod/my-mongo-mongodb-0 1/1 Running 0 52mpod/my-mongo-mongodb-1 1/1 Running 0 52mpod/my-mongo-mongodb-arbiter-0 1/1 Running 0 52mNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 6d1hservice/my-mongo-mongodb-arbiter-headless ClusterIP None &lt;none&gt; 27017/TCP 52mservice/my-mongo-mongodb-headless ClusterIP None &lt;none&gt; 27017/TCP 52mNAME READY AGEstatefulset.apps/my-mongo-mongodb 2/2 52mstatefulset.apps/my-mongo-mongodb-arbiter 1/1 52m# 部署应用到指定的命名空间$ kubectl apply -f app.yml --namespace testapp# 查询指定命名空间的 pod$ kubectl get pod --namespace kube-systemNAME READY STATUS RESTARTS AGEcoredns-78fcd69978-mk82n 1/1 Running 5 (17h ago) 6d1hetcd-minikube 1/1 Running 5 (17h ago) 6d1hkube-apiserver-minikube 1/1 Running 5 (90m ago) 6d1hkube-controller-manager-minikube 1/1 Running 5 (17h ago) 6d1hkube-proxy-pbjtn 1/1 Running 5 (17h ago) 6d1hkube-scheduler-minikube 1/1 Running 5 (90m ago) 6d1hstorage-provisioner 1/1 Running 11 (90m ago) 6d1h 切换默认命名空间1$ kubectl config set-context --current --namespace=&lt;名字空间名称&gt; 快速切换 namespace可以用 kubens 快速切换 namespace 123456# 切换命名空间$ kubens kube-system# 回到上个命名空间$ kubens -# 切换集群$ kubectx minikube","link":"/Kubernetes-%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Kubernetes-控制器(Controller)模型","text":"简介Pod 这个看似复杂的 API 对象，实际上就是对容器的进一步抽象和封装而已。 Pod 对象，其实就是容器的升级版。它对容器进行了组合，添加了更多的属性和字段。这就好比给容器集装箱四面安装了吊环，使得 Kubernetes 这架“吊车”，可以更轻松地操作它。 而操作这些“集装箱”的逻辑，都由控制器（Controller）完成 控制器模式控制器集合在Kubernetes 架构中，有一个叫作kube-controller-manager 的组件。实际上，这个组件，就是一系列控制器的集合。我们可以查看一下 Kubernetes 项目的 pkg/controller 目录： 1234567$ cd kubernetes/pkg/controller/$ ls -d */ deployment/ job/ podautoscaler/ cloud/ disruption/ namespace/ replicaset/ serviceaccount/ volume/cronjob/ garbagecollector/ nodelifecycle/ replication/ statefulset/ daemon/... 控制器通用编排模式这个目录下面的每一个控制器，都以独有的方式负责某种编排功能。实际上，这些控制器之所以被统一放在 pkg/controller 目录下，就是因为它们都遵循 Kubernetes 项目中的一个通用编排模式，即：控制循环（control loop）。 看一个nginx-deployment 例子： 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx replicas: 2 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 这个 Deployment 定义的编排动作非常简单，即：确保携带了 app=nginx 标签的 Pod 的个数，永远等于 spec.replicas 指定的个数，即 2 个。 这就意味着，如果在这个集群中，携带 app=nginx 标签的 Pod 的个数大于 2 的时候，就会有旧的 Pod 被删除；反之，就会有新的 Pod 被创建。 控制循环的实现步骤： Deployment 控制器从 Etcd 中获取到所有携带了“app: nginx”标签的 Pod，然后统计它们的数量，这就是实际状态； Deployment 对象的 Replicas 字段的值就是期望状态； Deployment 控制器将两个状态做比较，然后根据比较结果，确定是创建 Pod，还是删除已有的 Pod Kubernetes 对象的主要编排逻辑，实际上是在第三步的“对比”阶段完成的。 这个操作，通常被叫作调谐（Reconcile）。这个调谐的过程，则被称作“Reconcile Loop”（调谐循环）或者“Sync Loop”（同步循环）。它们其实指的都是同一个东西：控制循环。 而调谐的最终结果，往往都是对被控制对象的某种写操作。 控制器组成 如上图所示，类似 Deployment 这样的一个控制器，实际上都是由上半部分的控制器定义（包括期望状态），加上下半部分的被控制对象的模板组成的。 可以看到，Deployment 这个 template 字段里的内容，跟一个标准的 Pod 对象的 API 定义，丝毫不差。而所有被这个 Deployment 管理的 Pod 实例，其实都是根据这个 template 字段的内容创建出来的。 像 Deployment 定义的 template 字段，在 Kubernetes 项目中有一个专有的名字，叫作 PodTemplate（Pod 模板）。 Deployment实现原理Deployment 实现了 Kubernetes 项目中一个非常重要的功能：Pod 的“水平扩展 / 收缩”（horizontal scaling out/in）。 如果你更新了 Deployment 的 Pod 模板（比如，修改了容器的镜像），那么 Deployment 就需要遵循一种叫作“滚动更新”（rolling update）的方式，来升级现有的容器。 而这个能力的实现，依赖的是 Kubernetes 项目中的一个非常重要的概念（API 对象）：ReplicaSet。 ReplicaSet 的结构非常简单，可以通过这个 YAML 文件查看一下： 12345678910111213141516171819apiVersion: apps/v1kind: ReplicaSetmetadata: name: nginx-set labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 从这个 YAML 文件中，可以看到，一个 ReplicaSet 对象，其实就是由副本数目的定义和一个 Pod 模板组成的。不难发现，它的定义其实是 Deployment 的一个子集。 Deployment 控制器实际操纵的，正是这样的 ReplicaSet 对象，而不是 Pod 对象。 实现方法明白了这个原理，再来分析一个如下所示的 Deployment： 123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 可以看到，这就是一个常用的 nginx-deployment，它定义的 Pod 副本个数是 3（spec.replicas=3）。 Deployment与 ReplicaSet的关系是怎样的呢？ 可以用一张图描述出来： 清楚地看到，一个定义了 replicas=3 的 Deployment，与它的 ReplicaSet，以及 Pod 的关系，实际上是一种“层层控制”的关系。 其中，ReplicaSet 负责通过“控制器模式”，保证系统中 Pod 的个数永远等于指定的个数（比如，3 个）。这也正是 Deployment 只允许容器的 restartPolicy=Always 的主要原因：只有在容器能保证自己始终是 Running 状态的前提下，ReplicaSet 调整 Pod 的个数才有意义。 而在此基础上，Deployment 同样通过“控制器模式”，来操作 ReplicaSet 的个数和属性，进而实现“水平扩展 / 收缩”和“滚动更新”这两个编排动作。 水平扩展/收缩“水平扩展 / 收缩”非常容易实现，Deployment Controller 只需要修改它所控制的 ReplicaSet 的 Pod 副本个数就可以了。 比如，把这个值从 3 改成 4，那么 Deployment 所对应的 ReplicaSet，就会根据修改后的值自动创建一个新的 Pod。这就是“水平扩展”了；“水平收缩”则反之。 命令如下：kubectl scale 12$ kubectl scale deployment nginx-deployment --replicas=4deployment.apps/nginx-deployment scaled 滚动更新定义将一个集群中正在运行的多个 Pod 版本，交替地逐一升级的过程，就是“滚动更新”。 更新流程下面用实际例子来解释一下： 首先，来创建这个 nginx-deployment： 1$ kubectl create -f nginx-deployment.yaml --record --record：记录下每次操作所执行的命令，以方便后面查看。 检查一下 nginx-deployment 创建后的状态信息： 123$ kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 3 0 0 0 1s 在返回结果中，可以看到四个状态字段，它们的含义如下所示。 DESIRED：用户期望的 Pod 副本个数（spec.replicas 的值）； CURRENT：当前处于 Running 状态的 Pod 的个数； UP-TO-DATE：当前处于最新版本的 Pod 的个数，所谓最新版本指的是 Pod 的 Spec 部分与 Deployment 里 Pod 模板里定义的完全一致； AVAILABLE：当前已经可用的 Pod 的个数，即：既是 Running 状态，又是最新版本，并且已经处于 Ready（健康检查正确）状态的 Pod 的个数。 可以看到，只有这个 AVAILABLE 字段，描述的才是用户所期望的最终状态。vs 还可以实时查看 Deployment 对象的状态变化。 命令：kubectl rollout status 1234$ kubectl rollout status deployment/nginx-deployment# 意味着已经有 2 个 Pod 进入了 UP-TO-DATE 状态。Waiting for rollout to finish: 2 out of 3 new replicas have been updated...deployment.apps/nginx-deployment successfully rolled out 继续等待一会儿，就能看到这个 Deployment 的 3 个 Pod，就进入到了 AVAILABLE 状态： 123$ kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 3 3 3 3 20s 查看一下这个 Deployment 所控制的 ReplicaSet： 命令：kubectl get rs 123$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-3167673210 3 3 3 20s 如上所示，在用户提交了一个 Deployment 对象后，Deployment Controller 就会立即创建一个 Pod 副本个数为 3 的 ReplicaSet。这个 ReplicaSet 的名字，则是由 Deployment 的名字和一个随机字符串共同组成。 这个随机字符串叫作 pod-template-hash，在这个例子里就是：3167673210。ReplicaSet 会把这个随机字符串加在它所控制的所有 Pod 的标签里，从而保证这些 Pod 不会与集群里的其他 Pod 混淆。 而 ReplicaSet 的 DESIRED、CURRENT 和 READY 字段的含义，和 Deployment 中是一致的。所以，相比之下，Deployment 只是在 ReplicaSet 的基础上，添加了 UP-TO-DATE 这个跟版本有关的状态字段。 编辑Pod模版，“滚动更新”就会被自动触发，编辑有很多方式 直接编辑原来的yaml文件 kubectl set image命令(下面会写到) 直接使用kubectl edit指令编辑 Etcd 里的 API 对象。 12345678910$ kubectl edit deployment/nginx-deployment... spec: containers: - name: nginx image: nginx:1.9.1 # 1.7.9 -&gt; 1.9.1 ports: - containerPort: 80...deployment.extensions/nginx-deployment edited 这个 kubectl edit 指令，会帮你直接打开 nginx-deployment 的 API 对象。然后，你就可以修改这里的 Pod 模板部分了。比如，在这里，我将 nginx 镜像的版本升级到了 1.9.1。 备注：kubectl edit 命令实际上是把 API 对象的内容下载到了本地文件，等修改完成后再提交上去。 通过 kubectl rollout status 指令查看 nginx-deployment 的状态变化： 123$ kubectl rollout status deployment/nginx-deploymentWaiting for rollout to finish: 2 out of 3 new replicas have been updated...deployment.extensions/nginx-deployment successfully rolled out 通过查看 Deployment 的 Events，看到这个“滚动更新”的流程： 123456789101112$ kubectl describe deployment nginx-deployment...Events: Type Reason Age From Message ---- ------ ---- ---- -------... Normal ScalingReplicaSet 24s deployment-controller Scaled up replica set nginx-deployment-1764197365 to 1 Normal ScalingReplicaSet 22s deployment-controller Scaled down replica set nginx-deployment-3167673210 to 2 Normal ScalingReplicaSet 22s deployment-controller Scaled up replica set nginx-deployment-1764197365 to 2 Normal ScalingReplicaSet 19s deployment-controller Scaled down replica set nginx-deployment-3167673210 to 1 Normal ScalingReplicaSet 19s deployment-controller Scaled up replica set nginx-deployment-1764197365 to 3 Normal ScalingReplicaSet 14s deployment-controller Scaled down replica set nginx-deployment-3167673210 to 0 Pod 的版本升级过程： 首先，当你修改了 Deployment 里的 Pod 定义之后，Deployment Controller 会使用这个修改后的 Pod 模板，创建一个新的 ReplicaSet（hash=1764197365），这个新的 ReplicaSet 的初始 Pod 副本数是：0。 然后，在 Age=24 s 的位置，Deployment Controller 开始将这个新的 ReplicaSet 所控制的 Pod 副本数从 0 个变成 1 个，即：“水平扩展”出一个副本。 紧接着，在 Age=22 s 的位置，Deployment Controller 又将旧的 ReplicaSet（hash=3167673210）所控制的旧 Pod 副本数减少一个，即：“水平收缩”成两个副本。 如此交替进行，新 ReplicaSet 管理的 Pod 副本数，从 0 个变成 1 个，再变成 2 个，最后变成 3 个。而旧的 ReplicaSet 管理的 Pod 副本数则从 3 个变成 2 个，再变成 1 个，最后变成 0 个。 像这样，将一个集群中正在运行的多个 Pod 版本，交替地逐一升级的过程，就是“滚动更新”。 在这个“滚动更新”过程完成之后，可以查看一下新、旧两个 ReplicaSet 的最终状态： 1234$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-1764197365 3 3 3 6snginx-deployment-3167673210 0 0 0 30s 其中，旧 ReplicaSet（hash=3167673210）已经被“水平收缩”成了 0 个副本。 更新原则为了保证服务的连续性，Deployment Controller 还会确保，在任何时间窗口内，只有指定比例的 Pod 处于离线状态。同时，它也会确保，在任何时间窗口内，只有指定比例的新 Pod 被创建出来。这两个比例的值都是可以配置的，默认都是 DESIRED 值的 25%。 所以，在上面这个 Deployment 的例子中，它有 3 个 Pod 副本，那么控制器在“滚动更新”的过程中永远都会确保至少有 2 个 Pod 处于可用状态，至多只有 4 个 Pod 同时存在于集群中。这个策略，是 Deployment 对象的一个字段，名叫 RollingUpdateStrategy，如下所示： 12345678910111213apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec:... strategy: type: RollingUpdate rollingUpdate: maxSurge: 1 maxUnavailable: 1 maxSurge：除了 DESIRED 数量之外，在一次“滚动”中，Deployment 控制器还可以创建多少个新 Pod； maxUnavailable：在一次“滚动”中，Deployment 控制器可以删除多少个旧 Pod。 同时，这两个配置还可以用前面我们介绍的百分比形式来表示，比如：maxUnavailable=50%，指的是我们最多可以一次删除“50%*DESIRED 数量”个 Pod。 滚动回滚(降级)先把镜像名字修改成为了一个错误的名字，比如：nginx:1.91，这样，这个 Deployment 就会出现一个升级失败的版本。 这次，使用 kubectl set image 的指令，直接修改 nginx-deployment 所使用的镜像。这个命令的好处就是，你可以不用像 kubectl edit 那样需要打开编辑器。 12$ kubectl set image deployment/nginx-deployment nginx=nginx:1.91deployment.extensions/nginx-deployment image updated 查一下 ReplicaSet 的状态，如下所示： 12345$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-1764197365 2 2 2 24snginx-deployment-3167673210 0 0 0 35snginx-deployment-2156724341 2 2 0 7s 通过这个返回结果，可以看到，新版本的 ReplicaSet（hash=2156724341）的“水平扩展”已经停止。而且此时，它已经创建了两个 Pod，但是它们都没有进入 READY 状态。这当然是因为这两个 Pod 都拉取不到有效的镜像。 与此同时，旧版本的 ReplicaSet（hash=1764197365）的“水平收缩”，也自动停止了。此时，已经有一个旧 Pod 被删除，还剩下两个旧 Pod。 回滚到上一个版本执行kubectl rollout undo 命令，就能把整个 Deployment 回滚到上一个版本： 12$ kubectl rollout undo deployment/nginx-deploymentdeployment.extensions/nginx-deployment 在具体操作上，Deployment 的控制器，其实就是让这个旧 ReplicaSet（hash=1764197365）再次“扩展”成 3 个 Pod，而让新的 ReplicaSet（hash=2156724341）重新“收缩”到 0 个 Pod。 回滚到任意一个版本使用kubectl rollout history命令，查看每次 Deployment 变更对应的版本。由于在创建这个 Deployment 的时候，指定了–record 参数，所以我们创建这些版本时执行的 kubectl 命令，都会被记录下来。还可以通过这个指令，看到每个版本对应的 Deployment 的 API 对象的细节，最后加上具体的版本即可，这个操作的输出如下所示： 123456$ kubectl rollout history deployment/nginx-deployment [--revision=2]deployments &quot;nginx-deployment&quot;REVISION CHANGE-CAUSE1 kubectl create -f nginx-deployment.yaml --record2 kubectl edit deployment/nginx-deployment3 kubectl set image deployment/nginx-deployment nginx=nginx:1.91 可以看到，前面执行的创建和更新操作，分别对应了版本 1 和版本 2，而那次失败的更新操作，则对应的是版本 3。 最后使用kubectl rollout undo 命令，再加上要回滚到的指定版本的版本号，就可以回滚到指定版本了。这个指令的用法如下： 12$ kubectl rollout undo deployment/nginx-deployment --to-revision=2deployment.extensions/nginx-deployment 这样，Deployment Controller 会按照“滚动更新”的方式，完成对 Deployment 的降级操作。 控制多余版本的生成控制多次编辑版本的数量Kubernetes 项目还提供了一个指令，使得对 Deployment 的多次更新操作，最后 只生成一个 ReplicaSet。 具体的做法是，在更新 Deployment 前，你要先执行一条 kubectl rollout pause 指令。它的用法如下所示： 12$ kubectl rollout pause deployment/nginx-deploymentdeployment.extensions/nginx-deployment paused 这个 kubectl rollout pause 的作用，是让这个 Deployment 进入了一个“暂停”状态。 所以接下来，就可以随意使用 kubectl edit 或者 kubectl set image 指令，修改这个 Deployment 的内容了。 由于此时 Deployment 正处于“暂停”状态，所以对 Deployment 的所有修改，都不会触发新的“滚动更新”，也不会创建新的 ReplicaSet。 而等到对 Deployment 修改操作都完成之后，只需要再执行一条 kubectl rollout resume 指令，就可以把这个 Deployment“恢复”回来，如下所示： 12$ kubectl rollout resume deployment/nginx-deploymentdeployment.extensions/nginx-deployment resumed 而在这个 kubectl rollout resume 指令执行之前，在 kubectl rollout pause 指令之后的这段时间里，对 Deployment 进行的所有修改，最后只会触发一次“滚动更新”。 可以通过检查 ReplicaSet 状态的变化，来验证一下 kubectl rollout pause 和 kubectl rollout resume 指令的执行效果，如下所示： 1234$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-1764197365 0 0 0 2mnginx-3196763511 3 3 3 28s 通过返回结果，可以看到，只有一个 hash=3196763511 的 ReplicaSet 被创建了出来。 控制ReplicaSet 的数量Deployment 对象有一个字段，叫作 spec.revisionHistoryLimit，就是 Kubernetes 为 Deployment 保留的“历史版本”个数。所以，如果把它设置为 0，你就再也不能做回滚操作了。 Deployment、ReplicaSet 和 Pod 的关系 如上所示，Deployment 的控制器，实际上控制的是 ReplicaSet 的数目，以及每个 ReplicaSet 的属性。 而一个应用的版本，对应的正是一个 ReplicaSet；这个版本应用的 Pod 数量，则由 ReplicaSet 通过它自己的控制器（ReplicaSet Controller）来保证。 通过这样的多个 ReplicaSet 对象，Kubernetes 项目就实现了对多个“应用版本”的描述。 Deployment 实际上是一个两层控制器。首先，它通过 ReplicaSet 的个数来描述应用的版本；然后，它再通过 ReplicaSet 的属性（比如 replicas 的值），来保证 Pod 的副本数量。 Deployment 控制 ReplicaSet（版本），ReplicaSet 控制 Pod（副本数）。","link":"/Kubernetes-%E6%8E%A7%E5%88%B6%E5%99%A8-Controller-%E6%A8%A1%E5%9E%8B/"},{"title":"Kubernetes-搭建mysql集群(非operator)","text":"集群介绍首先，用自然语言来描述一下我们想要部署的“有状态应用”。 是一个“主从复制”（Maser-Slave Replication）的 MySQL 集群； 有 1 个主节点（Master）； 有多个从节点（Slave）； 从节点需要能水平扩展； 所有的写操作，只能在主节点上执行； 读操作可以在所有节点上执行。 在常规环境里，部署这样一个主从模式的 MySQL 集群的主要难点在于：如何让从节点能够拥有主节点的数据，即：如何配置主（Master）从（Slave）节点的复制与同步。 所以，在安装好 MySQL 的 Master 节点之后，你需要做的第一步工作，就是通过 XtraBackup 将 Master 节点的数据备份到指定目录。 备注：XtraBackup 是业界主要使用的开源 MySQL 备份和恢复工具。 这一步会自动在目标目录里生成一个备份信息文件，名叫：xtrabackup_binlog_info。这个文件一般会包含如下两个信息： 12$ cat xtrabackup_binlog_infoTheMaster-bin.000001 481 这两个信息会在接下来配置 Slave 节点的时候用到。 第二步：配置 Slave 节点。Slave 节点在第一次启动前，需要先把 Master 节点的备份数据，连同备份信息文件，一起拷贝到自己的数据目录（/var/lib/mysql）下。然后，我们执行这样一句 SQL： 123456TheSlave|mysql&gt; CHANGE MASTER TO MASTER_HOST='$masterip', MASTER_USER='xxx', MASTER_PASSWORD='xxx', MASTER_LOG_FILE='TheMaster-bin.000001', MASTER_LOG_POS=481; 其中，MASTER_LOG_FILE 和 MASTER_LOG_POS，就是该备份对应的二进制日志（Binary Log）文件的名称和开始的位置（偏移量），也正是 xtrabackup_binlog_info 文件里的那两部分内容（即：TheMaster-bin.000001 和 481）。 第三步，启动 Slave 节点。在这一步，我们需要执行这样一句 SQL： 1TheSlave|mysql&gt; START SLAVE; 这样，Slave 节点就启动了。它会使用备份信息文件中的二进制日志文件和偏移量，与主节点进行数据同步。 第四步，在这个集群中添加更多的 Slave 节点。 需要注意的是，新添加的 Slave 节点的备份数据，来自于已经存在的 Slave 节点。 所以，在这一步，我们需要将 Slave 节点的数据备份在指定目录。而这个备份操作会自动生成另一种备份信息文件，名叫：xtrabackup_slave_info。同样地，这个文件也包含了 MASTER_LOG_FILE 和 MASTER_LOG_POS 两个字段。 然后，我们就可以执行跟前面一样的“CHANGE MASTER TO”和“START SLAVE” 指令，来初始化并启动这个新的 Slave 节点了。 集群容器化将部署 MySQL 集群的流程迁移到 Kubernetes 项目上，需要能够“容器化”地解决下面的三个问题： Master 节点和 Slave 节点需要有不同的配置文件（即：不同的 my.cnf）； Master 节点和 Slave 节点需要能够传输备份信息文件； 在 Slave 节点第一次启动之前，需要执行一些初始化 SQL 操作； 处理不同的配置文件 需要给主从节点分别准备两份不同的 MySQL 配置文件，然后根据 Pod 的序号（Index）挂载进去，这样的配置文件信息，应该保存在 ConfigMap 里供 Pod 使用。它的定义如下所示： application/mysql/mysql-configmap.yaml 123456789101112131415apiVersion: v1kind: ConfigMapmetadata: name: mysql labels: app: mysqldata: master.cnf: | # 主节点MySQL的配置文件 [mysqld] log-bin slave.cnf: | # 从节点MySQL的配置文件 [mysqld] super-read-only 1$ kubectl apply -f mysql-configmap.yaml 在这里，定义了 master.cnf 和 slave.cnf 两个 MySQL 的配置文件。 master.cnf 开启了 log-bin，即：使用二进制日志文件的方式进行主从复制，这是一个标准的设置。 slave.cnf 的开启了 super-read-only，代表的是从节点会拒绝除了主节点的数据同步操作之外的所有写操作，即：它对用户是只读的。 接下来，需要创建两个 Service 来供 StatefulSet 以及用户使用。这两个 Service 的定义如下所示： application/mysql/mysql-services.yaml 1234567891011121314151617181920212223242526apiVersion: v1kind: Servicemetadata: name: mysql labels: app: mysqlspec: ports: - name: mysql port: 3306 clusterIP: None selector: app: mysql---apiVersion: v1kind: Servicemetadata: name: mysql-read labels: app: mysqlspec: ports: - name: mysql port: 3306 selector: app: mysql 1$ kubectl apply -f mysql-services.yaml 可以看到，这两个 Service 都代理了所有携带 app=mysql 标签的 Pod，也就是所有的 MySQL Pod。端口映射都是用 Service 的 3306 端口对应 Pod 的 3306 端口。 不同的是，第一个名叫“mysql”的 Service 是一个 Headless Service（即：clusterIP= None）。所以它的作用，是通过为 Pod 分配 DNS 记录来固定它的拓扑状态，比如“mysql-0.mysql”和“mysql-1.mysql”这样的 DNS 名字。其中，编号为 0 的节点就是我们的主节点。 而第二个名叫“mysql-read”的 Service，则是一个常规的 Service。 并且我们规定，所有用户的读请求，都必须访问第二个 Service 被自动分配的 DNS 记录，即：“mysql-read”（当然，也可以访问这个 Service 的 VIP）。这样，读请求就可以被转发到任意一个 MySQL 的主节点或者从节点上。 备注：Kubernetes 中的所有 Service、Pod 对象，都会被自动分配同名的 DNS 记录。 而所有用户的写请求，则必须直接以 DNS 记录的方式访问到 MySQL 的主节点，也就是：“mysql-0.mysql“这条 DNS 记录。 节点之间传输备份文件推荐的做法是：先搭建框架，再完善细节。其中，Pod 部分如何定义，是完善细节时的重点。 搭建StatefulSet框架所以首先，我们先为 StatefulSet 对象规划一个大致的框架，如下图所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546apiVersion: apps/v1kind: StatefulSetmetadata: name: mysqlspec: # selector 表示，这个 StatefulSet 要管理的 Pod 必须携带 app=mysql 标签 selector: matchLabels: app: mysql # serviceName 表示 它声明要使用的 Headless Service 的名字是：mysql serviceName: mysql # StatefulSet 的 replicas 值是 3，表示它定义的 MySQL 集群有三个节点：一个 Master 节点，两个 Slave 节点。 replicas: 3 template: metadata: labels: app: mysql spec: initContainers: - name: init-mysql ... - name: clone-mysql ... containers: - name: mysql ... - name: xtrabackup ... volumes: - name: conf emptyDir: {} - name: config-map configMap: name: mysql # 通过 volumeClaimTemplate（PVC 模板）来为每个 Pod 定义 PVC，将来，这个 PV 对应的的 Volume 就会充当 MySQL Pod 的存储数据目录 volumeClaimTemplates: - metadata: name: data spec: # 指定了该存储的属性为可读写，并且一个 PV 只允许挂载在一个宿主机上 accessModes: [&quot;ReadWriteOnce&quot;] storageClassName: rook-ceph-block resources: requests: # 指定了存储的大小为 10 GiB storage: 10Gi 然后，我们来重点设计一下这个 StatefulSet 的 Pod 模板，也就是 template 字段。 设计 StatefulSet 的 Pod 模板由于 StatefulSet 管理的 Pod 都来自于同一个镜像，这就要求我们在编写 Pod 时，一定要保持清醒，用“人格分裂”的方式进行思考： 如果这个 Pod 是 Master 节点，我们要怎么做； 如果这个 Pod 是 Slave 节点，我们又要怎么做。 想清楚这两个问题，我们就可以按照 Pod 的启动过程来一步步定义它们了。 第一步：从 ConfigMap 中，获取 MySQL 的 Pod 对应的配置文件。 获取 MySQL 的 Pod 对应的配置文件为此，我们需要进行一个初始化操作，根据节点的角色是 Master 还是 Slave 节点，为 Pod 分配对应的配置文件。此外，MySQL 还要求集群里的每个节点都有一个唯一的 ID 文件，名叫 server-id.cnf。 123456789101112131415161718192021222324252627282930... # template.spec # 需要进行一个初始化操作，根据节点的角色是 Master 还是 Slave 节点，为 Pod 分配对应的配置文件。此外，MySQL 还要求集群里的每个节点都有一个唯一的 ID 文件，名叫 server-id.cnf initContainers: - name: init-mysql image: mysql:5.7 command: - bash - &quot;-c&quot; - | set -ex # 从 Pod 的 hostname 里，读取到了 Pod 的序号，以此作为 MySQL 节点的 server-id [[ `hostname` =~ -([0-9]+)$ ]] || exit 1 ordinal=${BASH_REMATCH[1]} echo [mysqld] &gt; /mnt/conf.d/server-id.cnf # 由于server-id=0有特殊含义，我们给ID加一个100来避开它 echo server-id=$((100 + $ordinal)) &gt;&gt; /mnt/conf.d/server-id.cnf # 如果Pod序号是0，说明它是Master节点，从ConfigMap里把Master的配置文件拷贝到/mnt/conf.d/目录； # 否则，拷贝Slave的配置文件 if [[ $ordinal -eq 0 ]]; then cp /mnt/config-map/master.cnf /mnt/conf.d/ else cp /mnt/config-map/slave.cnf /mnt/conf.d/ fi # init-mysql 在声明了挂载 config-map 这个 Volume 之后，ConfigMap 里保存的内容，就会以文件的方式出现在它的 /mnt/config-map 目录当中 volumeMounts: - name: conf mountPath: /mnt/conf.d - name: config-map mountPath: /mnt/config-map 第二步：在 Slave Pod 启动前，从 Master 或者其他 Slave Pod 里拷贝数据库数据到自己的目录下。 从 Master 或者其他 Slave Pod 里拷贝数据库数据为了实现这个操作，我们就需要再定义第二个 InitContainer，如下所示： 12345678910111213141516171819202122232425262728... # template.spec.initContainers - name: clone-mysql # 使用的是 xtrabackup 镜像（它里面安装了 xtrabackup 工具） image: gcr.io/google-samples/xtrabackup:1.0 command: - bash - &quot;-c&quot; - | set -ex # 拷贝操作只需要在第一次启动时进行，所以如果数据已经存在，跳过 [[ -d /var/lib/mysql/mysql ]] &amp;&amp; exit 0 # Master节点(序号为0)不需要做这个操作 [[ `hostname` =~ -([0-9]+)$ ]] || exit 1 ordinal=${BASH_REMATCH[1]} [[ $ordinal -eq 0 ]] &amp;&amp; exit 0 # 使用ncat指令，远程地向 DNS 记录为“mysql-&lt; 当前序号减一 &gt;.mysql”的 Pod，也就是当前 Pod 的前一个 Pod，发起数据传输请求，并且直接用 xbstream 指令将收到的备份数据保存在 /var/lib/mysql 目录下; # 3307 是一个特殊端口，运行着一个专门负责备份 MySQL 数据的辅助进程 # 这一步还可以用其他方法来传输数据。比如，用 scp 或者 rsync，都没问题 ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql # 执行--prepare，这样拷贝来的数据就可以用作恢复了 xtrabackup --prepare --target-dir=/var/lib/mysql volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d 你可能已经注意到，这个容器里的 /var/lib/mysql 目录，实际上正是一个名为 data 的 PVC，即：我们在前面声明的持久化存储。 这就可以保证，哪怕宿主机宕机了，我们数据库的数据也不会丢失。更重要的是，由于 Pod Volume 是被 Pod 里的容器共享的，所以后面启动的 MySQL 容器，就可以把这个 Volume 挂载到自己的 /var/lib/mysql 目录下，直接使用里面的备份数据进行恢复操作。 不过，clone-mysql 容器还要对 /var/lib/mysql 目录，执行一句 xtrabackup –prepare 操作，目的是让拷贝来的数据进入一致性状态，这样，这些数据才能被用作数据恢复。 至此，我们就通过 InitContainer 完成了对“主、从节点间备份文件传输”操作的处理过程。 从节点首次启动之前执行初始化 SQL 操作可以为这个 MySQL 容器额外定义一个 sidecar 容器，来完成这个操作，它的定义如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566... # template.spec.containers # 在这个名叫 xtrabackup 的 sidecar 容器的启动命令里，其实实现了两部分工作。 - name: xtrabackup image: gcr.io/google-samples/xtrabackup:1.0 ports: - name: xtrabackup containerPort: 3307 command: - bash - &quot;-c&quot; - | set -ex cd /var/lib/mysql #第一部分工作，是 MySQL 节点的初始化工作。这个初始化需要使用的 SQL，是 sidecar 容器拼装出来、保存在一个名为 change_master_to.sql.in 的文件里的，具体过程如下所示 # 从备份信息文件里读取MASTER_LOG_FILEM和MASTER_LOG_POS这两个字段的值，用来拼装集群初始化SQL if [[ -f xtrabackup_slave_info ]]; then # 如果xtrabackup_slave_info文件存在，说明这个备份数据来自于另一个Slave节点。这种情况下，XtraBackup工具在备份的时候，就已经在这个文件里自动生成了&quot;CHANGE MASTER TO&quot; SQL语句。所以，我们只需要把这个文件重命名为change_master_to.sql.in，后面直接使用即可 mv xtrabackup_slave_info change_master_to.sql.in # 所以，也就用不着xtrabackup_binlog_info了，否则，下次这个容器重启时，就会发现这些文件存在，所以又会重新执行一次数据恢复和集群初始化的操作，这是不对的 rm -f xtrabackup_binlog_info elif [[ -f xtrabackup_binlog_info ]]; then # 如果只存在xtrabackup_binlog_inf文件，那说明备份来自于Master节点，我们就需要解析这个备份信息文件，读取所需的两个字段的值 [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1 # 同上，这里也就用不着xtrabackup_binlog_info了，否则，下次这个容器重启时，就会发现这些文件存在，所以又会重新执行一次数据恢复和集群初始化的操作，这是不对的 rm xtrabackup_binlog_info # 把两个字段的值拼装成SQL，写入change_master_to.sql.in文件 echo &quot;CHANGE MASTER TO MASTER_LOG_FILE='${BASH_REMATCH[1]}',\\ MASTER_LOG_POS=${BASH_REMATCH[2]}&quot; &gt; change_master_to.sql.in fi # 接下来，sidecar 容器就可以执行初始化了 # 如果这个 change_master_to.sql.in 文件存在，就意味着需要做集群初始化工作 if [[ -f change_master_to.sql.in ]]; then # 但一定要先等MySQL容器启动之后才能进行下一步连接MySQL的操作 echo &quot;Waiting for mysqld to be ready (accepting connections)&quot; until mysql -h 127.0.0.1 -e &quot;SELECT 1&quot;; do sleep 1; done echo &quot;Initializing replication from clone position&quot; # 将文件change_master_to.sql.in改个名字，防止这个Container重启的时候，因为又找到了change_master_to.sql.in，从而重复执行一遍这个初始化流程 mv change_master_to.sql.in change_master_to.sql.orig # 使用change_master_to.sql.orig的内容，也是就是前面拼装的SQL，组成一个完整的初始化和启动Slave的SQL语句 mysql -h 127.0.0.1 &lt;&lt;EOF $(&lt;change_master_to.sql.orig), MASTER_HOST='mysql-0.mysql', MASTER_USER='root', MASTER_PASSWORD='', MASTER_CONNECT_RETRY=10; START SLAVE; EOF fi #第二部分工作，则是启动一个数据传输服务，具体过程如下所示 # 使用ncat监听3307端口。它的作用是，在收到传输请求的时候，直接执行&quot;xtrabackup --backup&quot;命令，备份MySQL的数据并发送给请求者 # 由于 sidecar 容器和 MySQL 容器同处于一个 Pod 里，所以它是直接通过 Localhost 来访问和备份 MySQL 容器里的数据的，非常方便 exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \\ &quot;xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root&quot; volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d 定义 Pod -MySQL 容器有了前面这些定义和初始化工作，MySQL 容器本身的定义就非常简单了，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738...# template.speccontainers:- name: mysql image: mysql:5.7 env: - name: MYSQL_ALLOW_EMPTY_PASSWORD value: &quot;1&quot; ports: - name: mysql containerPort: 3306 volumeMounts: - name: data # 数据目录是 /var/lib/mysql mountPath: /var/lib/mysql subPath: mysql - name: conf # 配置文件目录是 /etc/mysql/conf.d mountPath: /etc/mysql/conf.d resources: requests: cpu: 500m memory: 1Gi # 定义了一个 livenessProbe，通过 mysqladmin ping 命令来检查它是否健康 livenessProbe: exec: command: [&quot;mysqladmin&quot;, &quot;ping&quot;] initialDelaySeconds: 30 periodSeconds: 10 timeoutSeconds: 5 # 定义了一个 readinessProbe，通过查询 SQL（select 1）来检查 MySQL 服务是否可用，凡是 readinessProbe 检查失败的 MySQL Pod，都会从 Service 里被摘除掉。 readinessProbe: exec: # 通过TCP连接的方式进行健康检查 command: [&quot;mysql&quot;, &quot;-h&quot;, &quot;127.0.0.1&quot;, &quot;-e&quot;, &quot;SELECT 1&quot;] initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 1 这时候，应该能够明白，如果 MySQL 容器是 Slave 节点的话，它的数据目录里的数据，就来自于 InitContainer 从其他节点里拷贝而来的备份。它的配置文件目录 /etc/mysql/conf.d 里的内容，则来自于 ConfigMap 对应的 Volume。而它的初始化工作，则是由同一个 Pod 里的 sidecar 容器完成的。这些操作，正是刚刚前三部讲述的大部分内容。 至此，一个完整的主从复制模式的 MySQL 集群就定义完了。 完整的StatefulSet如下： application/mysql/mysql-statefulset.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189apiVersion: apps/v1kind: StatefulSetmetadata: name: mysqlspec: # selector 表示，这个 StatefulSet 要管理的 Pod 必须携带 app=mysql 标签 selector: matchLabels: app: mysql # serviceName 表示 它声明要使用的 Headless Service 的名字是：mysql serviceName: mysql # StatefulSet 的 replicas 值是 3，表示它定义的 MySQL 集群有三个节点：一个 Master 节点，两个 Slave 节点。 replicas: 3 template: metadata: labels: app: mysql spec: # 需要进行一个初始化操作，根据节点的角色是 Master 还是 Slave 节点，为 Pod 分配对应的配置文件。此外，MySQL 还要求集群里的每个节点都有一个唯一的 ID 文件，名叫 server-id.cnf initContainers: - name: init-mysql image: mysql:5.7 command: - bash - &quot;-c&quot; - | set -ex # 从 Pod 的 hostname 里，读取到了 Pod 的序号，以此作为 MySQL 节点的 server-id [[ `hostname` =~ -([0-9]+)$ ]] || exit 1 ordinal=${BASH_REMATCH[1]} echo [mysqld] &gt; /mnt/conf.d/server-id.cnf # 由于server-id=0有特殊含义，我们给ID加一个100来避开它 echo server-id=$((100 + $ordinal)) &gt;&gt; /mnt/conf.d/server-id.cnf # 如果Pod序号是0，说明它是Master节点，从ConfigMap里把Master的配置文件拷贝到/mnt/conf.d/目录； # 否则，拷贝Slave的配置文件 if [[ $ordinal -eq 0 ]]; then cp /mnt/config-map/master.cnf /mnt/conf.d/ else cp /mnt/config-map/slave.cnf /mnt/conf.d/ fi # init-mysql 在声明了挂载 config-map 这个 Volume 之后，ConfigMap 里保存的内容，就会以文件的方式出现在它的 /mnt/config-map 目录当中 volumeMounts: - name: conf mountPath: /mnt/conf.d - name: config-map mountPath: /mnt/config-map - name: clone-mysql # 使用的是 xtrabackup 镜像（它里面安装了 xtrabackup 工具） image: gcr.io/google-samples/xtrabackup:1.0 command: - bash - &quot;-c&quot; - | set -ex # 拷贝操作只需要在第一次启动时进行，所以如果数据已经存在，跳过 [[ -d /var/lib/mysql/mysql ]] &amp;&amp; exit 0 # Master节点(序号为0)不需要做这个操作 [[ `hostname` =~ -([0-9]+)$ ]] || exit 1 ordinal=${BASH_REMATCH[1]} [[ $ordinal -eq 0 ]] &amp;&amp; exit 0 # 使用ncat指令，远程地向 DNS 记录为“mysql-&lt; 当前序号减一 &gt;.mysql”的 Pod，也就是当前 Pod 的前一个 Pod，发起数据传输请求，并且直接用 xbstream 指令将收到的备份数据保存在 /var/lib/mysql 目录下; # 3307 是一个特殊端口，运行着一个专门负责备份 MySQL 数据的辅助进程 # 这一步还可以用其他方法来传输数据。比如，用 scp 或者 rsync，都没问题 ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql # 执行--prepare，这样拷贝来的数据就可以用作恢复了 xtrabackup --prepare --target-dir=/var/lib/mysql volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d containers: - name: mysql image: mysql:5.7 env: - name: MYSQL_ALLOW_EMPTY_PASSWORD value: &quot;1&quot; ports: - name: mysql containerPort: 3306 volumeMounts: - name: data # 数据目录是 /var/lib/mysql mountPath: /var/lib/mysql subPath: mysql - name: conf # 配置文件目录是 /etc/mysql/conf.d mountPath: /etc/mysql/conf.d resources: requests: cpu: 500m memory: 1Gi # 定义了一个 livenessProbe，通过 mysqladmin ping 命令来检查它是否健康 livenessProbe: exec: command: [&quot;mysqladmin&quot;, &quot;ping&quot;] initialDelaySeconds: 30 periodSeconds: 10 timeoutSeconds: 5 # 定义了一个 readinessProbe，通过查询 SQL（select 1）来检查 MySQL 服务是否可用，凡是 readinessProbe 检查失败的 MySQL Pod，都会从 Service 里被摘除掉。 readinessProbe: exec: # 通过TCP连接的方式进行健康检查 command: [&quot;mysql&quot;, &quot;-h&quot;, &quot;127.0.0.1&quot;, &quot;-e&quot;, &quot;SELECT 1&quot;] initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 1 - name: xtrabackup image: gcr.io/google-samples/xtrabackup:1.0 ports: - name: xtrabackup containerPort: 3307 command: - bash - &quot;-c&quot; - | set -ex cd /var/lib/mysql #第一部分工作，是 MySQL 节点的初始化工作。这个初始化需要使用的 SQL，是 sidecar 容器拼装出来、保存在一个名为 change_master_to.sql.in 的文件里的，具体过程如下所示 # 从备份信息文件里读取MASTER_LOG_FILEM和MASTER_LOG_POS这两个字段的值，用来拼装集群初始化SQL if [[ -f xtrabackup_slave_info ]]; then # 如果xtrabackup_slave_info文件存在，说明这个备份数据来自于另一个Slave节点。这种情况下，XtraBackup工具在备份的时候，就已经在这个文件里自动生成了&quot;CHANGE MASTER TO&quot; SQL语句。所以，我们只需要把这个文件重命名为change_master_to.sql.in，后面直接使用即可 mv xtrabackup_slave_info change_master_to.sql.in # 所以，也就用不着xtrabackup_binlog_info了，否则，下次这个容器重启时，就会发现这些文件存在，所以又会重新执行一次数据恢复和集群初始化的操作，这是不对的 rm -f xtrabackup_binlog_info elif [[ -f xtrabackup_binlog_info ]]; then # 如果只存在xtrabackup_binlog_inf文件，那说明备份来自于Master节点，我们就需要解析这个备份信息文件，读取所需的两个字段的值 [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1 # 同上，这里也就用不着xtrabackup_binlog_info了，否则，下次这个容器重启时，就会发现这些文件存在，所以又会重新执行一次数据恢复和集群初始化的操作，这是不对的 rm xtrabackup_binlog_info # 把两个字段的值拼装成SQL，写入change_master_to.sql.in文件 echo &quot;CHANGE MASTER TO MASTER_LOG_FILE='${BASH_REMATCH[1]}',\\ MASTER_LOG_POS=${BASH_REMATCH[2]}&quot; &gt; change_master_to.sql.in fi # 接下来，sidecar 容器就可以执行初始化了 # 如果这个 change_master_to.sql.in 文件存在，就意味着需要做集群初始化工作 if [[ -f change_master_to.sql.in ]]; then # 但一定要先等MySQL容器启动之后才能进行下一步连接MySQL的操作 echo &quot;Waiting for mysqld to be ready (accepting connections)&quot; until mysql -h 127.0.0.1 -e &quot;SELECT 1&quot;; do sleep 1; done echo &quot;Initializing replication from clone position&quot; # 将文件change_master_to.sql.in改个名字，防止这个Container重启的时候，因为又找到了change_master_to.sql.in，从而重复执行一遍这个初始化流程 mv change_master_to.sql.in change_master_to.sql.orig # 使用change_master_to.sql.orig的内容，也是就是前面拼装的SQL，组成一个完整的初始化和启动Slave的SQL语句 mysql -h 127.0.0.1 &lt;&lt;EOF $(&lt;change_master_to.sql.orig), MASTER_HOST='mysql-0.mysql', MASTER_USER='root', MASTER_PASSWORD='', MASTER_CONNECT_RETRY=10; START SLAVE; EOF fi #第二部分工作，则是启动一个数据传输服务，具体过程如下所示 # 使用ncat监听3307端口。它的作用是，在收到传输请求的时候，直接执行&quot;xtrabackup --backup&quot;命令，备份MySQL的数据并发送给请求者 # 由于 sidecar 容器和 MySQL 容器同处于一个 Pod 里，所以它是直接通过 Localhost 来访问和备份 MySQL 容器里的数据的，非常方便 exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \\ &quot;xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root&quot; volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d volumes: - name: conf emptyDir: {} - name: config-map configMap: name: mysql # 通过 volumeClaimTemplate（PVC 模板）来为每个 Pod 定义 PVC，将来，这个 PV 对应的的 Volume 就会充当 MySQL Pod 的存储数据目录 volumeClaimTemplates: - metadata: name: data spec: # 指定了该存储的属性为可读写，并且一个 PV 只允许挂载在一个宿主机上 accessModes: [&quot;ReadWriteOnce&quot;] storageClassName: rook-ceph-block resources: requests: # 指定了存储的大小为 10 GiB storage: 10Gi 开始搭建集群创建configmap1$ kubectl apply -f mysql-configmap.yaml 创建service1$ kubectl apply -f mysql-services.yaml 创建PV首先，我们需要在 Kubernetes 集群里创建满足条件的 PV。 application/mysql/rook-storage.yaml 1234567891011121314151617apiVersion: ceph.rook.io/v1kind: CephBlockPoolmetadata: name: replicapool namespace: rook-cephspec: replicated: size: 3---apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: rook-ceph-blockprovisioner: ceph.rook.io/blockparameters: pool: replicapool clusterNamespace: rook-ceph 1$ kubectl create -f rook-storage.yaml 在这里，用到了 StorageClass 来完成这个操作。它的作用，是自动地为集群里存在的每一个 PVC，调用存储插件（Rook）创建对应的 PV，从而省去了我们手动创建 PV 的机械劳动。 备注：在使用 Rook 的情况下，mysql-statefulset.yaml 里的 volumeClaimTemplates 字段需要加上声明 storageClassName=rook-ceph-block，才能使用到这个 Rook 提供的持久化存储。 创建StatefulSet1$ kubectl create -f mysql-statefulset.yaml 你可以通过运行以下命令查看启动进度： 1kubectl get pods -l app=mysql --watch 一段时间后，你应该看到所有 3 个 Pod 进入 Running 状态： 12345$ kubectl get pod -l app=mysqlNAME READY STATUS RESTARTS AGEmysql-0 2/2 Running 0 2mmysql-1 2/2 Running 0 1mmysql-2 2/2 Running 0 1m 验证集群尝试向这个 MySQL 集群发起请求，执行一些 SQL 操作来验证它是否正常： 123456$ kubectl run mysql-client --image=mysql:5.7 -i --rm --restart=Never --\\ mysql -h mysql-0.mysql &lt;&lt;EOFCREATE DATABASE test;CREATE TABLE test.messages (message VARCHAR(250));INSERT INTO test.messages VALUES ('hello');EOF 通过启动一个容器，使用 MySQL client 执行了创建数据库和表、以及插入数据的操作。需要注意的是，我们连接的 MySQL 的地址必须是 mysql-0.mysql（即：Master 节点的 DNS 记录）。因为，只有 Master 节点才能处理写操作。 通过连接 mysql-read 这个 Service，我们就可以用 SQL 进行读操作，如下所示： 123456789$ kubectl run mysql-client --image=mysql:5.7 -i -t --rm --restart=Never --\\ mysql -h mysql-read -e &quot;SELECT * FROM test.messages&quot;Waiting for pod default/mysql-client to be running, status is Pending, pod ready: false+---------+| message |+---------+| hello |+---------+pod &quot;mysql-client&quot; deleted 扩展 MySQL 集群，比如： 1$ kubectl scale statefulset mysql --replicas=5 这时候，就会发现新的 Slave Pod mysql-3 和 mysql-4 被自动创建了出来 如果你像如下所示的这样，直接连接 mysql-3.mysql，即 mysql-3 这个 Pod 的 DNS 名字来进行查询操作： 123456789$ kubectl run mysql-client --image=mysql:5.7 -i -t --rm --restart=Never --\\ mysql -h mysql-3.mysql -e &quot;SELECT * FROM test.messages&quot;Waiting for pod default/mysql-client to be running, status is Pending, pod ready: false+---------+| message |+---------+| hello |+---------+pod &quot;mysql-client&quot; deleted 就会看到，从 StatefulSet 为新创建的 mysql-3 上，同样可以读取到之前插入的记录。也就是说，数据备份和恢复，都是有效的。","link":"/Kubernetes-%E6%90%AD%E5%BB%BAmysql%E9%9B%86%E7%BE%A4(%E9%9D%9Eoperator)/"},{"title":"Kubernetes-数据持久化","text":"介绍kubernetes 集群不会为你处理数据的存储，我们可以为数据库挂载一个磁盘来确保数据的安全。你可以选择云存储、本地磁盘、NFS。 hostPath：把节点上的一个目录挂载到Pod，官方不推荐了，仅供单节点测试使用；不适用于多节点集群； 本地磁盘：可以挂载某个节点上的目录，但是这需要限定 pod 在这个节点上运行 云存储：不限定节点，不受集群影响，安全稳定；需要云服务商提供，裸机集群是没有的。 NFS：不限定节点，不受集群影响 hostPath 挂载优缺点 把节点上的一个目录挂载到 Pod，但是已经不推荐使用了，文档 配置方式简单，需要手动指定 Pod 跑在某个固定的节点。 仅供单节点测试使用；不适用于多节点集群。 minikube 提供了 hostPath 存储，文档 示例 创建 yaml 文件 mongo.yaml12345678910111213141516171819202122232425262728293031323334353637383940414243apiVersion: apps/v1kind: StatefulSetmetadata: name: mongodbspec: serviceName: mongodb replicas: 1 selector: matchLabels: app: mongodb template: metadata: labels: app: mongodb spec: containers: - name: mongo image: mongo:4.4 # IfNotPresent 仅本地没有镜像时才远程拉，Always 永远都是从远程拉，Never 永远只用本地镜像，本地没有则报错 imagePullPolicy: IfNotPresent volumeMounts: - mountPath: /data/db # 容器里面的挂载路径 name: mongo-data # 卷名字，必须跟下面定义的名字一致 volumes: - name: mongo-data # 卷名字 hostPath: path: /data/mongo-data # 节点上的路径 type: DirectoryOrCreate # 指向一个目录，不存在时自动创建---apiVersion: v1kind: Servicemetadata: name: mongodbspec: selector: app: mongodb type: ClusterIP # HeadLess clusterIP: None ports: - port: 27017 protocol: TCP targetPort: 27017 部署 yaml 1234567$ kubectl apply -f mongo.yamlstatefulset.apps/mongodb createdservice/mongodb created$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmongodb-0 1/1 Running 0 14s 172.17.0.2 minikube &lt;none&gt; &lt;none&gt; 查看目录是否挂载成功，即 看节点上是否有目录 /data/mogo-data 12345$ docker exec -it minikube bashroot@minikube:/$ cd /data/mongo-data/root@minikube:/data/mongo-data% lsWiredTiger WiredTiger.turtle WiredTigerHS.wt collection-0-4204941809035389281.wt collection-4-4204941809035389281.wt index-1-4204941809035389281.wt index-5-4204941809035389281.wt journal sizeStorer.wtWiredTiger.lock WiredTiger.wt _mdb_catalog.wt collection-2-4204941809035389281.wt diagnostic.data index-3-4204941809035389281.wt index-6-4204941809035389281.wt mongod.lock storage.bson 更高级的抽象 Storage Class (SC)将存储卷划分为不同的种类，例如：SSD，普通磁盘，本地磁盘，按需使用。文档 sc.yaml123456789apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: slowprovisioner: kubernetes.io/aws-ebsparameters: type: io1 iopsPerGB: &quot;10&quot; fsType: ext4 Persistent Volume (PV)描述卷的具体信息，例如磁盘大小，访问模式。文档，类型，Local 示例 pv.yaml1234567891011121314151617181920212223apiVersion: v1kind: PersistentVolumemetadata: name: mongodataspec: capacity: storage: 2Gi volumeMode: Filesystem # Filesystem（文件系统） Block（块） accessModes: - ReadWriteOnce # 卷可以被一个节点以读写方式挂载 persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /root/data nodeAffinity: required: # 通过 hostname 限定在某个节点创建存储卷 nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - node2 Persistent Volume Claim (PVC)对存储需求的一个申明，可以理解为一个申请单，系统根据这个申请单去找一个合适的 PV还可以根据 PVC 自动创建 PV。 pvc.yaml12345678910apiVersion: v1kind: PersistentVolumeClaimmetadata: name: mongodataspec: accessModes: [&quot;ReadWriteOnce&quot;] storageClassName: &quot;local-storage&quot; resources: requests: storage: 2Gi 为什么要这么多层抽象 更好的分工，运维人员负责提供好存储，开发人员不需要关注磁盘细节，只需要写一个申请单。 方便云服务商提供不同类型的，配置细节不需要开发者关注，只需要一个申请单。 动态创建，开发人员写好申请单后，供应商可以根据需求自动创建所需存储卷。 腾讯云示例 本地磁盘示例不支持动态创建，需要提前创建好 配置文件也可以分开写，也可以写在一起，用 ---隔开 mongo.yaml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485apiVersion: apps/v1kind: StatefulSetmetadata: name: mongodbspec: serviceName: mongodb replicas: 1 selector: matchLabels: app: mongodb template: metadata: labels: app: mongodb spec: containers: - name: mongo image: mongo:4.4 # IfNotPresent 仅本地没有镜像时才远程拉，Always 永远都是从远程拉，Never 永远只用本地镜像，本地没有则报错 imagePullPolicy: IfNotPresent volumeMounts: - mountPath: /data/db # 容器里面的挂载路径 name: mongo-data # 卷名字，必须跟下面定义的名字一致 volumes: - name: mongo-data persistentVolumeClaim: claimName: mongodata---apiVersion: v1kind: Servicemetadata: name: mongodbspec: clusterIP: None ports: - port: 27017 protocol: TCP targetPort: 27017 selector: app: mongodb type: ClusterIP---apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: local-storageprovisioner: kubernetes.io/no-provisionervolumeBindingMode: WaitForFirstConsumer---apiVersion: v1kind: PersistentVolumemetadata: name: mongodataspec: capacity: storage: 2Gi volumeMode: Filesystem # Filesystem（文件系统） Block（块） accessModes: - ReadWriteOnce # 卷可以被一个节点以读写方式挂载 persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /root/data nodeAffinity: required: # 通过 hostname 限定在某个节点创建存储卷 # 由于我使用的是 minikube 虚拟出来的节点，所以这里配置 minikube # 正常的话，应该配置某个节点，例如：node2 nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - minikube---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: mongodataspec: accessModes: [&quot;ReadWriteOnce&quot;] storageClassName: &quot;local-storage&quot; resources: requests: storage: 2Gi 部署 yaml ： 因为我们挂载目录到 /root/data ,所以先要提前创建好该目录 12345678910111213141516171819202122232425262728293031323334353637383940414243# 提前创建好挂载到的目录$ mkdir -p /root/data# 执行 yaml 文件$ kubectl apply -f mongo.yamlstatefulset.apps/mongodb createdservice/mongodb createdstorageclass.storage.k8s.io/local-storage createdpersistentvolume/mongodata createdpersistentvolumeclaim/mongodata created# 查看 pod$ kubectl get allNAME READY STATUS RESTARTS AGEpod/mongodb-0 1/1 Running 0 15sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 5d2hservice/mongodb ClusterIP None &lt;none&gt; 27017/TCP 15sNAME READY AGEstatefulset.apps/mongodb 1/1 16s# 查看 sc pv pvc$ kubectl get scNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGElocal-storage kubernetes.io/no-provisioner Delete WaitForFirstConsumer false 3m52sstandard (default) k8s.io/minikube-hostpath Delete Immediate false 5d2h$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEmongodata 2Gi RWO Delete Bound default/mongodata local-storage 3m55s$ kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEmongodata Bound mongodata 2Gi RWO local-storage 3m58s# 查看目录是否挂载成功，即:查看 目录 /root/data 中是否有文件$ docker exec -it minikube bashroot@minikube:/$ cd /root/dataroot@minikube:~/data$ lsWiredTiger WiredTiger.turtle WiredTigerHS.wt collection-0--1433628362673469070.wt collection-4--1433628362673469070.wt index-1--1433628362673469070.wt index-5--1433628362673469070.wt journal sizeStorer.wtWiredTiger.lock WiredTiger.wt _mdb_catalog.wt collection-2--1433628362673469070.wt diagnostic.data index-3--1433628362673469070.wt index-6--1433628362673469070.wt mongod.lock storage.bson","link":"/Kubernetes-%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/"},{"title":"Kubernetes-深入理解 StatefulSet","text":"背景无状态应用一个应用的所有 Pod，是完全一样的。它们互相之间没有顺序，也无所谓运行在哪台宿主机上。需要的时候，Deployment 就可以通过 Pod 模板创建新的 Pod；不需要的时候，Deployment 就可以“杀掉”任意一个 Pod。这种情况就被称为 “无状态应用”（Stateless Application） 有状态应用在分布式应用中，它的多个实例之间，往往有依赖关系，比如：主从关系、主备关系。 还有就是数据存储类应用，它的多个实例，往往都会在本地磁盘上保存一份数据。而这些实例一旦被杀掉，即便重建出来，实例与数据之间的对应关系也已经丢失，从而导致应用失败。 这种实例之间有不对等关系，以及实例对外部数据有依赖关系的应用，就被称为“有状态应用”（Stateful Application）。 编排工具StatefulSet简介容器技术诞生后，大家很快发现，它用来封装“无状态应用”（Stateless Application），尤其是 Web 服务，非常好用。但是，一旦你想要用容器运行“有状态应用”（Stateful Application），其困难程度就会直线上升。而且，这个问题解决起来，单纯依靠容器技术本身已经无能为力，这也就导致了很长一段时间内，“有状态应用”几乎成了容器技术圈子的“忌讳”，大家一听到这个词，就纷纷摇头。 得益于“控制器模式”的设计思想，Kubernetes 项目很早就在 Deployment 的基础上，扩展出了对“有状态应用”的初步支持。这个编排功能，就是：StatefulSet。StatefulSet 其实可以认为是对 Deployment 的改良。 StatefulSet 的设计其实非常容易理解。它把真实世界里的应用状态，抽象为了两种情况： 拓扑状态。应用的多个实例之间不是完全对等的关系。这些应用实例，必须按照某些顺序启动，比如应用的主节点 A 要先于从节点 B 启动。而如果你把 A 和 B 两个 Pod 删除掉，它们再次被创建出来时也必须严格按照这个顺序才行。并且，新创建出来的 Pod，必须和原来 Pod 的网络标识一样，这样原先的访问者才能使用同样的方法，访问到这个新 Pod。 存储状态。应用的多个实例分别绑定了不同的存储数据。对于这些应用实例来说，Pod A 第一次读取到的数据，和隔了十分钟之后再次读取到的数据，应该是同一份，哪怕在此期间 Pod A 被重新创建过。这种情况最典型的例子，就是一个数据库应用的多个存储实例。 StatefulSet 的核心功能，就是通过某种方式记录这些状态，然后在 Pod 被重新创建时，能够为新 Pod 恢复这些状态。 Headless Service介绍在开始掌握 StatefulSet 的工作原理之前，就必须先了解一个 Kubernetes 项目中非常实用的概念：Headless Service。 Service 是 Kubernetes 项目中用来将一组 Pod 暴露给外界访问的一种机制。比如，一个 Deployment 有 3 个 Pod，那么我就可以定义一个 Service。然后，用户只要能访问到这个 Service，它就能访问到某个具体的 Pod。 Service的访问方式Virtual IP(虚拟 IP)第一种方式，是以 Service 的 VIP（Virtual IP，即：虚拟 IP）方式。当访问 10.0.23.1 这个 Service 的 IP 地址时，10.0.23.1 其实就是一个 VIP，它会把请求转发到该 Service 所代理的某一个 Pod 上。 Service DNS第二种方式，就是以 Service 的 DNS 方式。只要访问“my-svc.my-namespace.svc.cluster.local”这条 DNS 记录，就可以访问到名叫 my-svc 的 Service 所代理的某一个 Pod。 在 Service DNS 的方式下，具体还可以分为两种处理方法： Normal Service在这种情况下，你访问“my-svc.my-namespace.svc.cluster.local”解析到的，正是 my-svc 这个 Service 的 VIP，后面的流程就跟 VIP 方式一致了。 Headless Service在这种情况下，你访问“my-svc.my-namespace.svc.cluster.local”解析到的，直接就是 my-svc 代理的某一个 Pod 的 IP 地址。可以看到，这里的区别在于，Headless Service 不需要分配一个 VIP，而是可以直接以 DNS 记录的方式解析出被代理 Pod 的 IP 地址。 Headless Service生成DNS记录从 Headless Service 的定义方式来分析一下。 下面是一个标准的 Headless Service 对应的 YAML 文件：svc.yaml 12345678910111213apiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web clusterIP: None selector: app: nginx 可以看到，所谓的 Headless Service，其实仍是一个标准 Service 的 YAML 文件。只不过，它的 clusterIP 字段的值是：None，即：这个 Service，没有一个 VIP 作为“头”。这也就是 Headless 的含义。所以，这个 Service 被创建后并不会被分配一个 VIP，而是会以 DNS 记录的方式暴露出它所代理的 Pod。 而它所代理的 Pod，依然是采用 Label Selector 机制选择出来的，即：所有携带了 app=nginx 标签的 Pod，都会被这个 Service 代理起来。 当你按照这样的方式创建了一个 Headless Service 之后，它所代理的所有 Pod 的 IP 地址，都会被绑定一个这样格式的 DNS 记录，如下所示： 1&lt;pod-name&gt;.&lt;svc-name&gt;.&lt;namespace&gt;.svc.cluster.local 这个 DNS 记录，正是 Kubernetes 项目为 Pod 分配的唯一的“可解析身份”（Resolvable Identity）。 有了这个“可解析身份”，只要你知道了一个 Pod 的名字，以及它对应的 Service 的名字，你就可以非常确定地通过这条 DNS 记录访问到 Pod 的 IP 地址。 StatefulSet维持 Pod 的拓扑状态StatefulSet 是使用这个 DNS 记录来维持 Pod 的拓扑状态的，具体流程如下： 先来编写一个 StatefulSet 的 YAML 文件，如下所示：statefulset.yaml 123456789101112131415161718192021apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: serviceName: &quot;nginx&quot; replicas: 2 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.9.1 ports: - containerPort: 80 name: web 这个 YAML 文件，和之前用到的 nginx-deployment 的唯一区别，就是多了一个 serviceName=nginx 字段。 这个字段的作用，就是告诉 StatefulSet 控制器，在执行控制循环（Control Loop）的时候，请使用 nginx 这个 Headless Service 来保证 Pod 的“可解析身份”。 所以，当通过 kubectl create 创建了上面这个 Service 和 StatefulSet 之后，就会看到如下两个对象： 123456789$ kubectl create -f svc.yaml$ kubectl get service nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEnginx ClusterIP None &lt;none&gt; 80/TCP 10s$ kubectl create -f statefulset.yaml$ kubectl get statefulset webNAME DESIRED CURRENT AGEweb 2 1 19s 可以通过 kubectl 的 -w 参数，即：Watch 功能，实时查看 StatefulSet 创建两个有状态实例的过程： 备注：如果手不够快的话，Pod 很快就创建完了。不过，依然可以通过这个 StatefulSet 的 Events 看到这些信息。 12345678910$ kubectl get pods -w -l app=nginxNAME READY STATUS RESTARTS AGEweb-0 0/1 Pending 0 0sweb-0 0/1 Pending 0 0sweb-0 0/1 ContainerCreating 0 0sweb-0 1/1 Running 0 19sweb-1 0/1 Pending 0 0sweb-1 0/1 Pending 0 0sweb-1 0/1 ContainerCreating 0 0sweb-1 1/1 Running 0 20s 通过上面这个 Pod 的创建过程，可以看到，StatefulSet 给它所管理的所有 Pod 的名字，进行了编号，编号规则是：StatefulSet的名字+—+index。 而且这些编号都是从 0 开始累加，与 StatefulSet 的每个 Pod 实例一一对应，绝不重复。 更重要的是，这些 Pod 的创建，也是严格按照编号顺序进行的。比如，在 web-0 进入到 Running 状态、并且细分状态（Conditions）成为 Ready 之前，web-1 会一直处于 Pending 状态。 备注：Ready 状态再一次提醒了我们，为 Pod 设置 livenessProbe 和 readinessProbe 的重要性。 当这两个 Pod 都进入了 Running 状态之后，就可以查看到它们各自唯一的“网络身份”了。 使用 kubectl exec 命令进入到容器中查看它们的 hostname： 1234$ kubectl exec web-0 -- sh -c 'hostname'web-0$ kubectl exec web-1 -- sh -c 'hostname'web-1 可以看到，这两个 Pod 的 hostname 与 Pod 名字是一致的，都被分配了对应的编号。接下来，我们再试着以 DNS 的方式，访问一下这个 Headless Service： 1$ kubectl run -i --tty --image busybox:1.28.4 dns-test --restart=Never --rm /bin/sh 通过这条命令，启动了一个一次性的 Pod，因为–rm 意味着 Pod 退出后就会被删除掉。然后，在这个 Pod 的容器里面，尝试用 nslookup 命令，解析一下 Pod 对应的 Headless Service： 1234567891011121314$ kubectl run -i --tty --image busybox:1.28.4 dns-test --restart=Never --rm /bin/sh$ nslookup web-0.nginxServer: 10.0.0.10Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.localName: web-0.nginxAddress 1: 10.244.1.7$ nslookup web-1.nginxServer: 10.0.0.10Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.localName: web-1.nginxAddress 1: 10.244.2.7 从 nslookup 命令的输出结果中，我们可以看到，在访问 web-0.nginx 的时候，最后解析到的，正是 web-0 这个 Pod 的 IP 地址；而当访问 web-1.nginx 的时候，解析到的则是 web-1 的 IP 地址。 这时候，如果在另外一个 Terminal 里把这两个“有状态应用”的 Pod 删掉： 123$ kubectl delete pod -l app=nginxpod &quot;web-0&quot; deletedpod &quot;web-1&quot; deleted 然后，再在当前 Terminal 里 Watch 一下这两个 Pod 的状态变化，就会发现一个有趣的现象： 12345678$ kubectl get pod -w -l app=nginxNAME READY STATUS RESTARTS AGEweb-0 0/1 ContainerCreating 0 0sNAME READY STATUS RESTARTS AGEweb-0 1/1 Running 0 2sweb-1 0/1 Pending 0 0sweb-1 0/1 ContainerCreating 0 0sweb-1 1/1 Running 0 32s 可以看到，当我们把这两个 Pod 删除之后，Kubernetes 会按照原先编号的顺序，创建出了两个新的 Pod。并且，Kubernetes 依然为它们分配了与原来相同的“网络身份”：web-0.nginx 和 web-1.nginx。 通过这种严格的对应规则，StatefulSet 就保证了 Pod 网络标识的稳定性。 比如，如果 web-0 是一个需要先启动的主节点，web-1 是一个后启动的从节点，那么只要这个 StatefulSet 不被删除，你访问 web-0.nginx 时始终都会落在主节点上，访问 web-1.nginx 时，则始终都会落在从节点上，这个关系绝对不会发生任何变化。 所以，如果我们再用 nslookup 命令，查看一下这个新 Pod 对应的 Headless Service 的话： 1234567891011121314$ kubectl run -i --tty --image busybox dns-test --restart=Never --rm /bin/sh $ nslookup web-0.nginxServer: 10.0.0.10Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.localName: web-0.nginxAddress 1: 10.244.1.8$ nslookup web-1.nginxServer: 10.0.0.10Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.localName: web-1.nginxAddress 1: 10.244.2.8 我们可以看到，在这个 StatefulSet 中，这两个新 Pod 的“网络标识”（比如：web-0.nginx 和 web-1.nginx），再次解析到了正确的 IP 地址（比如：web-0 Pod 的 IP 地址 10.244.1.8）。 通过这种方法，Kubernetes 就成功地将 Pod 的拓扑状态（比如：哪个节点先启动，哪个节点后启动），按照 Pod 的“名字 + 编号”的方式固定了下来。此外，Kubernetes 还为每一个 Pod 提供了一个固定并且唯一的访问入口，即：这个 Pod 对应的 DNS 记录。 这些状态，在 StatefulSet 的整个生命周期里都会保持不变，绝不会因为对应 Pod 的删除或者重新创建而失效。 不过，相信你也已经注意到了，尽管 web-0.nginx 这条记录本身不会变，但它解析到的 Pod 的 IP 地址，并不是固定的。这就意味着，对于“有状态应用”实例的访问，你必须使用 DNS 记录或者 hostname 的方式，而绝不应该直接访问这些 Pod 的 IP 地址。 StatefulSet维持 Pod 的存储状态Kubernetes 项目引入了一组叫作 Persistent Volume Claim（PVC）和 Persistent Volume（PV）的 API 对象，大大降低了用户声明和使用持久化 Volume 的门槛。 要使用一个 Volume，只需要简单的两步即可： 定义一个 PVC 这个 PVC 对象里，不需要任何关于 Volume 细节的字段，只有描述性的属性和定义 123456789101112kind: PersistentVolumeClaimapiVersion: v1metadata: name: pv-claimspec: accessModes: # 挂载方式是可读写,并且只能被挂载在一个节点上而非被多个节点共享 - ReadWriteOnce resources: requests: # Volume 大小至少是 1 GiB storage: 1Gi 在应用的 Pod 中，声明使用这个 PVC： 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: pv-podspec: containers: - name: pv-container image: nginx ports: - containerPort: 80 name: &quot;http-server&quot; volumeMounts: - mountPath: &quot;/usr/share/nginx/html&quot; name: pv-storage volumes: - name: pv-storage # 声明Volumes的类型是 persistentVolumeClaim persistentVolumeClaim: # 指定 PVC 的名字 claimName: pv-claim 只要创建这个 PVC 对象，Kubernetes 就会自动为它绑定一个符合条件的 PV（Persistent Volume）对象 常见的 PV 对象的 YAML 文件： 1234567891011121314151617181920212223kind: PersistentVolumeapiVersion: v1metadata: name: pv-volume labels: type: localspec: capacity: storage: 10Gi accessModes: - ReadWriteOnce rbd: monitors: # 使用 kubectl get pods -n rook-ceph 查看 rook-ceph-mon- 开头的 POD IP 即可得下面的列表 - '10.16.154.78:6789' - '10.16.154.82:6789' - '10.16.154.83:6789' pool: kube image: foo fsType: ext4 readOnly: true user: admin keyring: /etc/ceph/keyring Kubernetes 中 PVC 和 PV 的设计，实际上类似于“接口”和“实现”的思想。开发者只要知道并会使用“接口”，即：PVC；而运维人员则负责给“接口”绑定具体的实现，即：PV。 拓扑状态和存储状态联合使用123456789101112131415161718192021222324252627282930313233apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: serviceName: &quot;nginx&quot; replicas: 2 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.9.1 ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi 为这个 StatefulSet 额外添加了一个 volumeClaimTemplates 字段。从名字就可以看出来，它跟 Deployment 里 Pod 模板（PodTemplate）的作用类似。也就是说，凡是被这个 StatefulSet 管理的 Pod，都会声明一个对应的 PVC；而这个 PVC 的定义，就来自于 volumeClaimTemplates 这个模板字段。更重要的是，这个 PVC 的名字，会被分配一个与这个 Pod 完全一致的编号。 这个自动创建的 PVC，与 PV 绑定成功后，就会进入 Bound 状态，这就意味着这个 Pod 可以挂载并使用这个 PV 了。 如果还是不太理解 PVC 的话，可以先记住这样一个结论：PVC 其实就是一种特殊的 Volume。只不过一个 PVC 具体是什么类型的 Volume，要在跟某个 PV 绑定之后才知道。 当然，PVC 与 PV 的绑定得以实现的前提是，运维人员已经在系统里创建好了符合条件的 PV（比如，我们在前面用到的 pv-volume）；或者，你的 Kubernetes 集群运行在公有云上，这样 Kubernetes 就会通过 Dynamic Provisioning 的方式，自动为你创建与 PVC 匹配的 PV。 所以，在使用 kubectl create 创建了 StatefulSet 之后，就会看到 Kubernetes 集群里出现了两个 PVC： 12345$ kubectl create -f statefulset.yaml$ kubectl get pvc -l app=nginxNAME STATUS VOLUME CAPACITY ACCESSMODES AGEwww-web-0 Bound pvc-15c268c7-b507-11e6-932f-42010a800002 1Gi RWO 48swww-web-1 Bound pvc-15c79307-b507-11e6-932f-42010a800002 1Gi RWO 48s 可以看到，这些 PVC，都以“&lt;PVC 名字 &gt;-&lt;StatefulSet 名字 &gt;-&lt; 编号 &gt;”的方式命名，并且处于 Bound 状态。 这个 StatefulSet 创建出来的所有 Pod，都会声明使用编号的 PVC。比如，在名叫 web-0 的 Pod 的 volumes 字段，它会声明使用名叫 www-web-0 的 PVC，从而挂载到这个 PVC 所绑定的 PV。 所以，就可以使用如下所示的指令，在 Pod 的 Volume 目录里写入一个文件，来验证一下上述 Volume 的分配情况： 1$ for i in 0 1; do kubectl exec web-$i -- sh -c 'echo hello $(hostname) &gt; /usr/share/nginx/html/index.html'; done 如上所示，通过 kubectl exec 指令，在每个 Pod 的 Volume 目录里，写入了一个 index.html 文件。这个文件的内容，正是 Pod 的 hostname。比如，在 web-0 的 index.html 里写入的内容就是”hello web-0”。 此时，如果你在这个 Pod 容器里访问“http://localhost”，你实际访问到的就是 Pod 里 Nginx 服务器进程，而它会为你返回 /usr/share/nginx/html/index.html 里的内容。这个操作的执行方法如下所示： 123$ for i in 0 1; do kubectl exec -it web-$i -- curl localhost; donehello web-0hello web-1 如果你使用 kubectl delete 命令删除这两个 Pod，这些 Volume 里的文件也不会丢失。也就是说，原先与名叫 web-0 的 Pod 绑定的 PV，在这个 Pod 被重新创建之后，依然同新的名叫 web-0 的 Pod 绑定在了一起。对于 Pod web-1 来说，也是完全一样的情况。 保持存储状态的原理： 首先，当你把一个 Pod，比如 web-0，删除之后，这个 Pod 对应的 PVC 和 PV，并不会被删除，而这个 Volume 里已经写入的数据，也依然会保存在远程存储服务里（比如，我们在这个例子里用到的 Ceph 服务器）。 此时，StatefulSet 控制器发现，一个名叫 web-0 的 Pod 消失了。所以，控制器就会重新创建一个新的、名字还是叫作 web-0 的 Pod 来，“纠正”这个不一致的情况。 需要注意的是，在这个新的 Pod 对象的定义里，它声明使用的 PVC 的名字，还是叫作：www-web-0。这个 PVC 的定义，还是来自于 PVC 模板（volumeClaimTemplates），这是 StatefulSet 创建 Pod 的标准流程。 所以，在这个新的 web-0 Pod 被创建出来之后，Kubernetes 为它查找名叫 www-web-0 的 PVC 时，就会直接找到旧 Pod 遗留下来的同名的 PVC，进而找到跟这个 PVC 绑定在一起的 PV。 这样，新的 Pod 就可以挂载到旧 Pod 对应的那个 Volume，并且获取到保存在 Volume 里的数据。 StatefulSet 的工作原理首先，StatefulSet 的控制器直接管理的是 Pod。这是因为，StatefulSet 里的不同 Pod 实例，不再像 ReplicaSet 中那样都是完全一样的，而是有了细微区别的。比如，每个 Pod 的 hostname、名字等都是不同的、携带了编号的。而 StatefulSet 区分这些实例的方式，就是通过在 Pod 的名字里加上事先约定好的编号。 其次，Kubernetes 通过 Headless Service，为这些有编号的 Pod，在 DNS 服务器中生成带有同样编号的 DNS 记录。只要 StatefulSet 能够保证这些 Pod 名字里的编号不变，那么 Service 里类似于 web-0.nginx.default.svc.cluster.local 这样的 DNS 记录也就不会变，而这条记录解析出来的 Pod 的 IP 地址，则会随着后端 Pod 的删除和再创建而自动更新。这当然是 Service 机制本身的能力，不需要 StatefulSet 操心。 最后，StatefulSet 还为每一个 Pod 分配并创建一个同样编号的 PVC。这样，Kubernetes 就可以通过 Persistent Volume 机制为这个 PVC 绑定上对应的 PV，从而保证了每一个 Pod 都拥有一个独立的 Volume。 在这种情况下，即使 Pod 被删除，它所对应的 PVC 和 PV 依然会保留下来。所以当这个 Pod 被重新创建出来之后，Kubernetes 会为它找到同样编号的 PVC，挂载这个 PVC 对应的 Volume，从而获取到以前保存在 Volume 里的数据。","link":"/Kubernetes-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-StatefulSet/"},{"title":"Kubernetes-深入理解DaemonSet","text":"","link":"/Kubernetes-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3DaemonSet/"},{"title":"Kubernetes-深入理解Pod","text":"基本概念Pod，不是容器，是 Kubernetes 项目中的最小编排单位。将这个设计落实到 API 对象上，容器（Container）就成了 Pod 属性里的一个普通的字段。 Pod 扮演的是传统部署环境里“虚拟机”的角色。这样的设计，是为了使用户从传统环境（虚拟机环境）向 Kubernetes（容器环境）的迁移，更加平滑。 而如果你能把 Pod 看成传统环境里的“机器”、把容器看作是运行在这个“机器”里的“用户程序”，那么很多关于 Pod 对象的设计就非常容易理解了。 到底哪些属性属于 Pod 对象，而又有哪些属性属于 Container 呢？ 凡是调度、网络、存储，以及安全相关的属性，基本上是 Pod 级别的。 跟“机器”相关的属性-PodNodeSelector是一个供用户将 Pod 与 Node 进行绑定的字段，用法如下所示： 123456apiVersion: v1kind: Pod...spec: nodeSelector: disktype: ssd 这样的一个配置，意味着这个 Pod 永远只能运行在携带了“disktype: ssd”标签（Label）的节点上；否则，它将调度失败。 NodeName一旦 Pod 的这个字段被赋值，Kubernetes 项目就会被认为这个 Pod 已经经过了调度，调度的结果就是赋值的节点名字。所以，这个字段一般由调度器负责设置，但用户也可以设置它来“骗过”调度器，当然这个做法一般是在测试或者调试的时候才会用到。 HostAliases定义了 Pod 的 hosts 文件（比如 /etc/hosts）里的内容，用法如下： 12345678910apiVersion: v1kind: Pod...spec: hostAliases: - ip: &quot;10.1.2.3&quot; hostnames: - &quot;foo.remote&quot; - &quot;bar.remote&quot;... 在这个 Pod 的 YAML 文件中，设置了一组 IP 和 hostname 的数据。这样，这个 Pod 启动后，/etc/hosts 文件的内容将如下所示： 12345678$ cat /etc/hosts# Kubernetes-managed hosts file.127.0.0.1 localhost...10.244.135.10 hostaliases-pod10.1.2.3 foo.remote10.1.2.3 bar.remote 其中，最下面两行记录，就是我通过 HostAliases 字段为 Pod 设置的。需要指出的是，在 Kubernetes 项目中，如果要设置 hosts 文件里的内容，一定要通过这种方法。否则，如果直接修改了 hosts 文件的话，在 Pod 被删除重建之后，kubelet 会自动覆盖掉被修改的内容。 跟容器的Linux Namespace相关的属性-Pod除了上述跟“机器”相关的配置外，凡是跟容器的 Linux Namespace 相关的属性，也一定是 Pod 级别的。这个原因也很容易理解：Pod 的设计，就是要让它里面的容器尽可能多地共享 Linux Namespace，仅保留必要的隔离和限制能力。这样，Pod 模拟出的效果，就跟虚拟机里程序间的关系非常类似了。 shareProcessNamespace举个例子，在下面这个 Pod 的 YAML 文件中，定义了 shareProcessNamespace=true，这就意味着这个 Pod 里的容器要共享 PID Namespace。 12345678910111213apiVersion: v1kind: Podmetadata: name: nginxspec: shareProcessNamespace: true containers: - name: nginx image: nginx - name: shell image: busybox stdin: true tty: true 在这个 YAML 文件中，还定义了两个容器：一个是 nginx 容器，一个是开启了 tty 和 stdin 的 shell 容器。 在 Pod 的 YAML 文件里声明开启tty 和 stdin，其实等同于设置了 docker run 里的 -it（-i 即 stdin，-t 即 tty）参数 关于tty和stdin，可以直接认为 tty 就是 Linux 给用户提供的一个常驻小程序，用于接收用户的标准输入，返回操作系统的标准输出。当然，为了能够在 tty 中输入信息，你还需要同时开启 stdin（标准输入流）。 于是，这个 Pod 被创建后，你就可以使用 shell 容器的 tty 跟这个容器进行交互了 操作一下： 12$ kubectl create -f nginx.yamlpod/nginx created 使用 kubectl attach 命令，连接到 shell 容器的 tty 上： 12345678910$ kubectl attach -it nginx -c shellIf you don't see a command prompt, try pressing enter./ # ps axPID USER TIME COMMAND 1 root 0:00 /pause 7 root 0:00 nginx: master process nginx -g daemon off; 37 101 0:00 nginx: worker process 38 root 0:00 sh 46 root 0:00 ps ax/ # 可以看到，在这个容器里，我们不仅可以看到它本身的 ps ax 指令，还可以看到 nginx 容器的进程，以及 Infra 容器的 /pause 进程。这就意味着，整个 Pod 里的每个容器的进程，对于所有容器来说都是可见的：它们共享了同一个 PID Namespace。 Network、IPC 和 PID Namespace类似地，凡是 Pod 中的容器要共享宿主机的 Namespace，也一定是 Pod 级别的定义，比如： 123456789101112131415apiVersion: v1kind: Podmetadata: name: nginxspec: hostNetwork: true hostIPC: true hostPID: true containers: - name: nginx image: nginx - name: shell image: busybox stdin: true tty: true 在这个 Pod 中，定义了共享宿主机的 Network、IPC 和 PID Namespace。这就意味着，这个 Pod 里的所有容器，会直接使用宿主机的网络、直接与宿主机进行 IPC 通信、看到宿主机里正在运行的所有进程。 Pod对容器(Containers)的定义Init Containers与Containers这两个字段都属于 Pod 对容器的定义，内容也完全相同，只是 Init Containers 的生命周期，会先于所有的 Containers，并且严格按照定义的顺序执行。 docker相关的属性Kubernetes 项目中对 Container 的定义，和 Docker 相比并没有什么太大区别。包括 Image（镜像）、Command（启动命令）、workingDir（容器的工作目录）、Ports（容器要开发的端口），以及 volumeMounts（容器要挂载的 Volume）都是构成 Kubernetes 项目中 Container 的主要字段。 ImagePullPolicy它定义了镜像拉取的策略。而它之所以是一个 Container 级别的属性，是因为容器镜像本来就是 Container 定义中的一部分。它的值定义如下： Always：即每次创建 Pod 都重新拉取一次镜像。另外，当容器的镜像是类似于 nginx 或者 nginx:latest 这样的名字时，ImagePullPolicy 也会被认为 Always。 Never ： Pod 永远不会主动拉取这个镜像 IfNotPresent： 只在宿主机上不存在这个镜像时才拉取。 Lifecycle它定义的是 Container Lifecycle Hooks。顾名思义，Container Lifecycle Hooks 的作用，是在容器状态发生变化时触发一系列“钩子”。看这样一个例子： 123456789101112131415apiVersion: v1kind: Podmetadata: name: lifecycle-demospec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the postStart handler &gt; /usr/share/message&quot;] preStop: exec: command: [&quot;/usr/sbin/nginx&quot;,&quot;-s&quot;,&quot;quit&quot;] 这是一个来自 Kubernetes 官方文档的 Pod 的 YAML 文件。它其实非常简单，只是定义了一个 nginx 镜像的容器。不过，在这个 YAML 文件的容器（Containers）部分，你会看到这个容器分别设置了一个 postStart 和 preStop 参数。 postStart：它指的是，在容器启动后，立刻执行一个指定的操作。需要明确的是，postStart 定义的操作，虽然是在 Docker 容器 ENTRYPOINT 执行之后，但它并不严格保证顺序。也就是说，在 postStart 启动时，ENTRYPOINT 有可能还没有结束。如果 postStart 执行超时或者错误，Kubernetes 会在该 Pod 的 Events 中报出该容器启动失败的错误信息，导致 Pod 也处于失败的状态。 preStop：指的是容器被杀死之前（比如，收到了 SIGKILL 信号），执行一个指定的操作。而需要明确的是，preStop 操作的执行，是同步的。所以，它会阻塞当前的容器杀死流程，直到这个 Hook 定义操作完成之后，才允许容器被杀死，这跟 postStart 不一样。 在这个例子中，在容器成功启动之后，在 /usr/share/message 里写入了一句“欢迎信息”（即 postStart 定义的操作）。而在这个容器被删除之前，则先调用了 nginx 的退出指令（即 preStop 定义的操作），从而实现了容器的“优雅退出”。 Pod对象在Kubernetes中的生命周期Pod 生命周期的变化，主要体现在 Pod API 对象的 Status 部分，这是它除了 Metadata 和 Spec 之外的第三个重要字段。其中，pod.status.phase，就是 Pod 的当前状态，它有如下几种可能的情况： Pending。这个状态意味着，Pod 的 YAML 文件已经提交给了 Kubernetes，API 对象已经被创建并保存在 Etcd 当中。但是，这个 Pod 里有些容器因为某种原因而不能被顺利创建。比如，调度不成功。 Running。这个状态下，Pod 已经调度成功，跟一个具体的节点绑定。它包含的容器都已经创建成功，并且至少有一个正在运行中。 Succeeded。这个状态意味着，Pod 里的所有容器都正常运行完毕，并且已经退出了。这种情况在运行一次性任务时最为常见。 Failed。这个状态下，Pod 里至少有一个容器以不正常的状态（非 0 的返回码）退出。这个状态的出现，意味着你得想办法 Debug 这个容器的应用，比如查看 Pod 的 Events 和日志。 Unknown。这是一个异常状态，意味着 Pod 的状态不能持续地被 kubelet 汇报给 kube-apiserver，这很有可能是主从节点（Master 和 Kubelet）间的通信出现了问题。 更进一步地，Pod 对象的 Status 字段，还可以再细分出一组 Conditions。这些细分状态的值包括：PodScheduled、Ready、Initialized，以及 Unschedulable。它们主要用于描述造成当前 Status 的具体原因是什么。 比如，Pod 当前的 Status 是 Pending，对应的 Condition 是 Unschedulable，这就意味着它的调度出现了问题。 而其中，Ready 这个细分状态非常值得关注：它意味着 Pod 不仅已经正常启动（Running 状态），而且已经可以对外提供服务了。这两者之间（Running 和 Ready）是有区别的。 Pod 的这些状态信息，是我们判断应用运行情况的重要标准，尤其是 Pod 进入了非“Running”状态后，你一定要能迅速做出反应，根据它所代表的异常情况开始跟踪和定位，而不是去手忙脚乱地查阅文档。 Pod的使用Projected Volume(投射数据卷) 备注：Projected Volume 是 Kubernetes v1.11 之后的新特性 在 Kubernetes 中，有几种特殊的 Volume，它们存在的意义不是为了存放容器里的数据，也不是用来进行容器和宿主机之间的数据交换。这些特殊 Volume 的作用，是为容器提供预先定义好的数据。 所以，从容器的角度来看，这些 Volume 里的信息就是仿佛是被 Kubernetes“投射”（Project）进入容器当中的。这正是 Projected Volume 的含义。 到目前为止，Kubernetes 支持的 Projected Volume 一共有四种： Secret ConfigMap Downward API ServiceAccountToken(特殊的Secret) Secret它的作用，是帮你把 Pod 想要访问的加密数据，存放到 Etcd 中。然后，你就可以通过在 Pod 的容器里挂载 Volume 的方式，访问到这些 Secret 里保存的信息了。 Secret 最典型的使用场景，莫过于存放数据库的 Credential 信息，比如下面这个例子： 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: test-projected-volume spec: containers: - name: test-secret-volume image: busybox args: - sleep - &quot;86400&quot; volumeMounts: - name: mysql-cred mountPath: &quot;/projected-volume&quot; readOnly: true volumes: - name: mysql-cred projected: sources: - secret: name: user - secret: name: pass 在这个 Pod 中，定义了一个简单的容器。它声明挂载的 Volume，并不是常见的 emptyDir 或者 hostPath 类型，而是 projected 类型。而这个 Volume 的数据来源（sources），则是名为 user 和 pass 的 Secret 对象，分别对应的是数据库的用户名和密码。 这里用到的数据库的用户名、密码，正是以 Secret 对象的方式交给 Kubernetes 保存的。完成这个操作的指令，如下所示： 创建 Secret 对象(两种方式) 使用 kubectl create secret 指令的方式创建 123456789$ cat username.txtbuubiu$ cat password.txtAa1234!$ kubectl create secret generic user --from-file=username.txtsecret/user created$ kubectl create secret generic pass --from-file=password.txtsecret/pass created 其中，username.txt 和 password.txt 文件里，存放的就是用户名和密码；而 user 和 pass，则是为 Secret 对象指定的名字。 查看Secret对象： 命令：kubectl get secrets 1234$ kubectl get secretsNAME TYPE DATA AGEpass Opaque 1 42suser Opaque 1 54s 编写 YAML 文件的方式创建 Secret 对象要求这些数据必须是经过 Base64 转码的，以免出现明文密码的安全隐患，索引提前给user和pass进行base64转码： 1234$ echo -n 'buubiu' | base64YnV1Yml1$ echo -n 'Aa1234!' | base64QWExMjM0IQ== 创建YAML文件： 12345678apiVersion: v1kind: Secretmetadata: name: mysecrettype: Opaquedata: user: YnV1Yml1 pass: QWExMjM0IQ== 执行YAML文件： 1$ kubectl create -f mysecret.yaml 查看Secret对象： 命令：kubectl get secrets 123$ kubectl get secretsNAME TYPE DATA AGEmysecret Opaque 2 19s 可以看到，通过编写 YAML 文件创建出来的 Secret 对象只有一个。但它的 data 字段，却以 Key-Value 的格式保存了两份 Secret 数据。其中，“user”就是第一份数据的 Key，“pass”是第二份数据的 Key。 这里需要注意的是，像这样创建的 Secret 对象，它里面的内容仅仅是经过了转码，而并没有被加密。在真正的生产环境中，需要在 Kubernetes 中开启 Secret 的加密插件，增强数据的安全性。 创建这个Pod1$ kubectl create -f test-projected-volume.yaml 注意：如果是第二种方式创建的secret，那么pod的yaml需要修改一下： 1234567...volumes: - name: mysql-cred projected: sources: - secret: name: mysecret 当 Pod 变成 Running 状态之后，我们再验证一下这些 Secret 对象是不是已经在容器里了： 123456789101112131415161718192021$ kubectl get podsNAME READY STATUS RESTARTS AGEtest-projected-volume 1/1 Running 0 61s# 以第一种方式创建的时候$ kubectl exec -it test-projected-volume -- /bin/sh/ $ ls /projected-volume/password.txt username.txt/ $ cat /projected-volume/username.txtbuubiu/ $ cat /projected-volume/password.txtAa1234!# 以第二种方式创建的时候$ kubectl exec -it test-projected-volume -- /bin/sh/ $ ls /projected-volume/pass user/ $ cat /projected-volume/userbuubiu/ $ cat /projected-volume/passAa1234! 删除Sceret123$ kubectl delete secret -f mysecret.yaml# 或者$ kubectl delete secret [user/pass] ConfigMap它与 Secret 的区别在于，ConfigMap 保存的是不需要加密的、应用所需的配置信息。而 ConfigMap 的用法几乎与 Secret 完全相同：你可以使用 kubectl create configmap 从文件或者目录创建 ConfigMap，也可以直接编写 ConfigMap 对象的 YAML 文件。 比如，一个 Java 应用所需的配置文件（.properties 文件），就可以通过下面这样的方式保存在 ConfigMap 里： 1234567891011121314151617181920212223# .properties文件的内容$ cat example/ui.propertiescolor.good=purplecolor.bad=yellowallow.textmode=truehow.nice.to.look=fairlyNice# 从.properties文件创建ConfigMap$ kubectl create configmap ui-config --from-file=example/ui.properties# 查看这个ConfigMap里保存的信息(data)$ kubectl get configmaps ui-config -o yamlapiVersion: v1data: ui.properties: | color.good=purple color.bad=yellow allow.textmode=true how.nice.to.look=fairlyNicekind: ConfigMapmetadata: name: ui-config ... 备注：kubectl get -o yaml 这样的参数，会将指定的 Pod API 对象以 YAML 的方式展示出来。 Downward API它的作用是：让 Pod 里的容器能够直接获取到这个 Pod API 对象本身的信息。 举个例子： 12345678910111213141516171819202122232425262728293031323334353637apiVersion: v1kind: Podmetadata: name: test-downwardapi-volume labels: zone: us-est-coast cluster: test-cluster1 rack: rack-22spec: containers: - name: client-container image: k8s.gcr.io/busybox command: [&quot;sh&quot;, &quot;-c&quot;] args: - while true; do if [[ -e /etc/podinfo/labels ]]; then echo -en '\\n\\n'; cat /etc/podinfo/labels; fi; sleep 5; done; volumeMounts: - name: podinfo mountPath: /etc/podinfo readOnly: false volumes: - name: podinfo projected: sources: - downwardAPI: items: - path: &quot;labels&quot; fieldRef: fieldPath: metadata.labels - path: &quot;cpu_limit&quot; resourceFieldRef: containerName: client-container resource: limits.cpu divisor: 1m 在这个 Pod 的 YAML 文件中，我定义了一个简单的容器，声明了一个 projected 类型的 Volume。只不过这次 Volume 的数据来源，变成了 Downward API。而这个 Downward API Volume，则声明了要暴露 Pod 的 metadata.labels 信息给容器。 通过这样的声明方式，当前 Pod 的 Labels 字段的值，就会被 Kubernetes 自动挂载成为容器里的 /etc/podinfo/labels 文件。 而这个容器的启动命令，则是不断打印出 /etc/podinfo/labels 里的内容。所以，当我创建了这个 Pod 之后，就可以通过 kubectl logs 指令，查看到这些 Labels 字段被打印出来，如下所示： 12345$ kubectl create -f dapi-volume.yaml$ kubectl logs test-downwardapi-volumecluster=&quot;test-cluster1&quot;rack=&quot;rack-22&quot;zone=&quot;us-est-coast&quot; 目前，Downward API 支持的字段如下： 使用fieldRef可以声明使用: 字段 备注 spec.nodeName 宿主机名字 status.hostIP 宿主机IP metadata.name Pod的名字 metadata.namespace Pod的Namespace status.podIP Pod的IP spec.serviceAccountName Pod的Service Account的名字 metadata.uid Pod的UID metadata.labels[‘&lt;KEY&gt;‘] 指定&lt;KEY&gt;的Label值 metadata.annotations[‘&lt;KEY&gt;‘] 指定&lt;KEY&gt;的Annotation值 metadata.labels Pod的所有Label metadata.annotations Pod的所有Annotation 使用resourceFieldRef可以声明使用: 字段 备注 limits.cpu 容器的CPU requests.cpu 容器的CPU limits.memory 容器的memory requests.memory 容器的memory 需要注意的是，Downward API 能够获取到的信息，一定是 Pod 里的容器进程启动之前就能够确定下来的信息。而如果你想要获取 Pod 容器运行后才会出现的信息，比如，容器进程的 PID，那就肯定不能使用 Downward API 了，而应该考虑在 Pod 里定义一个 sidecar 容器。 其实，Secret、ConfigMap，以及 Downward API 这三种 Projected Volume 定义的信息，大多还可以通过环境变量的方式出现在容器里。但是，通过环境变量获取这些信息的方式，不具备自动更新的能力。所以，一般情况下，我都建议你使用 Volume 文件的方式获取这些信息。 ServiceAccountTokenService Account 对象的作用，就是 Kubernetes 系统内置的一种“服务账户”，它是 Kubernetes 进行权限分配的对象。比如，Service Account A，可以只被允许对 Kubernetes API 进行 GET 操作，而 Service Account B，则可以有 Kubernetes API 的所有操作权限。 像这样的 Service Account 的授权信息和文件，实际上保存在它所绑定的一个特殊的 Secret 对象里的。这个特殊的 Secret 对象，就叫作 ServiceAccountToken。任何运行在 Kubernetes 集群上的应用，都必须使用这个 ServiceAccountToken 里保存的授权信息，也就是 Token，才可以合法地访问 API Server。 所以说，Kubernetes 项目的 Projected Volume 其实只有三种，因为第四种 ServiceAccountToken，只是一种特殊的 Secret 而已。 另外，为了方便使用，Kubernetes 已经为你提供了一个默认“服务账户”（default Service Account）。并且，任何一个运行在 Kubernetes 里的 Pod，都可以直接使用这个默认的 Service Account，而无需显示地声明挂载它。 实现原理通过Projected Volume 机制实现的。 查看一下任意一个运行在 Kubernetes 集群里的 Pod，就会发现，每一个 Pod，都已经自动声明一个类型是 Secret、名为 default-token-xxxx 的 Volume，然后 自动挂载在每个容器的一个固定目录上。比如： 12345678910111213$ kubectl describe pod test-projected-volumeContainers:... Mounts: /projected-volume from mysql-cred (ro) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-l4gjj (ro)Volumes: kube-api-access-l4gjj: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: &lt;nil&gt; DownwardAPI: true 这个 Secret 类型的 Volume，正是默认 Service Account 对应的 ServiceAccountToken。所以说，Kubernetes 其实在每个 Pod 创建的时候，自动在它的 spec.volumes 部分添加上了默认 ServiceAccountToken 的定义，然后自动给每个容器加上了对应的 volumeMounts 字段。这个过程对于用户来说是完全透明的。 这样，一旦 Pod 创建完成，容器里的应用就可以直接从这个默认 ServiceAccountToken 的挂载目录里访问到授权信息和文件。这个容器内的路径在 Kubernetes 里是固定的，即：/var/run/secrets/kubernetes.io/serviceaccount ，而这个 Secret 类型的 Volume 里面的内容如下所示： 12$ ls /var/run/secrets/kubernetes.io/serviceaccount ca.crt namespace token 所以，应用程序只要直接加载这些授权文件，就可以访问并操作 Kubernetes API 了。而且，如果使用的是 Kubernetes 官方的 Client 包（k8s.io/client-go）的话，它还可以自动加载这个目录下的文件，不需要做任何配置或者编码操作。 这种把 Kubernetes 客户端以容器的方式运行在集群里，然后使用 default Service Account 自动授权的方式，被称作“InClusterConfig”，也是最推荐的进行 Kubernetes API 编程的授权方式。 当然，考虑到自动挂载默认 ServiceAccountToken 的潜在风险，Kubernetes 允许设置默认不为 Pod 里的容器自动挂载这个 Volume。 除了这个默认的 Service Account 外，我们很多时候还需要创建一些我们自己定义的 Service Account，来对应不同的权限设置。这样，我们的 Pod 里的容器就可以通过挂载这些 Service Account 对应的 ServiceAccountToken，来使用这些自定义的授权信息。 容器健康检查和恢复机制健康检查livenessProbe在 Kubernetes 中，可以为 Pod 里的容器定义一个健康检查“探针”（Probe）。这样，kubelet 就会根据这个 Probe 的返回值决定这个容器的状态，而不是直接以容器镜像是否运行（来自 Docker 返回的信息）作为依据。这种机制，是生产环境中保证应用健康存活的重要手段。 看一个 Kubernetes 文档中的例子： 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: labels: test: liveness name: test-liveness-execspec: containers: - name: liveness image: busybox args: - /bin/sh - -c - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600 livenessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 5 periodSeconds: 5 在这个 Pod 中，定义了一个有趣的容器。它在启动之后做的第一件事，就是在 /tmp 目录下创建了一个 healthy 文件，以此作为自己已经正常运行的标志。而 30 s 过后，它会把这个文件删除掉。 与此同时，定义了一个这样的 livenessProbe（健康检查）。它的类型是 exec，这意味着，它会在容器启动后，在容器里面执行一条我们指定的命令，比如：“cat /tmp/healthy”。这时，如果这个文件存在，这条命令的返回值就是 0，Pod 就会认为这个容器不仅已经启动，而且是健康的。这个健康检查，在容器启动 5 s 后开始执行（initialDelaySeconds: 5），每 5 s 执行一次（periodSeconds: 5）。 现在，来具体实践一下这个过程。 首先，创建这个 Pod： 12$ kubectl create -f test-liveness-exec.yamlpod/test-liveness-exec created 然后，查看这个 Pod 的状态： 123$ kubectl get podNAME READY STATUS RESTARTS AGEtest-liveness-exec 1/1 Running 0 10s 可以看到，由于已经通过了健康检查，这个 Pod 就进入了 Running 状态。 而 30 s 之后，我们再查看一下 Pod 的 Events，会发现，这个 Pod 在 Events 报告了一个异常： 12345678$ kubectl describe pod test-liveness-execEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 117s default-scheduler Successfully assigned default/test-liveness-exec to node2 Normal Pulled 101s kubelet Successfully pulled image &quot;busybox&quot; in 15.3033542s Warning Unhealthy 57s (x3 over 67s) kubelet Liveness probe failed: cat: can't open '/tmp/healthy': No such file or directory Normal Killing 57s kubelet Container liveness failed liveness probe, will be restarted 显然，这个健康检查探查到 /tmp/healthy 已经不存在了，所以它报告容器是不健康的。 那么接下来会发生什么呢？不妨再次查看一下这个 Pod 的状态： 123$ kubectl get pod test-liveness-execNAME READY STATUS RESTARTS AGEliveness-exec 1/1 Running 1 1m 这时我们发现，Pod 并没有进入 Failed 状态，而是保持了 Running 状态。这是为什么呢？ 其实，如果你注意到 RESTARTS 字段从 0 到 1 的变化，就明白原因了：这个异常的容器已经被 Kubernetes 重启了。在这个过程中，Pod 保持 Running 状态不变。 除了在容器中执行命令外，livenessProbe 也可以定义为发起 HTTP 或者 TCP 请求的方式，定义格式如下： 12345678910...livenessProbe: httpGet: path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 3 periodSeconds: 3 123456...livenessProbe: tcpSocket: port: 8080 initialDelaySeconds: 15 periodSeconds: 20 所以， Pod 其实可以暴露一个健康检查 URL（比如 /healthz），或者直接让健康检查去检测应用的监听端口。这两种配置方法，在 Web 服务类的应用中非常常用。 readinessProbe在 Kubernetes 的 Pod 中，还有一个叫 readinessProbe 的字段。虽然它的用法与 livenessProbe 类似，但作用却大不一样。readinessProbe 检查结果的成功与否，决定的这个 Pod 是不是能被通过 Service 的方式访问到，而并不影响 Pod 的生命周期。这部分内容，在后面在重点介绍。 恢复机制(restartPolicy)需要注意的是：Kubernetes 中并没有 Docker 的 Stop 语义。所以虽然是 Restart（重启），但实际却是重新创建了容器。 这个功能就是 Kubernetes 里的 Pod 恢复机制，也叫 restartPolicy。它是 Pod 的 Spec 部分的一个标准字段（pod.spec.restartPolicy），默认值是 Always，即：任何时候这个容器发生了异常，它一定会被重新创建。 但一定要强调的是，Pod 的恢复过程，永远都是发生在当前节点上，而不会跑到别的节点上去。事实上，一旦一个 Pod 与一个节点（Node）绑定，除非这个绑定发生了变化（pod.spec.node 字段被修改），否则它永远都不会离开这个节点。这也就意味着，如果这个宿主机宕机了，这个 Pod 也不会主动迁移到其他节点上去。 而如果你想让 Pod 出现在其他的可用节点上，就必须使用 Deployment 这样的“控制器”来管理 Pod，哪怕你只需要一个 Pod 副本 除了 Always，restartPolicy还有 OnFailure 和 Never 两种情况： Always：默认；即在任何情况下，只要容器不在运行状态，就自动重启容器； OnFailure: 只在容器 异常时才自动重启容器； Never: 从来不重启容器。 在实际使用时，我们需要根据应用运行的特性，合理设置这三种恢复策略。 比如，一个 Pod，它只计算 1+1=2，计算完成输出结果后退出，变成 Succeeded 状态。这时，你如果再用 restartPolicy=Always 强制重启这个 Pod 的容器，就没有任何意义了。 而如果你要关心这个容器退出后的上下文环境，比如容器退出后的日志、文件和目录，就需要将 restartPolicy 设置为 Never。因为一旦容器被自动重新创建，这些内容就有可能丢失掉了（被垃圾回收了）。 值得一提的是，Kubernetes 的官方文档，把 restartPolicy 和 Pod 里容器的状态，以及 Pod 状态的对应关系，总结了非常复杂的一大堆情况。实际上，你根本不需要死记硬背这些对应关系，只要记住如下两个基本的设计原理即可： 只要 Pod 的 restartPolicy 指定的策略允许重启异常的容器（比如：Always），那么这个 Pod 就会保持 Running 状态，并进行容器重启。否则，Pod 就会进入 Failed 状态 对于包含多个容器的 Pod，只有它里面所有的容器都进入异常状态后，Pod 才会进入 Failed 状态。在此之前，Pod 都是 Running 状态。此时，Pod 的 READY 字段会显示正常容器的个数，比如： 123$ kubectl get pod test-liveness-execNAME READY STATUS RESTARTS AGEliveness-exec 0/1 Running 1 1m 所以，假如一个 Pod 里只有一个容器，然后这个容器异常退出了。那么，只有当 restartPolicy=Never 时，这个 Pod 才会进入 Failed 状态。而其他情况下，由于 Kubernetes 都可以重启这个容器，所以 Pod 的状态保持 Running 不变。 而如果这个 Pod 有多个容器，仅有一个容器异常退出，它就始终保持 Running 状态，哪怕即使 restartPolicy=Never。只有当所有容器也异常退出之后，这个 Pod 才会进入 Failed 状态。 其他情况，都可以以此类推出来。 Pod预设置(PodPreset)Pod 的字段这么多，不可能全记住，所以，有个叫作 PodPreset（Pod 预设置）的功能 已经出现在了 v1.11 版本的 Kubernetes 中。 举个例子，现在开发人员编写了如下一个 pod.yaml 文件： 12345678910111213apiVersion: v1kind: Podmetadata: name: website labels: app: website role: frontendspec: containers: - name: website image: nginx ports: - containerPort: 80 这是最简单的 Pod，可是，这种 Pod 在生产环境里根本不能用！ 所以，这个时候，运维人员就可以定义一个 PodPreset 对象。在这个对象中，凡是他想在开发人员编写的 Pod 里追加的字段，都可以预先定义好。比如这个 preset.yaml： 1234567891011121314151617apiVersion: settings.k8s.io/v1alpha1kind: PodPresetmetadata: name: allow-databasespec: selector: matchLabels: role: frontend env: - name: DB_PORT value: &quot;6379&quot; volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: {} 在这个 PodPreset 的定义中，首先是一个 selector。这就意味着后面这些追加的定义，只会作用于 selector 所定义的、带有“role: frontend”标签的 Pod 对象，这就可以防止“误伤”。 然后，我们定义了一组 Pod 的 Spec 里的标准字段，以及对应的值。比如，env 里定义了 DB_PORT 这个环境变量，volumeMounts 定义了容器 Volume 的挂载目录，volumes 定义了一个 emptyDir 的 Volume。 接下来，我们假定运维人员先创建了这个 PodPreset，然后开发人员才创建 Pod： 12$ kubectl create -f preset.yaml$ kubectl create -f pod.yaml 这时，Pod 运行起来之后，我们查看一下这个 Pod 的 API 对象： 12345678910111213141516171819202122232425$ kubectl get pod website -o yamlapiVersion: v1kind: Podmetadata: name: website labels: app: website role: frontend annotations: podpreset.admission.kubernetes.io/podpreset-allow-database: &quot;resource version&quot;spec: containers: - name: website image: nginx volumeMounts: - mountPath: /cache name: cache-volume ports: - containerPort: 80 env: - name: DB_PORT value: &quot;6379&quot; volumes: - name: cache-volume emptyDir: {} 这个时候，我们就可以清楚地看到，这个 Pod 里多了新添加的 labels、env、volumes 和 volumeMount 的定义，它们的配置跟 PodPreset 的内容一样。此外，这个 Pod 还被自动加上了一个 annotation 表示这个 Pod 对象被 PodPreset 改动过。 需要说明的是，PodPreset 里定义的内容，只会在 Pod API 对象被创建之前追加在这个对象本身上，而不会影响任何 Pod 的控制器的定义。 比如，现在提交的是一个 nginx-deployment，那么这个 Deployment 对象本身是永远不会被 PodPreset 改变的，被修改的只是这个 Deployment 创建出来的所有 Pod。这一点请务必区分清楚。 如果你定义了同时作用于一个 Pod 对象的多个 PodPreset，Kubernetes 项目会帮你合并（Merge）这两个 PodPreset 要做的修改。而如果它们要做的修改有冲突的话，这些冲突字段就不会被修改。","link":"/Kubernetes-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Pod/"},{"title":"Kubernetes基本概念","text":"Kubernetes是Google团队发起并维护的基于Docker的开源容器集群管理系统，它不仅支持常见的云平台，而且支持内部数据中心。 建于 Docker 之上的 Kubernetes 可以构建一个容器的调度服务，其目的是让用户透过 Kubernetes 集群来进行云端容器集群的管理，而无需用户进行复杂的设置工作。系统会自动选取合适的工作节点来执行具体的容器集群调度处理工作。其核心概念是 Container Pod。一个 Pod 由一组工作于同一物理工作节点的容器构成。这些组容器拥有相同的网络命名空间、IP以及存储配额，也可以根据实际情况对每一个 Pod 进行端口映射。此外，Kubernetes 工作节点会由主系统进行管理，节点包含了能够运行 Docker 容器所用到的服务。 简介Kubernetes是Google团队发起的开源项目，它的目标是管理跨多个主机的容器，提供基本的部署，维护以及应用伸缩，主要实现语言为Go语言。Kubernetes是： 易学：轻量级，简单，容易理解 便携：支持公有云，私有云，混合云，以及各种云平台 可拓展：模块化，可插拔，支持钩子，可任意组合 自修复：自动重调度，自动重启，自动复制 Kubernetes构建于Google数十年经验，一大半来源于Google生产环境规模的经验。结合了社区最佳的想法和实践。 在分布式系统中，部署，调度，伸缩一直是最为重要的，也是最为基础的功能。Kubernetes就是洗完解决这一序列问题的。 Kubernetes目前在GitHub镜像维护。 基本概念 节点（Node）：一个节点是一个运行Kubernetes中的主机 容器组（Pod）：一个Pod对应于由若干容器组成的一个容器组，同个组内的容器共享一个存储卷(volume)。 容器组生命周期（pos-states）：包含所有容器状态集合，包括容器组状态类型，容器组生命周期，事件，重启策略，以及replication controllers。 Replication Controllers：主要负责指定数量的pod在同一时间一起运行。 服务（services）：一个Kubernetes服务是容器组逻辑的高级抽象，同时也对外提供访问容器组的策略。 卷（volumes）：一个卷就是一个目录，容器对其有访问权限。 标签（labels）：标签是用来连接一组对象的，比如容器组。标签可以被用来组织和选择子对象。 接口权限（accessing_the_api）：端口，IP地址和代理的防火墙规则。 web界面（ux）：用户可以通过web界面操作Kubernetes。 命令行操作（cli）：kubectl命令。 节点(node)在Kubernetes中，节点是实际工作的点，节点可以是虚拟机或者物理机器，依赖于一个集群环境。每个节点都有一个些必要的服务以运行容器组，并且它们都可以通过主节点来管理。必要服务包括Docker，kubelet和代理服务。 容器状态容器状态用来描述节点的当前状态。现在，其中包含三个信息： 主机IP主机IP需要云平台来查询，Kubernetes把它作为状态的一部分来保存。如果Kubernetes没有运行在云平台上，节点ID就是必需的。IP地址可以变化，并且可以包含多种类型的IP地址，如公共IP，私有IP，动态IP，ipv6等等。 节点周期通常来说节点有Pending(等待中)、Running(运行中)、Terminated(已终止)三个周期，如果Kubernetes发现了一个节点并且其可用，那么Kubernetes就把它标记为Pending。然后在某个时刻，Kubernetes将会标记其为Running。节点的结束周期成为Terminated。一个已经Terminated的节点不会接受和调度任何请求，并且已经在其上运行的容器组也会删除。 节点状态节点状态主要是用来描述处于Running的节点。当前可用的有NodeReachable和NodeReady。 以后可能会增加其他状态。NodeReachable表示集群可达。NodeReady表示kubelet返回Status Ok并且HTTP状态检查健康。 节点管理节点并非Kubernetes创建，而是由云平台创建，或者就是物理机器、虚拟机。在Kubernetes中，节点仅仅是一条记录，节点创建后，Kubernetes会检查其是否可用。在Kubernetes中，节点用如下结构保存： 1234567891011121314{ &quot;id&quot;: &quot;10.1.2.3&quot;, &quot;kind&quot;: &quot;Minion&quot;, &quot;apiVersion&quot;: &quot;v1beta1&quot;, &quot;resources&quot;: { &quot;capacity&quot;: { &quot;cpu&quot;: 1000, &quot;memory&quot;: 1073741824 }, }, &quot;labels&quot;: { &quot;name&quot;: &quot;my-first-k8s-node&quot;, },} Kubernetes校验节点可用依赖于 ID。在当前的版本中，有两个接口可以用来管理节点：节点控制和Kube管理。 节点控制在Kubernetes主节点中，节点控制器是用来管理节点的组件。主要包括： 集群范围内节点同步 单节点生命周期管理 节点控制有一个同步轮询，主要监听所有云平台的虚拟实例，会根据节点状态创建和删除。可以通过 --node_sync_period标志来控制该轮询。如果一个实例已经创建，节点控制将会为其创建一个结构。同样的，如果一个节点被删除，节点控制也会删除该结构。在 Kubernetes 启动时可用通过 --machines标记来显示指定节点。同样可以使用 kubectl 来一条一条的添加节点，两者是相同的。通过设置 --sync_nodes=false标记来禁止集群之间的节点同步，你也可以使用 api/kubectl 命令行来增删节点。 容器组（pod）在 Kubernetes 中，使用的最小单位是容器组，容器组是创建，调度，管理的最小单位。 一个容器组使用相同的 Docker 容器并共享卷（挂载点）。一个容器组是一个特定应用的打包集合，包含一个或多个容器。 和运行的容器类似，一个容器组被认为只有很短的运行周期。容器组被调度到一组节点运行，直到容器的生命周期结束或者其被删除。如果节点死掉，运行在其上的容器组将会被删除而不是重新调度。（也许在将来的版本中会添加容器组的移动）。 容器组设计的初衷假设 Kubernetes 中调度的基本单元就是容器，对于一个非常简单的应用可以直接被调度直接使用，没有什么问题，但是往往还有很多应用程序是由多个进程组成的，有的同学可能会说把这些进程都打包到一个容器中去不就可以了吗？理论上是可以实现的，但是不要忘记了 Docker 管理的进程是 pid=1 的主进程，其他进程死掉了就会成为僵尸进程，没办法进行管理了，这种方式本身也不是容器推荐的运行方式，一个容器最只干一件事情，所以在真实的环境中不会使用这种方式。 那么我们就把这个应用的进程进行拆分，拆分成一个一个的容器总可以了吧？但是不要忘记一个问题，拆分成一个一个的容器后，是不是就有可能出现一个应用下面的某个进程容器被调度到了不同的节点上呢？往往我们应用内部的进程与进程间通信（通过 IPC 或者共享本地文件之类）都是要求在本地进行的，也就是需要在同一个节点上运行。 所以我们需要一个更高级别的结构来将这些容器绑定在一起，并将他们作为一个基本的调度单元进行管理，这样就可以保证这些容器始终在同一个节点上面，这也就是容器组设计的初衷。 资源共享和通信容器组主要是为了数据共享和它们之间的通信。 在一个容器组中，容器都使用相同的网络地址和端口，可以通过本地网络来相互通信。每个容器组都有独立的 IP，可以通过网络来和其他物理主机或者容器通信。 容器组有一组存储卷（挂载点），主要是为了让容器在重启之后可以不丢失数据。 容器组管理容器组是一个应用管理和部署的高层次抽象，同时也是一组容器的接口。容器组是部署、水平收缩的最小单位。 容器组的使用容器组可以通过组合来构建复杂的应用，其本来的意义包含： 内容管理，文件和数据加载以及本地缓存管理等。 日志和检查点备份，压缩，快照等。 监听数据变化，跟踪日志，日志和监控代理，消息发布等。 代理，网桥 控制器，管理，配置以及更新 替代方案为什么不在一个单一的容器里运行多个程序？ 透明化。为了使容器组中的容器保持一致的基础设施和服务，比如进程管理和资源监控。这样设计是为了用户的便利性。 解偶软件之间的依赖。每个容器都可能重新构建和发布，Kubernetes 必须支持热发布和热更新（将来）。 方便使用。用户不必运行独立的程序管理，也不用担心每个应用程序的退出状态。 高效。考虑到基础设施有更多的职责，容器必须要轻量化。 容器组的生命状态包括若干状态值：pending、running、succeeded、failed。 pending容器组已经被节点接受，但有一个或多个容器还没有运行起来。这将包含某些节点正在下载镜像的时间，这种情形会依赖于网络情况。 running容器组已经被调度到节点，并且所有的容器都已经启动。至少有一个容器处于运行状态（或者处于重启状态） succeeded所有的容器都正常退出。 failed容器组中所有容器都意外中断了。 容器组的生命周期通常来说，如果容器组被创建了就不会自动销毁，除非被某种行为触发，而触发此种情况可能是人为，或者复制控制器所为。唯一例外的是容器组由 succeeded 状态成功退出，或者在一定时间内重试多次依然失败。 如果某个节点死掉或者不能连接，那么节点控制器将会标记其上的容器组的状态为 failed。 举例如下。 容器组状态 running，有 1 容器，容器正常退出 记录完成事件 如果重启策略为： 始终：重启容器，容器组保持 running 失败时：容器组变为 succeeded 从不：容器组变为 succeeded 容器组状态 running，有1容器，容器异常退出 记录失败事件 如果重启策略为： 始终：重启容器，容器组保持 running 失败时：重启容器，容器组保持 running 从不：容器组变为 failed 容器组状态 running，有2容器， 当有1容器异常退出 记录失败事件 如果重启策略为： 始终：重启容器，容器组保持 running 失败时：重启容器，容器组保持 running 从不：容器组保持 running 当有2容器退出 记录失败事件 如果重启策略为： 始终：重启容器，容器组保持 running 失败时：重启容器，容器组保持 running 从不：容器组变为 failed 容器组状态 running，容器内存不足 标记容器错误中断 记录内存不足事件 如果重启策略为： 始终：重启容器，容器组保持 running 失败时：重启容器，容器组保持 running 从不：记录错误事件，容器组变为 failed 容器组状态 running，一块磁盘死掉 杀死所有容器 记录事件 容器组变为 failed 如果容器组运行在一个控制器下，容器组将会在其他地方重新创建 容器组状态 running，对应的节点段溢出 节点控制器等到超时 节点控制器标记容器组 failed 如果容器组运行在一个控制器下，容器组将会在其他地方重新创建 Replication ControllersReplicationController确保在任何时候都有特定数量的容器组副本处于运行状态。 换句话说，ReplicationController 确保一个 容器组 或一组同类的 容器组 总是可用的。 ReplicationController 如何工作当 Pod 数量过多时，ReplicationController 会终止多余的 Pod。当 Pod 数量太少时，ReplicationController 将会启动新的 Pod。 与手动创建的 Pod 不同，由 ReplicationController 创建的 Pod 在失败、被删除或被终止时会被自动替换。 例如，在中断性维护（如内核升级）之后，你的 Pod 会在节点上重新创建。 因此，即使你的应用程序只需要一个 Pod，你也应该使用 ReplicationController 创建 Pod。 ReplicationController 类似于进程管理器，但是 ReplicationController 不是监控单个节点上的单个进程，而是监控跨多个节点的多个 Pod。 在讨论中，ReplicationController 通常缩写为 “rc”，并作为 kubectl 命令的快捷方式。 一个简单的示例是创建一个 ReplicationController 对象来可靠地无限期地运行 Pod 的一个实例。 更复杂的用例是运行一个多副本服务（如 web 服务器）的若干相同副本。 服务(service)将运行在一组 Pods上的应用程序公开为网络服务的抽象方法。 使用 Kubernetes，你无需修改应用程序即可使用不熟悉的服务发现机制。 Kubernetes 为 Pods 提供自己的 IP 地址，并为一组 Pod 提供相同的 DNS 名， 并且可以在它们之间进行负载均衡。 卷容器中的文件在磁盘上是临时存放的，这给容器中运行的较重要的应用 程序带来一些问题： 当容器崩溃时文件丢失。kubelet 会重新启动容器， 但容器会以干净的状态重启。 会在同一 Pod 中运行多个容器并共享文件时出现。 Kubernetes 卷（Volume） 这一抽象概念能够解决这两个问题。 标签标签（Labels）是附加到 Kubernetes 对象（比如 Pods）上的键值对。 标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接对核心系统有语义含义。 标签可以用于组织和选择对象的子集。标签可以在创建时附加到对象，随后可以随时添加和修改。 每个对象都可以定义一组键/值标签。每个键对于给定对象必须是唯一的。 123456&quot;metadata&quot;: { &quot;labels&quot;: { &quot;key1&quot; : &quot;value1&quot;, &quot;key2&quot; : &quot;value2&quot; }} 标签能够支持高效的查询和监听操作，对于用户界面和命令行是很理想的。 接口权限Pod 的安全性配置一般通过使用 安全性上下文（Security Context）来保证。安全性上下文允许用户逐个 Pod 地定义特权级及访问控制。 以前，对集群的安全性上下文的需求的实施及其基于策略的定义都通过使用 Pod 安全性策略来实现。 Pod 安全性策略（Pod Security Policy）是一种集群层面的资源，控制 Pod 规约中 安全性敏感的部分。 不过，新的策略实施方式不断涌现，或增强或替换 PodSecurityPolicy 的使用。 web界面Dashboard 是基于网页的 Kubernetes 用户界面。 你可以使用 Dashboard 将容器应用部署到 Kubernetes 集群中，也可以对容器应用排错，还能管理集群资源。 你可以使用 Dashboard 获取运行在集群中的应用的概览信息，也可以创建或者修改 Kubernetes 资源 （如 Deployment，Job，DaemonSet 等等）。 例如，你可以对 Deployment 实现弹性伸缩、发起滚动升级、重启 Pod 或者使用向导创建新的应用。 Dashboard 同时展示了 Kubernetes 集群中的资源状态信息和所有报错信息。 命令行操作可以使用 Kubectl 命令行工具管理 Kubernetes 集群。 kubectl 在 $HOME/.kube 目录中查找一个名为 config 的配置文件。 可以通过设置 KUBECONFIG 环境变量或设置 --kubeconfig 参数来指定其它 kubeconfig文件。 安装工具介绍KubeadmKubeadm 是一个提供了 kubeadm init 和 kubeadm join 的工具，作为创建 Kubernetes 集群的 “快捷途径” 的最佳实践。 kubeadm 通过执行必要的操作来启动和运行最小可用集群。按照设计，它只关注启动引导，而非配置机器。同样的，安装各种 “锦上添花” 的扩展，例如 Kubernetes Dashboard, 监控方案，以及特定云平台的扩展，都不在讨论范围内。 相反，我们希望在 kubeadm 之上构建更高级别以及更加合规的工具，理想情况下，使用 kubeadm 作为所有部署工作的基准将会更加易于创建一致性集群。 Kubectl使用 Kubectl 命令行工具管理 Kubernetes 集群。 从用户的角度来看，kubectl是控制Kubernetes的驾驶舱。它允许您执行所有可能的Kubernetes操作。 从技术角度来看，kubectl是Kubernetes API的客户端。 Kubernetes API是一个HTTP REST API。此API是真正的Kubernetes用户接口。通过API我们可以完全控制Kubernetes。这意味着每个Kubernetes操作都作为API端点公开，并且可以通过对此端点的HTTP请求来执行。 因此，kubectl的主要工作是对Kubernetes API执行HTTP请求。 KubeletKubelet 是 kubernetes 工作节点上的一个代理组件，运行在每个节点上。 Kubelet是工作节点上的主要服务，定期从kube-apiserver组件接收新的或修改的Pod规范，并确保Pod及其容器在期望规范下运行。同时该组件作为工作节点的监控组件，向kube-apiserver汇报主机的运行状况。 kubelet 是运行在每个节点上的主要的“节点代理”，每个节点都会启动 kubelet进程，用来处理 Master 节点下发到本节点的任务，按照 PodSpec 描述来管理Pod 和其中的容器（PodSpec 是用来描述一个 pod 的 YAML 或者 JSON 对象）。 kubelet 通过各种机制（主要通过 apiserver ）获取一组 PodSpec 并保证在这些 PodSpec 中描述的容器健康运行。","link":"/Kubernetes%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"},{"title":"Kubernetes的Dashboard部署","text":"Web 界面 (Dashboard)Kubernetes Dashboard 是基于网页的 Kubernetes 用户界面。 你可以使用 Dashboard 将容器应用部署到 Kubernetes 集群中，也可以对容器应用排错，还能管理集群资源。 你可以使用 Dashboard 获取运行在集群中的应用的概览信息，也可以创建或者修改 Kubernetes 资源 （如 Deployment，Job，DaemonSet 等等）。 例如，你可以对 Deployment 实现弹性伸缩、发起滚动升级、重启 Pod 或者使用向导创建新的应用。 Dashboard 同时展示了 Kubernetes 集群中的资源状态信息和所有报错信息。 部署 Dashboard UI 默认情况下不会部署 Dashboard。可以通过以下命令部署： 1$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml 或 1kubectl create -f kubernetes-dashboard.yaml 检查 kubernetes-dashboard 应用状态 1kubectl get pod -n kubernetes-dashboard 访问 Dashboard UI通过命令行代理访问，执行以下命令： 1$ kubectl proxy 通过如下 URL 访问 Kubernetes dashboard http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ 登录Dashboard UI访问令牌登录对于Mac环境 123TOKEN=$(kubectl -n kube-system describe secret default| awk '$1==&quot;token:&quot;{print $2}')kubectl config set-credentials docker-for-desktop --token=&quot;${TOKEN}&quot;echo $TOKEN 对于Windows环境 123$TOKEN=((kubectl -n kube-system describe secret default | Select-String &quot;token:&quot;) -split &quot; +&quot;)[1]kubectl config set-credentials docker-for-desktop --token=&quot;${TOKEN}&quot;echo $TOKEN 选择 令牌,输入上文控制台输出的内容，即可登录。 Kubeconfig登录路径如下： 12Mac: $HOME/.kube/configWin: %UserProfile%\\.kube\\config 点击登陆，进入Kubernetes Dashboard","link":"/Kubernetes%E7%9A%84Dashboard%E9%83%A8%E7%BD%B2/"},{"title":"Kubernetes的架构设计","text":"任何优秀的项目都离不开优秀的架构设计。下面介绍 Kubernetes 在架构方面的设计考虑。 基本考虑如果让我们自己从头设计一套容器管理平台，有如下几个方面是很容易想到的： 分布式架构，保证扩展性； 逻辑集中式的控制平面 + 物理分布式的运行平面； 一套资源调度系统，管理哪个容器该分配到哪个节点上； 一套对容器内服务进行抽象和 HA 的系统。 运行原理下面这张图完整展示了 Kubernetes 的运行原理。 可见，Kubernetes 首先是一套分布式系统，由多个节点组成，节点分为两类：一类是属于管理平面的主节点/控制节点（Master Node）；一类是属于运行平面的工作节点（Worker Node）。 显然，复杂的工作肯定都交给控制节点去做了，工作节点负责提供稳定的操作接口和能力抽象即可。 从这张图上，我们没有能发现 Kubernetes 中对于控制平面的分布式实现，但是由于数据后端自身就是一套分布式的数据库 Etcd，因此可以很容易扩展到分布式实现。 控制平面主节点服务主节点上需要提供如下的管理服务： apiserver 是整个系统的对外接口，提供一套 RESTful 的 Kubernetes API，供客户端和其它组件调用； scheduler 负责对资源进行调度，分配某个 pod 到某个节点上。是 pluggable 的，意味着很容易选择其它实现方式； controller-manager 负责管理控制器，包括 endpoint-controller（刷新服务和 pod 的关联信息）和 replication-controller（维护某个 pod 的复制为配置的数值）。 Etcd这里 Etcd 即作为数据后端，又作为消息中间件。 通过 Etcd 来存储所有的主节点上的状态信息，很容易实现主节点的分布式扩展。 组件可以自动的去侦测 Etcd 中的数值变化来获得通知，并且获得更新后的数据来执行相应的操作。 工作节点 kubelet 是工作节点执行操作的 agent，负责具体的容器生命周期管理，根据从数据库中获取的信息来管理容器，并上报 pod 运行状态等； kube-proxy 是一个简单的网络访问代理，同时也是一个 Load Balancer。它负责将访问到某个服务的请求具体分配给工作节点上的 Pod（同一类标签）。","link":"/Kubernetes%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"title":"Kubernetes的部署-Docker Desktop方式","text":"使用 Docker Desktop 可以很方便的启用 Kubernetes，由于国内获取不到 k8s.gcr.io 镜像，我们必须首先解决这一问题。 获取 k8s.gcr.io 镜像由于国内拉取不到 k8s.gcr.io 镜像，我们可以使用开源项目 AliyunContainerService/k8s-for-docker-desktop 来获取所需的镜像。 1git clone git@github.com:AliyunContainerService/k8s-for-docker-desktop.git 说明: 需安装 Docker Desktop 的 Mac 或者 Windows 版本，如果没有请下载下载 Docker CE最新版本 当前 master 分支已经在 Docker for Mac/Windows 3.1.0 (包含 Docker CE 20.10.3 和 Kubernetes 1.19.7) 版本测试通过 如果需要测试其他版本，请查看 Docker Desktop版本，Docker -&gt; About Docker Desktop 注：如果发现K8s版本与您的环境不一致，可以修改images.properties文件指明所需镜像版本，欢迎Pull Request。 开启 Kubernetes为 Docker daemon 配置镜像加速，参考阿里云镜像服务 或中科大镜像加速地址https://docker.mirrors.ustc.edu.cn 可选操作: 为 Kubernetes 配置 CPU 和 内存资源，建议分配 4GB 或更多内存。 从阿里云镜像服务下载 Kubernetes 所需要的镜像 在 Mac 上执行如下脚本 1./load_images.sh 在Windows上，使用 PowerShell 1.\\load_images.ps1 说明: 如果因为安全策略无法执行 PowerShell 脚本，请在 “以管理员身份运行” 的 PowerShell 中执行 Set-ExecutionPolicy RemoteSigned 命令。 如果需要，可以通过修改 images.properties 文件自行加载你自己需要的镜像 在 Docker Desktop 设置页面，点击 Kubernetes，选择 Enable Kubernetes，稍等片刻，看到左下方 Kubernetes 变为 running，Kubernetes 启动成功。 问题诊断： 如果看到 Kubernetes一直在启动状态，请参考 在macOS上面，退出docker，执行 rm -fr ~/Library/Group\\ Containers/group.com.docker/pki，然后重启docker 在Windows上面删除 ‘C:\\ProgramData\\DockerDesktop\\pki’ 目录 和 ‘C:\\Users\\yourUserName\\AppData\\Local\\Docker\\pki’ 目录 验证验证 Kubernetes 集群状态 123$ kubectl version #查看版本 如果正常输出信息，则证明 Kubernetes 成功启动。$ kubectl cluster-info$ kubectl get nodes","link":"/Kubernetes%E7%9A%84%E9%83%A8%E7%BD%B2-Docker-Desktop%E6%96%B9%E5%BC%8F/"},{"title":"Kubernetes的部署-kubeadm方式","text":"目前，Kubernetes 支持在多种环境下使用，包括本地主机（Ubuntu、Debian、CentOS、Fedora 等）、云服务（腾讯云、阿里云、百度云 等）。 可以使用以下几种方式部署 Kubernetes： kubeadm docker-desktop 一步步部署 kubernetes 集群 可以参考 opsnull/follow-me-install-kubernetes-cluster 项目一步步部署 kubernetes 集群。 接下来对以上几种方式进行详细介绍。 准备开始 一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令 每台机器 2 GB 或更多的 RAM （如果少于这个数字将会影响你应用的运行内存) 2 CPU 核或更多 集群中的所有机器的网络彼此均能相互连接(公网和内网都可以) 节点之中不可以有重复的主机名、MAC 地址或 product_uuid。 12345678#修改主机名[root@localhost ~]# cat /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6172.16.198.3 server1172.16.198.4 server2172.16.198.5 server3[root@localhost ~]# 你可以使用命令 ip link 或 ifconfig -a 来获取网络接口的 MAC 地址 可以使用 sudo cat /sys/class/dmi/id/product_uuid 命令对 product_uuid 校验 一般来讲，硬件设备会拥有唯一的地址，但是有些虚拟机的地址可能会重复。 Kubernetes 使用这些值来唯一确定集群中的节点。 如果这些值在每个节点上不唯一，可能会导致安装失败。 开启机器上的某些端口。 也可以关闭并禁用防火墙： 1$ systemctl stop firewalld &amp;&amp; systemctl disable firewalld 控制平面节点 | 协议 | 方向 | 端口范围 | 作用 | 使用者 | | —- | —- | ——— | ———————– | —————————- | | TCP | 入站 | 6443 | Kubernetes API 服务器 | 所有组件 | | TCP | 入站 | 2379-2380 | etcd 服务器客户端 API | kube-apiserver, etcd | | TCP | 入站 | 10250 | Kubelet API | kubelet 自身、控制平面组件 | | TCP | 入站 | 10251 | kube-scheduler | kube-scheduler 自身 | | TCP | 入站 | 10252 | kube-controller-manager | kube-controller-manager 自身 | 工作节点 协议 方向 端口范围 作用 使用者 TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件 TCP 入站 30000-32767 NodePort 服务† 所有组件 允许 iptables 检查桥接流量(可选) 123456789cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.confbr_netfilterEOFcat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsudo sysctl --system 禁用交换分区。为了保证 kubelet 正常工作，你 必须 禁用交换分区。 临时关闭swap，重启后失效 12#临时关闭swap，重启后失效$ swapoff -a 永久关闭 编辑/etc/fstab 注释掉最后一行 12345678910111213$ vi /etc/fstab## /etc/fstab# Created by anaconda on Mon Apr 19 21:45:29 2021## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/centos-root / xfs defaults 0 0UUID=a6721c24-7d5a-4b12-90cd-f3a239de944c /boot xfs defaults 0 0# /dev/mapper/centos-swap swap swap defaults 0 0 编辑/etc/sysctl.d/k8s.conf，最后加入 vm.swappiness = 0 12345$ vi /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1vm.swappiness = 0$ sysctl --system 关闭SELinux 把 SELINUX=enforcing 改为 SELINUX=disabled 12345678910111213141516$ vi /etc/selinux/config# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled# SELINUXTYPE= can take one of three values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected.# mls - Multi Level Security protection.SELINUXTYPE=targeted$ setenforce 0$ getenforcePermissive 使用 kubeadm 部署 kubernetes在每台机器上安装以下的软件包： kubeadm：用来初始化集群的指令。 kubelet：在集群中的每个节点上用来启动 Pod 和容器等。 kubectl：用来与集群通信的命令行工具。 安装Docker参考安装Docker一节安装Docker 在线安装kubelet,kubeadm,kubectlUbuntu/Debian 更新 apt 包索引并安装使用 Kubernetes apt 仓库所需要的包： 12sudo apt-get updatesudo apt-get install -y apt-transport-https ca-certificates curl 下载 Google Cloud 或者 阿里云 公开签名秘钥： 1sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg 或者 1sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg 添加 Kubernetes apt 仓库 或者 阿里云 仓库： 1echo &quot;deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main&quot; | sudo tee /etc/apt/sources.list.d/kubernetes.list 或者 1echo &quot;deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main&quot; | sudo tee /etc/apt/sources.list.d/kubernetes.list 更新 apt 包索引，安装 kubelet、kubeadm 和 kubectl，并锁定其版本(可选)： 123sudo apt-get updatesudo apt-get install -y kubelet kubeadm kubectlsudo apt-mark hold kubelet kubeadm kubectl CentOS/Fedora 使用Google镜像源或者阿里云镜像源安装： 12345678910cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearchenabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgexclude=kubelet kubeadm kubectlEOF 或者 123456789$ cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF yum安装 直接安装最新版本 1sudo yum install -y kubelet kubeadm kubectl 指定版本安装（有可能最新版本和centos7不兼容） 1234567#查询可用的版本#disablerepo：禁止查看所有#enablerepo：只允许查看$ yum --disablerepo=&quot;*&quot; --enablerepo=&quot;kubernetes&quot; list available --showduplicates -y#1.18.0版本比较稳定，这里安装1.18.0$ yum install -y --enablerepo=&quot;kubernetes&quot; kubelet-1.18.0-0.x86_64 kubeadm-1.18.0-0.x86_64 kubectl-1.18.0-0.x86_64 无包管理器的系统 安装 CNI 插件（大多数 Pod 网络都需要）： 123CNI_VERSION=&quot;v0.8.2&quot;sudo mkdir -p /opt/cni/bincurl -L &quot;https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-amd64-${CNI_VERSION}.tgz&quot; | sudo tar -C /opt/cni/bin -xz 定义要下载命令文件的目录。 说明： DOWNLOAD_DIR 变量必须被设置为一个可写入的目录。 如果你在运行 Flatcar Container Linux，可将 DOWNLOAD_DIR 设置为 /opt/bin。 12DOWNLOAD_DIR=/usr/local/binsudo mkdir -p $DOWNLOAD_DIR 安装 crictl（kubeadm/kubelet 容器运行时接口（CRI）所需） 12CRICTL_VERSION=&quot;v1.17.0&quot;curl -L &quot;https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-amd64.tar.gz&quot; | sudo tar -C $DOWNLOAD_DIR -xz 安装 kubeadm、kubelet、kubectl 并添加 kubelet 系统服务： 123456789RELEASE=&quot;$(curl -sSL https://dl.k8s.io/release/stable.txt)&quot;cd $DOWNLOAD_DIRsudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/${RELEASE}/bin/linux/amd64/{kubeadm,kubelet,kubectl}sudo chmod +x {kubeadm,kubelet,kubectl}RELEASE_VERSION=&quot;v0.4.0&quot;curl -sSL &quot;https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service&quot; | sed &quot;s:/usr/bin:${DOWNLOAD_DIR}:g&quot; | sudo tee /etc/systemd/system/kubelet.servicesudo mkdir -p /etc/systemd/system/kubelet.service.dcurl -sSL &quot;https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf&quot; | sed &quot;s:/usr/bin:${DOWNLOAD_DIR}:g&quot; | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 激活并启动 kubelet1234567$ systemctl enable --now kubelet#查看kubelet版本$ kubelet --version#查看启动是否成功(到目前不是running正常)$ systemctl status kubelet#若启动失败，查看失败原因$ journalctl -xefu kubelet 配置kubeadm命令行提示 安装bash-completion 1$ yum install -y bash-completion 让提示生效 123456#编辑 /root/.bashrc 最后追加一下内容$ vi /root/.bashrcsource /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)source &lt;(kubeadm completion bash)$ source /root/.bashrc 部署集群初始化master主节点12345$ sudo kubeadm init \\--apiserver-advertise-address=172.16.198.3 \\--image-repository registry.aliyuncs.com/google_containers \\--kubernetes-version v1.18.0 \\--pod-network-cidr 10.244.0.0/16 --apiserver-advertise-address 指定哪一台机器作为集群的第一台主机 --image-repository 指定镜像站地址 --kubernetes-version 指定k8s的当前版本，跟当前版本一致 --pod-network-cidr 参数与后续 CNI 插件有关，这里以 flannel 为例，若后续部署其他类型的网络插件请更改此参数。 执行成功会输出 12345678910111213141516171819...[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 172.16.198.3:6443 --token rvpzzt.3gwnmotcapinra6q \\ --discovery-token-ca-cert-hash sha256:9728236a9ea68b174d7c34011353b561240260a15f907c18de3a2c7eac9d0647 注意： token 有效期24小时，过期的话需要用以下命令生成： 123456789#查看token列表[root@server1 ~]# kubeadm token listTOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPSrvpzzt.3gwnmotcapinra6q 18h 2021-04-21T15:23:49+08:00 authentication,signing The default bootstrap token generated by 'kubeadm init'. system:bootstrappers:kubeadm:default-node-token#生成token[root@server1 ~]# kubeadm token createW0420 21:21:58.768890 17752 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]yoqnpb.7ycamplku2ya5qre[root@server1 ~]# 配置可查看集群环境命令要想在控制台查看集群情况，请执行以下命令： 如果是Linux管理员可以 1$ export KUBECONFIG=/etc/kubernetes/admin.conf 如果是Linux普通用户可以 123$ mkdir -p $HOME/.kube$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config$ sudo chown $(id -u):$(id -g) $HOME/.kube/config 配置网络因为之前初始化的时候使用的是flannel，所以要配置一下相关网络 新增文件kube-flannel.yml（只在主节点就行了） https://github.com/flannel-io/flannel/blob/master/Documentation/kube-flannel.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223---apiVersion: policy/v1beta1kind: PodSecurityPolicymetadata: name: psp.flannel.unprivileged annotations: seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/defaultspec: privileged: false volumes: - configMap - secret - emptyDir - hostPath allowedHostPaths: - pathPrefix: &quot;/etc/cni/net.d&quot; - pathPrefix: &quot;/etc/kube-flannel&quot; - pathPrefix: &quot;/run/flannel&quot; readOnlyRootFilesystem: false # Users and groups runAsUser: rule: RunAsAny supplementalGroups: rule: RunAsAny fsGroup: rule: RunAsAny # Privilege Escalation allowPrivilegeEscalation: false defaultAllowPrivilegeEscalation: false # Capabilities allowedCapabilities: ['NET_ADMIN', 'NET_RAW'] defaultAddCapabilities: [] requiredDropCapabilities: [] # Host namespaces hostPID: false hostIPC: false hostNetwork: true hostPorts: - min: 0 max: 65535 # SELinux seLinux: # SELinux is unused in CaaSP rule: 'RunAsAny'---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: flannelrules:- apiGroups: ['extensions'] resources: ['podsecuritypolicies'] verbs: ['use'] resourceNames: ['psp.flannel.unprivileged']- apiGroups: - &quot;&quot; resources: - pods verbs: - get- apiGroups: - &quot;&quot; resources: - nodes verbs: - list - watch- apiGroups: - &quot;&quot; resources: - nodes/status verbs: - patch---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: flannelroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: flannelsubjects:- kind: ServiceAccount name: flannel namespace: kube-system---apiVersion: v1kind: ServiceAccountmetadata: name: flannel namespace: kube-system---kind: ConfigMapapiVersion: v1metadata: name: kube-flannel-cfg namespace: kube-system labels: tier: node app: flanneldata: cni-conf.json: | { &quot;name&quot;: &quot;cbr0&quot;, &quot;cniVersion&quot;: &quot;0.3.1&quot;, &quot;plugins&quot;: [ { &quot;type&quot;: &quot;flannel&quot;, &quot;delegate&quot;: { &quot;hairpinMode&quot;: true, &quot;isDefaultGateway&quot;: true } }, { &quot;type&quot;: &quot;portmap&quot;, &quot;capabilities&quot;: { &quot;portMappings&quot;: true } } ] } net-conf.json: | { &quot;Network&quot;: &quot;10.244.0.0/16&quot;, &quot;Backend&quot;: { &quot;Type&quot;: &quot;vxlan&quot; } }---apiVersion: apps/v1kind: DaemonSetmetadata: name: kube-flannel-ds namespace: kube-system labels: tier: node app: flannelspec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/os operator: In values: - linux hostNetwork: true priorityClassName: system-node-critical tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.14.0-rc1 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.14.0-rc1 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: &quot;100m&quot; memory: &quot;50Mi&quot; limits: cpu: &quot;100m&quot; memory: &quot;50Mi&quot; securityContext: privileged: false capabilities: add: [&quot;NET_ADMIN&quot;, &quot;NET_RAW&quot;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg 提前下载镜像，防止安装失败(node节点最好也下载) 1docker pull quay.io/coreos/flannel:v0.14.0-rc1 执行yml配置（只在主节点执行就行了） 12345678[root@server1 ~]# kubectl apply -f kube-flannel.ymlpodsecuritypolicy.policy/psp.flannel.unprivileged createdclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.apps/kube-flannel-ds created[root@server1 ~]# 添加node工作节点在 另一主机 重复 部署集群 以前的步骤，最后提前下载好flannel镜像，根据提示，加入到集群。 12kubeadm join 172.16.198.3:6443 --token rvpzzt.3gwnmotcapinra6q \\ --discovery-token-ca-cert-hash sha256:9728236a9ea68b174d7c34011353b561240260a15f907c18de3a2c7eac9d0647 查看集群情况在主节点执行以下命令： 1234567891011121314151617181920[root@server1 ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONserver1 Ready master 5h48m v1.18.0server2 Ready &lt;none&gt; 21s v1.18.0server3 Ready &lt;none&gt; 12s v1.18.0[root@server1 ~]# kubectl get pod --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-7ff77c879f-7x5lm 1/1 Running 2 5h55mkube-system coredns-7ff77c879f-pwblv 1/1 Running 2 5h55mkube-system etcd-server1 1/1 Running 2 5h55mkube-system kube-apiserver-server1 1/1 Running 2 5h55mkube-system kube-controller-manager-server1 1/1 Running 2 5h55mkube-system kube-flannel-ds-6qgbz 1/1 Running 0 7m38skube-system kube-flannel-ds-79dws 1/1 Running 0 7m47skube-system kube-flannel-ds-sjp2z 1/1 Running 2 3h32mkube-system kube-proxy-jk4wp 1/1 Running 0 7m47skube-system kube-proxy-s4vfp 1/1 Running 0 7m38skube-system kube-proxy-vkwth 1/1 Running 2 5h55mkube-system kube-scheduler-server1 1/1 Running 3 5h55m[root@server1 ~]# 执行报错集合报错 123456789[root@server2 ~]# kubeadm join 172.16.198.3:6443 --token rvpzzt.3gwnmotcapinra6q --discovery-token-ca-cert-hash sha256:9728236a9ea68b174d7c34011353b561240260a15f907c18de3a2c7eac9d0647W0420 21:10:51.619387 9540 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.[preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https://kubernetes.io/docs/setup/cri/ [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 20.10.6. Latest validated version: 19.03error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`To see the stack trace of this error execute with --v=5 or higher ​ 解决 12[root@server2 ~]# kubeadm reset[root@server2 ~]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward","link":"/Kubernetes%E7%9A%84%E9%83%A8%E7%BD%B2-kubeadm%E6%96%B9%E5%BC%8F/"},{"title":"Kubernetes的部署-kubeadm方式二","text":"准备工作修改hostsname1234$ vi /etc/hosts172.16.198.102 master172.16.198.103 node1172.16.198.104 node2 关闭并禁止防火墙1$ systemctl stop firewalld &amp;&amp; systemctl disable firewalld 关闭swap 临时关闭，重启失效 1234$ swapoff -a# 重新开启$ swapon -a 永久关闭 123# 编辑/etc/fstab 注释掉最后一行$ vi /etc/fstab# 重启生效 安装docker并启动参考安装Docker一节安装Docker 安装docker依赖 123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 设置docker的yum源 123$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 安装最新版的docker 1$ sudo yum install -y docker-ce docker-ce-cli containerd.io 配置阿里云镜像加速以及Docker 守护程序 12345678910111213$ mkdir -p /etc/docker$ vi /etc/docker/daemon.json{ &quot;registry-mirrors&quot;: [ &quot;https://lz2nib3q.mirror.aliyuncs.com&quot; ], &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: { &quot;max-size&quot;: &quot;100m&quot; }, &quot;storage-driver&quot;: &quot;overlay2&quot;} 启动docker 12$ sudo systemctl enable docker$ sudo systemctl start docker 开始安装添加 kubeadm 的源123456789$ cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF yum安装123$ yum -y install kubeadm# 设置kubelet自启动$ systemctl enable kubelet 部署 Master 节点1234567891011121314151617181920# 查看需要下载的镜像$ kubeadm config images list# 因为阿里云没有dns镜像，需要提前下载一个镜像 并修改 tag$ docker pull coredns/coredns:1.8.0$ docker tag coredns/coredns:v1.8.0 registry.aliyuncs.com/google_containers/coredns/coredns:v1.8.0# 开始安装主节点$ kubeadm init --image-repository registry.aliyuncs.com/google_containers# 安装成功后执行$ mkdir -p $HOME/.kube$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config$ sudo chown $(id -u):$(id -g) $HOME/.kube/config# 安装网络插件$ kubectl apply -f https://github.com/weaveworks/weave/releases/download/latest_release/weave-daemonset-k8s-1.11.yaml# 查看节点列表$ kubectl get nodes# 查看pod$ kubectl get pods -n kube-system 部署 node 节点1234# 执行步骤1，2，3# 加入主节点$ kubeadm join 172.16.198.101:6443 --token ha3qeh.9eqf46erh8kpmwl8 \\ --discovery-token-ca-cert-hash sha256:1b76a7ac832e7582527c9d7e618289784bf4d00b414c2350023e8622d85eba1d","link":"/Kubernetes%E7%9A%84%E9%83%A8%E7%BD%B2-kubeadm%E6%96%B9%E5%BC%8F%E4%BA%8C/"},{"title":"Kubernetes部署Pod","text":"简介Kubernetes 跟 Docker 等很多项目最大的不同，就在于它不推荐你使用命令行的方式直接运行容器（虽然 Kubernetes 项目也支持这种方式，比如：kubectl run），而是希望你用 YAML 文件的方式，即：把容器的定义、参数、配置，统统记录在一个 YAML 文件中，然后用这样一句指令把它运行起来： kubectl create -f 我的配置文件 这么做最直接的好处是，你会有一个文件能记录下 Kubernetes 到底“run”了什么。 配置文件nginx-deployment.yaml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455apiVersion: apps/v1# 指定了这个 API 对象的类型（Type），是一个 Deployment# 1.所谓 Deployment，是一个定义多副本应用（即多个副本 Pod）的对象# 2.此外，Deployment 还负责在 Pod 定义发生变化时，对每个副本进行滚动更新（Rolling Update）kind: Deploymentmetadata: name: nginx-deploymentspec: selector: # 过滤规则的定义，我们一般称之为：Label Selector matchLabels: app: nginx # 定义的 Pod 副本个数是：2 replicas: 2 # 定义了一个 Pod 模版 template: # 一个 Kubernetes 的 API 对象的定义，大多可以分为 Metadata 和 Spec 两个部分 # 前者(metadata)存放的是API 对象的“标识”，即元数据 metadata: # 一组 key-value 格式的标签 # 可以通过这个 Labels 字段从 Kubernetes 中过滤出它所关心的被控制对象, # 在本例中，Deployment 会把所有正在运行的、携带“app: nginx”标签的 Pod 识别为被管理的对象，并确保这些 Pod 的总数严格等于两个 labels: app: nginx # 后者（spec)：存放的，则是属于这个对象独有的定义，用来描述它所要表达的功能 # 包含一个容器 spec: containers: # 容器名称 - name: nginx # 容器的镜像是 nginx:1.7.9 image: nginx:1.7.9 # 容器监听端口是 80 ports: - containerPort: 80 # 声明自己要挂载哪个 Volume volumeMounts: # 容器内部的路径 - mountPath: &quot;/usr/share/nginx/html&quot; # 挂载名称 name: nginx-vol # 定义了这个Pod的所有 Volume volumes: # 挂载名称 - name: nginx-vol # 挂载的类型为emptyDir # 等同于Docker 的隐式 Volume 参数，即：不显式声明宿主机目录的 Volume，Kubernetes 会在宿主机上创建一个临时目录，这个目录将来就会被绑定挂载到容器所声明的 Volume 目录上，最后交给 Docker emptyDir: {} # 挂载名称 - name: nginx-vol2 # 挂载类型为hostPath，即显式的 Volume 定义，类似docker的 -v hostPath: # 宿主机的绝对路径 path: &quot; /var/data&quot; 在这里，**Pod 就是 Kubernetes 世界里的“应用”；而一个应用，可以由多个容器组成。** 需要注意的是，像这样使用一种 API 对象（Deployment）管理另一种 API 对象（Pod）的方法，在 Kubernetes 中，叫作“控制器”模式（controller pattern）。在我们的例子中，Deployment 扮演的正是 Pod 的控制器的角色。 运行配置文件运行命令 使用kubectl apply命令(推荐)，既能创建，也能更新 12$ kubectl apply -f nginx-deployment.yamldeployment.apps/nginx-deployment apply 使用 kubectl create命令，只能创建，不能更新 12$ kubectl create -f nginx-deployment.yamldeployment.apps/nginx-deployment created 查看运行状态1234$ kubectl get pods -l app=nginxNAME READY STATUS RESTARTS AGEnginx-deployment-5d59d67564-b9925 1/1 Running 0 40snginx-deployment-5d59d67564-tmxk4 1/1 Running 0 40s -l:获取所有匹配 app:nginx 标签的 Pod。 在命令行中，所有 key-value 格式的参数，都使用“=”而非“:”表示 查看一个 API 对象的细节命令格式：kubectl describe pod &lt;PodNAME&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162$ kubectl describe pod nginx-deployment-5d59d67564-b9925Name: nginx-deployment-67655c6769-ktbxvNamespace: defaultPriority: 0Node: node2/172.16.198.103Start Time: Wed, 26 May 2021 22:41:32 +0800Labels: app=nginx pod-template-hash=67655c6769Annotations: &lt;none&gt;Status: RunningIP: 10.47.0.7IPs: IP: 10.47.0.7Controlled By: ReplicaSet/nginx-deployment-67655c6769Containers: nginx: Container ID: docker://96d4fa867e89c330cd94cc4febcae5d9ce610ac40b5ad8392612ef77a829fe2f Image: nginx:1.8 Image ID: docker-pullable://nginx@sha256:c97ee70c4048fe79765f7c2ec0931957c2898f47400128f4f3640d0ae5d60d10 Port: 80/TCP Host Port: 0/TCP State: Running Started: Wed, 26 May 2021 22:41:34 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /usr/share/nginx/html from nginx-vol (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-swqh8 (ro)Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled TrueVolumes: nginx-vol: Type: EmptyDir (a temporary directory that shares a pod's lifetime) Medium: SizeLimit: &lt;unset&gt; nginx-vol2: Type: HostPath (bare host directory volume) Path: /var/data HostPathType: kube-api-access-swqh8: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: &lt;nil&gt; DownwardAPI: trueQoS Class: BestEffortNode-Selectors: &lt;none&gt;Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300sEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 5m21s default-scheduler Successfully assigned default/nginx-deployment-67655c6769-ktbxv to node2 Normal Pulled 5m19s kubelet Container image &quot;nginx:1.8&quot; already present on machine Normal Created 5m19s kubelet Created container nginx Normal Started 5m19s kubelet Started container nginx[root@master ~]# 在 kubectl describe 命令返回的结果中，可以清楚地看到这个 Pod 的详细信息，比如它的 IP 地址等等。其中，有一个部分值得你特别关注，它就是 Events（事件）。 在 Kubernetes 执行的过程中，对 API 对象的所有重要操作，都会被记录在这个对象的 Events 里，并且显示在 kubectl describe 指令返回的结果中。 比如，对于这个 Pod，我们可以看到它被创建之后，被调度器调度（Successfully assigned）到了 node2，拉取了指定的镜像（pulling image），然后启动了 Pod 里定义的容器（Started container）。所以，这个部分正是我们将来进行 Debug 的重要依据。如果有异常发生，你一定要第一时间查看这些 Events，往往可以看到非常详细的错误信息。 对镜像变更修改yaml文件即可 1234567... spec: containers: - name: nginx image: nginx:1.8 #这里被从1.7.9修改为1.8 ports: - containerPort: 80 使用 kubectl apply命令(推荐) 12$ kubectl apply -f nginx-deployment.yamldeployment.apps/nginx-deployment apply 使用kubectl replace命令 12$ kubectl replace -f nginx-deployment.yamldeployment.apps/nginx-deployment replaced 进入Pod中命令格式：kubectl exec -it &lt;PodNAME&gt; 123$ kubectl exec -it nginx-deployment-64c9d67564-gnnxl -- /bin/bashroot@nginx-deployment-64c9d67564-gnnxl:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 删除Pod12$ kubectl delete -f nginx-deployment.yamldeployment.apps &quot;nginx-deployment&quot; deleted","link":"/Kubernetes%E9%83%A8%E7%BD%B2Pod/"},{"title":"Kubernetes部署容器存储插件","text":"简介很多时候我们需要用数据卷（Volume）把外面宿主机上的目录或者文件挂载进容器的 Mount Namespace 中，从而达到容器和宿主机共享这些目录或者文件的目的。容器里的应用，也就可以在这些数据卷中新建和写入文件。 可是，如果你在某一台机器上启动的一个容器，显然无法看到其他机器上的容器在它们的数据卷里写入的文件。这是容器最典型的特征之一：无状态。 而容器的持久化存储，就是用来保存容器存储状态的重要手段：存储插件会在容器里挂载一个基于网络或者其他机制的远程数据卷，使得在容器里创建的文件，实际上是保存在远程存储服务器上，或者以分布式的方式保存在多个节点上，而与当前宿主机没有任何绑定关系。这样，无论你在其他哪个宿主机上启动新的容器，都可以请求挂载指定的持久化存储卷，从而访问到数据卷里保存的内容。这就是“持久化”的含义。 使用Rook存储插件由于 Kubernetes 本身的松耦合设计，绝大多数存储项目，比如 Ceph、GlusterFS、NFS 等，都可以为 Kubernetes 提供持久化存储能力。在这次的部署实战中，我会选择部署一个很重要的 Kubernetes 存储插件项目：Rook。 Rook 项目是一个基于 Ceph 的 Kubernetes 存储插件（它后期也在加入对更多存储实现的支持）。不过，不同于对 Ceph 的简单封装，Rook 在自己的实现中加入了水平扩展、迁移、灾难备份、监控等大量的企业级功能，使得这个项目变成了一个完整的、生产级别可用的容器存储插件。 得益于容器化技术，用几条指令，Rook 就可以把复杂的 Ceph 存储后端部署起来： 安装在主节点执行： 12345678$ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/common.yaml$ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/operator.yaml$ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/crds.yaml$ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/cluster.yaml 验证在部署完成后，你就可以看到 Rook 项目会将自己的 Pod 放置在由它自己管理的 Namespace 当中： 1234567891011121314$ kubectl get pods -n rook-cephNAME READY STATUS RESTARTS AGEcsi-cephfsplugin-76z8v 2/3 ImagePullBackOff 0 2m31scsi-cephfsplugin-grcfb 2/3 ImagePullBackOff 0 2m31scsi-cephfsplugin-provisioner-6f75644874-fjd7f 2/6 ErrImagePull 0 2m31scsi-cephfsplugin-provisioner-6f75644874-s8vtx 2/6 ErrImagePull 0 2m31scsi-rbdplugin-jvg76 2/3 ImagePullBackOff 0 2m32scsi-rbdplugin-provisioner-67fb987799-t7hvf 2/6 ErrImagePull 0 2m32scsi-rbdplugin-provisioner-67fb987799-wkbrj 2/6 ErrImagePull 0 2m32scsi-rbdplugin-r4p7t 2/3 ImagePullBackOff 0 2m32srook-ceph-mon-a-canary-7856b7fb64-p7zg5 1/1 Running 0 2m13srook-ceph-mon-b-canary-56d9f5ccd9-skhl7 1/1 Running 0 2m13srook-ceph-mon-c-canary-dc75bd77d-llrv4 0/1 Pending 0 2m13srook-ceph-operator-84c85574d9-rm5nj 1/1 Running 4 12m 这样，一个基于 Rook 持久化存储集群就以容器的方式运行起来了，而接下来在 Kubernetes 项目上创建的所有 Pod 就能够通过 Persistent Volume（PV）和 Persistent Volume Claim（PVC）的方式，在容器里挂载由 Ceph 提供的数据卷了。 而 Rook 项目，则会负责这些数据卷的生命周期管理、灾难备份等运维工作。关于这些容器持久化存储的知识，我会在后续章节中专门讲解。 其实，是因为这个项目很有前途。如果你去研究一下 Rook 项目的实现，就会发现它巧妙地依赖了 Kubernetes 提供的编排能力，合理的使用了很多诸如 Operator、CRD 等重要的扩展特性（这些特性我都会在后面的文章中逐一讲解到）。这使得 Rook 项目，成为了目前社区中基于 Kubernetes API 构建的最完善也最成熟的容器存储插件。我相信，这样的发展路线，很快就会得到整个社区的推崇。 备注：其实，在很多时候，大家说的所谓“云原生”，就是“Kubernetes 原生”的意思。而像 Rook、Istio 这样的项目，正是贯彻这个思路的典范。在我们后面讲解了声明式 API 之后，相信你对这些项目的设计思想会有更深刻的体会。","link":"/Kubernetes%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%AD%98%E5%82%A8%E6%8F%92%E4%BB%B6/"},{"title":"Kubernetes部署应用","text":"运行应用直接命令行运行 12345678# kubectl run NAME --image=镜像地址[:TAG]$ kubectl run testapp --image=ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1pod/testapp created# 查看运行的pod$ kubectl get podNAME READY STATUS RESTARTS AGEtestapp 1/1 Running 0 61s yaml方式启动Pod方式pod.yaml123456789101112apiVersion: v1# 定义以 pod 方式管理kind: Pod# 定义元数据metadata: # pod 的名称 name: test-podspec: # 定义容器，可以多个 containers: - name: test-k8s # 容器名字 image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1 # 镜像 123456789# 运行pod：$ kubectl apply -f pod.yamlpod/test-pod created# 查看运行的pod$ kubectl get podNAME READY STATUS RESTARTS AGEtest-pod 1/1 Running 0 22stestapp 1/1 Running 0 2m29s Deployment方式Deployment 通过 label 关联起来 Pods 单独运行pod不是很方便，在集群里面会有很多pod，这样需要用 Deployment ： deployment.yaml1234567891011121314151617181920212223apiVersion: apps/v1# 定义以 Deployment 方式管理kind: Deploymentmetadata: # Deployment 的名称 name: test-k8sspec: # 运行的 pod 副本数量 replicas: 2 # 用来查找关联的 Pod，所有标签都匹配才行 selector: matchLabels: app: test-k8s # 定义 Pod 相关数据 template: metadata: labels: app: test-k8s spec: # 定义容器，可以多个 containers: - name: test-k8s # 容器名字 image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1 # 镜像 12345678# 运行 deployment$ kubectl apply -f deployment.yamldeployment.apps/test-k8s created# 查看运行的 deployment$ kubectl get deploymentNAME READY UP-TO-DATE AVAILABLE AGEtest-k8s 2/2 2 2 28s 常用命令部署应用123# kubectl apply -f app.yaml$ kubectl apply -f deployment.yamldeployment.apps/test-k8s created 查看 deployment pod123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# 查看运行的 deployment$ kubectl get deploymentNAME READY UP-TO-DATE AVAILABLE AGEtest-k8s 2/2 2 2 8s# 查看运行的 pod$ kubectl get podNAME READY STATUS RESTARTS AGEtest-k8s-8598bbb8c6-pwhjh 1/1 Running 0 27stest-k8s-8598bbb8c6-t2szm 1/1 Running 0 27s# 查看详细的pod，带有ip,运行在哪个节点等$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-8598bbb8c6-pwhjh 1/1 Running 0 43s 10.244.0.7 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-t2szm 1/1 Running 0 43s 10.244.0.7 node1 &lt;none&gt; &lt;none&gt;# 查看 pod 详细数据# kubectl describe pod POD-NAME# 或者 kubectl describe pod/POD-NAME$ kubectl describe pod test-k8s-8598bbb8c6-pwhjhName: test-k8s-8598bbb8c6-pwhjhNamespace: default # 命名空间Priority: 0Node: node2/10.211.55.103Start Time: Fri, 07 Jan 2022 14:02:34 +0800Labels: app=test-k8s pod-template-hash=8598bbb8c6Annotations: &lt;none&gt;Status: RunningIP: 10.244.0.7 # ipIPs: IP: 10.244.0.7Controlled By: ReplicaSet/test-k8s-8598bbb8c6Containers: # 容器相关信息 test-k8s: Container ID: docker://9aa023b175d4c7655bd5a601975be90d34c5896b2b8a871fab7bd1227cea6ca5 Image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1 Image ID: docker-pullable://ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s@sha256:9b452816d6493045a21d8b3d6a851f21ca2e50c86cd57ba8c41141f001d9911d Port: &lt;none&gt; Host Port: &lt;none&gt; State: Running Started: Fri, 07 Jan 2022 14:02:35 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-r8nvq (ro)Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled TrueVolumes: kube-api-access-r8nvq: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: &lt;nil&gt; DownwardAPI: trueQoS Class: BestEffortNode-Selectors: &lt;none&gt;Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s# 事件（重要）-按照时间倒序Events: Type Reason Age From Message ---- ------ ---- ---- ------- # 节点上的 kubelet 收到了任务后，进行拉取镜像，并启动镜像 Normal Pulled 72s kubelet Container image &quot;ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1&quot; already present on machine Normal Created 72s kubelet Created container test-k8s Normal Started 72s kubelet Started container test-k8s # 1.首先节点上的 kubelet 收到了任务后，进行拉取镜像，并启动镜像 Normal Scheduled 70s default-scheduler Successfully assigned default/test-k8s-8598bbb8c6-pwhjh to node2 查看 log12345678# 查看 pod 上的日志, -f 为持续查看日志# kubectl logs POD-NAME [-f]# 或者 kubectl logs pods/POD-NAME [-f]$ kubectl logs test-k8s-8598bbb8c6-pwhjh -f[2022-01-07T06:02:36.007] [INFO] app - run in docker[2022-01-07T06:02:36.014] [INFO] app - Server started successfully and listened on 8080http://localhost:8080 进入 Pod 容器终端12345678# 进入 Pod 容器终端# 若pod里面有多个容器，可以加上 -c container-name 可以指定进入哪个容器。# kubectl exec -it POD-NAME [-c container-name] -- bash$ kubectl exec -it test-k8s-8598bbb8c6-pwhjh -- bashroot@test-k8s-8598bbb8c6-pwhjh:/app$ lsapp.js docker-compose.yml draw log log.js log4js.json node_modules package-lock.json package.json yamlroot@test-k8s-8598bbb8c6-pwhjh:/app$ exitexit 伸缩副本数量两种方式 修改配置文件 首先修改 deployment.yaml 文件内的 spec.replicas 为5 deployment.yaml1234567891011121314151617181920212223apiVersion: apps/v1# 定义以 Deployment 方式管理kind: Deploymentmetadata: # Deployment 的名称 name: test-k8sspec: # 运行的 pod 副本数量 replicas: 5 # 用来查找关联的 Pod，所有标签都匹配才行 selector: matchLabels: app: test-k8s # 定义 Pod 相关数据 template: metadata: labels: app: test-k8s spec: # 定义容器，可以多个 containers: - name: test-k8s # 容器名字 image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1 # 镜像 重新执行 yaml 文件 1234567891011$ kubectl apply -f deployment.yamldeployment.apps/test-k8s configured# 查看 pod$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-8598bbb8c6-66jzz 1/1 Running 0 38s 10.244.0.8 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-pwhjh 1/1 Running 0 6m14s 10.244.0.7 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-qjcnd 1/1 Running 0 38s 10.244.0.9 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-t2szm 1/1 Running 0 6m14s 10.244.0.7 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-wsprz 1/1 Running 0 38s 10.244.0.8 node2 &lt;none&gt; &lt;none&gt; 通过命令行调整12345678910111213141516171819202122232425262728293031323334353637383940# kubectl scale deployment DEPLOYMENT-NAME --replicas=副本数量$ kubectl scale deployment test-k8s --replicas=10deployment.apps/test-k8s scaled# 查看 pod$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-8598bbb8c6-66jzz 1/1 Running 0 67s 10.244.0.8 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-7qcqq 1/1 Running 0 10s 10.244.0.11 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-k8nlz 1/1 Running 0 10s 10.244.0.10 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-n6bsl 1/1 Running 0 10s 10.244.0.10 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-nmrm2 1/1 Running 0 10s 10.244.0.9 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-pwhjh 1/1 Running 0 6m43s 10.244.0.7 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-qjcnd 1/1 Running 0 67s 10.244.0.9 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-t2szm 1/1 Running 0 6m43s 10.244.0.7 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-wsprz 1/1 Running 0 67s 10.244.0.8 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-zrctz 1/1 Running 0 10s 10.244.0.11 node2 &lt;none&gt; &lt;none&gt;# 也可以减下来$ kubectl scale deployment test-k8s --replicas=2deployment.apps/test-k8s scaled# 查看 pod$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-8598bbb8c6-66jzz 1/1 Terminating 0 93s 10.244.0.8 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-7qcqq 1/1 Terminating 0 36s 10.244.0.11 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-k8nlz 1/1 Terminating 0 36s 10.244.0.10 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-n6bsl 1/1 Terminating 0 36s 10.244.0.10 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-nmrm2 1/1 Terminating 0 36s 10.244.0.9 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-pwhjh 1/1 Running 0 7m9s 10.244.0.7 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-qjcnd 1/1 Terminating 0 93s 10.244.0.9 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-t2szm 1/1 Running 0 7m9s 10.244.0.7 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-wsprz 1/1 Terminating 0 93s 10.244.0.8 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-zrctz 1/1 Terminating 0 36s 10.244.0.11 node2 &lt;none&gt; &lt;none&gt;$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-8598bbb8c6-pwhjh 1/1 Running 0 7m37s 10.244.0.7 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-t2szm 1/1 Running 0 7m37s 10.244.0.7 node1 &lt;none&gt; &lt;none&gt; 把集群内端口映射到节点1234567# kubectl port-forward POD-NAME 宿主机端口:容器内端口# 或者 kubectl port-forward pod/POD-NAME 宿主机端口:容器内端口# 或者 kubectl port-forward deployment/DEPLOYMENT-NAME 宿主机端口:容器内端口$ kubectl port-forward test-k8s-8598bbb8c6-pwhjh 8090:8080Forwarding from 127.0.0.1:8090 -&gt; 8080Forwarding from [::1]:8090 -&gt; 8080 查看历史版本 目前只有一个历史版本 123456# kubectl rollout history deployment DEPLOYMENT-NAME# 目前只有一个历史$ kubectl rollout history deployment test-k8sdeployment.apps/test-k8sREVISION CHANGE-CAUSE1 &lt;none&gt; 现在修改 yaml 文件 中的镜像版本 deployment.yaml1234567891011121314151617181920212223apiVersion: apps/v1# 定义以 Deployment 方式管理kind: Deploymentmetadata: # Deployment 的名称 name: test-k8sspec: # 运行的 pod 副本数量 replicas: 5 # 用来查找关联的 Pod，所有标签都匹配才行 selector: matchLabels: app: test-k8s # 定义 Pod 相关数据 template: metadata: labels: app: test-k8s spec: # 定义容器，可以多个 containers: - name: test-k8s # 容器名字 image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v2-with-error # 镜像 重新部署 12345678910111213141516171819202122$ kubectl apply -f deployment.yamldeployment.apps/test-k8s configured$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-5dd85b6897-628bb 1/1 Running 0 36s 10.244.0.12 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-6twbp 1/1 Running 0 36s 10.244.0.14 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-ld72w 1/1 Running 0 36s 10.244.0.14 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-r287p 1/1 Running 0 31s 10.244.0.15 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-vbr9v 1/1 Running 0 31s 10.244.0.15 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-hnfgk 1/1 Terminating 0 36s 10.244.0.13 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-nsdld 1/1 Terminating 0 36s 10.244.0.13 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-pwhjh 1/1 Terminating 0 9m25s 10.244.0.7 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-t2szm 1/1 Terminating 0 9m25s 10.244.0.7 node1 &lt;none&gt; &lt;none&gt;$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-5dd85b6897-628bb 1/1 Running 0 42s 10.244.0.12 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-6twbp 1/1 Running 0 42s 10.244.0.14 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-ld72w 1/1 Running 0 42s 10.244.0.14 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-r287p 1/1 Running 0 37s 10.244.0.15 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-vbr9v 1/1 Running 0 37s 10.244.0.15 node2 &lt;none&gt; &lt;none&gt; 1/1 Running 0 88m 查看现在的历史版本 现在有两个版本了 12345$ kubectl rollout history deployment test-k8sdeployment.apps/test-k8sREVISION CHANGE-CAUSE1 &lt;none&gt;2 &lt;none&gt; 回到上个版本123456789101112131415161718192021222324252627282930# kubectl rollout undo DEPLOYMENT-NAME $ kubectl rollout undo deployment test-k8sdeployment.apps/test-k8s rolled back$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-5dd85b6897-6twbp 1/1 Terminating 0 99s 10.244.0.14 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-ld72w 1/1 Terminating 0 99s 10.244.0.14 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-r287p 1/1 Terminating 0 94s 10.244.0.15 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-vbr9v 1/1 Terminating 0 94s 10.244.0.15 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-g556j 1/1 Running 0 30s 10.244.0.18 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-k599w 1/1 Running 0 31s 10.244.0.16 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-krz9j 1/1 Running 0 30s 10.244.0.17 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-qnclg 1/1 Running 0 31s 10.244.0.17 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-s98pd 1/1 Running 0 31s 10.244.0.16 node1 &lt;none&gt; &lt;none&gt;$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-8598bbb8c6-g556j 1/1 Running 0 34s 10.244.0.18 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-k599w 1/1 Running 0 35s 10.244.0.16 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-krz9j 1/1 Running 0 34s 10.244.0.17 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-qnclg 1/1 Running 0 35s 10.244.0.17 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-s98pd 1/1 Running 0 35s 10.244.0.16 node1 &lt;none&gt; &lt;none&gt;# 查看历史版本$ kubectl rollout history deployment test-k8sdeployment.apps/test-k8sREVISION CHANGE-CAUSE2 &lt;none&gt;3 &lt;none&gt; 回到指定版本12345678910111213141516171819202122232425262728293031# kubectl rollout undo deployment DEPLOYMENT-NAME --to-revision=版本号$ kubectl rollout undo deployment test-k8s --to-revision=2deployment.apps/test-k8s rolled back$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-5dd85b6897-5b2l4 1/1 Running 0 27s 10.244.0.18 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-ldrz4 1/1 Running 0 27s 10.244.0.20 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-mhfrx 1/1 Running 0 25s 10.244.0.21 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-txh85 1/1 Running 0 25s 10.244.0.19 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-zmm7h 1/1 Running 0 27s 10.244.0.19 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-g556j 1/1 Terminating 0 89s 10.244.0.18 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-k599w 1/1 Terminating 0 90s 10.244.0.16 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-krz9j 1/1 Terminating 0 89s 10.244.0.17 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-qnclg 1/1 Terminating 0 90s 10.244.0.17 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-s98pd 1/1 Terminating 0 90s 10.244.0.16 node1 &lt;none&gt; &lt;none&gt;$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-5dd85b6897-5b2l4 1/1 Running 0 38s 10.244.0.18 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-ldrz4 1/1 Running 0 38s 10.244.0.20 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-mhfrx 1/1 Running 0 36s 10.244.0.21 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-txh85 1/1 Running 0 36s 10.244.0.19 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-zmm7h 1/1 Running 0 38s 10.244.0.19 node1 &lt;none&gt; &lt;none&gt;# 查看历史版本$ kubectl rollout history deployment test-k8sdeployment.apps/test-k8sREVISION CHANGE-CAUSE3 &lt;none&gt;4 &lt;none&gt; 删除部署1234567891011121314151617# kubectl delete deployment DEPLOYMENT-NAME$ kubectl delete deployment test-k8sdeployment.apps &quot;test-k8s&quot; deleted$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-5dd85b6897-5b2l4 1/1 Terminating 0 69s 10.244.0.18 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-ldrz4 1/1 Terminating 0 69s 10.244.0.20 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-mhfrx 1/1 Terminating 0 67s 10.244.0.21 node1 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-txh85 1/1 Terminating 0 67s 10.244.0.19 node2 &lt;none&gt; &lt;none&gt;test-k8s-5dd85b6897-zmm7h 1/1 Terminating 0 69s 10.244.0.19 node1 &lt;none&gt; &lt;none&gt;$ kubectl get pod -o wideNo resources found in default namespace.$ kubectl get deploymentNo resources found in default namespace. 其他命令查看全部12345678910111213141516$ kubectl get allNAME READY STATUS RESTARTS AGEpod/test-k8s-8598bbb8c6-cp4bp 1/1 Running 0 96spod/test-k8s-8598bbb8c6-jq9s7 1/1 Running 0 96spod/test-k8s-8598bbb8c6-mn9w9 1/1 Running 0 96spod/test-k8s-8598bbb8c6-snfk4 1/1 Running 0 96spod/test-k8s-8598bbb8c6-vntkv 1/1 Running 0 96sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 158mNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/test-k8s 5/5 5 5 96sNAME DESIRED CURRENT READY AGEreplicaset.apps/test-k8s-8598bbb8c6 5 5 5 96s 重新部署123456789101112131415161718192021222324# kubectl rollout restart deployment DEPLOYMENT-NAME$ kubectl rollout restart deployment test-k8sdeployment.apps/test-k8s restarted$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-8598bbb8c6-cp4bp 1/1 Terminating 0 2m56s 10.244.0.21 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-jq9s7 1/1 Terminating 0 2m56s 10.244.0.20 node2 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-mn9w9 1/1 Terminating 0 2m56s 10.244.0.22 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-snfk4 1/1 Terminating 0 2m56s 10.244.0.24 node1 &lt;none&gt; &lt;none&gt;test-k8s-8598bbb8c6-vntkv 1/1 Terminating 0 2m56s 10.244.0.23 node1 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-7n6cv 1/1 Running 0 5s 10.244.0.22 node2 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-8fqx4 1/1 Running 0 4s 10.244.0.24 node2 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-dfznv 1/1 Running 0 5s 10.244.0.25 node1 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-dxldl 1/1 Running 0 4s 10.244.0.26 node1 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-q68qb 1/1 Running 0 5s 10.244.0.23 node2 &lt;none&gt; &lt;none&gt;$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-cf5b7766c-7n6cv 1/1 Running 0 35s 10.244.0.22 node2 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-8fqx4 1/1 Running 0 34s 10.244.0.24 node2 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-dfznv 1/1 Running 0 35s 10.244.0.25 node1 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-dxldl 1/1 Running 0 34s 10.244.0.26 node1 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-q68qb 1/1 Running 0 35s 10.244.0.23 node2 &lt;none&gt; &lt;none&gt; 命令修改镜像1234567891011121314151617181920212223242526272829303132333435363738# kubectl set image deployment DEPLOYMENT-NAME CONTAINER-NAME=镜像地址:TAG --record# --record 表示把这个命令记录到操作历史中 方便历史版本回退$ kubectl set image deployment test-k8s test-k8s=ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v2-with-error --recordFlag --record has been deprecated, --record will be removed in the futuredeployment.apps/test-k8s image updated# 查看历史记录$ kubectl rollout history deployment test-k8sdeployment.apps/test-k8sREVISION CHANGE-CAUSE1 &lt;none&gt;2 &lt;none&gt;3 kubectl set image deployment test-k8s test-k8s=ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v2-with-error --record=true# 回退到历史版本$ kubectl rollout undo deployment test-k8s --to-revision=2deployment.apps/test-k8s rolled back$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-6d9979f884-8m78s 1/1 Terminating 0 70s 10.244.0.25 node2 &lt;none&gt; &lt;none&gt;test-k8s-6d9979f884-d7kgf 1/1 Terminating 0 70s 10.244.0.27 node1 &lt;none&gt; &lt;none&gt;test-k8s-6d9979f884-mvcr8 1/1 Terminating 0 69s 10.244.0.26 node2 &lt;none&gt; &lt;none&gt;test-k8s-6d9979f884-w28bb 1/1 Terminating 0 68s 10.244.0.29 node1 &lt;none&gt; &lt;none&gt;test-k8s-6d9979f884-xlth7 1/1 Terminating 0 70s 10.244.0.28 node1 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-4skvd 1/1 Running 0 7s 10.244.0.27 node2 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-gltpn 1/1 Running 0 5s 10.244.0.31 node1 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-gzwtw 1/1 Running 0 5s 10.244.0.29 node2 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-jn69v 1/1 Running 0 7s 10.244.0.28 node2 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-nj9ml 1/1 Running 0 7s 10.244.0.30 node1 &lt;none&gt; &lt;none&gt;$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-k8s-cf5b7766c-4skvd 1/1 Running 0 78s 10.244.0.27 node2 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-gltpn 1/1 Running 0 76s 10.244.0.31 node1 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-gzwtw 1/1 Running 0 76s 10.244.0.29 node2 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-jn69v 1/1 Running 0 78s 10.244.0.28 node2 &lt;none&gt; &lt;none&gt;test-k8s-cf5b7766c-nj9ml 1/1 Running 0 78s 10.244.0.30 node1 &lt;none&gt; &lt;none&gt; 暂停运行1234# 暂停后，对 deployment 的修改不会立刻生效，恢复后才应用设置# kubectl rollout pause deployment DEPLOYMENT-NAME$ kubectl rollout pause deployment test-k8sdeployment.apps/test-k8s paused 恢复运行123# kubectl rollout resume deployment DEPLOYMENT-NAME$ kubectl rollout resume deployment test-k8sdeployment.apps/test-k8s resumed 输出到文件通过 yaml 格式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# kubectl get deployment DEPLOYMENT-NAME -o yaml$ kubectl get deployment test-k8s -o yamlapiVersion: apps/v1kind: Deploymentmetadata: annotations: deployment.kubernetes.io/revision: &quot;4&quot; kubectl.kubernetes.io/last-applied-configuration: | {&quot;apiVersion&quot;:&quot;apps/v1&quot;,&quot;kind&quot;:&quot;Deployment&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;test-k8s&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;spec&quot;:{&quot;replicas&quot;:5,&quot;selector&quot;:{&quot;matchLabels&quot;:{&quot;app&quot;:&quot;test-k8s&quot;}},&quot;template&quot;:{&quot;metadata&quot;:{&quot;labels&quot;:{&quot;app&quot;:&quot;test-k8s&quot;}},&quot;spec&quot;:{&quot;containers&quot;:[{&quot;image&quot;:&quot;ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1&quot;,&quot;name&quot;:&quot;test-k8s&quot;}]}}}} creationTimestamp: &quot;2022-01-07T06:16:44Z&quot; generation: 6 name: test-k8s namespace: default resourceVersion: &quot;16052&quot; uid: ac382819-09e6-415b-a021-5110e94a5c1cspec: progressDeadlineSeconds: 600 replicas: 5 revisionHistoryLimit: 10 selector: matchLabels: app: test-k8s strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: annotations: kubectl.kubernetes.io/restartedAt: &quot;2022-01-07T14:19:35+08:00&quot; creationTimestamp: null labels: app: test-k8s spec: containers: - image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1 imagePullPolicy: IfNotPresent name: test-k8s resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: {} terminationGracePeriodSeconds: 30status: availableReplicas: 5 conditions: - lastTransitionTime: &quot;2022-01-07T06:16:47Z&quot; lastUpdateTime: &quot;2022-01-07T06:16:47Z&quot; message: Deployment has minimum availability. reason: MinimumReplicasAvailable status: &quot;True&quot; type: Available - lastTransitionTime: &quot;2022-01-07T06:28:51Z&quot; lastUpdateTime: &quot;2022-01-07T06:28:51Z&quot; message: ReplicaSet &quot;test-k8s-cf5b7766c&quot; has successfully progressed. reason: NewReplicaSetAvailable status: &quot;True&quot; type: Progressing observedGeneration: 6 readyReplicas: 5 replicas: 5 updatedReplicas: 5 # kubectl get deployment DEPLOYMENT-NAME -o yaml &gt;&gt; 文件名$ kubectl get deployment test-k8s -o yaml &gt;&gt; deployment2.yaml$ ll总用量 8-rw-r--r-- 1 root root 2093 1月 7 14:33 deployment2.yaml-rw-r--r-- 1 root root 549 1月 7 14:16 deployment.yaml 通过 json 格式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697# kubectl get deployment DEPLOYMENT-NAME -o json$ kubectl get deployment test-k8s -o json{ &quot;apiVersion&quot;: &quot;apps/v1&quot;, &quot;kind&quot;: &quot;Deployment&quot;, &quot;metadata&quot;: { &quot;annotations&quot;: { &quot;deployment.kubernetes.io/revision&quot;: &quot;4&quot;, &quot;kubectl.kubernetes.io/last-applied-configuration&quot;: &quot;{\\&quot;apiVersion\\&quot;:\\&quot;apps/v1\\&quot;,\\&quot;kind\\&quot;:\\&quot;Deployment\\&quot;,\\&quot;metadata\\&quot;:{\\&quot;annotations\\&quot;:{},\\&quot;name\\&quot;:\\&quot;test-k8s\\&quot;,\\&quot;namespace\\&quot;:\\&quot;default\\&quot;},\\&quot;spec\\&quot;:{\\&quot;replicas\\&quot;:5,\\&quot;selector\\&quot;:{\\&quot;matchLabels\\&quot;:{\\&quot;app\\&quot;:\\&quot;test-k8s\\&quot;}},\\&quot;template\\&quot;:{\\&quot;metadata\\&quot;:{\\&quot;labels\\&quot;:{\\&quot;app\\&quot;:\\&quot;test-k8s\\&quot;}},\\&quot;spec\\&quot;:{\\&quot;containers\\&quot;:[{\\&quot;image\\&quot;:\\&quot;ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1\\&quot;,\\&quot;name\\&quot;:\\&quot;test-k8s\\&quot;}]}}}}\\n&quot; }, &quot;creationTimestamp&quot;: &quot;2022-01-07T06:16:44Z&quot;, &quot;generation&quot;: 6, &quot;name&quot;: &quot;test-k8s&quot;, &quot;namespace&quot;: &quot;default&quot;, &quot;resourceVersion&quot;: &quot;16052&quot;, &quot;uid&quot;: &quot;ac382819-09e6-415b-a021-5110e94a5c1c&quot; }, &quot;spec&quot;: { &quot;progressDeadlineSeconds&quot;: 600, &quot;replicas&quot;: 5, &quot;revisionHistoryLimit&quot;: 10, &quot;selector&quot;: { &quot;matchLabels&quot;: { &quot;app&quot;: &quot;test-k8s&quot; } }, &quot;strategy&quot;: { &quot;rollingUpdate&quot;: { &quot;maxSurge&quot;: &quot;25%&quot;, &quot;maxUnavailable&quot;: &quot;25%&quot; }, &quot;type&quot;: &quot;RollingUpdate&quot; }, &quot;template&quot;: { &quot;metadata&quot;: { &quot;annotations&quot;: { &quot;kubectl.kubernetes.io/restartedAt&quot;: &quot;2022-01-07T14:19:35+08:00&quot; }, &quot;creationTimestamp&quot;: null, &quot;labels&quot;: { &quot;app&quot;: &quot;test-k8s&quot; } }, &quot;spec&quot;: { &quot;containers&quot;: [ { &quot;image&quot;: &quot;ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1&quot;, &quot;imagePullPolicy&quot;: &quot;IfNotPresent&quot;, &quot;name&quot;: &quot;test-k8s&quot;, &quot;resources&quot;: {}, &quot;terminationMessagePath&quot;: &quot;/dev/termination-log&quot;, &quot;terminationMessagePolicy&quot;: &quot;File&quot; } ], &quot;dnsPolicy&quot;: &quot;ClusterFirst&quot;, &quot;restartPolicy&quot;: &quot;Always&quot;, &quot;schedulerName&quot;: &quot;default-scheduler&quot;, &quot;securityContext&quot;: {}, &quot;terminationGracePeriodSeconds&quot;: 30 } } }, &quot;status&quot;: { &quot;availableReplicas&quot;: 5, &quot;conditions&quot;: [ { &quot;lastTransitionTime&quot;: &quot;2022-01-07T06:16:47Z&quot;, &quot;lastUpdateTime&quot;: &quot;2022-01-07T06:16:47Z&quot;, &quot;message&quot;: &quot;Deployment has minimum availability.&quot;, &quot;reason&quot;: &quot;MinimumReplicasAvailable&quot;, &quot;status&quot;: &quot;True&quot;, &quot;type&quot;: &quot;Available&quot; }, { &quot;lastTransitionTime&quot;: &quot;2022-01-07T06:28:51Z&quot;, &quot;lastUpdateTime&quot;: &quot;2022-01-07T06:28:51Z&quot;, &quot;message&quot;: &quot;ReplicaSet \\&quot;test-k8s-cf5b7766c\\&quot; has successfully progressed.&quot;, &quot;reason&quot;: &quot;NewReplicaSetAvailable&quot;, &quot;status&quot;: &quot;True&quot;, &quot;type&quot;: &quot;Progressing&quot; } ], &quot;observedGeneration&quot;: 6, &quot;readyReplicas&quot;: 5, &quot;replicas&quot;: 5, &quot;updatedReplicas&quot;: 5 }} # kubectl get deployment DEPLOYMENT-NAME -o json &gt;&gt; 文件名$ kubectl get deployment test-k8s -o json &gt;&gt; deployment2.json$ ll总用量 12-rw-r--r-- 1 root root 3252 1月 7 14:36 deployment2.json-rw-r--r-- 1 root root 2093 1月 7 14:33 deployment2.yaml-rw-r--r-- 1 root root 549 1月 7 14:16 deployment.yaml 删除全部资源12345678910111213# 正常删除$ kubectl delete all --allpod &quot;test-k8s-cf5b7766c-4skvd&quot; deletedpod &quot;test-k8s-cf5b7766c-gltpn&quot; deletedpod &quot;test-k8s-cf5b7766c-gzwtw&quot; deletedpod &quot;test-k8s-cf5b7766c-jn69v&quot; deletedpod &quot;test-k8s-cf5b7766c-nj9ml&quot; deletedservice &quot;kubernetes&quot; deleteddeployment.apps &quot;test-k8s&quot; deletedreplicaset.apps &quot;test-k8s-6d9979f884&quot; deleted# 强制删除$ kubectl delete all --all --grace-period=0 --force 更多…更多官网关于 Deployment 的介绍 将 Pod 指定到某个节点运行：nodeselector限定 CPU、内存总量：文档 12345678910111213apiVersion: v1kind: Podmetadata: name: nginx labels: env: testspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeSelector: disktype: ssd 工作负载分类 Deployment适合无状态应用，所有pod等价，可替代 StatefulSet有状态的应用，适合数据库这种类型。 DaemonSet在每个节点上跑一个 Pod，可以用来做节点监控、节点日志收集等 Job &amp; CronJobJob 用来表达的是一次性的任务，而 CronJob 会根据其时间规划反复运行。 官方文档：文档","link":"/Kubernetes%E9%83%A8%E7%BD%B2%E5%BA%94%E7%94%A8/"},{"title":"Kubernetes集群的安装","text":"安装方式介绍 minikube只是一个 K8S 集群模拟器，只有一个节点的集群，只为测试用，master 和 worker 都在一起 直接用云平台 Kubernetes可视化搭建，只需简单几步就可以创建好一个集群。优点：安装简单，生态齐全，负载均衡器、存储等都给你配套好，简单操作就搞定 裸机安装（Bare Metal）至少需要两台机器（主节点、工作节点个一台），需要自己安装 Kubernetes 组件，配置会稍微麻烦点。可以到各云厂商按时租用服务器，费用低，用完就销毁。缺点：配置麻烦，缺少生态支持，例如负载均衡器、云存储。 minikube安装 需要提前安装好 Docker 必须用非root用户安装 安装非常简单，支持各种平台，安装方法 本篇以Centos 7.9为例： 安装Docker 安装minikube(除了安装在root下执行，其他都在非root下执行) 12345678$ curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-latest.x86_64.rpm % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 14.9M 100 14.9M 0 0 758k 0 0:00:20 0:00:20 --:--:-- 2207k$ sudo rpm -Uvh minikube-latest.x86_64.rpm准备中... ################################# [100%]正在升级/安装... 1:minikube-1.24.0-0 ################################# [100%] 启动集群1234567891011121314151617181920212223242526272829# 启动集群$ minikube start😄 minikube v1.24.0 on Centos 7.9.2009 (amd64)✨ Automatically selected the docker driver⛔ Requested memory allocation (1833MB) is less than the recommended minimum 1900MB. Deployments may fail.🧯 The requested memory allocation of 1833MiB does not leave room for system overhead (total system memory: 1833MiB). You may face stability issues.💡 Suggestion: Start minikube with less memory allocated: 'minikube start --memory=1833mb'👍 Starting control plane node minikube in cluster minikube🚜 Pulling base image ...💾 Downloading Kubernetes v1.22.3 preload ... &gt; preloaded-images-k8s-v13-v1...: 501.73 MiB / 501.73 MiB 100.00% 6.11 MiB &gt; index.docker.io/kicbase/sta...: 355.77 MiB / 355.78 MiB 100.00% 1.55 MiB❗ minikube was unable to download gcr.io/k8s-minikube/kicbase:v0.0.28, but successfully downloaded docker.io/kicbase/stable:v0.0.28 as a fallback image🔥 Creating docker container (CPUs=2, Memory=1833MB) ...❗ This container is having trouble accessing https://k8s.gcr.io💡 To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/🐳 Preparing Kubernetes v1.22.3 on Docker 20.10.8 ... ▪ Generating certificates and keys ... ▪ Booting up control plane ... ▪ Configuring RBAC rules ...🔎 Verifying Kubernetes components... ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5🌟 Enabled addons: default-storageclass, storage-provisioner💡 kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'🏄 Done! kubectl is now configured to use &quot;minikube&quot; cluster and &quot;default&quot; namespace by default 设置环境变量别名123$ alias kubectl=&quot;minikube kubectl --&quot;# 初始化 pod$ kubectl get pod 查看节点123456789101112# 查看节点。kubectl 是一个用来跟 K8S 集群进行交互的命令行工具$ kubectl -- get pods -A &gt; kubectl.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s &gt; kubectl: 44.73 MiB / 44.73 MiB [--------------] 100.00% 8.30 MiB p/s 5.6sNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-78fcd69978-t87dw 1/1 Running 0 104skube-system etcd-minikube 1/1 Running 0 119skube-system kube-apiserver-minikube 1/1 Running 0 2m1skube-system kube-controller-manager-minikube 1/1 Running 0 117skube-system kube-proxy-z44rx 1/1 Running 0 105skube-system kube-scheduler-minikube 1/1 Running 0 117skube-system storage-provisioner 1/1 Running 1 (101s ago) 116s 安装集群可视化（可选）12345678910$ minikube dashboard🔌 Enabling dashboard ... ▪ Using image kubernetesui/dashboard:v2.3.1 ▪ Using image kubernetesui/metrics-scraper:v1.0.7🤔 Verifying dashboard health ...🚀 Launching proxy ...🤔 Verifying proxy health ...🎉 Opening http://127.0.0.1:33489/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ in your default browser...👉 http://127.0.0.1:33489/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ 停止集群1234$ minikube stop✋ Stopping node &quot;minikube&quot; ...🛑 Powering off &quot;minikube&quot; via SSH ...🛑 1 node stopped. 清空集群12345$ minikube delete --all🔥 Deleting &quot;minikube&quot; in docker ...🔥 Removing /home/docker/.minikube/machines/minikube ...💀 Removed all traces of the &quot;minikube&quot; cluster.🔥 Successfully deleted all profiles 云平台搭建 腾讯云 TKE（控制台搜索容器） 阿里云 ACK （控制台搜索容器） 裸机搭建（Bare Metal）主节点需要组件 docker（也可以是其他容器运行时） kubectl 集群命令行交互工具 kubeadm 集群初始化工具 kubelet 管理 Pod 和容器，确保他们健康稳定运行。 工作节点需要组件 文档 docker（也可以是其他容器运行时） kubelet 管理 Pod 和容器，确保他们健康稳定运行 kubeadm 集群初始化工具 kube-proxy 网络代理，负责网络相关的工作 开始安装 你也可以试下 这个项目，用脚本快速搭建 K8S 裸机集群当然，为了更好的理解，你应该先手动搭建一次 设置对应主机名 1234567# 每个节点分别设置对应主机名$ hostnamectl set-hostname master$ hostnamectl set-hostname node1$ hostnamectl set-hostname node2# 查看是否修改成功$ hostname 修改 hosts 12345# 所有节点都修改 hosts,ip需要修改成实际的$ vi /etc/hosts10.211.55.101 master10.211.55.102 node110.211.55.103 node2 关闭 SELinux 123# 所有节点关闭 SELinux$ setenforce 0$ sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux 禁用交换分区(所有节点都执行) 临时关闭swap，重启后失效 12# 临时关闭swap，重启后失效$ swapoff -a 永久关闭 123$ swapoff -a# 编辑 /etc/fstab 删除或注释掉 swap 一行$ swapoff -a &amp;&amp; sudo sed -i 's/^.*swap/#&amp;/g' /etc/fstab 防火墙关闭 12# 所有节点确保防火墙关闭$ systemctl stop firewalld &amp;&amp; systemctl disable firewalld 添加安装源 12345678910111213141516# 所有节点 添加 k8s 安装源$ cat &lt;&lt;EOF &gt; kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF$ mv kubernetes.repo /etc/yum.repos.d/# 所有节点 添加 Docker 安装源$ yum install -y yum-utils$ yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装所需组件 12345# master 节点 安装 docker kubectl kubeadm kubelet$ yum install -y docker-ce kubectl kubeadm kubelet# node1 node2 节点 安装 docker kubeadm kubelet$ yum install -y docker-ce kubeadm kubelet 启动 kubelet、docker，并设置开机启动（所有节点） 1234$ systemctl enable kubelet$ systemctl start kubelet$ systemctl enable docker$ systemctl start docker 修改系统配置，在文件 /etc/sysctl.conf 追加一行 （所有节点） 12$ echo &quot;net.bridge.bridge-nf-call-iptables = 1&quot; &gt;&gt; /etc/sysctl.conf$ sysctl --system 修改 docker 配置123456789101112# kubernetes 官方推荐 docker 等使用 systemd 作为 cgroupdriver，否则 kubelet 启动不了$ cat &lt;&lt;EOF &gt; daemon.json{ &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;registry-mirrors&quot;: [&quot;https://lz2nib3q.mirror.aliyuncs.com&quot;]}EOF$ mv daemon.json /etc/docker/# 重启生效$ systemctl daemon-reload$ systemctl restart docker 初始化集群 用 kubeadm 初始化集群（仅在主节点执行）： 123456789101112131415# 初始化集群控制台 Control plane# 失败了可以用 kubeadm reset 重置# --pod-network-cidr 指定pod的IP地址范围，禁止与宿主机节点同网段，所以如果节点IP运行在192.168..，就使用10.0.0.0/16。如果是10.0..，就使用192.168.0.0/16$ kubeadm init --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers# 记得把 kubeadm join xxx 保存起来# 忘记了重新获取：kubeadm token create --print-join-command# 复制授权文件，以便 kubectl 可以有权限访问集群$ mkdir -p $HOME/.kube$ cp -i /etc/kubernetes/admin.conf $HOME/.kube/config$ chown $(id -u):$(id -g) $HOME/.kube/config# 在其他机器上创建 ~/.kube/config 文件也能通过 kubectl 访问到集群 把工作节点加入集群（只在工作节点跑） 1$ kubeadm join 10.211.55.101:6443 --token xxx --discovery-token-ca-cert-hash xxx 安装网络插件，否则 node 是 NotReady 状态（主节点跑） 1$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 查看集群状态 12345$ kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster Ready control-plane,master 24m v1.23.1node1 Ready &lt;none&gt; 7m17s v1.23.1node2 Ready &lt;none&gt; 3m52s v1.23.1 设置网络如果你运行 kubectl describe pod/pod-name 发现 Events 中有下面这个错误 1networkPlugin cni failed to set up pod &quot;test-k8s-68bb74d654-mc6b9_default&quot; network: open /run/flannel/subnet.env: no such file or directory 在每个节点创建文件/run/flannel/subnet.env写入以下内容即可解决 1234FLANNEL_NETWORK=10.244.0.0/16FLANNEL_SUBNET=10.244.0.1/24FLANNEL_MTU=1450FLANNEL_IPMASQ=true 清空集群 先清空与子节点的通信（主节点执行） 1234# kubectl drain &lt;node name&gt; --delete-emptydir-data --force --ignore-daemonsets$ kubectl drain node1 --delete-emptydir-data --force --ignore-daemonsets$ kubectl drain node2 --delete-emptydir-data --force --ignore-daemonsets 删除节点（主节点执行） 1234# kubectl delete node &lt;node name&gt;$ kubectl delete node node1$ kubectl delete node node2 重置 kubeadm（所有节点执行） 1$ kubeadm reset","link":"/Kubernetes%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E8%A3%85/"},{"title":"Linux 修改目录权限","text":"1. 实例：查看权限： 1ls -l xxx.xxx 注：xxx.xxx是文件名，或者不写文件名则是当前目录下所有文件 修改某个目录下的所有文件的权限，包括子目录中的文件，例子如下： 12345chmod 777 /home/user注：仅把/home/user目录的权限设置为rwxrwxrwxchmod -R 777 /home/user注：表示将整个/home/user目录与其中的文件和子目录的权限都设置为rwxrwxrwx`其中，参数`-R`表示启动递归处理 2. chmod 命令：chmod 用 3 个数字来表达对 用户（文件或目录的所有者），用户组（同组用户），其他用户 的权限：如：chmod 777 /test数字 7 是表达同时具有读，写，执行权限：读取–用数字 4 表示；写入–用数字 2 表示；执行–用数字 1 表示；按照规则，如你想设置/test 目录的权限为： 对用户可读可写：4（读取）+ 2（写入）= 6 ； 对用户组可读可执行：4（读取）+ 1（执行）= 5 ； 对其他用户仅可读：4（读取）； 这样就可以用命令： chmod 654 /test 3. 权限：针对文件的三种权限： 读文件内容（r），写数据到文件（w），作为命令执行文件（x）针对目录的三种权限： 读包含在目录中的文件名称（r）； 写信息到目录中去（增加和删除索引点的连结，w）； 搜索目录（能用该目录名称作为路径名去访问它所包含的文件和子目录）； 具体说明：有只读权限的用户不能用 cd 进入该目录：还必须有执行权限才能进入；有执行权限的用户只有在知道文件名，并拥有读权利的情况下才可以访问目录下的文件；必须有读和执行权限才可以 ls 列出目录清单，或使用 cd 命令进入目录；有目录的写权限，可以创建、删除或修改目录下的任何文件或子目录，即使使该文件或子目录属于其他用户也是如此； 几种常用权限实例： 1234567-rw------- (600) 只有所有者才有读和写的权限-rw-r--r-- (644) 只有所有者才有读和写的权限，组群和其他人只有读的权限-rwx------ (700) 只有所有者才有读，写，执行的权限-rwxr-xr-x (755) 只有所有者才有读，写，执行的权限，组群和其他人只有读和执行的权限-rwx--x--x (711) 只有所有者才有读，写，执行的权限，组群和其他人只有执行的权限-rw-rw-rw- (666) 每个人都有读写的权限-rwxrwxrwx (777) 每个人都有读写和执行的权限 4. 特殊权限：1234特殊权限有三种：--s--s--t； 所有人s权限：称为Set UID，简称为SUID的特殊权限；即当执行该文件时将具有该文件所有者的权限。 所在组s权限：称为Set GID，简称为SGID的特殊权限；即在该目录下建立的目录和文件都属于固定的组。 最后的t权限：称为Sticky Bit，简称为SBIT权限，只针对目录有效。它表示只能让所属主以及root可以删除（重命名/移动）该目录下的文件。 特殊权限赋予与取消： Set UID 12chmod u+s home/usr01/testchmod u-s home/usr01/test Set GID 12chmod g+s home/usr01/testchmod g-s home/usr01/test Sticky Bit 12chmod o+t home/usr01/testchmod o-t home/usr01/test 或者： 1chmod 0755 home/usr01/test 0755 最前面的 0 表示不使用任何特殊权限，该位上的数字可以是： 10（---）；1（--t）；2（-s-）；3（-st）；4（s--）；5（s-t）；6（ss-）；7（sst）； 注：如果该权限位上没有权限，特殊权限会显示为大写，如：-rwx–S–T 来源：Linux 修改目录权限","link":"/Linux-%E4%BF%AE%E6%94%B9%E7%9B%AE%E5%BD%95%E6%9D%83%E9%99%90/"},{"title":"Linux中createrepo自建仓库教程","text":"了解如何获取RPM包在默认配置下使用yum命令安装完软件后安装包是不会保留的，如果想在本地也留存一份安装包，只需要将yum配置文件/etc/yum.conf中的keepcache=0改为1即可，这样安装包都会留存在cachedir所指定的目录中，如下： 12345678910111213$ cat /etc/yum.conf [main]cachedir=/var/cache/yum/$basearch/$releaseverkeepcache=0debuglevel=2logfile=/var/log/yum.logexactarch=1obsoletes=1gpgcheck=1plugins=1installonly_limit=5bugtracker_url=http://bugs.centos.org/set_project.php?project_id=23&amp;ref=http://bugs.centos.org/bug_report_page.php?category=yumdistroverpkg=centos-release 该目录下还会根据不同的yum源创建不同的目录，软件包通过哪个源安装的就会保存在哪个目录中，同时相关依赖包也会自动下载，需要注意的如果执行了yum clean all的话是会删除掉这些安装包的： 123456789$ ll总用量 8drwxr-xr-x. 4 root root 278 4月 14 16:20 basedrwxr-xr-x. 4 root root 183 4月 14 16:20 extras-rw-r--r--. 1 root root 79 4月 14 16:21 timedhosts-rw-r--r--. 1 root root 451 4月 14 16:20 timedhosts.txtdrwxr-xr-x. 4 root root 183 4月 14 16:20 updates$ pwd/var/cache/yum/x86_64/7 如果仅仅只是想下载软件包而不进行安装，只需要加–downloadonly选项即可，示例: 1$ yum install httpd --downloadonly --downloaddir=/data/packages 详细用法见：Centos下载rpm全量依赖包的方式 自建YUM本地仓库 首先建立一个目录用于存放安装包，然后使用createrepo来创建repository仓库，如果系统里没有该命令的话需要先进行createrepo的安装 123$ mkdir /opt/yum/repo$ yum -y install createrepo$ createrepo /opt/yum/repo #将该目录制作成软件仓库 命令执行成功后会在该目录下创建一个repodata目录 123456789$ createrepo /opt/yum/repoSaving Primary metadataSaving file lists metadataSaving other metadataGenerating sqlite DBsSqlite DBs complete$ ll /opt/yum/repo/总用量 4drwxr-xr-x. 2 root root 4096 4月 14 16:29 repodata 创建.repo配置文件指向到本地仓库的路径，注意文件名一定要是.repo结尾 1234567891011# 文件内不要有中文# name: yum仓库的名字# baseurl: 仓库路径，由于是放在本地的只能用file协议而不是http# enabled: 开启该仓库# gpgcheck: 不做gpg检查$ vi /etc/yum.repos.d/buubiu.repo[buubiu]name=buubiubaseurl=file:///opt/yum/repoenabled=1gpgcheck=0 通过 yum repolist 命令查看仓库及包的数量，可以看到创建的buubiu仓库已经加载，而由于我们没有在目录中存放任何的rpm包，所以显示数量为0 1234567891011121314$ yum repolist已加载插件：fastestmirrorLoading mirror speeds from cached hostfile * base: mirrors.dgut.edu.cn * extras: mirrors.dgut.edu.cn * updates: mirrors.dgut.edu.cnbuubiu | 2.9 kB 00:00:00 buubiu/primary_db | 1.1 kB 00:00:00 源标识 源名称 状态base/7/x86_64 CentOS-7 - Base 10,072buubiu buubiu 0extras/7/x86_64 CentOS-7 - Extras 509updates/7/x86_64 CentOS-7 - Updates 3,732repolist: 14,313 创建YUM远程仓库在第二步的操作中只是在本地建立了一个YUM仓库，这样别人是无法使用的。所以通常会在计划任务中把公网YUM源同步到本地（推荐使用reposync），同步后再执行一次createrepo更新元数据，最后把仓库目录通过FTP或者Nginx、Apache、NFS服务等共享出来，然后客户端的配置文件中修改如下： 123456$ vi /etc/yum.repos.d/buubiu.repo[buubiu]name=buubiubaseurl=http://127.0.0.1enabled=1gpgcheck=0","link":"/Linux%E4%B8%ADcreaterepo%E8%87%AA%E5%BB%BA%E4%BB%93%E5%BA%93%E6%95%99%E7%A8%8B/"},{"title":"Linux中的pushd和popd用法","text":"介绍pushd和popd在linux中可以用来方便地在多个目录之间切换。 使用cd进行目录切换一般，Shell中都可以通过cd -命令回到之前的目录，下面是一个例子： 123456789$ pwd/opt/boms_auto_deploy$ cd /$ pwd/$ cd -/opt/boms_auto_deploy$ pwd/opt/boms_auto_deploy 实际上，cd -中，-就相当于变量$OLDPWD。cd -就相当于cd $OLDPWD。下面是一个例子： 12345678$ pwd/opt/boms_auto_deploy$ cd /$ echo $OLDPWD/opt/boms_auto_deploy$ cd $OLDPWD$ pwd/opt/boms_auto_deploy pushd、popd和dirspushd和popd是对一个目录栈进行操作，而dirs是显示目录栈的内容。而目录栈就是一个保存目录的栈结构，该栈结构的顶端永远都存放着当前目录（这里点从下面可以进一步看到） dirsdirs常用的参数： 选项 含义 无参数 显示所有目录栈，从左往右 -p 每行显示一条记录 -v 每行显示一条记录，同时展示该记录在栈中的index -c 清空目录栈 下面没有显示地对目录栈进行任何操作，我们来看下当前目录栈的内容是什么： 1234567891011121314$ pwd/opt/boms_auto_deploy$ dirs -p/opt/boms_auto_deploy$ dirs -v 0 /opt/boms_auto_deploy$ dirs/opt/boms_auto_deploy$ cd /$ dirs -v 0 /$ dirs -c$ dirs -v 0 / 可以看出，目录栈中只有一个目录(当然是在栈顶)，就是当前所在的目录。当切换目录之后，栈中的目录也随之改变。通过-c选项可以将目录栈中除当前目录之外的其它目录清除，由于上面的例子中目录栈只包含当前目录，所以没有变化 pushd每次pushd命令执行完成之后，默认都会执行一个dirs命令来显示目录栈的内容。pushd的用法主要有如下几种： pushd 目录 pushd后面如果直接跟目录使用，会切换到该目录并且将该目录置于目录栈的栈顶。(时时刻刻都要记住，目录栈的栈顶永远存放的是当前目录。如果当前目录发生变化，那么目录栈的栈顶元素肯定也变了；反过来，如果栈顶元素发生变化，那么当前目录肯定也变了。)下面是一个例子： 12345678910111213$ pwd/opt/boms_auto_deploy$ pushd // /opt/boms_auto_deploy$ dirs -v 0 / 1 /opt/boms_auto_deploy$ pushd /usr/usr / /opt/boms_auto_deploy$ dirs -v 0 /usr 1 / 2 /opt/boms_auto_deploy 这样，不难看出，用pushd在切换目录的同时，也将历史目录以栈结构的形式保存了下来。 pushd不带任何参数 pushd不带任何参数执行的效果就是，将目录栈最顶层的两个目录进行交换。前面说过，栈顶目录和当前目录一个发生变化，另一个也变。这样，实际上，就实现了cd -的功能。下面是一个例子(这个例子接上文的执行现场)： 12345678910111213141516$ dirs -v 0 /usr 1 / 2 /opt/boms_auto_deploy$ pushd/ /usr /opt/boms_auto_deploy$ dirs -v 0 / 1 /usr 2 /opt/boms_auto_deploy$ pushd/usr / /opt/boms_auto_deploy$ dirs -v 0 /usr 1 / 2 /opt/boms_auto_deploy pushd +n 到这里，可能会想如果想切换到目录栈中的任意一个目录，该如何？pushd +n正是这个作用：pushd +n切换到目录栈中的第n个目录(这里的n就是dirs -v命令展示的index)，并将该目录以栈循环的方式推到栈顶。下面是一个例子(接上文的执行现场)，注意栈循环的方式带来的栈中内容的变化规律： 12345678910111213141516$ dirs -v 0 /usr 1 / 2 /opt/boms_auto_deploy$ pushd +2/opt/boms_auto_deploy /usr /$ dirs -v 0 /opt/boms_auto_deploy 1 /usr 2 /$ pushd +1/usr / /opt/boms_auto_deploy$ dirs -v 0 /usr 1 / 2 /opt/boms_auto_deploy pushd -n 与 pushd +n相反 1234567891011121314151617181920$ dirs -v 0 /usr 1 / 2 /opt/boms_auto_deploy$ dirs /usr / /opt/boms_auto_deploy$ pushd -2/usr / /opt/boms_auto_deploy$ dirs/usr / /opt/boms_auto_deploy$ dirs -v 0 /usr 1 / 2 /opt/boms_auto_deploy$ pushd -1/ /opt/boms_auto_deploy /usr$ dirs -v 0 / 1 /opt/boms_auto_deploy 2 /usr 实际上，从默认的dirs命令的输出来解释：+n是指从左往右数，-n是指从右往左数，都是从0开始 popd每次popd命令执行完成之后，默认都会执行一个dirs命令来显示目录栈的内容。popd的用法主要有如下几种： popd不带参数 popd不带任何参数执行的效果，就是将目录栈中的栈顶元素出栈。这时，栈顶元素发生变化，自然当前目录也会发生相应的切换(接上文的执行现场)，下面是一个例子： 12345678910111213$ dirs -v 0 /usr 1 / 2 /opt/boms_auto_deploy$ popd/ /opt/boms_auto_deploy$ dirs -v 0 / 1 /opt/boms_auto_deploy$ popd/opt/boms_auto_deploy$ dirs -v 0 /opt/boms_auto_deploy popd +n 将目录栈中的第n个元素删除(这里的n就是命令dirs -v显示的目录index)。下面是一个例子： 123456789$ dirs -v 0 /usr 1 / 2 /opt/boms_auto_deploy$ popd +2/usr /$ dirs -v 0 /usr 1 / 这里可以发现，如果对于目录栈的操作没有引发栈顶元素的变化，将不会导致当前目录的切换。 popd -n 与 popd +n相反 123456789$ dirs -v 0 /usr 1 / 2 /opt/boms_auto_deploy$ popd -2/ /opt/boms_auto_deploy$ dirs -v 0 / 1 /opt/boms_auto_deploy 实际上，从默认的dirs命令的输出来解释：+n是指从左往右数，-n是指从右往左数，都是从0开始","link":"/Linux%E4%B8%AD%E7%9A%84pushd%E5%92%8Cpopd%E7%94%A8%E6%B3%95/"},{"title":"Linux管道符(&#39;|&#39;)","text":"利用Linux所提供的管道符“|”将两个命令隔开，管道符左边命令的输出就会作为管道符右边命令的输入。连续使用管道意味着第一个命令的输出会作为 第二个命令的输入，第二个命令的输出又会作为第三个命令的输入，依此类推。下面来看看管道是如何在构造一条Linux命令中得到应用的。 注意： 1、管道命令只处理前一个命令正确输出，不处理错误输出。 2、管道命令右边命令，必须能够接收标准输入流命令才行。 利用一个管道1$: rpm –qa | grep licq 这条命令使用一个管道符“|”建立了一个管道。管道将rpm -qa命令的输出（包括系统中所有安装的RPM包）作为grep命令的输入，从而列出带有licq字符的RPM包来。 利用多个管道1$: cat /etc/passwd | grep /bin/bash | wc -l 这条命令使用了两个管道，利用第一个管道将cat命令（显示passwd文件的内容）的输出送给grep命令，grep命令找出含有“/bin /bash”的所有行；第二个管道将grep的输出送给wc命令，wc命令统计出输入中的行数。这个命令的功能在于找出系统中有多少个用户使用bash。 管道命令与重定向区别区别是： 1、左边的命令应该有标准输出 | 右边的命令应该接受标准输入 左边的命令应该有标准输出 &gt; 右边只能是文件 左边的命令应该需要标准输入 &lt; 右边只能是文件 2、管道触发两个子进程执行”|”两边的程序；而重定向是在一个进程内执行 这些都是网上总结很多的，其实只要多加清楚用法，也一定有自己的一份不同描述。","link":"/Linux%E7%AE%A1%E9%81%93%E7%AC%A6/"},{"title":"Mac Launchpad 图标顺序大小个数设置","text":"重置 Launchpad 设置 重置 Dock 图标数据库在 Finder 中进入 ~/Library/Application Support/Dock/ 目录，删除该目录下的 desktoppicture.db 文件。或者在 Terminal 中键入 rm ~/Library/Application\\ Support/Dock/*.db &amp;&amp; killall Dock 后回车。 重置 Launchpad 图标数据库在 Terminal 中键入 defaults write com.apple.dock ResetLaunchPad -bool true &amp;&amp; killall Dock 后回车。 完成以上操作后，Launchpad 图标布局已经恢复默认设置，苹果官方提供的 App 都被重新排列到 Launchpad 第一屏幕中，然后根据自己的需要来进行重新排列 App 即可 调整 Launchpad 图标大小运行 终端 程序，执行以下命令： 调整每一列显示图标数量，7 表示每一列显示 7 个 1defaults write com.apple.dock springboard-rows -int 7 调整每一行显示图标数量，这里我用的是 8 1defaults write com.apple.dock springboard-columns -int 8 由于修改了每一页显示图标数量，可能需要重置 Launchpad 1defaults write com.apple.dock ResetLaunchPad -bool TRUE;killall Dock","link":"/Mac-Launchpad-%E5%9B%BE%E6%A0%87%E9%A1%BA%E5%BA%8F%E5%A4%A7%E5%B0%8F%E4%B8%AA%E6%95%B0%E8%AE%BE%E7%BD%AE/"},{"title":"Nacos使用","text":"什么是Nacos官方：https://nacos.io/zh-cn/index.html 英文缩写：Name Configurations 表示注册中心和配置中心 Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 总结：Nacos就是微服务架构中服务注册中心以及统一配置中心,用来替换原来的(eureka,consul)以及config组件。 安装Nacos准备环境Nacos 依赖 Java 环境来运行。如果您是从代码开始构建并运行Nacos，还需要为此配置 Maven环境，请确保是在以下版本环境中安装使用: 64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac。 64 bit JDK 1.8+；下载 &amp; 配置。 Maven 3.2.x+；下载 &amp; 配置。 下载Nacos（1.4.0）https://github.com/alibaba/nacos/releases 解压缩安装包到指定位置12345- bin 启动nacos服务的脚本目录- conf nacos的配置文件目录- target nacos的启动依赖存放目录- data nacos启动成功后保存数据的目录(启动后生成)- logs nacos的启动运行日志目录（启动后生成） 启动安装服务1234567- linux/unix/mac启动 打开终端进入nacos的bin目录执行如下命令 ./startup.sh -m standalone- windows启动 在 cmd中 执行 startup.cmd -m standalone 或者双击startup.cmd运行文件。 访问nacos的web服务管理界面http://localhost:8848/nacos/ 用户名 和 密码都是nacos 开发服务注册到Nacos创建项目并引入依赖分别创建服务消费者（users）和服务提供着（products）两个项目 12345&lt;!--引入nacos client 依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置文件12345678910#指定当前服务端口server.port=9099#指定服务名称spring.application.name=users#指定nacos服务地址spring.cloud.nacos.server-addr=localhost:8848#指定注册中心地址spring.cloud.nacos.discovery.server-addr=${spring.cloud.nacos.server-addr}#暴露所有web端点(可不加)management.endpoints.web.exposure.include=* 入口类加入服务注册注解注意：新版本之后这一步可以省略不写 123456789@SpringBootApplication@EnableDiscoveryClientpublic class Springcloudalibaba03Products9098Application { public static void main(String[] args) { SpringApplication.run(Springcloudalibaba03Products9098Application.class, args); }} 启动项目并查看nacos控制台 Nacos配合OpenFeign进行服务间调用 在服务提供着开发个接口 12345678910111213141516171819/** * @author buubiu **/@RestController@Slf4jpublic class ProductController { @Value(&quot;${server.port}&quot;) private int port; @GetMapping(&quot;/product/find&quot;) public Map&lt;String, Object&gt; find(@RequestParam(&quot;id&quot;) String id) { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); log.info(&quot;进入傻姑娘片服务，当前接收的商品id为：[{}]&quot;, id); map.put(&quot;status&quot;, true); map.put(&quot;msg&quot;,&quot;当前商品服务调用成功，查询商品id为：&quot;+id+&quot;,当前处理服务的端口为：&quot; + port); return map; }} 在服务消费者进行调用 通过restTemplate直接调用12345678910111213141516171819/** * @author buubiu **/@RestController@Slf4jpublic class UserController { @GetMapping(&quot;/user/getProductInfo&quot;) public String getProductInfo(String productId) { //第一种方式：通过restTemplate直接调用 RestTemplate restTemplate = new RestTemplate(); String forObject = restTemplate .getForObject(&quot;http://localhost:9098/product/find?id=&quot; + productId, String.class); log.info(&quot;返回的信息：[{}]&quot;, forObject); return forObject; }} DiscoveryClient (restTemplate + ribbon负载均衡客户端)自定义负载均衡 123456789101112131415161718192021222324/** * @author buubiu **/@RestController@Slf4jpublic class UserController { @Autowired private DiscoveryClient discoveryClient; @GetMapping(&quot;/user/getProductInfo&quot;) public String getProductInfo(String productId) { //restTemplate + ribbon 负载均衡客户端 DiscoveryClient LoadBalancerClient LoadBalanced注解形式 //第二种方式：DiscoveryClient获取到所有的服务器地址，然后再自定义负载均衡 List&lt;ServiceInstance&gt; productsServiceInstances = discoveryClient.getInstances(&quot;products&quot;); for (ServiceInstance productsServiceInstance: productsServiceInstances){ log.info(&quot;服务地址：[{}]&quot;,productsServiceInstance.getUri()); } log.info(&quot;返回的信息：[{}]&quot;, forObject); return forObject; }} LoadBalancerClient (restTemplate + ribbon负载均衡客户端)自动负载均衡 123456789101112131415161718192021222324/** * @author buubiu **/@RestController@Slf4jpublic class UserController { @Autowired private LoadBalancerClient loadBalancerClient; @GetMapping(&quot;/user/getProductInfo&quot;) public String getProductInfo(String productId) { //restTemplate + ribbon 负载均衡客户端 DiscoveryClient LoadBalancerClient LoadBalanced注解形式 //第三种方式：LoadBalancerClient 自动负载均衡 ServiceInstance productServiceInstance = loadBalancerClient.choose(&quot;products&quot;); log.info(&quot;当前处理服务负载均衡客户端主机为：[{}]&quot;,productServiceInstance.getUri()); String forObject = restTemplate .getForObject(productServiceInstance.getUri() + &quot;/product/find?id=&quot; + productId, String.class); log.info(&quot;返回的信息：[{}]&quot;, forObject); return forObject; }} LoadBalanced注解形式(restTemplate + ribbon负载均衡客户端) 首先创建一个具有负载均衡的RestTemplate对象 123456789101112/** * @author buubiu **/@Configurationpublic class RestTemplateConfig { @Bean @LoadBalanced //代表创建一个具有负载均衡的RestTemplate对象 public RestTemplate getRestTemplate() { return new RestTemplate(); }} 然后再去调用 12345678910111213141516171819202122/** * @author buubiu **/@RestController@Slf4jpublic class UserController { @Autowired private RestTemplate restTemplate; @GetMapping(&quot;/user/getProductInfo&quot;) public String getProductInfo(String productId) { //restTemplate + ribbon 负载均衡客户端 DiscoveryClient LoadBalancerClient LoadBalanced注解形式 //第四种方式：LoadBalanced注解形式 (新增RestTemplateConfig 配置类） String forObject = restTemplate .getForObject(&quot;http://products/product/find?id=&quot; + productId, String.class); log.info(&quot;返回的信息：[{}]&quot;, forObject); return forObject; }} openfeign调用（底层用ribbon做负载均衡）–推荐 首先创建调用商品服务的feign接口 1234567891011/** * 调用商品服务feign接口 * @author buubiu **/@FeignClient(&quot;products&quot;)public interface ProductClient { @GetMapping(&quot;/product/find&quot;) Map&lt;String, Object&gt; find(@RequestParam(&quot;id&quot;) String id);} 然后再去调用 1234567891011121314151617181920/** * @author buubiu **/@RestController@Slf4jpublic class UserController { @Autowired private ProductClient productClient; @GetMapping(&quot;/user/getProductInfo&quot;) public String getProductInfo(String productId) { //第五种方式：openfeign调用（底层用ribbon做负载均衡） Map&lt;String, Object&gt; map = productClient.find(productId); log.info(&quot;返回的信息：[{}]&quot;, map.toString()); return map.toString(); }} Nacos作为配置中心使用创建项目并引入依赖12345678910&lt;!--引入nacos client依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--引入nacos config 依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置文件由于要去获取配置中心的配置文件，所有本地的配置文件要改名为：bootstrap.proterties 12345678910111213141516171819##连接nacos配置中心#远程配置中心的地址spring.cloud.nacos.server-addr=localhost:8848#去指定nacos地址读取配置spring.cloud.nacos.config.server-addr=${spring.cloud.nacos.server-addr}#读取配置的命名空间ID(如果是默认public，不要配置)#spring.cloud.nacos.config.namespace=#读取配置的分组(默认DEFAULT_GROUP)spring.cloud.nacos.config.group=DEFAULT_GROUP## spring.application.name 和 spring.profiles.active 和 spring.cloud.nacos.config.file-extension 一起组成了配置中心的文件名称:configclient-prod.properties##配置应用名，也是配置中心的文件前缀spring.application.name=configclient#配置配中心的环境 是文件名称的中缀spring.profiles.active=prod#配置中心的文件后缀(默认properties)spring.cloud.nacos.config.file-extension=properties 在nacos中创建配置 编写控制器测试配置读取情况12345678910111213141516/** * @author buubiu **/@RestController@Slf4jpublic class TestController { @Value(&quot;${user.name}&quot;) private String name; public String test() { log.info(&quot;当前获取配置中name为：[{}]&quot;, name); return &quot;当前获取配置中name为：&quot;+name; }} 启动项目测试配置读取 DataId用来读取远程配置中心的中具体配置文件其完整格式如下: ${prefix}-${spring.profile.active}.${file-extension} prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix来配置。 spring.profile.active 即为当前环境对应的 profile，详情可以参考 Spring Boot文档。 注意：当 spring.profile.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成 ${prefix}.${file-extension} file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。 实现自动配置刷新默认情况下nacos已经实现了自动配置刷新功能，如果需要刷新配置直接在控制器中加入@RefreshScpoper注解即可 123456789101112131415161718/** * @author buubiu **/@RestController@Slf4j@RefreshScopepublic class TestController { @Value(&quot;${user.name}&quot;) private String name; @GetMapping(&quot;/test/test&quot;) public String test() { log.info(&quot;当前获取配置中name为：[{}]&quot;, name); return &quot;当前获取配置中name为：&quot;+name; }} 然后再控制台修改配置，刷新页面发现值变了 命名空间命名空间介绍（namespace）官方：https://github.com/alibaba/spring-cloud-alibaba/wiki/Nacos-config namespace命名空间是nacos针对于企业级开发设计用来针对于不同环境的区分,比如正在企业开发时有测试环境,生产环境,等其他环境,因此为了保证不同环境配置实现隔离,提出了namespace的概念,默认在nacos中存在一个public命名空间所有配置在没有指定命名空间时都在这个命名空间中获取配置,在实际开发时可以针对于不能环境创建不同的namespace空间。默认空间不能删除! 创建其他命名空间每个命名空间都有一个唯一id,这个id是读取配置时指定空间的唯一标识 在配置列表查看命名空间 在指定空间下创建配置文件 在项目中使用命名空间指定配置12345678910111213141516171819##连接nacos配置中心#远程配置中心的地址spring.cloud.nacos.server-addr=localhost:8848#去指定nacos地址读取配置spring.cloud.nacos.config.server-addr=${spring.cloud.nacos.server-addr}#读取配置的命名空间(如果是默认public，不要配置spring.cloud.nacos.config.namespace=e7a4564a-c135-4dfb-a77e-57b4a5c2c703#读取配置的分组(默认DEFAULT_GROUP)spring.cloud.nacos.config.group=DEFAULT_GROUP## spring.application.name 和 spring.profiles.active 和 spring.cloud.nacos.config.file-extension 一起组成了配置中心的文件名称:configclient-prod.properties##配置应用名，也是配置中心的文件前缀spring.application.name=configclient#配置配中心的环境 是文件名称的中缀spring.profiles.active=prod#配置中心的文件后缀(默认properties)spring.cloud.nacos.config.file-extension=properties 启动项目测试配置 配置分组分组介绍（GROUP）配置分组是对配置集进行分组，通过一个有意义的字符串（如 Buy 或 Trade ）来表示，不同的配置分组下可以有相同的配置集（Data ID）。当您在 Nacos 上创建一个配置时，如果未填写配置分组的名称，则配置分组的名称默认采用 DEFAULT_GROUP 。配置分组的常见场景：可用于区分不同的项目或应用，例如：学生管理系统的配置集可以定义一个group为：STUDENT_GROUP。 创建分组 项目读取指定分组的配置12345678910111213141516171819##连接nacos配置中心#远程配置中心的地址spring.cloud.nacos.server-addr=localhost:8848#去指定nacos地址读取配置spring.cloud.nacos.config.server-addr=${spring.cloud.nacos.server-addr}#读取配置的命名空间(如果是默认public，不要配置spring.cloud.nacos.config.namespace=e7a4564a-c135-4dfb-a77e-57b4a5c2c703#读取配置的分组(默认DEFAULT_GROUP)spring.cloud.nacos.config.group=BUUBIU## spring.application.name 和 spring.profiles.active 和 spring.cloud.nacos.config.file-extension 一起组成了配置中心的文件名称:configclient-prod.properties##配置应用名，也是配置中心的文件前缀spring.application.name=configclient#配置配中心的环境 是文件名称的中缀spring.profiles.active=prod#配置中心的文件后缀(默认properties)spring.cloud.nacos.config.file-extension=properties 启动项目测试配置","link":"/Nacos%E4%BD%BF%E7%94%A8/"},{"title":"Nexus3介绍与安装","text":"Nexus介绍目前 Nexus 分为 Nexus 2 和 Nexus 3 两个大版本，它们是并行的关系。与 Nexus 2 相比，Nexus 3 具有很多优势，例如支持更多的仓库格式（docker)、优化了用户的使用界面以及更加强大的搜索功能等等。这里介绍nexus3版本。 启动 Nexus 容器容器挂载目录需要提前拷贝出来，然后在删除重启 1234$ docker run -d --name nexus3 \\ -p 8081:8081 \\ -v nexus-data:/nexus-data \\ sonatype/nexus3 首次运行需等待 3-5 分钟，你可以使用 docker logs nexus3 -f 查看日志： 1234567891011$ docker logs -f nexus32021-12-16 09:31:12,339+0800 INFO [jetty-main-1] *SYSTEM org.sonatype.nexus.bootstrap.jetty.JettyServer - -------------------------------------------------Started Sonatype Nexus OSS 3.37.0-01------------------------------------------------- 如果你看到以上内容，说明 Nexus 已经启动成功，你可以使用浏览器打开 http://YourIP:8081 访问 Nexus 了。 首次运行请通过以下命令获取初始密码，或者看挂在目录文件也可以(/nexus-data/admin.password)： 123$ docker exec nexus3 cat /nexus-data/admin.passwordc0f6a2f2-b617-40fa-878e-82da37beeeb5 首次启动 Nexus 的默认帐号是 admin ，密码则是上边命令获取到的，点击右上角登录，首次登录需更改初始密码。","link":"/Nexus3%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%89%E8%A3%85/"},{"title":"Nexus3管理maven","text":"Nexus安装java后端开发人员，对于maven应该不会陌生，对于一些优秀的jar，我们都可以在maven仓库当中找到，同时maven还提供各类插件进行项目级的编译、打包等工作。通过maven很大程度解决了我们对于包管理的问题。无论是使用外部库还是内部发布的jar包管理，基于nexus的maven私服为我们提供了这中管理功能。 安装方式见：Nexus3介绍与安装 创建仓库登录之后可以点击页面上方的齿轮按钮按照下面的方法进行设置。 创建blob存储首先创建一个blob存储，用以和其他的仓库进行区分开来，当然，也可以不创建 创建私有仓库然后创建一个私有仓库的方法： Repository-&gt;Repositories 点击右边菜单 Create repository 选择 maven (hosted) 仓库区别： maven2 (hosted)类型的仓库链接到私有仓库中的镜像 maven2 (proxy) 类型的仓库链接到 Maven公共仓库 或其他私服 上，并缓存到 Nexus 中 maven2 (group) 类型的仓库把刚才的 hosted 与 proxy 添加在一起，主机在访问的时候默认下载私有仓库中的jar包，如果没有将链接到 代理服 中下载并缓存到 Nexus 中。 举例：以 hosted 方式创建 snapshots release仓库 Name: 仓库的名称 Maven2.Version policy：仓库类型，这里可以选择 snapshots、releases 在pom.xml区别是： pom.xml123&lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;#或者&lt;version&gt;1.0.0&lt;/version&gt; 举例：以proxy方式代理maven中央仓库 举例：以group方式创建仓库将上述所有存储进行分组，提供一个URL来配置到客户端pom文件中 添加访问权限菜单 Security-&gt;Realms 把 Docker Bearer Token Realm 移到右边的框中保存。 添加用户规则：菜单 Security-&gt;Roles-&gt;Create role 在 Privlleges 选项搜索 maven 把相应的规则移动到右边的框中然后保存。 添加用户：菜单 Security-&gt;Users-&gt;Create local user 在 Roles 选项中选中刚才创建的规则移动到右边的窗口保存。 配置客户端和项目以使用Nexus Repos修改配置文件 在~/.m2/settings.xml中配置，适用于所有项目 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.1.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.1.0 http://maven.apache.org/xsd/settings-1.1.0.xsd&quot;&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;nexus-group-local&lt;/id&gt; &lt;username&gt;buubiu&lt;/username&gt; &lt;password&gt;buubiu&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;profiles&gt; &lt;profile&gt; &lt;!--此id会在idea里面显示，供开发者选择激活--&gt; &lt;id&gt;profile-nexus-group-local&lt;/id&gt; &lt;!--一般的远程仓库--&gt; &lt;repositories&gt; &lt;repository&gt; &lt;!--此id要与上面server的id对应，才会用配置的用户密码--&gt; &lt;id&gt;nexus-group-local&lt;/id&gt; &lt;name&gt;nexus-group-local&lt;/name&gt; &lt;url&gt;http://your-host:8081/repository/maven_group_local/&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;!--表示更新的频率，值有：never, always,interval,daily, daily 为默认值--&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;!--表示更新的频率，值有：never, always,interval,daily, daily 为默认值--&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--下载插件的仓库--&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus-group-local&lt;/id&gt; &lt;name&gt;nexus-group-local&lt;/name&gt; &lt;url&gt;http://your-host:8081/repository/maven_group_local/&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/settings&gt; 如果想在一个项目里面用，就只单独配置pom.xml 1234567891011&lt;project ...&gt; ... &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus-group-local&lt;/id&gt; &lt;url&gt;http://your-host:8081/repository/maven_group_local/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 如果想发布项目也是分两种情况 适用于所有项目，在 ~/.m2/settings.xml中配置 1234567891011121314151617&lt;setting&gt; ... &lt;profile&gt; &lt;id&gt;profile-nexus-group-local-deploy&lt;/id&gt; &lt;properties&gt; &lt;altSnapshotDeploymentRepository&gt; nexus-group-local::default::http://your-host:8081/repository/maven_snapshot_local/ &lt;/altSnapshotDeploymentRepository&gt; &lt;altReleaseDeploymentRepository&gt; nexus-group-local::default::http://your-host:8081/repository/maven_release_local/ &lt;/altReleaseDeploymentRepository&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/settings&gt; 如果想单独配置，配置pom.xml即可 123456789101112131415&lt;project&gt; ... &lt;distributionManagement&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-group-local&lt;/id&gt; &lt;url&gt;http://your-host:8081/repository/maven_snapshot_local/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;repository&gt; &lt;id&gt;nexus-group-local&lt;/id&gt; &lt;url&gt;http://your-host:8081/repository/maven_release_local/&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt;&lt;/project&gt; 编译运行打包1$ mvn clean install -Dmaven.test.skip=true -P profile-nexus-group-local","link":"/Nexus3%E7%AE%A1%E7%90%86maven/"},{"title":"OpenFeign组件的使用","text":"简介官方：https://cloud.spring.io/spring-cloud-openfeign/reference/html/ Feign是一个声明式的伪Http客户端，它使得写Http客户端变得更简单。使用Feign，只需要创建一个接口并注解。它具有可插拔的注解特性(可以使用springmvc的注解)，可使用Feign 注解和JAX-RS注解。Feign支持可插拔的编码器和解码器。Feign默认集成了Ribbon，默认实现了负载均衡的效果并且springcloud为feign添加了springmvc注解的支持。 OpenFeign服务调用服务调用方 引入OpenFeign依赖12345&lt;!--引入openfeign依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 入口类加入注解开启OpenFeign支持123456789@SpringBootApplication@EnableFeignClients //开启openfeign支持public class Springcloud06Users9999Application { public static void main(String[] args) { SpringApplication.run(Springcloud06Users9999Application.class, args); }} 创建一个客户端调用接口123456789/** * @author buubiu **/@FeignClient(&quot;products&quot;) //用来标识当前接口是一个 feign 组件 value:书写调用服务serviceId(服务名称)public interface ProductClient { @GetMapping(&quot;/product/findAll&quot;) String findAll();} 使用feignClient客户端对象调用服务12345678910111213141516171819/** * @author buubiu **/@RestController@Slf4jpublic class TestFeignController { //注入客户端对象 @Autowired private ProductClient productClient; @GetMapping(&quot;/feign/test&quot;) public String test() { log.info(&quot;进入测试feign调用的方法....&quot;); String product = productClient.findAll(); log.info(&quot;调用商品服务返回的信息：[{}]&quot;, product); return product; }} 访问并测试服务http://localhost:9999/feign/test openFeign服务调用传递参数GET方式调用服务传递参数 在服务提供者添加方法(根据商品id获取商品信息) 1234567891011121314151617181920/** * @author buubiu **/@RestController@Slf4jpublic class ProductController { @Value(&quot;${server.port}&quot;) private int port; //根据商品id获取商品信息 @GetMapping(&quot;/product/findOneById&quot;) public Map&lt;String, Object&gt; findOneById(@RequestParam(&quot;productId&quot;) String productId) { log.info(&quot;商品服务，接收到商品id为：[{}]&quot;, productId); Map&lt;String, Object&gt; map = new HashMap&lt;String,Object&gt;(); map.put(&quot;msg&quot;,&quot;根据商品id查询商品信息成功！端口为: &quot;+port); map.put(&quot;status&quot;,true); return map; }} 在服务消费者的feignclient中声明对应的方法 12345678910/** * @author buubiu **/@FeignClient(&quot;products&quot;) //用来标识当前接口是一个 feign 组件 value:书写调用服务serviceId(服务名称)public interface ProductClient { //根据商品id获取商品信息 @GetMapping(&quot;/product/findOneById&quot;) Map&lt;String, Object&gt; findOneById(@RequestParam(&quot;productId&quot;) String productId);} 在服务消费者的业务中调用并传递参数 12345678910111213141516171819/** * @author buubiu **/@RestController@Slf4jpublic class TestFeignController { //注入客户端对象 @Autowired private ProductClient productClient; @GetMapping(&quot;/feign/findOneById&quot;) public Map&lt;String, Object&gt; findOneById(String productId) { log.info(&quot;用来测试OpenFiegn的GET方式参数传递&quot;); Map&lt;String, Object&gt; msg = productClient.findOneById(productId); log.info(&quot;调用返回信息：[{}]&quot;, msg); return msg; }} 访问并测试 POST方式调用服务传递参数传递零散参数（@RequestParam） 在服务提供者添加方法(根据商品name获取商品信息) 123456789101112131415161718192021/** * @author buubiu **/@RestController@Slf4jpublic class ProductController { @Value(&quot;${server.port}&quot;) private int port; //根据商品name获取商品信息 @PostMapping(&quot;/product/findOneByName&quot;) public Map&lt;String, Object&gt; findOneByName(@RequestParam(&quot;name&quot;) String name) { log.info(&quot;商品服务，接收到商品name为：[{}]&quot;, name); Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put(&quot;msg&quot;, &quot;根据商品name查询商品信息成功！端口为: &quot; + port); map.put(&quot;status&quot;, true); map.put(&quot;name&quot;, name); return map; }} 在服务消费者的feignclient中声明对应的方法 12345678910/** * @author buubiu **/@FeignClient(&quot;products&quot;) //用来标识当前接口是一个 feign 组件 value:书写调用服务serviceId(服务名称)public interface ProductClient { //根据商品name获取商品信息 @PostMapping(&quot;/product/findOneByName&quot;) Map&lt;String, Object&gt; findOneByName(@RequestParam(&quot;name&quot;) String name);} 在服务消费者的业务中调用并传递参数 12345678910111213141516171819/** * @author buubiu **/@RestController@Slf4jpublic class TestFeignController { //注入客户端对象 @Autowired private ProductClient productClient; @GetMapping(&quot;/feign/findOneByName&quot;) public Map&lt;String, Object&gt; findOneByName(String name) { log.info(&quot;用来测试OpenFiegn的POST方式传递零散参数&quot;); Map&lt;String, Object&gt; msg = productClient.findOneByName(name); log.info(&quot;调用返回信息：[{}]&quot;, msg); return msg; }} 访问并测试 传递对象参数（@RequestBody） 首先分别在服务提供者和服务消费者封装一个商品对象 1234567891011/** * @author buubiu **/@Datapublic class Product { private Integer productId; private String name; private Double price; private Date update;} 在服务提供者添加方法(新增商品信息) 123456789101112131415161718192021/** * @author buubiu **/@RestController@Slf4jpublic class ProductController { @Value(&quot;${server.port}&quot;) private int port; //新增商品信息 @PostMapping(&quot;/product/save&quot;) public Map&lt;String, Object&gt; save(@RequestBody Product product) { log.info(&quot;商品服务，接收到商品信息为：[{}]&quot;, product); Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put(&quot;msg&quot;, &quot;新增商品信息成功！端口为: &quot; + port); map.put(&quot;status&quot;, true); map.put(&quot;product&quot;, product); return map; }} 在服务消费者的feignclient中声明对应的方法 12345678910/** * @author buubiu **/@FeignClient(&quot;products&quot;) //用来标识当前接口是一个 feign 组件 value:书写调用服务serviceId(服务名称)public interface ProductClient { //新增商品信息 @PostMapping(&quot;/product/save&quot;) Map&lt;String, Object&gt; save(@RequestBody Product product);} 在服务消费者的业务中调用并传递参数 12345678910111213141516171819/** * @author buubiu **/@RestController@Slf4jpublic class TestFeignController { //注入客户端对象 @Autowired private ProductClient productClient; @GetMapping(&quot;/feign/save&quot;) public Map&lt;String, Object&gt; save(Product product) { log.info(&quot;用来测试OpenFiegn的POST方式传递对象参数&quot;); Map&lt;String, Object&gt; msg = productClient.save(product); log.info(&quot;调用返回信息：[{}]&quot;, msg); return msg; }} 访问并测试 OpenFeign超时设置超时说明默认情况下,openFiegn在进行服务调用时,要求服务提供方处理业务逻辑时间必须在1S内返回,如果超过1S没有返回则OpenFeign会直接报错,不会等待服务执行,但是往往在处理复杂业务逻辑是可能会超过1S,因此需要修改OpenFeign的默认服务调用超时时间。 修改默认超时时间在服务消费者方修改： 12345678#配置指定服务连接超时时间feign.client.config.products.connect-timeout=5000#配置指定服务等待超时时间feign.client.config.products.read-timeout=5000#配置所有服务连接超时时间#feign.client.config.default.connect-timeout=5000#配置所有服务连接等待时间#feign.client.config.default.read-timeout=5000 OpenFeign调用详细日志展示说明往往在服务调用时我们需要详细展示feign的日志,默认feign在调用是并不是最详细日志输出,因此在调试程序时应该开启feign的详细日志展示。feign对日志的处理非常灵活可为每个feign客户端指定日志记录策略，每个客户端都会创建一个logger默认情况下logger的名称是feign的全限定名需要注意的是，feign日志的打印只会DEBUG级别做出响应。 我们可以为feign客户端配置各自的logger.level对象，告诉feign记录那些日志logger.lever有以下的几种值 等级 说明 NONE 不记录任何日志 BASIC 仅仅记录请求方法，url，响应状态代码及执行时间 HEADERS 记录Basic级别的基础上，记录请求和响应的header FULL 记录HEADERS级别的基础上，记录body和元数据 配置日志展示在服务消费者方修改： 123456#开启指定服务日志展示feign.client.config.products.logger-level=full#开启全局服务日志展示#feign.client.config.default.logger-level=full#指定feign调用客户端对象所在包，必须是debug级别logging.level.com.buubiu.feignClients=debug","link":"/OpenFeign%E7%BB%84%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"OpenSSL创建证书","text":"一般Linux都自带安装了OpenSSL： 1234$ opensslOpenSSL&gt; versionOpenSSL 1.0.2k-fips 26 Jan 2017OpenSSL&gt; exit 基本概念 CA：认证机构。有自己的证书，可以拿自己的证书给别人签名然后收钱，这个星球上的CA被几家说英语的人垄断了。在这里我们会虚拟出一个CA机构，然后用他来给自己的证书认证签名。 (网站)证书 ：发送给客户端的证书，其中大部分是公钥。是一个包含自己网站的公钥、认证、签名等信息的文件。 (网站)私钥 ：服务器留存的解密私钥(server) *注意区分 CA机构的证书（可以拿来给其他网站证书签名）和 自己网站的证书（不可以），不一样* 基本流程 搞一个虚拟的CA机构，生成一个证书 生成一个自己的密钥，然后填写证书认证申请，拿给上面的CA机构去签名 于是就得到了（自建CA机构认证的）签名证书 首先，虚构一个CA认证机构出来1234567891011121314# 生成CA认证机构的证书私钥key# 需要设置密码，输入两次$ openssl genrsa -aes256 -out ca.key 2048# 去除密钥里的密码(可选),或者称之为公钥# 这里需要再输入一次原来设的密码$ openssl rsa -in ca.key -out ca.key# 用私钥ca.key生成CA认证机构的证书ca.crt,这里会让你输入一堆信息，比如组织名称、个人信息等(除了密码外其他的可以直接回车跳过，有的系统必须填个邮箱)# 其实就是相当于用私钥生成公钥，再把公钥包装成证书,如果第二步没有做，其实就是相当于用私钥包装成证书# 注意设置有效期（一般都设1年）$ openssl req -new -x509 -key ca.key -out ca.crt -days 365### 这个证书ca.crt有的又称为&quot;根证书&quot;,因为可以用来认证其他证书 其次，才是生成网站的证书用上面那个虚构出来的CA机构来认证，不收钱！ 12345678910111213141516171819# 生成自己网站的密钥server.key# 需要设置密码，输入两次$ openssl genrsa -aes256 -out server.key 2048# 去除密钥里的密码(可选),或者称之为公钥# 这里需要再输入一次原来设的密码$ openssl rsa -in server.key -out server.key# 生成自己网站证书的请求文件,这里会让你输入一堆信息，比如组织名称、个人信息等(除了密码外其他的可以直接回车跳过，有的系统必须填个邮箱)# 如果找外面的CA机构认证，也是发个请求文件给他们# 这个私钥(如果第二步没做，这里就是公钥）就包含在请求文件中了，认证机构要用它来生成网站的公钥，然后包装成一个证书$ openssl req -new -key server.key -out server.csr# 使用虚拟的CA认证机构的证书ca.crt，来对自己网站的证书请求文件server.csr进行处理，生成签名后的证书server.crt# 这里需要再输入一次原来设的 ca.key 的密码# 注意设置序列号和有效期（一般都设1年)$ openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -set_serial 01 -days 365 -out server.crt# 或者 设置序号可以用-CAcreateserial替代$ openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 365 -out server.crt 至此，私钥server.key和证书server.crt已全部生成完毕，可以放到网站源代码中去用了。 导出p12格式根证书1234# 把上面生成的 网站证书私钥 server.key 与 已签名的网站证书 server.crt 合并到一个pkcs12格式的文件# 这里需要再输入一次原来设的 server.key 的密码# 需要设置 server.p12 密码，输入两次$ openssl pkcs12 -export -clcerts -in server.crt -inkey server.key -out server.p12 导出jks格式根证书JKS证书是Java常用的证书： 在JDK bin目录下有个证书工具 keytool p12转jks123# 需要设置 server.jks 密码，输入两次# 这里需要再输入一次原来设的 server.p12 的密码$ keytool -importkeystore -srckeystore server.p12 -srcstoretype pkcs12 -deststoretype JKS -destkeystore server.jks crt转pfx在转jks1234567891011# crt转pfx## 这里需要再输入一次原来设的 server.key 的密码# 需要设置 server.pfx 密码，输入两次$ openssl pkcs12 -export -inkey server.key -in server.crt -out server.pfx# pfx转jks## 需要设置 server.jks 密码，输入两次# 这里需要再输入一次原来设的 server.pfx 的密码$ keytool -importkeystore -srckeystore server.pfx -srcstoretype pkcs12 -deststoretype jks -destkeystore server.jks keytool直接生成jks123456789101112131415161718192021222324# 创建一个新的JKS(Java Key Store)文件# 这里会让你输入一堆信息，比如组织名称、个人信息等(除了密码外其他的可以直接回车跳过，有的系统必须填个邮箱)# 这里会让你输入两个密码，一个是 server.jks 的密码， 还有一个是自己网站的密钥（类似上面章节 2.2 的 server.key）$ keytool -genkeypair -alias serverkey -keypass 123456 -storepass 123456 \\-dname &quot;C=CN,ST=JS,L=SZ,O=buubiu,OU=dev,CN=bu&quot; \\-keyalg RSA -keysize 2048 -validity 365 -keystore server.jks# 生成自己网站证书的请求文件# 这里需要再输入一次上一步设的 server.jks 的密码# 这里还需要再输入一次上一步设的 自己网站的密钥（server.key） 的密码$ keytool -certreq -alias serverkey -keyalg RSA -keystore server.jks -file server.csr# 使用虚拟的CA认证机构的证书ca.crt,用ca对请求文件进行签名（ca的生成请参考上面）# 使用虚拟的CA认证机构的证书ca.crt，来对自己网站的证书请求文件server.csr进行处理，生成签名后的证书server.crt# 这里需要再输入一次原来设的 ca.key 的密码# 注意设置序列号和有效期（一般都设1年)$ openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out server.crt -days 365# 或者 设置序号可以用-CAcreateserial替代$ openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 365# 导入已签名的证书 server.crt 到 server.jks# 这里需要再输入一次第一步设的 server.jks 的密码# 这里还需要再输入一次第一步设的 自己网站的密钥（server.key） 的密码$ keytool -importcert -alias serverkey -file server.crt -keystore server.jks 生成的jks转p12123456$ keytool -importkeystore -srckeystore server.jks -destkeystore server.p12 \\-srcalias serverkey -destalias serverkey \\-srcstoretype jks -deststoretype pkcs12 \\-srcstorepass 123456 -deststorepass 123456 \\-noprompt正在将密钥库 server.jks 导入到 server.p12...","link":"/OpenSSL%E5%88%9B%E5%BB%BA%E8%AF%81%E4%B9%A6/"},{"title":"Nexus3管理docker","text":"Nexus安装使用 Docker 官方的 Registry 创建的仓库面临一些维护问题。比如某些镜像删除以后空间默认是不会回收的，需要一些命令去回收空间然后重启 Registry。在企业中把内部的一些工具包放入 Nexus 中是比较常见的做法，最新版本 Nexus3.x 全面支持 Docker 的私有镜像。所以使用 Nexus3.x 一个软件来管理 Docker , Maven , Yum , PyPI 等是一个明智的选择。 安装方式见：Nexus3介绍与安装 创建仓库登录之后可以点击页面上方的齿轮按钮按照下面的方法进行设置。 创建blob存储首先创建一个blob存储，用以和其他的仓库进行区分开来，当然，也可以不创建 创建私有仓库然后创建一个私有仓库的方法： Repository-&gt;Repositories 点击右边菜单 Create repository 选择 docker (hosted) 仓库区别： docker (hosted)类型的仓库链接到私有仓库中的镜像 docker (proxy) 类型的仓库链接到 DockerHub 或其他私服 上，并缓存到 Nexus 中 docker (group) 类型的仓库把刚才的 hosted 与 proxy 添加在一起，主机在访问的时候默认下载私有仓库中的镜像，如果没有将链接到 DockerHub 中下载并缓存到 Nexus 中。 Name: 仓库的名称 HTTP: 仓库单独的访问端口（例如：5001） Hosted -&gt; Deployment pollcy: 请选择 Allow redeploy 否则无法上传 Docker 镜像。 添加访问权限菜单 Security-&gt;Realms 把 Docker Bearer Token Realm 移到右边的框中保存。 添加用户规则：菜单 Security-&gt;Roles-&gt;Create role 在 Privlleges 选项搜索 docker 把相应的规则移动到右边的框中然后保存。 添加用户：菜单 Security-&gt;Users-&gt;Create local user 在 Roles 选项中选中刚才创建的规则移动到右边的窗口保存。 Docker主机访问镜像仓库非https方式参考： 配置非 https 仓库地址 https方式参考：使用NGINX 加密代理配置 验证测试参考：测试私有仓库功能 只是docker login的用户名和密码是上面配置的nexus系统内的用户密码。 打标签上传后成功截图：","link":"/Nexus3%E7%AE%A1%E7%90%86docker/"},{"title":"RedHat8.4初始化","text":"介绍这边参考 centos； CentOS 8基于RHEL 8版本，最初发行时使用Linux kernel 4.18, GCC 8.2, glibc 2.28, systemd 239和GNOME 3.28。虽然yum仍然可以作为软件包管理器使用，并且您可以像以前一样继续使用它，但是它已经在后端进行了重大升级，从CentOS 7的版本3升级到CentOS 8的版本4。 网络设置修改静态IP12345678910111213141516171819202122232425$ vi /etc/sysconfig/network-scripts/ifcfg-enp0s5TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=noneDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noNAME=enp0s5UUID=be641410-f4bd-40c3-a3e6-558f3d5d0df2DEVICE=enp0s5ONBOOT=yesIPADDR=10.211.55.200PREFIX=24GATEWAY=10.211.55.1DNS1=10.211.55.1# 让网络设置生效$ systemctl restart NetworkManager$ nmcli connection up enp0s5 防火墙设置123456789101112131415161718192021$ systemctl start firewalld # 启动$ systemctl stop firewalld # 停止$ systemctl enable firewalld # 启用自动启动$ systemctl disable firewalld # 禁用自动启动# 查看状态$ systemctl status firewalld # 或者 $ firewall-cmd --state$ firewall-cmd --list-ports #查看端口开放列表# 添加端口$ firewall-cmd --permanent --zone=public --add-port=7001/tcp$ firewall-cmd --permanent --zone=public --add-port=8080/udp# 删除端口$ firewall-cmd --permanent --zone=public --remove-port=8080/tcp# 生效$ firewall-cmd --reload 修改yum源由于RedHat是付费版本Linux 因此不注册不能使用yum装软件。已开始在使用yum的时候会提示： 12345678$ yum -y install wgetFailed to set locale, defaulting to C.UTF-8Updating Subscription Management repositories.Unable to read consumer identityThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.Error: There are no enabled repositories in &quot;/etc/yum.repos.d&quot;, &quot;/etc/yum/repos.d&quot;, &quot;/etc/distro.repos.d&quot;. 解决办法就是用centos的源替换RedHat的源 备份提前备份 /etc/yum.repos.d/ 内的文件 1$ rename '.repo' '.repo.bak' /etc/yum.repos.d/*.repo 关闭官方订阅 Centos不需要执行 配置文件中关闭这个官方的订阅 1$ sed -i 's/enabled=1/enabled=0/g' /etc/yum/pluginconf.d/subscription-manager.conf 删除官方订阅(可选择) 1$ yum remove -y subscription-manager 新建 repo 源文件从阿里官方下载 下载最新的repo文件 12$ wget https://mirrors.aliyun.com/repo/Centos-vault-8.4.2105.repo -O /etc/yum.repos.d/Centos-vault-8.4.2105.repo$ wget https://mirrors.aliyun.com/repo/epel-archive-8.repo -O /etc/yum.repos.d/epel-archive-8.repo 替换repo文件中的链接 1$ sed -i 's/mirrors.cloud.aliyuncs.com/url_tmp/g' /etc/yum.repos.d/Centos-vault-8.4.2105.repo &amp;&amp; sed -i 's/mirrors.aliyun.com/mirrors.cloud.aliyuncs.com/g' /etc/yum.repos.d/Centos-vault-8.4.2105.repo &amp;&amp; sed -i 's/url_tmp/mirrors.aliyun.com/g' /etc/yum.repos.d/Centos-vault-8.4.2105.repo 手动输入12$ vi /etc/yum.repos.d/Centos-vault-8.4.2105.repo$ vi /etc/yum.repos.d/epel-archive-8.repo CentOS-8.4.2105.repo CentOS-8.4.2105.repo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# CentOS-8.4.2105.repo## The mirror system uses the connecting IP address of the client and the# update status of each mirror to pick mirrors that are updated to and# geographically close to the client. You should use this for CentOS updates# unless you are manually picking other mirrors.## If the mirrorlist= does not work for you, as a fall back you can try the # remarked out baseurl= line instead.## [base]name=CentOS-8.4.2105 - Base - mirrors.cloud.aliyuncs.combaseurl=http://mirrors.cloud.aliyuncs.com/centos-vault/8.4.2105/BaseOS/$basearch/os/ http://mirrors.aliyuncs.com/centos-vault/8.4.2105/BaseOS/$basearch/os/ http://mirrors.aliyun.com/centos-vault/8.4.2105/BaseOS/$basearch/os/gpgcheck=0gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-Official#additional packages that may be useful[extras]name=CentOS-8.4.2105 - Extras - mirrors.cloud.aliyuncs.combaseurl=http://mirrors.cloud.aliyuncs.com/centos-vault/8.4.2105/extras/$basearch/os/ http://mirrors.aliyuncs.com/centos-vault/8.4.2105/extras/$basearch/os/ http://mirrors.aliyun.com/centos-vault/8.4.2105/extras/$basearch/os/gpgcheck=0gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-Official#additional packages that extend functionality of existing packages[centosplus]name=CentOS-8.4.2105 - Plus - mirrors.cloud.aliyuncs.combaseurl=http://mirrors.cloud.aliyuncs.com/centos-vault/8.4.2105/centosplus/$basearch/os/ http://mirrors.aliyuncs.com/centos-vault/8.4.2105/centosplus/$basearch/os/ http://mirrors.aliyun.com/centos-vault/8.4.2105/centosplus/$basearch/os/gpgcheck=0enabled=0gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-Official[PowerTools]name=CentOS-8.4.2105 - PowerTools - mirrors.cloud.aliyuncs.combaseurl=http://mirrors.cloud.aliyuncs.com/centos-vault/8.4.2105/PowerTools/$basearch/os/ http://mirrors.aliyuncs.com/centos-vault/8.4.2105/PowerTools/$basearch/os/ http://mirrors.aliyun.com/centos-vault/8.4.2105/PowerTools/$basearch/os/gpgcheck=0enabled=0gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-Official[AppStream]name=CentOS-8.4.2105 - AppStream - mirrors.cloud.aliyuncs.combaseurl=http://mirrors.cloud.aliyuncs.com/centos-vault/8.4.2105/AppStream/$basearch/os/ http://mirrors.aliyuncs.com/centos-vault/8.4.2105/AppStream/$basearch/os/ http://mirrors.aliyun.com/centos-vault/8.4.2105/AppStream/$basearch/os/gpgcheck=0gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-Official epel-archive-8.repo epel-archive-8.repo1234567891011121314151617[epel-archive]name=Extra Packages for Enterprise Linux 8 - $basearchbaseurl=http://mirrors.aliyun.com/epel-archive/8/Everything/$basearchenabled=1gpgcheck=0[epel-archive-debuginfo]name=Extra Packages for Enterprise Linux 8 - $basearch - Debugbaseurl=http://mirrors.aliyun.com/epel-archive/8/Everything/$basearch/debugenabled=0gpgcheck=0[epel-archive-source]name=Extra Packages for Enterprise Linux 8 - $basearch - Sourcebaseurl=http://mirrors.aliyun.com/epel-archive/8/Everything/SRPMSenabled=0gpgcheck=0 重新创建缓存1$ yum clean all &amp;&amp; yum makecache","link":"/RedHat8-4%E5%88%9D%E5%A7%8B%E5%8C%96/"},{"title":"Seata与事务简介","text":"Seata 是什么?Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。 中文官方站点：https://seata.io/zh-cn/ seata github开源地址：https://github.com/seata 分布式事务简介本地事务在计算机系统中，更多的是通过关系型数据库来控制事务，这是利用数据库本身的事务特性来实现的， 因此叫数据库事务，由于应用主要靠关系数据库来控制事务，而数据库通常和应用在同一个服务器，所 以基于关系型数据库的事务又被称为本地事务。 数据库事务的四大特性：ACID A（Atomic）：原子性，构成事务的所有操作，要么都执行完成，要么全部不执行，不可能出现部分成 功部分失败的情况。 C（Consistency）：一致性，在事务执行前后，数据库的一致性约束没有被破坏。比如：张三向李四转 100 元，转账前和转账后的数据是正确状态这叫一致性，如果出现张三转出 100 元，李四账户没有增加 100 元这就出现了数 据错误，就没有达到一致性。 I（Isolation）：隔离性，数据库中的事务一般都是并发的，隔离性是指并发的两个事务的执行互不干 扰，一个事务不能看到其他事务的运行过程的中间状态。通过配置事务隔离级别可以比避免脏读、重复 读问题。 D（Durability）：持久性，事务完成之后，该事务对数据的更改会持久到数据库，且不会被回滚。 数据库事务在实现时会将一次事务的所有操作全部纳入到一个不可分割的执行单元，该执行单元的所有 操作要么都成功，要么都失败，只要其中任一操作执行失败，都将导致整个事务的回滚。 分布式事务随着互联网的快速发展，软件系统由原来的单体应用转变为分布式应用 分布式系统会把一个应用系统拆分为可独立部署的多个服务，因此需要服务与服务之间远程协作才能完 成事务操作，这种分布式系统环境下由不同的服务之间通过网络远程协作完成事务称之为分布式事务， 例如用户注册送积分事务、创建订单减库存事务，银行转账事务等都是分布式事务。","link":"/Seata%E4%B8%8E%E4%BA%8B%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"title":"Sentinel流量卫兵的使用","text":"什么是Sentinel 官方： https://spring-cloud-alibaba-group.github.io/github-pages/hoxton/en-us/index.html#_introduction_of_sentinel https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D As microservices become popular, the stability of service calls is becoming increasingly important. Sentinel takes “flow” as the breakthrough point, and works on multiple fields including flow control, circuit breaking and load protection to protect service reliability. —[摘自官网] 翻译：随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 通俗定义：用来在微服务系统中保护微服务的作用， 如何 服务雪崩 服务熔断 服务降级 就是用来替换hystrix 特性 丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。 完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。 Sentinel使用sentinel提供了两个服务组件 一个是 sentinel 用来实现微服务系统中服务熔断、降级等功能。这点和hystrix 类似 一个是 sentinel dashboard 用来监控微服务系统中流量调用等情况。这点和hystrix dashboard类似 sentinel dashboard的安装下载https://github.com/alibaba/Sentinel/releases 启动仪表盘是个jar包可以直接通过java命令启动 如: java -jar 方式运行 默认端口为 8080 1java -Dserver.port=8888 -jar sentinel-dashboard-1.8.0.jar 访问WEB界面http://localhost:8888 登录用户名和密码默认都是：sentinel Sentinel实时监控服务创建项目引入依赖12345&lt;!--引入sentinel 依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置文件12345678910111213141516server.port=8789spring.application.name=nacosclientspring.cloud.nacos.server-addr=localhost:8848spring.cloud.nacos.discovery.server-addr=${spring.cloud.nacos.server-addr}management.endpoints.web.exposure.include=*#开启sentinel（默认开启）spring.cloud.sentinel.enabled=true#开启sentinel立即加载，即不需要先调用才会有监控spring.cloud.sentinel.eager=true#设置sentinel dashboard地址spring.cloud.sentinel.transport.dashboard=localhost:8888#设置与dashboard通信的端口(默认8719)spring.cloud.sentinel.transport.port=8719 启动项目并测试访问dashboard界面查看服务监控默认情况下sentiel为延迟加载,不会在启动之后立即创建服务监控,需要对服务进行调用时才会初始化 开发控制服务12345678910111213141516171819/** * @author buubiu **/@RestController@Slf4jpublic class TestController { @GetMapping(&quot;/test/test&quot;) public String test() { log.info(&quot;进入test服务！！！&quot;); return &quot;test服务调用成功！！！&quot;; } @GetMapping(&quot;/test/test1&quot;) public String test1() { log.info(&quot;进入test1服务！！！&quot;); return &quot;test1服务调用成功！！！&quot;; }} 启动项目并进行调用 查看监控界面 Sentinel流量控制介绍官方：https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 流量控制（flow control），其原理是监控应用流量的 QPS 或并发线程数等指标，当达到指定的阈值时对流量进行控制，以避免被瞬时的流量高峰冲垮，从而保障应用的高可用性。 同一个资源可以创建多条限流规则。FlowSlot 会对该资源的所有限流规则依次遍历，直到有规则触发限流或者所有规则遍历完毕。 一条限流规则主要由下面几个因素组成，我们可以组合这些元素来实现不同的限流效果： resource：资源名，即限流规则的作用对象（一般都写请求路径，也可以写请求的别名，别名是注解SentinelResource的value值） count: 限流阈值 grade: 限流阈值类型（QPS 或并发线程数） limitApp: 流控针对的调用来源，若为 default 则不区分调用来源 strategy: 调用关系限流策略 controlBehavior: 流量控制效果（直接拒绝、Warm Up、匀速排队） 流量控制主要有两种统计类型，一种是统计并发线程数，另外一种则是统计 QPS。 QPS限流配置QPS流量控制 访问测试每秒只能最大接收1个请求，超过1个报错 线程数限流配置线程数限流 访问测试用JMeter测试 流控模式有三种模式 直接限流官方：https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 定义：标识流量控制规则到达阈值直接触发流量控制 关联限流官方：https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 定义：当两个资源之间具有资源争抢或者依赖关系的时候，这两个资源便具有了关联。比如对数据库同一个字段的读操作和写操作存在争抢，读的速度过高会影响写得速度，写的速度过高会影响读的速度。如果放任读写操作争抢资源，则争抢本身带来的开销会降低整体的吞吐量。可使用关联限流来避免具有关联关系的资源之间过度的争抢，举例来说，read_db 和 write_db 这两个资源分别代表数据库读写，我们可以给 read_db 设置限流规则来达到写优先的目的：设置 strategy 为 RuleConstant.STRATEGY_RELATE 同时设置 refResource 为 write_db。这样当写库操作过于频繁时，读数据的请求会被限流。 链路限流官方：https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 定义： NodeSelectorSlot 中记录了资源之间的调用链路，这些资源通过调用关系，相互之间构成一棵调用树。这棵树的根节点是一个名字为 machine-root 的虚拟节点，调用链的入口都是这个虚节点的子节点。 一棵典型的调用树如下图所示： 1234567 machine-root / \\ / \\ Entrance1 Entrance2 / \\ / \\DefaultNode(nodeA) DefaultNode(nodeA) 上图中来自入口 Entrance1 和 Entrance2 的请求都调用到了资源 NodeA，Sentinel 允许只根据某个入口的统计信息对资源限流。比如我们可以设置 strategy 为 RuleConstant.STRATEGY_CHAIN，同时设置 refResource 为 Entrance1 来表示只有从入口 Entrance1 的调用才会记录到 NodeA 的限流统计当中，而不关心经 Entrance2 到来的调用。 流控效果直接拒绝（RuleConstant.CONTROL_BEHAVIOR_DEFAULT）方式是默认的流量控制方式，当QPS超过任意规则的阈值后，新的请求就会被立即拒绝，拒绝方式为抛出FlowException。 Warm Up（RuleConstant.CONTROL_BEHAVIOR_WARM_UP）方式，即预热/冷启动方式。当系统长期处于低水位的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过”冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。更多:https://github.com/alibaba/Sentinel/wiki/%E9%99%90%E6%B5%81---%E5%86%B7%E5%90%AF%E5%8A%A8 匀速排队(RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER）方式会严格控制请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法。 只能对请求进行排队等待更多:https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6-%E5%8C%80%E9%80%9F%E6%8E%92%E9%98%9F%E6%A8%A1%E5%BC%8F 熔断降级介绍官方：https://github.com/alibaba/Sentinel/wiki/%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7 除了流量控制以外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。由于调用关系的复杂性，如果调用链路中的某个资源不稳定，最终会导致请求发生堆积。Sentinel 熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联错误。当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException）。 注意：本文档针对 Sentinel 1.8.0 以下版本。1.8.0 版本及以上对熔断降级特性进行了全新的改进升级，请使用最新版本以更好地利用熔断降级的能力。 降级策略平均响应时间 (DEGRADE_GRADE_RT)当 1s 内持续进入 N （默认最少5）个请求，对应时刻的平均响应时间（秒级）均超过阈值（count，以 ms 为单位），那么在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地熔断（抛出 DegradeException）。注意 Sentinel 默认统计的 RT 上限是 4900 ms，超出此阈值的都会算作 4900 ms，若需要变更此上限可以通过启动配置项 -Dcsp.sentinel.statistic.max.rt=xxx 来配置。 异常比例 (DEGRADE_GRADE_EXCEPTION_RATIO)当资源的每秒请求量 &gt;= N（可配置），并且每秒异常总数占通过量的比值超过阈值（DegradeRule 中的 count）之后，资源进入降级状态，即在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 异常数 (DEGRADE_GRADE_EXCEPTION_COUNT)当资源近 1 分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若 timeWindow 小于 60s，则结束熔断状态后仍可能再进入熔断状态。 @SentinelResource注解介绍官方：https://github.com/alibaba/Sentinel/wiki/%E6%B3%A8%E8%A7%A3%E6%94%AF%E6%8C%81 注意：注解方式埋点不支持 private 方法。 @SentinelResource 用于定义资源，并提供可选的异常处理和 fallback 配置项。 @SentinelResource 注解包含以下属性： value：资源名称，必需项（不能为空） entryType：entry 类型，可选项（默认为 EntryType.OUT） blockHandler / blockHandlerClass: blockHandler 对应处理 BlockException 的函数名称，可选项。blockHandler 函数访问范围需要是 public，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后加一个额外的参数，类型为 BlockException。blockHandler 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 blockHandlerClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 fallback/fallbackClass：fallback 函数名称，可选项，用于在抛出异常的时候提供 fallback 处理逻辑。fallback 函数可以针对所有类型的异常（除了exceptionsToIgnore里面排除掉的异常类型）进行处理。fallback 函数签名和位置要求： 返回值类型必须与原函数返回值类型一致； 方法参数列表需要和原函数一致，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 fallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 defaultFallback（since 1.6.0）：默认的 fallback 函数名称，可选项，通常用于通用的 fallback 逻辑（即可以用于很多服务或方法）。默认 fallback 函数可以针对所有类型的异常（除了exceptionsToIgnore里面排除掉的异常类型）进行处理。若同时配置了 fallback 和 defaultFallback，则只有 fallback 会生效。defaultFallback 函数签名要求： 返回值类型必须与原函数返回值类型一致； 方法参数列表需要为空，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 defaultFallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 exceptionsToIgnore（since 1.6.0）：用于指定哪些异常被排除掉，不会计入异常统计中，也不会进入 fallback 逻辑中，而是会原样抛出。 1.8.0 版本开始，defaultFallback 支持在类级别进行配置。 注：1.6.0 之前的版本 fallback 函数只针对降级异常（DegradeException）进行处理，不能针对业务异常进行处理。 特别地，若 blockHandler 和 fallback 都进行了配置，则被限流降级而抛出 BlockException 时只会进入 blockHandler 处理逻辑。若未配置 blockHandler、fallback 和 defaultFallback，则被限流降级时会将 BlockException 直接抛出（若方法本身未定义 throws BlockException 则会被 JVM 包装一层 UndeclaredThrowableException）。 举例使用BlockHandler/BlockHandlerClass使用blockHandler / blockHandlerClass: blockHandler 对应处理 BlockException 的函数名称，可选项。blockHandler 函数访问范围需要是 public，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后加一个额外的参数，类型为 BlockException。blockHandler 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 blockHandlerClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 改造原来的controller 1234567891011121314151617/** * @author buubiu **/@RestController@Slf4jpublic class TestController { @GetMapping(&quot;/test/test&quot;) @SentinelResource(value = &quot;aaa&quot;,blockHandler = &quot;testBlockHandler&quot;) public String test(int id) { log.info(&quot;进入test服务！！！,传入的ID为：[{}]&quot;,id); if (id &lt; 0) { throw new RuntimeException(&quot;非法参数！！！&quot;); } return &quot;test服务调用成功！！！&quot;+id; }} 添加blockHandler的FallBack方法 12345678910111213141516171819202122232425262728/** * @author buubiu **/@RestController@Slf4jpublic class TestController { @GetMapping(&quot;/test/test&quot;) @SentinelResource(value = &quot;aaa&quot;,blockHandler = &quot;testBlockHandler&quot;) public String test(int id) { log.info(&quot;进入test服务！！！,传入的ID为：[{}]&quot;,id); if (id &lt; 0) { throw new RuntimeException(&quot;非法参数！！！&quot;); } return &quot;test服务调用成功！！！&quot;+id; } //处理流控异常、降级异常 自定义的异常信息方法 public String testBlockHandler(int id, BlockException blockException) { if (blockException instanceof FlowException) { return &quot;活动异常火爆，当前请求被限流！！！&quot; + blockException.getClass().getSimpleName(); } if (blockException instanceof DegradeException) { return &quot;当前服务已被降级处理，请稍好再试！！！&quot; + blockException.getClass().getSimpleName(); } return &quot;当前服务不可用！！！&quot;; }} 启动项目，测试流控和降级 注意：由于我们针对/test/test使用了注解，并且加了value值，所以在所有的规则配置中的资源名，不能为请求路径了，应该为value的值，即aaa 测试流控 测试降级(注意：要先删除流控规则，否则不好测试出效果) Fallback/FallbackClass使用fallback/fallbackClass：fallback 函数名称，可选项，用于在抛出异常的时候提供 fallback 处理逻辑。fallback 函数可以针对所有类型的异常（除了exceptionsToIgnore里面排除掉的异常类型）进行处理。fallback 函数签名和位置要求： 返回值类型必须与原函数返回值类型一致； 方法参数列表需要和原函数一致，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 fallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 改造原来的controller 12345678910111213141516171819202122232425262728/** * @author buubiu **/@RestController@Slf4jpublic class TestController { @GetMapping(&quot;/test/test&quot;) @SentinelResource(value = &quot;aaa&quot;,blockHandler = &quot;testBlockHandler&quot;, fallback = &quot;testFallBack&quot;) public String test(int id) { log.info(&quot;进入test服务！！！,传入的ID为：[{}]&quot;,id); if (id &lt; 0) { throw new RuntimeException(&quot;非法参数！！！&quot;); } return &quot;test服务调用成功！！！&quot;+id; } //处理流控异常、降级异常 自定义的异常信息方法 public String testBlockHandler(int id, BlockException blockException) { if (blockException instanceof FlowException) { return &quot;活动异常火爆，当前请求被限流！！！&quot; + blockException.getClass().getSimpleName(); } if (blockException instanceof DegradeException) { return &quot;当前服务已被降级处理，请稍好再试！！！&quot; + blockException.getClass().getSimpleName(); } return &quot;当前服务不可用！！！&quot;; }} 添加FackBack的FallBack方法 123456789101112131415161718192021222324252627282930313233/** * @author buubiu **/@RestController@Slf4jpublic class TestController { @GetMapping(&quot;/test/test&quot;) @SentinelResource(value = &quot;aaa&quot;,blockHandler = &quot;testBlockHandler&quot;, fallback = &quot;testFallBack&quot;) public String test(int id) { log.info(&quot;进入test服务！！！,传入的ID为：[{}]&quot;,id); if (id &lt; 0) { throw new RuntimeException(&quot;非法参数！！！&quot;); } return &quot;test服务调用成功！！！&quot;+id; } //处理流控异常、降级异常 自定义的异常信息方法 public String testBlockHandler(int id, BlockException blockException) { if (blockException instanceof FlowException) { return &quot;活动异常火爆，当前请求被限流！！！&quot; + blockException.getClass().getSimpleName(); } if (blockException instanceof DegradeException) { return &quot;当前服务已被降级处理，请稍好再试！！！&quot; + blockException.getClass().getSimpleName(); } return &quot;当前服务不可用！！！&quot;; } //处理其他异常 public String testFallBack(int id) { return id + &quot;:为非法参数，请检查后再重试！！！&quot;; }} 启动项目，测试自定义异常","link":"/Sentinel%E6%B5%81%E9%87%8F%E5%8D%AB%E5%85%B5%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"Spring AOP 切入点的表达式","text":"作用：主要是用来决定项目中哪些组件中哪些地方需要加入通知语法结构：expression=”切入点表达式” execution 切入点表达式 方法级别的切入点表达式控制粒度：方法级别 效率低 完整语法 execution(访问权限修饰符 返回值 包名.类名.方法名(参数类型)) execution(返回值 包名.类名.方法名（参数类型)) * 表示任意多个字符 注意：尽可能精准切入 避免不必要的切入 .execution(* com.buubiu.service.*.*(..)) ​ 包： com.buubiu.service ​ 类： 任意类 方法： 任意方法 参数： 任意参数 返回值：任意返回值类型 .execution(String com.buubiu.service.*ServiceImpl.*(..)) ​ 包： com.buubiu.service ​ 类： 以ServiceImpl结尾的类 方法： 任意方法 参数： 任意参数 返回值：返回值必须是String类型的相关方法 .execution(String com.buubiu.service.*Service*.*(String)) ​ 包： com.buubiu.service ​ 类： 类名中包含Service关键字的类 方法： 任意方法 参数： 参数只有一个并且是String类型 返回值：返回值必须是String类型的相关方法 .execution(* com.buubiu.service..*.*(..)) 比较常用 ​ 包： com.buubiu.service及这个包中的子包的子包 ​ 类： 任意类 方法： 任意方法 参数： 任意参数 返回值：任意返回值类型 .execution(* com.buubiu.service.*ServiceImpl.*(..)) 比较常用 ​ 包： com.buubiu.service ​ 类： 以ServiceImpl结尾的类 方法： 任意方法 参数： 任意参数 返回值：任意返回值类型 .execution(* *.*(..)) 全部方法 避免使用这种方式 ​ 包： 项目中任意包 ​ 类： 任意类 方法： 任意方法 参数： 任意参数 返回值：任意返回值类型 within 切入点表达式 类级别的切入点表达式 控制粒度：类级别 效率高 完整语法 within(包.类名) * 表示任意多个字符 within(com.buubiu.service.*ServiceImpl) ​ 包： com.buubiu.service ​ 类： 以ServiceImpl结尾的类","link":"/Spring-AOP-%E5%88%87%E5%85%A5%E7%82%B9%E7%9A%84%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"Spring Cloud Alibaba介绍及环境搭建","text":"简介官方：https://spring.io/projects/spring-cloud-alibaba Spring Cloud Alibaba provides a one-stop solution for distributed application development. It contains all the components required to develop distributed applications, making it easy for you to develop your applications using Spring Cloud. With Spring Cloud Alibaba, you only need to add some annotations and a small amount of configurations to connect Spring Cloud applications to the distributed solutions of Alibaba, and build a distributed application system with Alibaba middleware. 翻译： 阿里云为分布式应用开发提供了一站式解决方案。它包含了开发分布式应用程序所需的所有组件，使您可以轻松地使用springcloud开发应用程序。 有了阿里云，你只需要添加一些注解和少量的配置，就可以将Spring云应用连接到阿里的分布式解决方案上，用阿里中间件搭建一个分布式应用系统。 环境搭建新建项目并引入依赖1234567891011121314&lt;!--定义spring cloud alibaba版本--&gt;&lt;spring.cloud.alibaba.version&gt;2.2.3.RELEASE&lt;/spring.cloud.alibaba.version&gt;&lt;!--全局引入springcloudalibaba下载依赖地址，并不会引入依赖--&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.cloud.alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;/dependencyManagement&gt;","link":"/Spring-Cloud-Alibaba%E4%BB%8B%E7%BB%8D%E5%8F%8A%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"Spring 创建简单和复杂对象","text":"通过工厂创建简单对象简单对象定义： 可以直接通过new关键字创建的对象 统一称为简单对象 工厂创建简单对象语法： 1&lt;bean id=&quot;&quot; class=&quot;xxx&quot; [scope=&quot;singleton|prototype&quot;]&gt; 通过工厂创建复杂对象复杂对象定义：不能直接通过new关键字进行创建的对象 ​ 例如：接口类型（Connection） ​ 抽象类型（Calendar MessageDisgest..) 工厂创建复杂对象步骤： 要自定义一个类，并且实现FactoryBean这个接口 语法： 对象名FactoryBean implements FactoryBean&lt;Calendar|Connection|复杂对象&gt;{ } 12345678910111213141516171819202122232425262728293031package factorybean;import java.util.Calendar;import org.springframework.beans.factory.FactoryBean;/** * 用来在工厂中创建复杂对象 * @author buubiu **/public class CalendarFactoryBean implements FactoryBean&lt;Calendar&gt; { //用书书写复杂对象的创建方式 /*Calendar instance = Calendar.getInstance();*/ @Override public Calendar getObject() throws Exception { return Calendar.getInstance(); } //指定创建的复杂对象的类型 @Override public Class&lt;?&gt; getObjectType() { return Calendar.class; } //用来指定创建的对象模式 true：单例 false：多例 @Override public boolean isSingleton() { return true; }} 通过工厂配置创建的复杂对象 12&lt;!--通过factorybean创建复杂对象--&gt; &lt;bean class=&quot;factorybean.CalendarFactoryBean&quot; id=&quot;calendar&quot;/&gt;","link":"/Spring-%E5%88%9B%E5%BB%BA%E7%AE%80%E5%8D%95%E5%92%8C%E5%A4%8D%E6%9D%82%E5%AF%B9%E8%B1%A1/"},{"title":"SpringBoot Data操作ElasticSearch","text":"引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;&lt;/dependency&gt; 配置es客户端 spring-data(2~3.x版本配置) 1234spring: data: elasticsearch: cluster-nodes: 127.0.0.1:9300 spring-data(新版本推荐配置) RestHighLevelClient rest客户端 ElasticSearchRespositoy接口 123456789101112131415161718/** * @author buubiu **/@Configurationpublic class ElasticSearchRestClientConfig extends AbstractElasticsearchConfiguration { //这个client用来替换transportClient(9300)对象 @Override @Bean public RestHighLevelClient elasticsearchClient() { //定义客户端配置对象 RestClient 9200 final ClientConfiguration clientConfiguration = ClientConfiguration.builder() .connectedTo(&quot;127.0.0.1:9200&quot;) .build(); //通过RestClients对象创建 return RestClients.create(clientConfiguration).rest(); }} RestHighLevelClient进行操作索引记录删除记录123456789101112@Autowiredprivate RestHighLevelClient restHighLevelClient;@Testpublic void testDelete() throws IOException { //参数1：索引 参数2：类型 参数3：删除id DeleteRequest deleteRequest = new DeleteRequest(&quot;buubiu&quot;, &quot;user&quot;, &quot;Ulqak3YBZ23tdxk-f2fE&quot;); DeleteResponse deleteResponse = restHighLevelClient .delete(deleteRequest, RequestOptions.DEFAULT); System.out.println(&quot;deleteResponse.status() = &quot; + deleteResponse.status());} 添加记录1234567@Testpublic void testAddIndex() throws IOException { IndexRequest indexRequest = new IndexRequest(&quot;buubiu&quot;, &quot;user&quot;, &quot;12&quot;); indexRequest.source(&quot;{\\&quot;name\\&quot;:\\&quot;小张\\&quot;,\\&quot;age\\&quot;:22}&quot;, XContentType.JSON); IndexResponse indexResponse = restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT); System.out.println(&quot;indexResponse.status() = &quot; + indexResponse.status());} 查询记录12345678910111213141516171819202122232425@Testpublic void testSearch() throws IOException { SearchRequest searchRequest = new SearchRequest(&quot;buubiu&quot;); //搜索构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchAllQuery())//执行查询条件 .from(0)//起始条数 .size(20)//每页展示记录数 .postFilter(QueryBuilders.matchAllQuery())//过滤条件 .sort(&quot;age&quot;, SortOrder.DESC)//排序 .highlighter(new HighlightBuilder().field(&quot;*&quot;).requireFieldMatch(false));//高亮 //创建搜索请求 searchRequest.types(&quot;user&quot;).source(searchSourceBuilder); SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); System.out.println( &quot;符合条件的文档总数 = &quot; + searchResponse.getHits().getTotalHits()); System.out.println( &quot;符合条件的文档最大得分 = &quot; + searchResponse.getHits().getMaxScore()); SearchHit[] hits = searchResponse.getHits().getHits(); for (SearchHit hit : hits) { System.out.println(&quot;hit = &quot; + hit); }} 更新记录1234567@Testpublic void testUpdate() throws IOException { UpdateRequest updateRequest = new UpdateRequest(&quot;buubiu&quot;,&quot;user&quot;,&quot;12&quot;); updateRequest.doc(&quot;{\\&quot;name\\&quot;:\\&quot;里斯\\&quot;,\\&quot;age\\&quot;:33}&quot;,XContentType.JSON); UpdateResponse updateResponse = restHighLevelClient.update(updateRequest, RequestOptions.DEFAULT); System.out.println(&quot;updateResponse.status() = &quot; + updateResponse.status());} 批量操作记录123456789101112131415161718192021@Testpublic void testBulk() throws IOException { BulkRequest bulkRequest = new BulkRequest(); //添加 IndexRequest indexRequest = new IndexRequest(&quot;buubiu&quot;, &quot;user&quot;, &quot;11&quot;); indexRequest.source(&quot;{\\&quot;name\\&quot;:\\&quot;王武\\&quot;,\\&quot;age\\&quot;:33}&quot;, XContentType.JSON); bulkRequest.add(indexRequest); //删除 DeleteRequest deleteRequest = new DeleteRequest(&quot;buubiu&quot;, &quot;user&quot;, &quot;12&quot;); bulkRequest.add(deleteRequest); //修改 UpdateRequest updateRequest = new UpdateRequest(&quot;buubiu&quot;, &quot;user&quot;, &quot;11&quot;); updateRequest.doc(&quot;{\\&quot;name\\&quot;:\\&quot;王无\\&quot;,\\&quot;age\\&quot;:55}&quot;,XContentType.JSON); bulkRequest.add(updateRequest); BulkResponse bulkItemResponses = restHighLevelClient.bulk(bulkRequest, RequestOptions.DEFAULT); BulkItemResponse[] items = bulkItemResponses.getItems(); for (BulkItemResponse item : items) { System.out.println(&quot;item.status() = &quot; + item.status()); }} 高亮查询1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//高亮查询@Testpublic void testSearchQueryHighlight() throws IOException, ParseException { //创建搜索请求 SearchRequest searchRequest = new SearchRequest(&quot;buubiu&quot;); //创建搜索对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.termQuery(&quot;content&quot;, &quot;日本&quot;))//设置条件 .sort(&quot;age&quot;, SortOrder.DESC)//排序 .from(0)//起始条数（当前页-1）*size 的值 .size(20)//每页展示条数 .highlighter(new HighlightBuilder().field(&quot;*&quot;).requireFieldMatch(false).preTags(&quot;&lt;span style='color:red'&gt;&quot;).postTags(&quot;&lt;/span&gt;&quot;)); searchRequest.types(&quot;user&quot;).source(searchSourceBuilder); SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); SearchHit[] searchHits = searchResponse.getHits().getHits(); List&lt;User&gt; users = new ArrayList&lt;&gt;(); for (SearchHit searchHit : searchHits) { //原始文档 Map&lt;String, Object&gt; sourceAsMap = searchHit.getSourceAsMap(); User user = new User(); user.setId(searchHit.getId()); user.setAge(Integer.parseInt(sourceAsMap.get(&quot;age&quot;).toString())); user.setBir(new SimpleDateFormat(&quot;yyyy-MM-dd&quot;).parse(sourceAsMap.get(&quot;bir&quot;).toString())); user.setContent(sourceAsMap.get(&quot;content&quot;).toString()); user.setAddress(sourceAsMap.get(&quot;address&quot;).toString()); //高亮字段 Map&lt;String, HighlightField&gt; highlightFields = searchHit.getHighlightFields(); if (highlightFields.containsKey(&quot;content&quot;)) { user.setContent(highlightFields.get(&quot;content&quot;).fragments()[0].toString()); } if (highlightFields.containsKey(&quot;name&quot;)) { user.setName(highlightFields.get(&quot;name&quot;).fragments()[0].toString()); } if (highlightFields.containsKey(&quot;address&quot;)) { user.setAddress(highlightFields.get(&quot;address&quot;).fragments()[0].toString()); } //放入集合 users.add(user); } users.forEach(user -&gt; System.out.println(&quot;user = &quot; + user));} Repository操作索引记录创建记录对应的实体类123456789101112131415161718192021222324252627/** * @author buubiu **/@Data/** * 用在类上 作用：将User的对象映射成ES中的一条json格式文档 * indexName：用来指定这个对象转为json文档存入哪个索引中 要求：ES服务器中之前不能存在此索引名 * type ：用来指定在当前这个索引下面创建的类型名称 */@Document(indexName = &quot;buubiu&quot;,type = &quot;User&quot;)public class User { @Id //用来将对象中id属性与文档中_id一一对应 private String id; //用在属性上 代表mapping中一个属性 一个字段 type属性：用来指定字段类型 analyzer：指定分词器 @Field(type = FieldType.Text,analyzer = &quot;ik_max_word&quot;) private String name; @Field(type = FieldType.Integer) private Integer age; @Field(type = FieldType.Date) private Date bir; @Field(type = FieldType.Text,analyzer = &quot;ik_max_word&quot;) private String content; @Field(type = FieldType.Text,analyzer = &quot;ik_max_word&quot;) private String address;} 创建实体类的接口类1234567/** * @author buubiu * 自定义UserRespository **/public interface UserRepository extends ElasticsearchRepository&lt;User,String&gt; {} 在业务中操作索引添加记录12345678910111213141516171819202122/** * @author buubiu **/@SpringBootTestpublic class TestUserRepository { @Autowired private UserRepository userRepository; //添加记录 @Test public void testSave() { User user = new User(); user.setId(UUID.randomUUID().toString()); user.setName(&quot;张三&quot;); user.setBir(new Date()); user.setAge(55); user.setAddress(&quot;日本&quot;); user.setContent(&quot;日本是个好地方！&quot;); userRepository.save(user); }} 更新记录12345678910111213141516171819202122/** * @author buubiu **/@SpringBootTestpublic class TestUserRepository { @Autowired private UserRepository userRepository; //更新记录 @Test public void testUpdate() { User user = new User(); user.setId(&quot;73a2e5f1-824c-47ba-b4a5-bea4ee486eb8&quot;); user.setName(&quot;张三333&quot;); user.setBir(new Date()); user.setAge(52); user.setAddress(&quot;日本3&quot;); user.setContent(&quot;日本是个好地方3！&quot;); userRepository.save(user); }} 删除记录123456789101112131415/** * @author buubiu **/@SpringBootTestpublic class TestUserRepository { @Autowired private UserRepository userRepository; //删除记录 @Test public void testDelete() { userRepository.deleteById(&quot;73a2e5f1-824c-47ba-b4a5-bea4ee486eb8&quot;); }} 删除所有123456789101112131415/** * @author buubiu **/@SpringBootTestpublic class TestUserRepository { @Autowired private UserRepository userRepository; //删除所有 @Test public void testDeleteAll() { userRepository.deleteAll(); }} 查询一条记录12345678910111213141516/** * @author buubiu **/@SpringBootTestpublic class TestUserRepository { @Autowired private UserRepository userRepository; //查询一条记录 @Test public void testFindOne() { Optional&lt;User&gt; optionalUser = userRepository.findById(&quot;7989eff8-f461-4242-98e4-d223eb6d20c8&quot;); System.out.println(&quot;optionalUser.get() = &quot; + optionalUser.get()); }} 查询所有12345678910111213141516/** * @author buubiu **/@SpringBootTestpublic class TestUserRepository { @Autowired private UserRepository userRepository; //查询所有 排序 @Test public void testFindAll() { Iterable&lt;User&gt; all = userRepository.findAll(Sort.by(Sort.Order.asc(&quot;age&quot;))); all.forEach(user -&gt; System.out.println(&quot;user = &quot; + user)); }} 分页查询123456789101112131415161718/** * @author buubiu **/@SpringBootTestpublic class TestUserRepository { @Autowired private UserRepository userRepository; //分页查询 @Test public void testFindPage() { //PageRequest.of 参数1：当前页 0 1 2 参数2：每页多少数据 Page&lt;User&gt; search = userRepository .search(QueryBuilders.matchAllQuery(), PageRequest.of(0, 20)); search.forEach(user -&gt; System.out.println(&quot;user = &quot; + user)); }} 自定义查询 Keyword Sample Elasticsearch Query String And findByNameAndPrice {&quot;bool&quot; : {&quot;must&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Or findByNameOrPrice {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Is findByName {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Not findByNameNot {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Between findByPriceBetween {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} LessThanEqual findByPriceLessThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} GreaterThanEqual findByPriceGreaterThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Before findByPriceBefore {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} After findByPriceAfter {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Like findByNameLike {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} StartingWith findByNameStartingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} EndingWith findByNameEndingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;*?&quot;,&quot;analyze_wildcard&quot; : true}}}}} Contains/Containing findByNameContaining {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;**?**&quot;,&quot;analyze_wildcard&quot; : true}}}}} In findByNameIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must&quot; : {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}} ]}}}} NotIn findByNameNotIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;bool&quot; : {&quot;should&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}}}} Near findByStoreNear Not Supported Yet ! True findByAvailableTrue {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} False findByAvailableFalse {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : false}}}} OrderBy findByAvailableTrueOrderByNameDesc {&quot;sort&quot; : [{ &quot;name&quot; : {&quot;order&quot; : &quot;desc&quot;} }],&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} 编写实体类接口123456789101112131415161718192021/** * @author buubiu * 自定义UserRespository **/public interface UserRepository extends ElasticsearchRepository&lt;User,String&gt; { //根据姓名查询 List&lt;User&gt; findByName(String name); //根据年龄查询 List&lt;User&gt; findByAge(Integer age); //根据姓名和地址和年龄查询，后面可以and无数个字段 List&lt;User&gt; findByNameAndAddressAndAge(String name, String address, Integer age); //根据姓名或年龄查询 List&lt;User&gt; findByNameOrAge(String name, Integer age); //查询年龄大于等于8 List&lt;User&gt; findByAgeGreaterThanEqual(Integer age);} 在业务中操作索引12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * @author buubiu **/@SpringBootTestpublic class TestUserRepository { @Autowired private UserRepository userRepository; //自定义查询 //根据姓名查询 @Test public void testFindByName() { List&lt;User&gt; users = userRepository.findByName(&quot;张三&quot;); users.forEach(user -&gt; System.out.println(&quot;user = &quot; + user)); } //自定义查询 //根据年龄查询 @Test public void testFindByAge() { List&lt;User&gt; users = userRepository.findByAge(55); users.forEach(user -&gt; System.out.println(&quot;user = &quot; + user)); } //自定义查询 //根据姓名和地址和年龄查询 @Test public void testFindByNameAndAddressAndAge() { List&lt;User&gt; users = userRepository.findByNameAndAddressAndAge(&quot;张三&quot;,&quot;日本&quot;, 55); users.forEach(user -&gt; System.out.println(&quot;user = &quot; + user)); } //自定义查询 //根据姓名或年龄查询 @Test public void testFindByNameOrAge() { List&lt;User&gt; users = userRepository.findByNameOrAge(&quot;张三&quot;,55); users.forEach(user -&gt; System.out.println(&quot;user = &quot; + user)); } //自定义查询 //查询年龄大于等于8 @Test public void testFindByAgeGreaterThanEqual() { List&lt;User&gt; users = userRepository.findByAgeGreaterThanEqual(2); users.forEach(user -&gt; System.out.println(&quot;user = &quot; + user)); }}","link":"/SpringBoot-Data%E6%93%8D%E4%BD%9CElasticSearch/"},{"title":"SpringBoot-thymeleaf基本语法","text":"在使用时必须在页面中加入下面命名空间： 1&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; 展示单个数据 在controller设置数据 12model.addAttribute(&quot;name&quot;, &quot;buubiu中文&quot;);model.addAttribute(&quot;link&quot;,&quot;&lt;a href=''&gt;buubiu&lt;/a&gt;&quot;); 获取数据 123&lt;span th:text=&quot;${name}&quot; /&gt;&lt;br&gt;&lt;span th:utext=&quot;${link}&quot; /&gt; &lt;br&gt;&lt;input type=&quot;text&quot; th:value=&quot;${name}&quot;&gt; 总结： 使用 th:text=&quot;${属性名}&quot; 获取对应数据,获取数据时会将对应标签中数据清空,因此最好是空标签 使用 th:utext=&quot;${属性名}&quot; 获取对应的数据,可以将数据中html先解析在渲染到页面 使用 th:value=&quot;${属性名}&quot; 获取数据直接作为表单元素value属性 展示对象数据 在controller设置数据 12User user = new User(&quot;111&quot;, &quot;buubiu名字&quot;, 22, new Date());model.addAttribute(&quot;user&quot;, user); 获取数据 1234567&lt;h1&gt;展示对象数据&lt;/h1&gt;&lt;ul&gt; &lt;li&gt;id:&lt;span th:text=&quot;${user.id}&quot; /&gt; &lt;/li&gt; &lt;li&gt;name:&lt;span th:text=&quot;${user.name}&quot; /&gt; &lt;/li&gt; &lt;li&gt;age:&lt;span th:text=&quot;${user.age}&quot; /&gt; &lt;/li&gt; &lt;li&gt;bir:&lt;span th:text=&quot;${#dates.format(user.bir,'yyyy-MM-dd')}&quot; /&gt; &lt;/li&gt;&lt;/ul&gt; 展示条件数据 获取数据 12&lt;h1&gt;展示条件数据(如果年龄小于等于22显示名字)&lt;/h1&gt;&lt;span th:if=&quot;${user.age le 22}&quot; th:text=&quot;${user.name}&quot; /&gt; 运算符 123456gt：great than（大于）&gt;ge：great equal（大于等于）&gt;=eq：equal（等于）==lt：less than（小于）&lt;le：less equal（小于等于）&lt;=ne：not equal（不等于）!= 展示集合（多条）数据 在controller添加数据 1234User user2 = new User(&quot;222&quot;, &quot;buubiu2名字&quot;, 23, new Date());User user3 = new User(&quot;333&quot;, &quot;buubiu3名字&quot;, 24, new Date());List&lt;User&gt; users = Arrays.asList(user, user2, user3);model.addAttribute(&quot;users&quot;, users); 获取数据 直接遍历集合，并且设置状态 1234567891011121314&lt;h1&gt;展示集合（多条）数据&lt;/h1&gt;&lt;ul th:each=&quot;user,userStat:${users}&quot;&gt; &lt;li&gt; 当前遍历是否是第一个：&lt;span th:text=&quot;${userStat.first}&quot;/&gt; 当前遍历的次数：&lt;span th:text=&quot;${userStat.count}&quot;/&gt; 当前遍历的索引：&lt;span th:text=&quot;${userStat.index}&quot;/&gt; 当前遍历是否是偶数：&lt;span th:text=&quot;${userStat.even}&quot;/&gt; 当前遍历是否是奇数：&lt;span th:text=&quot;${userStat.odd}&quot;/&gt; &lt;/li&gt; &lt;li&gt;id:&lt;span th:text=&quot;${user.id}&quot;/&gt;&lt;/li&gt; &lt;li&gt;name:&lt;span th:text=&quot;${user.name}&quot;/&gt;&lt;/li&gt; &lt;li&gt;age:&lt;span th:text=&quot;${user.age}&quot;/&gt;&lt;/li&gt; &lt;li&gt;bir:&lt;span th:text=&quot;${#dates.format(user.bir,'yyyy年MM月dd日')}&quot;/&gt;&lt;/li&gt;&lt;/ul&gt; 页面引入静态资源使用 thymeleaf模版项目中静态资源默认放在 resources路径的 static目录中 添加静态资源文件 1234567|--resources |--static |--css |--index.css |--js |--jquery-3.5.1.min.js |--img 页面中引入 @：代表当前项目的路径 12&lt;link rel=&quot;stylesheet&quot; th:href=&quot;@{/css/index.css}&quot;&gt;&lt;script th:src=&quot;@{/js/jquery-3.5.1.min.js}&quot;&gt;&lt;/script&gt; 展示超链接 开发控制器 12345@GetMapping(&quot;delete&quot;)@ResponseBodypublic String delete(String id, String name) { return id+&quot;删除成功&quot;+name;} 页面配置 @:代表当前项目路径 ():代表URL拼接参数 12&lt;h1&gt;测试超链接&lt;/h1&gt;&lt;a th:href=&quot;@{/user/delete(id='11',name='buubiu')}&quot;&gt;删除&lt;/a&gt;","link":"/SpringBoot-thymeleaf%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/"},{"title":"SpringBoot中两种模版配置","text":"SpringBoot 中支持 jsp 和 thymeleaf 官方默认支持thymeleaf，并且也推荐使用 如果想支持 jsp 需要额外的配置 集成JSP模版 引入依赖 123456789101112&lt;!--引入解析jsp页面的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--jstl标准标签库--&gt;&lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; 引入JSP运行插件 12345678910&lt;build&gt; &lt;finalName&gt;springboot&lt;/finalName&gt; &lt;!--引入jsp运行插件--&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在配置文件 application.properties中配置视图解析器 12spring.mvc.view.prefix=/spring.mvc.view.suffix=.jsp 集成thymeleaf模版 Thymeleaf is a modern server-side Java template engine for both web and standalone environments. –官网：https://www.thymeleaf.org Thymeleaf是跟Velocity、FreeMarker类似的模板引擎，它可以完全替代JSP，相较与其他的模板引擎相比, Thymeleaf在有网络和无网络的环境下皆可运行，即它可以让美工在浏览器查看页面的静态效果，也可以让程序员在服务器查看带数据的动态页面效果。 引入依赖 12345&lt;!--引入thymeleaf--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置 application.properties 1234spring.thymeleaf.prefix=classpath:/templates/ #使用模板目录spring.thymeleaf.suffix=.html #使用模板后缀spring.thymeleaf.encoding=UTF-8 #使用模板编码spring.thymeleaf.servlet.content-type=text/html #使用模板响应类型 开发控制器 12345678910111213141516171819package com.buubiu.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;/** * @author buubiu **/@Controller@RequestMapping(&quot;user&quot;)public class UserController { @GetMapping(&quot;findAll&quot;) public String findAll() { System.out.println(&quot;查询所有&quot;); return &quot;index&quot;;//逻辑名 classpath:/templates/逻辑名.html }} 在 resources 目录中添加文件夹 templates，写的html都放在这里面即可","link":"/SpringBoot%E4%B8%AD%E4%B8%A4%E7%A7%8D%E6%A8%A1%E7%89%88%E9%85%8D%E7%BD%AE/"},{"title":"SpringBoot中创建对象的方式","text":"在Springboot中提供两种方式配置classSpringBoot 支持 开发自定义Java类 和 XML 两种方式来配置对象 开发Java config 类，并加上注解 [推荐] 先开发自定义Java对象 注解有两种 @Configuration [推荐] 类似于@Component注解，如果有多个对象可以封装起来一起注解，需要@Bean配合使用 1234567891011121314package com.buubiu.entity;import org.springframework.context.annotation.Configuration;/** * 单独配置到对象上 * @author buubiu **/@Configurationpublic class User { private String id; private String name;} 12345678910111213141516171819202122232425package com.buubiu.configs;import com.buubiu.entity.Order;import com.buubiu.entity.User;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * 多个bean 一起管理 * @author buubiu **/@Configurationpublic class BeansConfig { @Bean public User getUser() { return new User(); } @Bean public Order getOrder() { return new Order(); }} 使用的时候，直接用注解 @Autowird 1234567891011121314151617181920212223242526package com.buubiu.controller;import com.buubiu.entity.User;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author buubiu **/@RestController@RequestMapping(&quot;hello&quot;)public class HelloController { @Autowired private User user; @GetMapping(&quot;hello&quot;) public String hell() { System.out.println(&quot;hello springboot&quot;); System.out.println(user); return &quot;hello springboot&quot;; }} @Import 在哪个类中引用就导入一个配置类，表示把该对象导入进来 12345678910111213141516171819202122232425package com.buubiu.controller;import com.buubiu.entity.User;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Import;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author buubiu **/@RestController@RequestMapping(&quot;hello&quot;)@Import(User.class)public class HelloController { @Autowired private User user; @GetMapping(&quot;hello&quot;) public String hell() { System.out.println(&quot;hello springboot&quot;); System.out.println(user); return &quot;hello springboot&quot;; }} XML方式 [了解] 在resources目录下创建 spring.xml配置文件 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!--交给工厂管理--&gt; &lt;bean class=&quot;com.buubiu.entity.User&quot; id=&quot;user&quot;/&gt;&lt;/beans&gt; 在入口类加入 注解 @ImportResource 123456789101112131415161718192021package com.buubiu;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.ImportResource;/** * @SpringBootApplication * 组合注解：相当于@EnableAutoConfiguration 和 @ComponentScan * * @author buubiu **/@SpringBootApplication@ImportResource(&quot;spring.xml&quot;)public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }}","link":"/SpringBoot%E4%B8%AD%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%96%B9%E5%BC%8F/"},{"title":"SpringBoot中文件上传和下载","text":"定义上传：指的是用户将自己本地计算机中文件通过网络的形式上传到系统所在服务器上的过程，这个过程称之为文件上传。 下载：指的是用户通过网络的形式将服务器上的文件下载到自己本地计算机上的过程，称之为下载 文件上传 配置application.properties 12345678910spring.resources.static-locations=classpath:/templates/,classpath:/static/,uploadfile:${uploadfile.dir}#配置上传文件大小限制(默认是10MB)#用来控制文件上传大小的限制spring.servlet.multipart.max-file-size=20MB#用来指定服务端最大文件大小spring.servlet.multipart.max-request-size=20MB#配置本地的附件存储路径uploadfile.dir=/Users/buubiu/uploadfile/ 开发上传页面html 1234&lt;form action=&quot;/springboot/file/upload&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;input type=&quot;file&quot; name=&quot;fileName&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;上传文件&quot; /&gt; &lt;/form&gt; 注意： 表单提交方式必须是post 表单的enctype属性必须为multipart/form-data 后台接受变量名字要与文件选择name属性一致 开发控制器 123456789101112131415161718192021222324252627282930@Value(&quot;${uploadfile.dir}&quot;)private String uploadfile;@PostMapping(&quot;upload&quot;)public String upload(MultipartFile fileName, HttpServletRequest request) throws IOException { //文件上传 System.out.println(&quot;文件名：&quot; + fileName.getOriginalFilename()); System.out.println(&quot;文件类型：&quot; + fileName.getContentType()); System.out.println(&quot;文件大小：&quot; + fileName.getSize()); //生成当天日期目录 LocalDate now = LocalDate.now(); int year = now.getYear(); int monthValue = now.getMonthValue(); int dayOfMonth = now.getDayOfMonth(); String datePath = year+&quot;/&quot;+monthValue+&quot;/&quot;+dayOfMonth; //处理文件上传 File dir = new File(uploadfile+datePath); if (!dir.exists()) { dir.mkdirs(); } //修改文件名 String currentTime= LocalDateTime.now().format(DateTimeFormatter.ofPattern(&quot;yyyyMMddHHmmssSSS&quot;)); String newFileNamePrefix = currentTime + UUID.randomUUID().toString(); String extension = FilenameUtils.getExtension(fileName.getOriginalFilename()); fileName.transferTo(new File(dir, newFileNamePrefix + &quot;.&quot;+extension)); return &quot;redirect:/upload.html&quot;;} 文件下载 开发页面 1&lt;a href=&quot;/springboot_07/file/down?fileName=jquery-3.5.1.min.js&quot;&gt;jquery-3.5.1.min.js&lt;/a&gt; 开发控制器 1234567891011121314151617181920212223@Value(&quot;${uploadfile.dir}&quot;)private String uploadfile;//文件下载@GetMapping(&quot;down&quot;)public void down(String openStyle, String fileName, HttpServletResponse response) throws IOException { openStyle = openStyle == null ? &quot;attachment&quot; : &quot;inline&quot;; //读取文件 File file = new File(uploadfile, fileName); //读取文件输入流 FileInputStream is = new FileInputStream(file); //获取响应输出流 response.setContentType(&quot;text/plain;charset=UTF-8&quot;); response.setHeader(&quot;content-disposition&quot;, openStyle + &quot;;fileName=&quot; + URLEncoder.encode(fileName, &quot;UTF-8&quot;)); ServletOutputStream os = response.getOutputStream(); //文件拷贝 IOUtils.copy(is, os); //关闭资源 IOUtils.closeQuietly(is); IOUtils.closeQuietly(os);}","link":"/SpringBoot%E4%B8%AD%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD/"},{"title":"SpringBoot中的拦截器","text":"定义拦截器（Interceptor ) 拦截、中断的意思，类似于 JavaWeb中的Filter，但不如Filter拦截的范围大。 作用通过将控制器中的通用代码放在拦截器中执行，减少控制器中的代码冗余。 拦截器的特点 请求到达会经过拦截器，响应回来同样会经过拦截器 拦截器只能拦截控制器相关请求，不能拦截jsp、静态资源相关请求 拦截器可以中断请求轨迹 开发拦截器 自定义类，并实现接口 HanHandlerInterceptor中的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.buubiu.interceptors;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.web.method.HandlerMethod;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;/** * 自定义拦截器 * @author buubiu **/public class MyInterceptor implements HandlerInterceptor { //请求流程： //1.请求经过拦截器会优先进入拦截器中preHandle方法执行 //2.如果preHandle返回true，代表放行请求，如果返回false，中断请求 //3.如果preHandle返回true，会执行当前请求对应的控制器方法 //4.当前控制器方法执行结束之后，会返回拦截器中执行拦截器中的postHandle方法 //5.postHandle方法执行之后响应请求，在响应请求完成后会执行afterCompletion方法 //参数1：当前请求对象 //参数2：当前请求对应响应对象 //参数3：当前请求的控制器对应的方法对象 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(&quot;===========1==========&quot;); System.out.println(&quot;请求的方法：&quot; + ((HandlerMethod) handler).getMethod().getName()); return true; } //如果控制器方法执行失败或者异常时不执行该方法 //参数1：当前请求对象 //参数2：当前请求对应响应对象 //参数3：当前请求的控制器对应的方法对象 //参数4：当前请求控制器方法返回值（当前请求控制器方法返回的ModelAndView对象） @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(&quot;===========3==========&quot;); System.out.println(modelAndView); } //无论控制器方法请求成功还是失败都会执行该方法 //参数1：当前请求对象 //参数2：当前请求对应响应对象 //参数3：当前请求的控制器对应的方法对象 //参数4：请求过程中出现异常时的异常 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(&quot;===========4==========&quot;); if (ex != null) { System.out.println(ex.getMessage()); } }} 配置拦截器，开发自定义配置类 并实现 WebMvcConfigurer接口 注意：在springboot2.x版本中自定义拦截器之后出现项目中静态资源 404情况,需要在自定义拦截器的配置中添加如下两种之一的配置 在方法 addInterceptors 中添加排除资源配置 在方法addResourceHandlers中添加不经过拦截器的资源 12345678910111213141516171819202122232425262728293031package com.buubiu.config;import com.buubiu.interceptors.MyInterceptor;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.ResourceHandlerRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;/** * * @author buubiu **/@Configurationpublic class InterceptorConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new MyInterceptor())//添加拦截器 .addPathPatterns(&quot;/hello/**&quot;)//添加拦截的请求路径 .excludePathPatterns(&quot;/hello/word&quot;,&quot;classpath:/templates/&quot;)//添加排除哪些请求路径不经过拦截器 .excludePathPatterns(&quot;classpath:/static/&quot;,&quot;classpath:/templates/&quot;);//排除静态资源 } @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(&quot;/**&quot;)//代表以什么样的请求路径访问静态资源 .addResourceLocations(&quot;classpath:/static/&quot;,&quot;classpath:/templates/&quot;);//添加静态资源不需要拦截 }}","link":"/SpringBoot%E4%B8%AD%E7%9A%84%E6%8B%A6%E6%88%AA%E5%99%A8/"},{"title":"SpringBoot中的war包部署","text":"由于SpringBoot默认是打成 jar包的，一旦使用war包部署注意： application.properties 中配置server.servlet.context-path、server.port 失效 访问时使用打成war包的名字和外部自己tomcat端口号进行访问项目 配置 pom.xml 由于SpringBoot默认是打成 jar包的，所以首先要在 pom.xml中配置为 war包的答包方式 1234&lt;groupId&gt;com.buubiu&lt;/groupId&gt;&lt;artifactId&gt;springboot&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;war&lt;/packaging&gt; 由于SpringBoot内嵌了tomcat，并且我们打成war包肯定是在自己的tomcat中运行，所以就要排除内嵌的to mcat 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;!--去掉内嵌tomcat--&gt;&lt;/dependency&gt; 如果你的页面是jsp模版开发的，那么也需要去掉内嵌的tomcat解析jsp 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;!--去掉使用内嵌tomcat解析jsp--&gt;&lt;/dependency&gt; 在配置 pom.xml中指定入口类 12345678910111213141516&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;!--使用热部署出现中文乱码解决方案--&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;!--增加jvm参数--&gt; &lt;jvmArguments&gt;-Dfile.encoding=UTF-8&lt;/jvmArguments&gt; &lt;!--指定入口类--&gt; &lt;mainClass&gt;com.buubiu.SpringbootApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 修改入口类修改入口类，让自己的tomcat知道我们的主入口在哪 继承 SpringBootServletInitializer类 覆盖configure方法 123456789101112131415161718192021package com.buubiu;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.boot.web.servlet.support.SpringBootServletInitializer;@SpringBootApplicationpublic class SpringbootApplication extends SpringBootServletInitializer { public static void main(String[] args) { SpringApplication.run(SpringbootApplication.class, args); } @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) { return builder.sources(SpringbootApplication.class); }}","link":"/SpringBoot%E4%B8%AD%E7%9A%84war%E5%8C%85%E9%83%A8%E7%BD%B2/"},{"title":"SpringBoot中的注入","text":"SpringBoot中提供了两种注入方式：注入基本属性,对象注入 基本属性注入 首先要注入的属性上添加 @Value 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.buubiu.controller;import java.util.Date;import java.util.List;import java.util.Map;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author buubiu **/@RestController@RequestMapping(&quot;hello&quot;)public class HelloController { @Value(&quot;${name}&quot;) private String name; @Value(&quot;${server.port}&quot;) private int port; @Value(&quot;${bir}&quot;) private Date bir; @Value(&quot;${strs}&quot;) private String[] strs; @Value(&quot;${lists}&quot;) private List&lt;String&gt; lists; @Value(&quot;#{${maps}}&quot;) private Map&lt;String, String&gt; maps; @GetMapping(&quot;hello&quot;) public String hello() { System.out.println(&quot;hello springboot&quot;); System.out.println(&quot;name = &quot; + name); System.out.println(&quot;port = &quot; + port); System.out.println(&quot;bir = &quot; + bir); for (String str : strs) { System.out.println(&quot;str = &quot; + str); } lists.forEach(list-&gt; System.out.println(&quot;list = &quot; + list)); maps.forEach((k,v)-&gt; System.out.println(&quot;k = &quot; + k + &quot; v = &quot; + v)); return &quot;hello springboot&quot;; }} 其次要修改配置文件 application.properties 12345name=buubiubir=2020/12/12 12:12:12strs=aa,bb,cc,ddlists=buubiu1,buubiu2,buubiu3maps={'aa':'buubiu','bb':'buubiu2','cc':'buubiu3'} 对象方式注入 在对象类上加上注解@Configuration或@Component 和 @ConfigurationProperties User.java 12345678910111213141516package com.buubiu.entity;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;/** * @author buubiu **/@Configuration@ConfigurationProperties(prefix = &quot;user&quot;)public class User { private String id; private Integer age; ...} HelloController.java 1234567891011121314151617181920212223242526package com.buubiu.controller;import com.buubiu.entity.User;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author buubiu **/@RestController@RequestMapping(&quot;hello&quot;)public class HelloController { @Autowired private User user; @GetMapping(&quot;hello&quot;) public String hello() { System.out.println(&quot;hello springboot&quot;); System.out.println(&quot;user = &quot; + user); return &quot;hello springboot&quot;; }} application.properties 12user.id=111user.age=22 如若想在配置文件中有提示，可以添加下面依赖 123456&lt;!--构建元数据--&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;&lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;","link":"/SpringBoot%E4%B8%AD%E7%9A%84%E6%B3%A8%E5%85%A5/"},{"title":"SpringBoot的切面编程","text":"概述​ SpringBoot是对原有项目中Spring框架和SpringMVC框架的进一步封装，因此在SpringBoot中同样支持Spring框架的AOP切面编程，不过在SpringBoot中为了快速开发，仅需要注解就可以开发切面编程。 使用 引入依赖 12345&lt;!--引入aop依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 自定义通知 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.buubiu.aspects;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.springframework.context.annotation.Configuration;import org.springframework.core.annotation.Order;/** * @author buubiu **/@Aspect@Configuration@Order(1)//切面的执行顺序，数字越小，优先级越高public class MyAspect { //前置通知方法 在目标方法执行之前执行操作 @Before(&quot;within(com.buubiu.service.*ServiceImpl)&quot;) public void before(JoinPoint joinPoint) { System.out.println(&quot;前置通知业务处理～～&quot;); System.out.println(&quot;目标方法名称：&quot; + joinPoint.getSignature().getName()); System.out.println(&quot;目标方法参数：&quot; + joinPoint.getArgs()); System.out.println(&quot;目标方法对象：&quot; + joinPoint.getTarget()); } //后置通知 在目标方法执行之后执行的操作 @After(&quot;within(com.buubiu.service.*ServiceImpl)&quot;) public void after(JoinPoint joinPoint) { System.out.println(&quot;后置通知业务处理～～&quot;); System.out.println(&quot;目标方法名称：&quot; + joinPoint.getSignature().getName()); System.out.println(&quot;目标方法对象：&quot; + joinPoint.getTarget()); } //环绕通知 //当目标方法执行时会先进入环绕通知，然后在环绕通知放行后继续执行目标方法；当目前方法执行后回到环绕通知 @Around(&quot;execution(* com.buubiu.service.*ServiceImpl.*(..))&quot;) public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(&quot;进入环绕通知～～&quot;); Object proceed = proceedingJoinPoint.proceed();//放行执行业务方法 System.out.println(&quot;目标方法名称：&quot; + proceedingJoinPoint.getSignature().getName()); System.out.println(&quot;目标方法参数：&quot; + proceedingJoinPoint.getArgs()); System.out.println(&quot;目标方法对象：&quot; + proceedingJoinPoint.getTarget()); return proceed; }} 相关注解解释 @Aspect: 用来类上,代表这个类是一个切面 @Before: 用在方法上代表这个方法是一个前置通知方法 @After:用在方法上代表这个方法是一个后置通知方法 @Around:用在方法上代表这个方法是一个环绕的方法 @Order(1):切面的执行顺序，数字越小，优先级越高","link":"/SpringBoot%E7%9A%84%E5%88%87%E9%9D%A2%E7%BC%96%E7%A8%8B/"},{"title":"SpringBoot编程概述","text":"概述 Spring Boot helps you to create stand-alone, production-grade Spring-based Applications that you can run. We take an opinionated view of the Spring platform and third-party libraries, so that you can get started with minimum fuss. Most Spring Boot applications need very little Spring configuration. springboot框架=SpringMVC+Spring 开发SpringBoot条件 springboot 项目中必须在 src/main/resources中放入application.yml或者application.properties核心配置文件，并且名称必须为：application springboot 项目中必须在src/main/java中所有子包之外构建全局入口类，xxxApplication.java,并且入口类有且只有一个 第一个工程创建 引入依赖 12345678910111213&lt;!--集成springboot父项目--&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--引入springboot的web支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 1src/main/resources/application.yml 开发入口类 Application.java 123456789101112131415161718192021package com.buubiu;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.context.annotation.ComponentScan;/** * @author buubiu **/@EnableAutoConfiguration //作用：开启自动配置 初始化Spring环境和SpringMVC环境@ComponentScan //作用：用来扫描相关注解 扫描范围：默认当前入口所在的包及其子包public class Application { public static void main(String[] args) { //springApplication spring应用类 作用：用来启动Springboot应用 //参数1：传入入口类 类对象 //参数2：main函数的参数 SpringApplication.run(Application.class, args); }} 说明：注解@SpringBootApplication 相当于@EnableAutoConfiguration 和 @ComponentScan 所以上面的代码也可以简化为： 12345678910111213141516171819package com.buubiu;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @SpringBootApplication * 组合注解：相当于@EnableAutoConfiguration 和 @ComponentScan * * @author buubiu **/@SpringBootApplicationpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} HelloController.java 1234567891011121314151617181920package com.buubiu.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author buubiu **/@RestController@RequestMapping(&quot;hello&quot;)public class HelloController { @GetMapping(&quot;hello&quot;) public String hell() { System.out.println(&quot;hello springboot&quot;); return &quot;hello springboot&quot;; }} springboot 相关注解说明123456789101112131415161718192021222324252627282930313233/** * @EnableAutoConfiguration * 作用：开启自动配置 * 修饰范围：只能用在类上 * 实际作用：根据pom.xml文件中引入的依赖自动判断，如在一个环境中引入了 spring-boot-starter-web * 会自动根据引入的这个依赖构建相关环境（springmvc环境和web容器环境） * * @ComponentScan * 作用：用来开启注解扫描 * 扫描范围：只能用在类上 默认当前包以及当前包下的子包 * * @RestController * 作用：用来实例化当前对象为一个控制器对象，并将类上所有方法的返回值转为json，响应给浏览器 * 相当于 @Controller(实例化当前类为一个控制器对象)+@ResponseBody(用来将当前方法返回值转为json，响应给浏览器) * 修饰范围：用在类上 * * @RequestMapping * 作用：用来加入访问路径 * 修饰范围：类（加入命名空间）和方法上（指定具体的路径） * @GetMapping * 作用：限定请求方式只能是GET，并指定路径 * 修饰范围：一般用在方法上 * @PostMapping @DeleteMapping @PutMapping 同上 * * main 方法： * 作用：通过标准Java入口方式委托给SpringApplication，并告知当前SpringBoot主应用类是谁，从而启动SpringBoot中tomcat容器 * args：可以在启动时指定外部参数 * * starters：启动器 * spring-boot-starter-xxx starters是一组方便的依赖关系描述符 * @author buubiu **/","link":"/SpringBoot%E7%BC%96%E7%A8%8B%E6%A6%82%E8%BF%B0/"},{"title":"SpringBoot配置热部署","text":"引言为了进一步提高开发效率,springboot为我们提供了全局项目热部署,日后在开发过程中修改了部分代码以及相关配置文件后,不需要每次重启使修改生效,在项目中开启了springboot全局热部署之后只需要在修改之后等待几秒即可使修改生效。 开启热部署 引入依赖 123456&lt;!--springboot热部署--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 配置开发工具支持热部署（eclipse不需要配置） IDEA操作如下： 开启自动编译 1Preferences | Build, Execution, Deployment | Compiler -&gt; 勾选上 Build project automatically 这个选项 开启允许在运行过程中修改文件 1command + option + shift + /(win:ctrl + alt + shift + /) ----&gt;选择1.Registry ---&gt; 勾选 compiler.automake.allow.when.app.running 这个选项 修改配置文件 1spring.thymeleaf.cache=false 启动日志出现restartedMain代表生效 1234567891011122020-08-14 13:16:35.327 INFO 10014 --- [ restartedMain] com.buubiu.Application 2020-08-14 13:16:35.329 INFO 10014 --- [ restartedMain] com.buubiu.Application 2020-08-14 13:16:35.377 INFO 10014 --- [ restartedMain] .e.DevToolsPropertyDefaultsPostProcessor2020-08-14 13:16:35.378 INFO 10014 --- [ restartedMain] .e.DevToolsPropertyDefaultsPostProcessor 2020-08-14 13:16:36.495 INFO 10014 --- [ restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer 2020-08-14 13:16:36.505 INFO 10014 --- [ restartedMain] o.apache.catalina.core.StandardService 2020-08-14 13:16:36.505 INFO 10014 --- [ restartedMain] org.apache.catalina.core.StandardEngine 2020-08-14 13:16:36.578 INFO 10014 --- [ restartedMain] w.s.c.ServletWebServerApplicationContext 2020-08-14 13:16:37.099 INFO 10014 --- [ restartedMain] o.s.s.concurrent.ThreadPoolTaskExecutor 2020-08-14 13:16:37.343 INFO 10014 --- [ restartedMain] o.s.b.d.a.OptionalLiveReloadServer 2020-08-14 13:16:37.391 INFO 10014 --- [ restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer2020-08-14 13:16:37.403 INFO 10014 --- [ restartedMain] com.buubiu.Application","link":"/SpringBoot%E9%85%8D%E7%BD%AE%E7%83%AD%E9%83%A8%E7%BD%B2/"},{"title":"SpringBoot集成Mybatis","text":"SpringBoot官方推荐了两种方式： 一个是在Java类上注解写sql 一个是配置mapper.xml(本次举例) 引入依赖pom.xml 1234567891011121314151617&lt;!--引入mybatis-springboot依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.3&lt;/version&gt;&lt;/dependency&gt;&lt;!--引入mysql--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--引入druid依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.23&lt;/version&gt;&lt;/dependency&gt; 修改配置文件application.properties 配置数据源 123456# 配置数据源spring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://localhost:3306/mybatisspring.datasource.username=rootspring.datasource.password=root 配置mybatis配置 12345#mybatis配置#指定mapper配置文件位置mybatis.mapper-locations=classpath:/com/buubiu/mapper/*.xml#指定起别名来的类mybatis.type-aliases-package=com.buubiu.entity 编辑入口类在入口类加注解 @MapperScan('com.buubiu.dao') 12345678910111213141516171819package com.buubiu;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @author buubiu **/@SpringBootApplication@MapperScan(&quot;com.buubiu.dao&quot;)public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 开发控制类以及页面123456789101112131415161718192021222324252627282930313233343536package com.buubiu.controller;import com.buubiu.entity.User;import com.buubiu.service.UserService;import java.util.List;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;/** * @author buubiu **/@Controller@RequestMapping(&quot;user&quot;)public class UserController { @Autowired private UserService userService; @GetMapping(&quot;findAll&quot;) public String findAll(Model model) { List&lt;User&gt; users = userService.findAll(); model.addAttribute(&quot;users&quot;, users); return &quot;showAll&quot;; } @GetMapping(&quot;save&quot;) public String save(User user) { userService.save(user); return &quot;redirect:/user/findAll&quot;; }} 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;ShowAll&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;ul th:each=&quot;user,userState:${users}&quot;&gt; &lt;li&gt;&lt;span th:text=&quot;${user.id}&quot;&gt;&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span th:text=&quot;${user.name}&quot;&gt;&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span th:text=&quot;${user.age}&quot;&gt;&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span th:text=&quot;${#dates.format(user.bir,'yyyy-MM-dd')}&quot;&gt;&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h1&gt;&lt;a th:href=&quot;@{/user/save(name='buubiu中间',age='33',bir='1997/09/10')}&quot;&gt;添加用户&lt;/a&gt; &lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;","link":"/SpringBoot%E9%9B%86%E6%88%90Mybatis/"},{"title":"SpringCloud介绍及环境搭建","text":"什么是SpringCloud官方定义 官方网址: https://docs.spring.io/spring-cloud/docs/Hoxton.SR9/reference/html/ Spring Cloud provides tools for developers to quickly build some of the common patterns in distributed systems (e.g. configuration management, service discovery, circuit breakers, intelligent routing, micro-proxy, control bus). Coordination of distributed systems leads to boiler plate patterns, and using Spring Cloud developers can quickly stand up services and applications that implement those patterns. ——-[摘自官网] 翻译 springcloud为开发人员提供了在分布式系统中快速构建一些通用模式的工具（例如配置管理、服务发现、断路器、智能路由、微代理、控制总线）。分布式系统的协调导致了锅炉板模式，使用springcloud开发人员可以快速地建立实现这些模式的服务和应用程序。 通俗理解 springcloud是一个含概多个子项目的开发工具集,集合了众多的开源框架,他利用了Spring Boot开发的便利性实现了很多功能,如服务注册,服务注册发现,负载均衡等.SpringCloud在整合过程中主要是针对Netflix(耐非)开源组件的封装.SpringCloud的出现真正的简化了分布式架构的开发。 NetFlix 是美国的一个在线视频网站,微服务业的翘楚,他是公认的大规模生产级微服务的杰出实践者,NetFlix的开源组件已经在他大规模分布式微服务环境中经过多年的生产实战验证,因此Spring Cloud中很多组件都是基于NetFlix组件的封装。 微服务架构下所存在问题? 要有个组件帮助我们记录服务,监控服务,服务发现 服务注册和发现组件 注册中心 服务调用问题http rest方式调用 — 如何调用? 服务调用时如何实现服务负载均衡 ? 服务雪崩效应? 服务配置文件管理? 网关组件? 核心架构及其组件 组件名称 组件描述 eurekaserver、consul、nacos 服务注册中心组件 rabbion &amp; openfeign 服务负载均衡 和 服务调用组件 hystrix &amp; hystrix dashboard 服务断路器 和 服务监控组件 zuul、gateway 服务网关组件 config 统一配置中心组件 bus 消息总线组件 …… …… 环境搭建版本命名 官网地址:https://spring.io/projects/spring-cloud Spring Cloud is an umbrella(伞) project consisting of independent projects with, in principle, different release cadences. To manage the portfolio a BOM (Bill of Materials) is published with a curated set of dependencies on the individual project (see below). The release trains have names, not versions, to avoid confusion with the sub-projects. The names are an alphabetic sequence (so you can sort them chronologically) with names of London Tube stations (“Angel” is the first release, “Brixton” is the second). When point releases of the individual projects accumulate to a critical mass, or if there is a critical bug in one of them that needs to be available to everyone, the release train will push out “service releases” with names ending “.SRX”, where “X” is a number. —[摘自官网] 翻译 springcloud是一个由众多独立子项目组成的大型综合项目，原则每个子项目上有不同的发布节奏,都维护自己发布版本号。为了更好的管理springcloud的版本,通过一个资源清单BOM(Bill of Materials),为避免与子项目的发布号混淆，所以没有采用版本号的方式，而是通过命名的方式。这些名字是按字母顺序排列的。如伦敦地铁站的名称（“天使”是第一个版本，“布里斯顿”是第二个版本,”卡姆登”是第三个版本）。当单个项目的点发布累积到一个临界量，或者其中一个项目中有一个关键缺陷需要每个人都可以使用时，发布序列将推出名称以“.SRX”结尾的“服务发布”，其中“X”是一个数字。 伦敦地铁站名称 [了解] Angel、Brixton、Camden、Dalston、Edgware、Finchley、Greenwich、Hoxton、 版本选择版本选择官方建议 https://spring.io/projects/spring-cloud 版本名称 版本说明 备注 Angel 版本基于springboot1.2.x版本构建与1.3版本不兼容 2017年Brixton and Angel release官方宣布报废 Brixton 版本基于springboot1.3.x版本构建与1.2版本不兼容 2017年Brixton and Angel release官方宣布报废 Camden 版本基于springboot1.4.x版本构建并在1.5版本通过测试 2018年Camden release官方宣布报废 Dalston、Edgware 版本基于springboot1.5.x版本构建目前不能再springboot2.0.x版本中使用 Dalston(达尔斯顿)将于2018年12月官方宣布报废。Edgware将遵循Spring Boot 1.5.x的生命周期结束。 Finchley 版本基于springboot2.0.x版本进行构建,不能兼容1.x版本 Greenwich 版本基于springboot2.1.x版本进行构建,不能兼容1.x版本 Hoxton 版本基于springboot2.2.x版本进行构建 环境搭建说明 SpringBoot 2.2.X SpringCloud Hoxton Java8+ Maven 3.3.6+ IDEA 2018.3.5+ 创建springboot项目引入springcloud的版本管理1234567891011121314151617&lt;!--定义springcloud使用版本号--&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Hoxton.SR9&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;!--全局管理springcloud版本,并不会引入具体依赖--&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 完成上述操作springboot与springcloud环境搭建完成，接下来就是使用到具体的springcloud组件,在项目中引入具体的组件即可","link":"/SpringCloud%E4%BB%8B%E7%BB%8D%E5%8F%8A%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"SpringMVC中数据传递机制","text":"数据传递机制下面列举servlet、struts2、springmvc控制器的数据传递机制： 控制器 数据怎么存储 数据在页面如何获取 在页面中获取的数据该如何展示 Servlet request,session,application EL表达式 EL+JSTL标签 Struts2 request,session,application EL表达式 EL+JSTL标签 SpringMVC request,session,application EL表达式 EL+JSTL标签 存数据具体使用哪种作用域使用哪种作用域根跳转的方式有关系： 如果是forward一次请求：用 request作用或者model(SpringMVC 封装的，且只能用在forward，不能用在redirect) 如果是redirect多次请求：可以用 session作用域、application作用域[不推荐]、问号[?]地址栏传递数据 如何在SpringMVC控制器方法中获取request对象和response对象注意：直接将request、response对象作为控制器方法参数声明即可获取 举例： AttrController.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package com.buubiu.controller;import com.buubiu.entity.User;import java.io.UnsupportedEncodingException;import java.net.URLEncoder;import java.util.Arrays;import java.util.Date;import java.util.List;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;/** * 用来测试springmvc中数据传递机制 * @author buubiu **/@Controller@RequestMapping(&quot;attr&quot;)public class AttrController { /** * 使用forward跳转页面数据传递 * 1.传递零散类型数据 * 2.传递对象类型数据 * 3.传递集合类型数据 * * Springmvc使用Model传递数据, 底层封装就是request对象并且只能用于forward * * @param request * @param response * @return */ @RequestMapping(&quot;test&quot;) public String test(Model model, HttpServletRequest request, HttpServletResponse response) { //1.收集参数 //2.调用业务方法 //零散类型数据 String name = &quot;buubiu&quot;; //传递对象类型数据 User user = new User(&quot;111&quot;, &quot;buubiu&quot;, 33, new Date()); //传递集合类型数据 User user1 = new User(&quot;222&quot;, &quot;buubiu2&quot;, 43, new Date()); User user2 = new User(&quot;333&quot;, &quot;buubiu333&quot;, 53, new Date()); List&lt;User&gt; users = Arrays.asList(user, user1, user2);// request.setAttribute(&quot;username&quot;, name);// request.setAttribute(&quot;user&quot;,user);// request.setAttribute(&quot;users&quot;, users); model.addAttribute(&quot;username&quot;, name); model.addAttribute(&quot;user&quot;,user); model.addAttribute(&quot;users&quot;, users); //3.流程跳转 return &quot;attr&quot;; } /** * 使用redirect跳转传递数据 * 1.地址栏?拼接数据 * 2.session对象 * @return */ @RequestMapping(&quot;test1&quot;) public String test1(HttpServletRequest request) throws UnsupportedEncodingException { //1.收集数据 //2.调用业务 String name = &quot;buubiu中文&quot;; User user = new User(&quot;111&quot;, &quot;buubiu&quot;, 33, new Date()); request.getSession().setAttribute(&quot;user&quot;, user); //3.流程跳转 return &quot;redirect:/attr.jsp?name=&quot;+ URLEncoder.encode(name,&quot;UTF-8&quot;); }} attr.jsp 123456789101112131415161718192021222324252627282930313233343536&lt;%@ taglib prefix=&quot;fmt&quot; uri=&quot;http://java.sun.com/jsp/jstl/fmt&quot; %&gt;&lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt;&lt;%@page contentType=&quot;text/html; UTF-8&quot; pageEncoding=&quot;utf-8&quot; isELIgnored=&quot;false&quot; %&gt;&lt;!doctype html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;测试数据传递&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;用来request测试数据传递&lt;/h1&gt; &lt;h3&gt;获取request作用域数据：${requestScope.username}&lt;/h3&gt; &lt;h3&gt;获取request作用域数据：${username}&lt;/h3&gt; &lt;hr color=&quot;red&quot;&gt; &lt;h3&gt;id:${requestScope.user.id}&lt;/h3&gt; &lt;h3&gt;name:${requestScope.user.name}&lt;/h3&gt; &lt;h3&gt;age:${requestScope.user.age}&lt;/h3&gt; &lt;h3&gt;bir:&lt;fmt:formatDate value=&quot;${requestScope.user.bir}&quot; pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;/&gt; &lt;/h3&gt; &lt;hr color=&quot;red&quot;&gt; &lt;c:forEach items=&quot;${requestScope.users}&quot; var=&quot;user&quot;&gt; id:${user.id}====name:${user.name}=====age:${user.age}=====&lt;fmt:formatDate value=&quot;${user.bir}&quot; pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;/&gt;&lt;br&gt; &lt;/c:forEach&gt; &lt;hr color=&quot;red&quot;/&gt; &lt;h3&gt;获取地址栏数据：${param.name}&lt;/h3&gt; &lt;h3&gt;获取session作用域数据：&lt;/h3&gt; &lt;h3&gt;id:${sessionScope.user.id}&lt;/h3&gt; &lt;h3&gt;name:${sessionScope.user.name}&lt;/h3&gt; &lt;h3&gt;age:${sessionScope.user.age}&lt;/h3&gt; &lt;h3&gt;bir:&lt;fmt:formatDate value=&quot;${sessionScope.user.bir}&quot; pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;/&gt;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;","link":"/SpringMVC%E4%B8%AD%E6%95%B0%E6%8D%AE%E4%BC%A0%E9%80%92%E6%9C%BA%E5%88%B6/"},{"title":"SpringMVC中文件上传和下载","text":"定义上传：指的是用户将自己本地计算机中文件通过网络的形式上传到系统所在服务器上的过程，这个过程称之为文件上传。 下载：指的是用户通过网络的形式将服务器上的文件下载到自己本地计算机上的过程，称之为下载 SpringMVC中如何开发文件上传 在系统中开发一个可以进行上传文件的上传页面，包含一个form表单，在表单中开发一个可以选择本地计算机文件的入口 form表单要求 form的method提交方式必须是post 修改form的enctype application/x-www.form-urlencoded 代表 文本 提交 multipart/form-data 代表 二进制 提交 1234&lt;form action=&quot;${pageContext.request.contextPath}/file/upload&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;input type=&quot;file&quot; name=&quot;img&quot;/&gt; &lt;input type=&quot;submit&quot; value=&quot;上传文件&quot;&gt;&lt;/form&gt; 开发controller 在控制器方法中使用 MultipartFile 进行文件的接收 在SpringMVC配置文件中加入文件上传解析器配置 12345&lt;!--配置文件上传解析器 id:必须指定为 multipartResolver --&gt; &lt;bean class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot; id=&quot;multipartResolver&quot;/&gt; 要求：文件上传解析器必须存在id，且 id必须为multipartResolver 引入文件上传的相关依赖 12345&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt; 如何修改文件上传时文件的原始名称 分隔符 1234567String fileName = &quot;name.aa.txt&quot;;//1.分隔符String[] split = fileName.split(&quot;\\\\.&quot;);System.out.println(split[split.length-1]);------结果----txt 字符串拆分 12345678String fileName = &quot;name.aa.txt&quot;;//2.字符串拆分int i = fileName.lastIndexOf(&quot;.&quot;);System.out.println(fileName.substring(i));------结果----.txt 工具类 12345678String fileName = &quot;name.aa.txt&quot;;//3.工具类 common-fileuploadString extension = FilenameUtils.getExtension(fileName);System.out.println(extension);------结果----txt 将用户上传的文件放入当天日期目录中 12345678910111213 //1.生成当天日期目录 LocalDate now = LocalDate.now(); int year = now.getYear(); int month = now.getMonthValue(); int day = now.getDayOfMonth(); String path = year+&quot;/&quot;+month+&quot;/&quot;+day; File dateDir = new File(realPath, path); if (!dateDir.exists()) { dateDir.mkdir(); } //2.将文件上传到upload对应路径// MultipartFile img; img.transferTo(new File(dateDir, fileName)); springmvc中解决文件上传大小的限制注意：在SpringMVC中默认不限制上传文件的大小；而在struts2中默认上传文件最大不超过2M 12345&lt;bean class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot; id=&quot;multipartResolver&quot;&gt; &lt;!--注入文件上传下载大小限制 单位：字节 2M=2097152字节 默认：没有限制--&gt; &lt;property name=&quot;maxUploadSize&quot; value=&quot;2097152&quot;/&gt;&lt;/bean&gt; SpringMVC中开发文件下载事例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 用来处理文件下载 请求响应输出流 * @param fileName * @param request * @param response * @throws IOException*/@RequestMapping(&quot;down&quot;)public void download(String openStyle,String fileName, HttpServletRequest request, HttpServletResponse response) throws IOException { openStyle = openStyle == null ? &quot;inline&quot; : &quot;attachment&quot;; System.out.println(&quot;下载的文件名：&quot; + fileName); //1.根据下载相对目录获取下载目录在服务器部署之后的绝对目录 String realPath = request.getSession().getServletContext().getRealPath(&quot;/down&quot;); //2.通过文件输入流读取文件 FileInputStream is = new FileInputStream(new File(realPath, fileName)); //3.获取响应输出流 // 3.1 设置字符编码 response.setContentType(&quot;text/plain;charset=UTF-8&quot;); //3.2 设置为附件下载而不是在线打开 //默认是 inline-在线打开；attachment--附件下载 response.setHeader(&quot;content-disposition&quot;, openStyle+&quot;;fileName=&quot; + fileName + URLEncoder.encode(fileName,&quot;UTF-8&quot;)); //4 处理下载流复制 ServletOutputStream os = response.getOutputStream(); //工具类写法//操作流的用IOUtils 操作文件用FileUtils IOUtils.copy(is, os); IOUtils.closeQuietly(is); IOUtils.closeQuietly(os); //传统写法 /* int len; byte[] b = new byte[1024]; while (true) { len = is.read(b); if (len == -1) { break; } os.write(b, 0,len); } //释放资源 is.close(); os.close();*/}","link":"/SpringMVC%E4%B8%AD%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD/"},{"title":"SpringMVC中的参数接收","text":"struts2框架中参数接收 语法：使用action中成员变量接收请求参数 要求：要求传递请求参数key与后台action中声明的成员变量名一致才能接收参数，同时成员变量必须提供GET和SET方法 SpringMVC中参数接收 语法：使用控制器中方法形参列表接收客户端的请求参数 要求：要求传递参数key要与对应方法的形参变量名一致才能完成自动赋值 零散类型参数接收​ 保证请求参数中key与对应方法中声明的形参变量名一致即可 例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.buubiu.controller;import java.util.Date;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;/** * 用来测试参数接收的controller * @author buubiu **/@Controller@RequestMapping(&quot;param&quot;)public class ParamController { /** * 用来测试零散类型参数接收 * 请求格式： * http://localhost:8080/springmvc/param/test?name=buubiu&amp;age=23&amp;price=23.43&amp;sex=false&amp;bir=2019/12/12%2023:44:50 * 输出结果： * name = buubiu * age = 23 * price = 23.43 * sex = false * bir = Thu Dec 12 23:44:50 CST 2019 * * 默认日期格式：yyyy/MM/dd HH:mm:ss * @param name * @param age * @param price * @param sex * @param bir * @return */ @RequestMapping(&quot;test&quot;) public String test(String name, Integer age, Double price, Boolean sex, Date bir) { System.out.println(&quot;name = &quot; + name); System.out.println(&quot;age = &quot; + age); System.out.println(&quot;price = &quot; + price); System.out.println(&quot;sex = &quot; + sex); System.out.println(&quot;bir = &quot; + bir); return &quot;index&quot;; }} 对象类型参数接收​ 接收对象类型也是直接将要接收对象作为控制器方法参数声明 ​ 注意：SpringMVC封装对象时直接根据传递参数key与对象中属性名一致自动封装对象 1234567891011121314151617181920212223242526272829303132333435363738394041package com.buubiu.controller;import com.buubiu.entity.User;import java.util.Date;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;/** * 用来测试参数接收的controller * @author buubiu **/@Controller@RequestMapping(&quot;param&quot;)public class ParamController { /** * 用来测试对象类型的参数接收 * 接收对象类型也是直接将要接收对象作为控制器方法参数声明 * 注意：SpringMVC封装对象时直接根据传递参数key与对象中属性名一致自动封装对象 * 请求格式： * URL： * http://localhost:8080/springmvc/param/test1?id=2222&amp;name=buubiu&amp;age=23&amp;bir=2019/12/12%2023:44:50 * 输出结果： * user = User{id='2222', name='buubiu', age=23, bir=Thu Dec 12 23:44:50 CST 2019} * name = buubiu * form： * input name=&quot;id&quot; * input name=&quot;name&quot; * input name=&quot;age&quot; * ..... * @param user * @param name * @return */ @RequestMapping(&quot;test1&quot;) public String test1(User user, String name) { System.out.println(&quot;user = &quot; + user); System.out.println(&quot;name = &quot; + name); return &quot;index&quot;; }} 数组或集合类型参数接收 数组 接收数组：将要接收数组类型直接声明为方法的形参即可 *** 注意：保证请求参数多个参数key与声明数组变量名一致，SpringMVC会自动放入同一个数组中** 例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.buubiu.controller;import com.buubiu.entity.User;import java.util.Date;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;/** * 用来测试参数接收的controller * @author buubiu **/@Controller@RequestMapping(&quot;param&quot;)public class ParamController { /** * 用来测试数据类型参数接收 * 接收数组：将要接收数组类型直接声明为方法的形参即可 * 注意：保证请求参数多个参数key与声明数组变量名一致，SpringMVC会自动放入同一个数组中 * 请求格式： * URL： * http://localhost:8080/springmvc/param/test2？hobbys=kanshu&amp;hobbys=chifan&amp;hobbys=tiaowu * 输出结果： * hobby = kanshu * hobby = chifan * hobby = tiaowu * * form： checkbox * input type=&quot;checkbox&quot; name=&quot;hobbys&quot; value=&quot;看书&quot; * input type=&quot;checkbox&quot; name=&quot;hobbys&quot; value=&quot;吃饭&quot; * input type=&quot;checkbox&quot; name=&quot;hobbys&quot; value=&quot;跳舞&quot; * input type=&quot;checkbox&quot; name=&quot;hobbys&quot; value=&quot;唱歌&quot; * .... * * @param hobbys * @return */ @RequestMapping(&quot;test2&quot;) public String test2(String[] hobbys) { for (String hobby : hobbys) { System.out.println(&quot;hobby = &quot; + hobby); } return &quot;index&quot;; }} 集合 springmvc不能直接通过形参列表方式收集集合类型参数； 如果要接收集合类型的参数必须将集合放入对象中接收才可以，官方推荐放入vo对象中接收集合类型； vo = value object 值对象 例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.buubiu.controller;import com.buubiu.entity.User;import com.buubiu.vo.CollectionVO;import java.util.Date;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;/** * 用来测试参数接收的controller * @author buubiu **/@Controller@RequestMapping(&quot;param&quot;)public class ParamController { /** * 用来测试集合类型参数接收 * list set map * 注意： * springmvc不能直接通过形参列表方式收集集合类型参数； * 如果要接收集合类型的参数必须将集合放入对象中接收才可以，官方推荐放入vo对象中接收集合类型； * vo = value object 值对象 * 请求格式： * URL： * http://localhost:8080/springmvc/param/test3?lists=zhangsan&amp;lists=lisi&amp;lists=wangwu * 输出结果： * =========== * str = zhangsan * str = lisi * str = wangwu * @param collectionVO * @return */ @RequestMapping(&quot;test3&quot;) public String test3(CollectionVO collectionVO) { System.out.println(&quot;===========&quot;); collectionVO.getLists().forEach(str-&gt; System.out.println(&quot;str = &quot; + str)); return &quot;index&quot;; } /** * 用来测试集合类型参数接收 * map * 注意： * springmvc不能直接通过形参列表方式收集集合类型参数； * 如果要接收集合类型的参数必须将集合放入对象中接收才可以，官方推荐放入vo对象中接收集合类型； * vo = value object 值对象 * 请求格式： * URL： * http://localhost:8080/springmvc_01/param/test4?maps['aaa']=zhangsan$maps['bbb']=lisi%maps['ccc']=wangwu * 输出结果： * =========== * str = zhangsan * str = lisi * str = wangwu * @param collectionVO * @return */ @RequestMapping(&quot;test4&quot;) public String test4(CollectionVO collectionVO) { System.out.println(&quot;==========map===========&quot;); collectionVO.getMaps().forEach((k,v)-&gt; System.out.println(&quot;k = &quot; + k+&quot; v = &quot; + v)); return &quot;index&quot;; }}","link":"/SpringMVC%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%E6%8E%A5%E6%94%B6/"},{"title":"SpringMVC中的拦截器","text":"定义拦截器（Interceptor ) 拦截、中断的意思，类似于 JavaWeb中的Filter，但不如Filter拦截的范围大。 作用通过将控制器中的通用代码放在拦截器中执行，减少控制器中的代码冗余。 拦截器的特点 请求到达会经过拦截器，响应回来同样会经过拦截器 拦截器只能拦截控制器相关请求，不能拦截jsp、静态资源相关请求 拦截器可以中断请求轨迹 开发拦截器 自定义类，并实现接口 HanHandlerInterceptor中的方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.buubiu.interceptors;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.web.method.HandlerMethod;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;/** * 自定义拦截器 * @author buubiu **/public class MyInterceptor implements HandlerInterceptor { //请求流程： //1.请求经过拦截器会优先进入拦截器中preHandle方法执行 //2.如果preHandle返回true，代表放行请求，如果返回false，中断请求 //3.如果preHandle返回true，会执行当前请求对应的控制器方法 //4.当前控制器方法执行结束之后，会返回拦截器中执行拦截器中的postHandle方法 //5.postHandle方法执行之后响应请求，在响应请求完成后会执行afterCompletion方法 //参数1：当前请求对象 //参数2：当前请求对应响应对象 //参数3：当前请求的控制器对应的方法对象 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(&quot;===========preHandle===========&quot;); System.out.println(&quot;请求的方法：&quot; + ((HandlerMethod) handler).getMethod().getName()); //强制用户登录 /*Object user = request.getSession().getAttribute(&quot;user&quot;); if (user == null) { response.sendRedirect(request.getContextPath() + &quot;/login.jsp&quot;); return false; }*/ return true; } //如果控制器方法执行失败或者异常时不执行该方法 //参数1：当前请求对象 //参数2：当前请求对应响应对象 //参数3：当前请求的控制器对应的方法对象 //参数4：当前请求控制器方法返回值（当前请求控制器方法返回的ModelAndView对象） @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(&quot;===========postHandle===========&quot;); System.out.println(modelAndView); } //无论控制器方法请求成功还是失败都会执行该方法 //参数1：当前请求对象 //参数2：当前请求对应响应对象 //参数3：当前请求的控制器对应的方法对象 //参数4：请求过程中出现异常时的异常 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(&quot;===========afterCompletion===========&quot;); if (ex != null) { System.out.println(ex.getMessage()); } }} 配置拦截器 在SpringMVC配置文件注册拦截器对象 12&lt;!--注册拦截器--&gt;&lt;bean class=&quot;com.buubiu.interceptors.MyInterceptor&quot; id=&quot;myInterceptor&quot;/&gt; 配置拦截器拦截请求 123456789101112&lt;!--配置拦截器--&gt;&lt;mvc:interceptors&gt; &lt;!--配置一个拦截器--&gt; &lt;mvc:interceptor&gt; &lt;!--mvc:mapping 代表拦截哪个请求路径--&gt; &lt;mvc:mapping path=&quot;/json/*&quot;/&gt; &lt;!--mvc:exclude-mapping 排除拦截哪个请求--&gt; &lt;mvc:exclude-mapping path=&quot;/json/showAll&quot;/&gt; &lt;!--使用哪个拦截器--&gt; &lt;ref bean=&quot;myInterceptor&quot;/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;","link":"/SpringMVC%E4%B8%AD%E7%9A%84%E6%8B%A6%E6%88%AA%E5%99%A8/"},{"title":"SpringMVC中的跳转方式","text":"原始servlet技术中的跳转方式 forward跳转 定义：请求转发 特点：服务器内部跳转，跳转之后地址不变，是一次跳转，跳转时可以使用request作用域传递数据 redirect跳转 定义：请求重定向 特点：客户端跳转，跳转之后地址栏改变，是多次跳转，跳转过程不能使用request作用域传递数据 SpringMVC中的跳转方式总体上也是 forward 和 redirect 两种，只是 SpringMVC做了更细致的划分： Controller 到 JSP 页面的跳转 forward：默认就是forward跳转 具体语法： 1return &quot;页面逻辑名&quot;;例如：return “index&quot;; redirect：使用SpringMVC提供的关键字 redirect: 具体语法： 1return &quot;redirect:视图全名&quot;;例如：return “redirect:/index.jsp&quot;; 注意：使用redirect跳转不会经过视图解析器，所以用redirect时要写jsp页面的全路径。 Controller 到 Controller之间跳转（相同、不同控制器） forward：使用SpringMVC提供的关键字 forward: 具体语法： 1return &quot;forward:/跳转Controller类上@RequestMapping路径/跳转类中指定方法上@RequestMapping路径&quot;;例如：return &quot;forward:/forwardAndRedirect/test&quot;; redirect：使用SpringMVC提供的关键字 redirect: 具体语法： 1return &quot;redirect:/跳转Controller类上@RequestMapping路径/跳转类中指定方法上@RequestMapping路径&quot;;例如：return &quot;redirect:/forwardAndRedirect/test&quot;; 总结： 1return &quot;forward|redirect:/跳转Controller类上@RequestMapping路径/跳转类中指定方法上@RequestMapping路径&quot;;","link":"/SpringMVC%E4%B8%AD%E7%9A%84%E8%B7%B3%E8%BD%AC%E6%96%B9%E5%BC%8F/"},{"title":"SpringMVC中静态资源拦截问题","text":"出现静态资源拦截问题的原因由于在 web.xml中配置SpringMVC的核心servlet(DispatherServlet)时 url-pattern 配置为 “/“，因此会导致项目中所有 / 开头的请求，均被作为控制器请求处理，这样会导致项目中的静态资源被（css,js,img）拦截。 解决方案 把url-pattern的/改为 *.action或者*.do 使用这种方式后，访问路径结尾必须加入指定后缀 url.action 或者 url.do如下： 1http://localhost:8080/springmvc/user/findAll.do url-pattern 依然使用 /，在springmvc配置文件中加入如下配置： 123456&lt;mvc:default-servlet-handler/&gt;&lt;!--或者 mapping是映射的路径； loctaion是实际资源的路径--&gt;&lt;mvc:resources mapping=&quot;/resource/**&quot; location=&quot;js&quot;/&gt;","link":"/SpringMVC%E4%B8%AD%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E6%8B%A6%E6%88%AA%E9%97%AE%E9%A2%98/"},{"title":"SpringMVC全局异常处理","text":"作用当控制器中某个方法在运行过程中突然发生运行时异常，为了增加用户体验对于用户不能出现类似500错误代码，应该给用户良好展示错误界面，全局异常处理就能更好解决这个问题 全局异常处理开发 自定义类 实现接口 HandlerExceptionResolver 123456789101112131415161718192021222324252627282930313233343536373839package com.buubiu.handlerexception;import com.buubiu.exceptions.UserNameNotFoundException;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.web.servlet.HandlerExceptionResolver;import org.springframework.web.servlet.ModelAndView;/** * 自定以全局异常类 * @author buubiu **/public class GlobalExceptionResolver implements HandlerExceptionResolver { /** * 用来处理发生异常时的方法 * @param request 当前请求对象 * @param response 当前请求对应的响应对象 * @param handler 当前请求的方法对象 * @param ex 出现异常时展示视图和数据 * @return */ @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { System.out.println(&quot;进入全局异常处理器获取的异常信息为：&quot; + ex.getMessage()); ModelAndView modelAndView = new ModelAndView(); //基于不能业务异常跳转到不同页面 if (ex instanceof UserNameNotFoundException) { modelAndView.setViewName(&quot;redirect:/login.jsp&quot;); } else { modelAndView.setViewName(&quot;redirect:/error.jsp&quot;); } //modelandview 中 model 默认放入request作用域中，如果使用redirect跳转：model中数据会自动拼接到跳转url modelAndView.addObject(&quot;msg&quot;, ex.getMessage()); return modelAndView; }} 在SpringMVC配置文件中配置全局异常处理类 12&lt;!--配置全局异常处理类--&gt;&lt;bean class=&quot;com.buubiu.handlerexception.GlobalExceptionResolver&quot;/&gt;","link":"/SpringMVC%E5%85%A8%E5%B1%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"},{"title":"SpringMVC对Ajax的支持","text":"实现思路 给按钮绑定一个单击事件 在单击事件触发时发送异步请求 $.ajax $.get $.post $.getJSON springmvc 控制器将对应数据转为json两种方式： 使用fastjson等第三方工具包转换为json格式字符串 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.buubiu.controller;import com.alibaba.fastjson.JSONObject;import com.buubiu.entity.User;import java.io.IOException;import java.util.ArrayList;import java.util.Date;import java.util.List;import java.util.UUID;import javax.servlet.http.HttpServletResponse;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;/** * SpringMVC与Ajax集成 * @author buubiu **/@Controller@RequestMapping(&quot;json&quot;)public class JsonController { /** * 使用阿里fastjson转换为json * @param response * @throws IOException */ @RequestMapping(&quot;findAll&quot;) public void findAll(HttpServletResponse response) throws IOException { //收集数据 //调用业务 List&lt;User&gt; users = new ArrayList&lt;&gt;(); users.add(new User(UUID.randomUUID().toString(), &quot;buubiu张三&quot;, 22, new Date())); users.add(new User(UUID.randomUUID().toString(), &quot;buubiu李四&quot;, 23, new Date())); users.add(new User(UUID.randomUUID().toString(), &quot;buubiu王五&quot;, 24, new Date())); //fastjson String s = JSONObject.toJSONStringWithDateFormat(users, &quot;yyyy-MM-dd&quot;); response.setContentType(&quot;application/json;charset=UTF-8&quot;); response.getWriter().println(s); }} 使用SpringMVC提供的注解@ResponseBody 作用范围：用在方法或者方法的返回值上 作用：用来将方法的返回值自动转为json格式字符串并响应到前台 底层使用：Jackson转换json 注意：别忘了引入jackson依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.11.2&lt;/version&gt;&lt;/dependency&gt; 解决日期格式问题： 在实体类的日期属性上加注解 12@JsonFormat(pattern = &quot;yyyy-MM-dd&quot;)private Date bir; 12345678910111213141516171819202122232425262728293031323334353637package com.buubiu.controller;import com.buubiu.entity.User;import java.util.ArrayList;import java.util.Date;import java.util.List;import java.util.UUID;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;/** * SpringMVC与Ajax集成 * @author buubiu **/@Controller@RequestMapping(&quot;json&quot;)public class JsonController { /** * 使用SpringMVC提供的注解@ResponseBody * @return */ @RequestMapping(&quot;showAll&quot;) public @ResponseBody List&lt;User&gt; showAll() { //收集数据 //调用业务 List&lt;User&gt; users = new ArrayList&lt;&gt;(); users.add(new User(UUID.randomUUID().toString(), &quot;buubiu张三&quot;, 22, new Date())); users.add(new User(UUID.randomUUID().toString(), &quot;buubiu李四&quot;, 23, new Date())); users.add(new User(UUID.randomUUID().toString(), &quot;buubiu王五&quot;, 24, new Date())); return users; }}","link":"/SpringMVC%E5%AF%B9Ajax%E7%9A%84%E6%94%AF%E6%8C%81/"},{"title":"SpringMVC概述","text":"SpringMVC 的由来和诞生 由来：基于Spring框架基础之上开发的一个全新的框架 SpringMVC 作用：SpringMVC 是web开发时的控制器框架，用来替换现有项目中Struts2或者servlet控制器框架 目的：为了使现有项目中使用Spring框架在MVC架构中存在自己的位置，因此开发了一个 SpringMVC 框架 MVC概念： 编程步骤，三层编程 关键字 释义 组成 技术 M model模型 service + dao + entity JDBC|Mybatis V view视图 webapp 页面 jsp|html C Controller控制器 action servlet|Struts2|SpringMVC SpringMVC引言SpringMVC 是典型的MVC框架，是控制器框架，它是在Spring基础之上进行二次开发，用来替换原有项目中Servlet或者Struts2框架 为什么是SpringMVC（优势） Spring框架流行程度非常之高 SpringMVC 运行效率高于 Struts2的运行效率，体现在：Struts2必须是多例创建action，但是SpringMVC默认单例创建action，最大原因是：SpringMVC将成员变量转换为了局部变量，局部变量用完就没了，而成员变量在同一个对象中是共享的。 SpringMVC 推荐使用注解式，其注解式开发更高效更灵活","link":"/SpringMVC%E6%A6%82%E8%BF%B0/"},{"title":"SpringMVC请求参数中文乱码解决方案","text":"GET 方式的请求出现乱码 tomcat8.x版本之前 默认使用 server.xml 中 URIEncoding=”iso-8895-1”，编码不是utf-8，所以出现了中文乱码 tomcat8.x版本之后 默认使用server.xml 中 URIEncoding=&quot;UTF-8&quot; 所以没有出现中文乱码 POST方式的请求出现乱码说明：在SpringMVC中默认没有对post方式请求进行任何编码处理，所以直接接收post方式请求会出现中文乱码 解决方案： 自定义filter CharacterEncodingFilter.java 123456789101112131415161718192021222324252627282930313233343536373839package com.buubiu.filter;import java.io.IOException;import javax.servlet.Filter;import javax.servlet.FilterChain;import javax.servlet.FilterConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;/** * 自定义编码filter * @author buubiu **/public class CharacterEncodingFilter implements Filter { private String encoding; @Override public void init(FilterConfig filterConfig) throws ServletException { this.encoding = filterConfig.getInitParameter(&quot;encoding&quot;); System.out.println(&quot;this.encoding = &quot; + this.encoding); } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { request.setCharacterEncoding(encoding); response.setCharacterEncoding(encoding); chain.doFilter(request, response); } @Override public void destroy() { }} web.xml 12345678910111213&lt;!--配置自定义编码filter--&gt; &lt;filter&gt; &lt;filter-name&gt;charter&lt;/filter-name&gt; &lt;filter-class&gt;com.buubiu.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;charter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 使用SpringMVC提供号的编码filter web.xml 12345678910111213&lt;!--配置post请求方式中文乱码的Filter--&gt; &lt;filter&gt; &lt;filter-name&gt;charset&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;charset&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;","link":"/SpringMVC%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"title":"Spring中处理事务两种方式","text":"编程式事务处理定义：通过在业务层中注入事务管理器对象，然后通过编码的方式进行事务控制 缺点： 代码冗余 不够通用 不便于维护 1234567//创建事务配置对象TransactionDefinition transactionDefinition = new DefaultTransactionDefinition();//获取事务状态TransactionStatus status = platformTransactionManager.getTransaction(transactionDefinition);....platformTransactionManager.commit(status);platformTransactionManager.rollback(status); 声明式事务处理 （推荐）定义：通过利用AOP切面编程进行事务控制，并对事物属性在配置文件中完成细粒度配置 好处： 通用 减少代码冗余 更加专注于业务逻辑开发 无需重复编码 spring 框架提供 tx:advice标签 作用： 可以根据事务管理器创建一个基于事务的环绕通知对象 tx:advice标签可以对事务进行细粒度控制 语法： 12345678&lt;tx:advice id=&quot;transactionAdvice(创建出来通知对象在工厂中的唯一标识)&quot; transaction-manager=&quot;事务管理器是谁&quot;&gt; &lt;!--事务细粒度配置--&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;save*(需要做事务处理的方法名，支持通配符)&quot;/&gt; &lt;tx:method name=&quot;delete*&quot;/&gt; &lt;tx:method name=&quot;update*&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 配置切面 语法： 1234&lt;aop:config&gt; &lt;aop:pointcut id=&quot;pc&quot; expression=&quot;within(com.buubiu.service.*ServiceImpl)&quot;/&gt; &lt;aop:advisor advice-ref=&quot;transactionAdvice&quot; pointcut-ref=&quot;pc&quot;/&gt;&lt;/aop:config&gt;","link":"/Spring%E4%B8%AD%E5%A4%84%E7%90%86%E4%BA%8B%E5%8A%A1%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F/"},{"title":"Spring基础知识-Spring控制反转(IOC)","text":"什么是 Spring IOC 容器？控制反转即 IOC (Inversion of Control)，它把传统上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。所谓的“控制反转”概念就是对组件对象控制权的转移，从程序代码本身转移到了外部容器。 Spring IOC 负责创建对象，管理对象（通过依赖注入 DI），装配对象，配置对象，并且管理这些对象的整个生命周期。 控制反转(IOC)有什么作用 管理对象的创建和依赖关系的维护。对象的创建并不是一件简单的事，在对象关系比较复杂时，如果依赖关系需要程序猿来维护的话，那是相当头疼的 解耦，由容器去维护具体的对象 托管了类的产生过程，比如我们需要在类的产生过程中做一些处理，最直接的例子就是代理，如果有容器程序可以把这部分处理交给容器，应用程序则无需去关心类是如何完成代理的 IOC 的优点是什么？ IOC 或 依赖注入把应用的代码量降到最低。 它使应用容易测试，单元测试不再需要单例和 JNDI 查找机制。 最小的代价和最小的侵入性使松散耦合得以实现。 IOC 容器支持加载服务时的饿汉式初始化和懒加载。 Spring IOC 的实现机制Spring 中的 IOC 的实现原理就是工厂模式加反射机制。 示例： 123456789101112131415161718192021222324252627282930313233343536interface Fruit { public abstract void eat(); }class Apple implements Fruit { public void eat(){ System.out.println(&quot;Apple&quot;); }}class Orange implements Fruit { public void eat(){ System.out.println(&quot;Orange&quot;); }}class Factory { public static Fruit getInstance(String ClassName) { Fruit f=null; try { f=(Fruit)Class.forName(ClassName).newInstance(); } catch (Exception e) { e.printStackTrace(); } return f; }}class Client { public static void main(String[] a) { Fruit f=Factory.getInstance(&quot;io.github.dunwu.spring.Apple&quot;); if(f!=null){ f.eat();//Apple } }} Spring 的 IOC 支持哪些功能Spring 的 IOC 设计支持以下功能： 依赖注入 依赖检查 自动装配 支持集合 指定初始化方法和销毁方法 支持回调某些方法（但是需要实现 Spring 接口，略有侵入） 其中，最重要的就是依赖注入，从 XML 的配置上说，即 ref 标签。对应 Spring RuntimeBeanReference 对象。 对于 IOC 来说，最重要的就是容器。容器管理着 Bean 的生命周期，控制着 Bean 的依赖注入。 BeanFactory 和 ApplicationContext 有什么区别？BeanFactory 和 ApplicationContext 是 Spring 的两大核心接口，都可以当做 Spring 的容器。其中 ApplicationContext 是 BeanFactory 的子接口。 依赖关系 BeanFactory：是 Spring 里面最底层的接口，包含了各种 Bean 的定义，读取 bean 配置文档，管理 bean 的加载、实例化，控制 bean 的生命周期，维护 bean 之间的依赖关系。 ApplicationContext 接口作为 BeanFactory 的派生，除了提供 BeanFactory 所具有的功能外，还提供了更完整的框架功能： 继承 MessageSource，因此支持国际化。 统一的资源文件访问方式。 提供在监听器中注册 bean 的事件。 同时加载多个配置文件。 载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的 web 层。 加载方式 BeanFactroy 采用的是延迟加载形式来注入 Bean 的，即只有在使用到某个 Bean 时(调用 getBean())，才对该 Bean 进行加载实例化。这样，我们就不能发现一些存在的 Spring 的配置问题。如果 Bean 的某一个属性没有注入，BeanFacotry 加载后，直至第一次使用调用 getBean 方法才会抛出异常。 ApplicationContext，它是在容器启动时，一次性创建了所有的 Bean。这样，在容器启动时，我们就可以发现 Spring 中存在的配置错误，这样有利于检查所依赖属性是否注入。 ApplicationContext 启动后预载入所有的单实例 Bean，通过预载入单实例 bean ,确保当你需要的时候，你就不用等待，因为它们已经创建好了。 相对于基本的 BeanFactory，ApplicationContext 唯一的不足是占用内存空间。当应用程序配置 Bean 较多时，程序启动较慢。 创建方式 BeanFactory 通常以编程的方式被创建，ApplicationContext 还能以声明的方式创建，如使用 ContextLoader。 注册方式 BeanFactory 和 ApplicationContext 都支持 BeanPostProcessor、BeanFactoryPostProcessor 的使用，但两者之间的区别是：BeanFactory 需要手动注册，而 ApplicationContext 则是自动注册。 Spring 如何设计容器的，BeanFactory 和 ApplicationContext 的关系详解Spring 作者 Rod Johnson 设计了两个接口用以表示容器。 BeanFactory ApplicationContext BeanFactory 简单粗暴，可以理解为就是个 HashMap，Key 是 BeanName，Value 是 Bean 实例。通常只提供注册（put），获取（get）这两个功能。我们可以称之为 “低级容器”。 ApplicationContext 可以称之为 “高级容器”。因为他比 BeanFactory 多了更多的功能。他继承了多个接口。因此具备了更多的功能。例如资源的获取，支持多种消息（例如 JSP tag 的支持），对 BeanFactory 多了工具级别的支持等待。所以你看他的名字，已经不是 BeanFactory 之类的工厂了，而是 “应用上下文”， 代表着整个大容器的所有功能。该接口定义了一个 refresh 方法，此方法是所有阅读 Spring 源码的人的最熟悉的方法，用于刷新整个容器，即重新加载/刷新所有的 bean。 当然，除了这两个大接口，还有其他的辅助接口，这里就不介绍他们了。 BeanFactory 和 ApplicationContext 的关系 为了更直观的展示 “低级容器” 和 “高级容器” 的关系，这里通过常用的 ClassPathXmlApplicationContext 类来展示整个容器的层级 UML 关系。 有点复杂？ 先不要慌，我来解释一下。 最上面的是 BeanFactory，下面的 3 个绿色的，都是功能扩展接口，这里就不展开讲。 看下面的隶属 ApplicationContext 粉红色的 “高级容器”，依赖着 “低级容器”，这里说的是依赖，不是继承哦。他依赖着 “低级容器” 的 getBean 功能。而高级容器有更多的功能：支持不同的信息源头，可以访问文件资源，支持应用事件（Observer 模式）。 通常用户看到的就是 “高级容器”。 但 BeanFactory 也非常够用啦！ 左边灰色区域的是 “低级容器”， 只负载加载 Bean，获取 Bean。容器其他的高级功能是没有的。例如上图画的 refresh 刷新 Bean 工厂所有配置，生命周期事件回调等。 小结 说了这么多，不知道你有没有理解 Spring IOC？ 这里小结一下：IOC 在 Spring 里，只需要低级容器就可以实现，2 个步骤： 加载配置文件，解析成 BeanDefinition 放在 Map 里。 调用 getBean 的时候，从 BeanDefinition 所属的 Map 里，拿出 Class 对象进行实例化，同时，如果有依赖关系，将递归调用 getBean 方法 —— 完成依赖注入。 上面就是 Spring 低级容器（BeanFactory）的 IOC。 至于高级容器 ApplicationContext，他包含了低级容器的功能，当他执行 refresh 模板方法的时候，将刷新整个容器的 Bean。同时其作为高级容器，包含了太多的功能。一句话，他不仅仅是 IOC。他支持不同信息源头，支持 BeanFactory 工具类，支持层级容器，支持访问文件资源，支持事件发布通知，支持接口回调等等。 ApplicationContext 通常的实现是什么？FileSystemXmlApplicationContext：此容器从一个 XML 文件中加载 beans 的定义，XML Bean 配置文件的全路径名必须提供给它的构造函数。 ClassPathXmlApplicationContext：此容器也从一个 XML 文件中加载 beans 的定义，这里，你需要正确设置 classpath 因为这个容器将在 classpath 里找 bean 配置。 WebXmlApplicationContext：此容器加载一个 XML 文件，此文件定义了一个 WEB 应用的所有 bean。 什么是 Spring 的依赖注入？控制反转 IOC 是一个很大的概念，可以用不同的方式来实现。其主要实现方式有两种：依赖注入和依赖查找 依赖注入：相对于 IOC 而言，依赖注入(DI)更加准确地描述了 IOC 的设计理念。所谓依赖注入（Dependency Injection），即组件之间的依赖关系由容器在应用系统运行期来决定，也就是由容器动态地将某种依赖关系的目标对象实例注入到应用系统中的各个关联的组件之中。组件不做定位查询，只提供普通的 Java 方法让容器去决定依赖关系。 依赖注入的基本原则依赖注入的基本原则是：应用组件不应该负责查找资源或者其他依赖的协作对象。配置对象的工作应该由 IOC 容器负责，“查找资源”的逻辑应该从应用组件的代码中抽取出来，交给 IOC 容器负责。容器全权负责组件的装配，它会把符合依赖关系的对象通过属性（JavaBean 中的 setter）或者是构造器传递给需要的对象。 依赖注入有什么优势依赖注入之所以更流行是因为它是一种更可取的方式：让容器全权负责依赖查询，受管组件只需要暴露 JavaBean 的 setter 方法或者带参数的构造器或者接口，使容器可以在初始化时组装对象的依赖关系。其与依赖查找方式相比，主要优势为： 查找定位操作与应用代码完全无关。 不依赖于容器的 API，可以很容易地在任何容器以外使用应用对象。 不需要特殊的接口，绝大多数对象可以做到完全不必依赖容器。 有哪些不同类型的依赖注入实现方式？依赖注入是时下最流行的 IOC 实现方式，依赖注入分为接口注入（Interface Injection），Setter 方法注入（Setter Injection）和构造器注入（Constructor Injection）三种方式。其中接口注入由于在灵活性和易用性比较差，现在从 Spring4 开始已被废弃。 构造器依赖注入：构造器依赖注入通过容器触发一个类的构造器来实现的，该类有一系列参数，每个参数代表一个对其他类的依赖。 Setter 方法注入：Setter 方法注入是容器通过调用无参构造器或无参 static 工厂 方法实例化 bean 之后，调用该 bean 的 setter 方法，即实现了基于 setter 的依赖注入。 构造器依赖注入和 Setter 方法注入的区别 构造函数注入 setter 注入 没有部分注入 有部分注入 不会覆盖 setter 属性 会覆盖 setter 属性 任意修改都会创建一个新实例 任意修改不会创建一个新实例 适用于设置很多属性 适用于设置少量属性 两种依赖方式都可以使用，构造器注入和 Setter 方法注入。最好的解决方案是用构造器参数实现强制依赖，setter 方法实现可选依赖。 参考：https://blog.csdn.net/ThinkWon","link":"/Spring%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-Spring%E6%8E%A7%E5%88%B6%E5%8F%8D%E8%BD%AC-IOC/"},{"title":"Spring基础知识-Spring概述","text":"什么是 spring?Spring 是一个轻量级 Java 开发框架，最早有 Rod Johnson 创建，目的是为了解决企业级应用开发的业务逻辑层和其他各层的耦合问题。它是一个分层的 JavaSE/JavaEE full-stack（一站式）轻量级开源框架，为开发 Java 应用程序提供全面的基础架构支持。Spring 负责基础架构，因此 Java 开发者可以专注于应用程序的开发。 Spring 最根本的使命是解决企业级应用开发的复杂性，即简化 Java 开发。 Spring 可以做很多事情，它为企业级开发提供给了丰富的功能，但是这些功能的底层都依赖于它的两个核心特性，也就是依赖注入（dependency injection，DI）和面向切面编程（aspect-oriented programming，AOP）。 为了降低 Java 开发的复杂性，Spring 采取了以下 4 种关键策略 基于 POJO 的轻量级和最小侵入性编程； 通过依赖注入和面向接口实现松耦合； 基于切面和惯例进行声明式编程； 通过切面和模板减少样板式代码。 Spring 框架的设计目标，设计理念，和核心是什么Spring 设计目标：Spring 为开发者提供一个一站式轻量级应用开发平台； Spring 设计理念：在 JavaEE 开发中，支持 POJO 和 JavaBean 开发方式，使应用面向接口开发，充分支持 OO（面向对象）设计方法；Spring 通过 IOC 容器实现对象耦合关系的管理，并实现依赖反转，将对象之间的依赖关系交给 IOC 容器，实现解耦； Spring 框架的核心：IOC 容器和 AOP 模块。通过 IOC 容器管理 POJO 对象以及他们之间的耦合关系；通过 AOP 以动态非侵入的方式增强服务。 IOC 让相互协作的组件保持松散的耦合，而 AOP 编程允许你把遍布于应用各层的功能分离出来形成可重用的功能组件。 Spring 的优缺点是什么？优点 方便解耦，简化开发 Spring 就是一个大工厂，可以将所有对象的创建和依赖关系的维护，交给 Spring 管理。 AOP 编程的支持 Spring 提供面向切面编程，可以方便的实现对程序进行权限拦截、运行监控等功能。 声明式事务的支持 只需要通过配置就可以完成对事务的管理，而无需手动编程。 方便程序的测试 Spring 对 Junit4 支持，可以通过注解方便的测试 Spring 程序。 方便集成各种优秀框架 Spring 不排斥各种优秀的开源框架，其内部提供了对各种优秀框架的直接支持（如：Struts、Hibernate、MyBatis 等）。 降低 JavaEE API 的使用难度 Spring 对 JavaEE 开发中非常难用的一些 API（JDBC、JavaMail、远程调用等），都提供了封装，使这些 API 应用难度大大降低。 缺点 Spring 明明一个很轻量级的框架，却给人感觉大而全 Spring 依赖反射，反射影响性能 使用门槛升高，入门 Spring 需要较长时间 Spring 有哪些应用场景应用场景：JavaEE 企业应用开发，包括 SSH、SSM 等 Spring 价值： Spring 是非侵入式的框架，目标是使应用程序代码对框架依赖最小化； Spring 提供一个一致的编程模型，使应用直接使用 POJO 开发，与运行环境隔离开来； Spring 推动应用设计风格向面向对象和面向接口开发转变，提高了代码的重用性和可测试性； Spring 由哪些模块组成？Spring 总共大约有 20 个模块， 由 1300 多个不同的文件构成。 而这些组件被分别整合在核心容器（Core Container） 、 AOP（Aspect Oriented Programming）和设备支持（Instrmentation） 、数据访问与集成（Data Access/Integeration） 、 Web、 消息（Messaging） 、 Test 等 6 个模块中。 以下是 Spring 5 的模块结构图： spring core：提供了框架的基本组成部分，包括控制反转（Inversion of Control，IOC）和依赖注入（Dependency Injection，DI）功能。 spring beans：提供了 BeanFactory，是工厂模式的一个经典实现，Spring 将管理对象称为 Bean。 spring context：构建于 core 封装包基础上的 context 封装包，提供了一种框架式的对象访问方法。 spring jdbc：提供了一个 JDBC 的抽象层，消除了烦琐的 JDBC 编码和数据库厂商特有的错误代码解析， 用于简化 JDBC。 spring aop：提供了面向切面的编程实现，让你可以自定义拦截器、切点等。 spring Web：提供了针对 Web 开发的集成特性，例如文件上传，利用 servlet listeners 进行 ioc 容器初始化和针对 Web 的 ApplicationContext。 spring test：主要为测试提供支持的，支持使用 JUnit 或 TestNG 对 Spring 组件进行单元测试和集成测试。 Spring 框架中都用到了哪些设计模式？ 工厂模式：BeanFactory 就是简单工厂模式的体现，用来创建对象的实例； 单例模式：Bean 默认为单例模式。 代理模式：Spring 的 AOP 功能用到了 JDK 的动态代理和 CGLIB 字节码生成技术； 模板方法：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。 观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如 Spring 中 listener 的实现–ApplicationListener。 详细讲解一下核心容器（spring context 应用上下文) 模块这是基本的 Spring 模块，提供 spring 框架的基础功能，BeanFactory 是 任何以 spring 为基础的应用的核心。Spring 框架建立在此模块之上，它使 Spring 成为一个容器。 Bean 工厂是工厂模式的一个实现，提供了控制反转功能，用来把应用的配置和依赖从真正的应用代码中分离。最常用的就是 org.springframework.beans.factory.xml.XmlBeanFactory ，它根据 XML 文件中的定义加载 beans。该容器从 XML 文件读取配置元数据并用它去创建一个完全配置的系统或应用。 Spring 框架中有哪些不同类型的事件Spring 提供了以下 5 种标准的事件： 上下文更新事件（ContextRefreshedEvent）：在调用 ConfigurableApplicationContext 接口中的 refresh()方法时被触发。 上下文开始事件（ContextStartedEvent）：当容器调用 ConfigurableApplicationContext 的 Start()方法开始/重新开始容器时触发该事件。 上下文停止事件（ContextStoppedEvent）：当容器调用 ConfigurableApplicationContext 的 Stop()方法停止容器时触发该事件。 上下文关闭事件（ContextClosedEvent）：当 ApplicationContext 被关闭时触发该事件。容器被关闭时，其管理的所有单例 Bean 都被销毁。 请求处理事件（RequestHandledEvent）：在 Web 应用中，当一个 http 请求（request）结束触发该事件。如果一个 bean 实现了 ApplicationListener 接口，当一个 ApplicationEvent 被发布以后，bean 会自动被通知。 Spring 应用程序有哪些不同组件？Spring 应用一般有以下组件： 接口 - 定义功能。 Bean 类 - 它包含属性，setter 和 getter 方法，函数等。 Bean 配置文件 - 包含类的信息以及如何配置它们。 Spring 面向切面编程（AOP） - 提供面向切面编程的功能。 用户程序 - 它使用接口。 使用 Spring 有哪些方式？使用 Spring 有以下方式： 作为一个成熟的 Spring Web 应用程序。 作为第三方 Web 框架，使用 Spring Frameworks 中间层。 作为企业级 Java Bean，它可以包装现有的 POJO（Plain Old Java Objects）。 用于远程使用。 参考：https://blog.csdn.net/ThinkWon","link":"/Spring%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-Spring%E6%A6%82%E8%BF%B0/"},{"title":"Spring整合Mybatis思路分析(SM整合)","text":"引入相关依赖spring&nbsp;&nbsp;&nbsp;&nbsp;mybatis&nbsp;&nbsp;&nbsp;&nbsp;mysql&nbsp;&nbsp;&nbsp;&nbsp;mybatis-spring&nbsp;&nbsp; druid…… 如何整合？Spring是项目管理框架 主要是用来负责项目中组件对象的创建、使用、销毁 --对象创建 Mybatis是持久层框架 主要是用来简化原始jdbc技术对数据库访问操作 --操作数据库 整合思路：通过Spring框架接管Mybatis框架中核心对象的创建 Mybatis框架中核心对象是谁？ SqlSessionFactory Mybatis中核心对象，读取 Mybatis-Config.xml[数据源配置和mapper文件配置] SM整合（Spring整合mybatis框架）整合思路：通过Spring框架接管Mybatis中核心的SqlSessionFactory对象的创建 Spring如何管理 SqlSessionFactory 对象的创建 简单对象：&lt;bean id=&quot;&quot; class=&quot;&quot;/&gt; 复杂对象(接口和抽象类等)：类 implement FactoryBean&lt;创建的对象&gt;{} SqlSessionFactory：通过查看源码得知它是一个接口类型的复杂对象。 普通如何创建： 12InputStream inputStream = Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;);sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); 复杂对象如何创建： 1234567891011121314151617181920212223242526272829303132package factorybean;import java.io.InputStream;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.springframework.beans.factory.FactoryBean;/** * 自定义创建SqlSessionFactory * @author buubiu **/public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt; { @Override public SqlSessionFactory getObject() throws Exception { InputStream inputStream = Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;); SqlSessionFactory build = new SqlSessionFactoryBuilder().build(inputStream); return build; } @Override public Class&lt;?&gt; getObjectType() { return SqlSessionFactory.class; } @Override public boolean isSingleton() { return true; }} 工厂管理 SqlSessionFactory 1&lt;bean class=&quot;buubiu.sqlSessionFactoryBean&quot; id=&quot;sqlSessionFactory&quot; /&gt; 工厂获取 123SqlSessionFactory sqlSessionFactory = (SqlSessionFactory) context .getBean(&quot;sqlSessionFactory&quot;);SqlSession sqlSession = sqlSessionFactory.openSession(); Mybatis官方提供jar包mybatis-spring.jar 封装了 SqlSessionFactory 对象的创建，即我们刚刚创建的 SqlSessionFactoryBean 所以，在工厂管理时，直接引用jar包里面的SqlSessionFactoryBean 1&lt;bean class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot; id=&quot;sqlSessionFactory&quot;/&gt; 注意：官方提供的 SqlSessionFactoryBean 不能再使用mybatis-config.xml 创建数据源对象（driud c3p0 dbcp） 引入依赖 123456&lt;!--druid--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.23&lt;/version&gt;&lt;/dependency&gt; 创建数据源对象 1234567&lt;!--创建数据源对象 druid c3p0 dbcp--&gt; &lt;bean class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; id=&quot;druidDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/bean&gt; 工厂获取 123SqlSessionFactory sqlSessionFactory = (SqlSessionFactory) context .getBean(&quot;sqlSessionFactory&quot;);SqlSession sqlSession = sqlSessionFactory.openSession();","link":"/Spring%E6%95%B4%E5%90%88Mybatis%E6%80%9D%E8%B7%AF%E5%88%86%E6%9E%90-SM%E6%95%B4%E5%90%88/"},{"title":"Swagger简介","text":"引言相信无论是前端还是后端开发，都或多或少地被接口文档折磨过。前端经常抱怨后端给的接口文档与实际情况不一致。后端又觉得编写及维护接口文档会耗费不少精力，经常来不及更新。其实无论是前端调用后端，还是后端调用后端，都期望有一个好的接口文档。但是这个接口文档对于程序员来说，就跟注释一样，经常会抱怨别人写的代码没有写注释，然而自己写起代码起来，最讨厌的，也是写注释。所以仅仅只通过强制来规范大家是不够的，随着时间推移，版本迭代，接口文档往往很容易就跟不上代码了。 什么是Swagger发现了痛点就要去找解决方案。解决方案用的人多了，就成了标准的规范，这就是Swagger的由来。通过这套规范，你只需要按照它的规范去定义接口及接口相关的信息。再通过Swagger衍生出来的一系列项目和工具，就可以做到生成各种格式的接口文档，生成多种语言的客户端和服务端的代码，以及在线接口调试页面等等。这样，如果按照新的开发模式，在开发新版本或者迭代版本的时候，只需要更新Swagger描述文件，就可以自动生成接口文档和客户端服务端代码，做到调用端代码、服务端代码以及接口文档的一致性。 但即便如此，对于许多开发来说，编写这个yml或json格式的描述文件，本身也是有一定负担的工作，特别是在后面持续迭代开发的时候，往往会忽略更新这个描述文件，直接更改代码。久而久之，这个描述文件也和实际项目渐行渐远，基于该描述文件生成的接口文档也失去了参考意义。所以作为Java届服务端的大一统框架Spring，迅速将Swagger规范纳入自身的标准，建立了Spring-swagger项目，后面改成了现在的Springfox。通过在项目中引入Springfox，可以扫描相关的代码，生成该描述文件，进而生成与代码一致的接口文档和客户端代码。这种通过代码生成接口文档的形式，在后面需求持续迭代的项目中，显得尤为重要和高效。 总结：Swagger就是一个用来定义接口标准，接口规范，同时能根据你的代码自动生成接口说明文档的一个工具。 官方提供的工具 Swagger Codegen: 通过Codegen 可以将描述文件生成html格式和cwiki形式的接口文档，同时也能生成多钟语言的服务端和客户端的代码。支持通过jar包，docker，node等方式在本地化执行生成。也可以在后面的Swagger Editor中在线生成。 Swagger UI:提供了一个可视化的UI页面展示描述文件。接口的调用方、测试、项目经理等都可以在该页面中对相关接口进行查阅和做一些简单的接口请求。该项目支持在线导入描述文件和本地部署UI项目。 Swagger Editor: 类似于markendown编辑器的编辑Swagger描述文件的编辑器，该编辑支持实时预览描述文件的更新效果。也提供了在线编辑器和本地部署编辑器两种方式。 Swagger Inspector: 感觉和postman差不多，是一个可以对接口进行测试的在线版的postman。比在Swagger UI里面做接口请求，会返回更多的信息，也会保存你请求的实际请求参数等数据。 Swagger Hub：集成了上面所有项目的各个功能，你可以以项目和版本为单位，将你的描述文件上传到Swagger Hub中。在Swagger Hub中可以完成上面项目的所有工作，需要注册账号，分免费版和收费版。 Springfox Swagger: Spring 基于swagger规范，可以将基于SpringMVC和Spring Boot项目的项目代码，自动生成JSON格式的描述文件。本身不是属于Swagger官网提供的，在这里列出来做个说明，方便后面作一个使用的展开。 构建Swagger与SpringBoot环境引入依赖12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 编写Swagger配置类1234567891011121314151617181920@Configuration@EnableSwagger2public class SwaggerConfig { @Bean public Docket createRestApi(){ return new Docket(DocumentationType.SWAGGER_2) .pathMapping(&quot;/&quot;) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.buubiu.controller&quot;)) .paths(PathSelectors.any()) .build().apiInfo(new ApiInfoBuilder() .title(&quot;标题：SpringBoot整合Swagger使用&quot;) .description(&quot;SpringBoot整合Swagger，详细信息......&quot;) .version(&quot;1.1&quot;) .contact(new Contact(&quot;bubiu&quot;, &quot;https://buubiu.com&quot;,&quot;me.buubiu@gmail.com&quot;)) .license(&quot;The buubiu License&quot;) .licenseUrl(&quot;https://buubiu.com&quot;) .build()); }} 访问Swagger的UI界面 开发Controller接口 启动SpringBoot应用 访问Swagger提供的UI界面：http://localhost:8080/swagger-ui.html Swagger的注解@Api 作用：用来指定接口的描述文字 修饰范围：用在类上 123456@RestController@RequestMapping(&quot;user&quot;)@Api(tags = &quot;用户服务相关接口&quot;)public class UserController { ....} @ApiOperation 作用：用来对接口中具体的方法做描述 修饰范围：用在方法上 123456789@GetMapping(&quot;findAll&quot;)@ApiOperation(value = &quot;查询所有用户信息&quot;, notes = &quot;&lt;span style='color:red;'&gt;描述：&lt;/span&gt;&amp;nbsp;&amp;nbsp;用来查询所有用户信息的接口&quot;)public Map&lt;String, Object&gt; findAll() { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;success&quot;, &quot;查询成功&quot;); map.put(&quot;state&quot;, true); return map;} value： 用来对接口的说明 notes： 用来对接口的详细描述 @ApiImplicitParams 作用：用来对接口的中参数进行说明 修饰范围：用在方法上 12345678910111213141516171819202122@GetMapping(&quot;findAll2/{id}/{name}&quot;)@ApiOperation(value = &quot;查询所有用户信息2&quot;, notes = &quot;&lt;span style='color:red;'&gt;描述：&lt;/span&gt;&amp;nbsp;&amp;nbsp;用来查询所有用户信息的接口&quot;)@ApiImplicitParams({ @ApiImplicitParam(name = &quot;id&quot;,value = &quot;用户ID&quot;,dataType = &quot;String&quot;,defaultValue = &quot;22&quot;,paramType = &quot;path&quot;), @ApiImplicitParam(name = &quot;name&quot;,value = &quot;用户姓名&quot;,dataType = &quot;String&quot;,defaultValue = &quot;buubiu&quot;,paramType = &quot;path&quot;)})public Map&lt;String, Object&gt; findAll2(@PathVariable(&quot;id&quot;) String id, @PathVariable(&quot;name&quot;) String name) { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;success&quot;, &quot;查询成功&quot;); map.put(&quot;state&quot;, true); return map;}@PostMapping(&quot;findAll3&quot;)@ApiOperation(value = &quot;查询所有用户信息3&quot;, notes = &quot;&lt;span style='color:red;'&gt;描述：&lt;/span&gt;&amp;nbsp;&amp;nbsp;用来查询所有用户信息的接口&quot;)public Map&lt;String, Object&gt; findAll3(@RequestBody User user) { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;success&quot;, &quot;查询成功&quot;); map.put(&quot;state&quot;, true); return map;} @ApiResponse 作用：用于请求的方法上，表示一组响应 修饰范围：用在方法上 123456789101112131415161718@GetMapping(&quot;findAll&quot;)@ApiOperation(value = &quot;查询所有用户信息&quot;, notes = &quot;&lt;span style='color:red;'&gt;描述：&lt;/span&gt;&amp;nbsp;&amp;nbsp;用来查询所有用户信息的接口&quot;)@ApiImplicitParams({ @ApiImplicitParam(name = &quot;id&quot;,value = &quot;用户ID&quot;,dataType = &quot;String&quot;,defaultValue = &quot;22&quot;), @ApiImplicitParam(name = &quot;name&quot;,value = &quot;用户姓名&quot;,dataType = &quot;String&quot;,defaultValue = &quot;buubiu&quot;)})@ApiResponses({ @ApiResponse(code = 401,message = &quot;当前请求没有被授权&quot;), @ApiResponse(code = 404,message = &quot;当前请求路径不存在&quot;), @ApiResponse(code = 200,message = &quot;请求成功&quot;),})public Map&lt;String, Object&gt; findAll(String id, String name) { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;success&quot;, &quot;查询成功&quot;); map.put(&quot;state&quot;, true); return map;}","link":"/Swagger%E7%AE%80%E4%BB%8B/"},{"title":"TypeScript Array（数组）","text":"数组对象是使用单独的变量名来存储一系列的值。 数组非常常用。 TypeScript 声明数组的语法格式如下所示： 12var array_name[:datatype]; //声明 array_name = [val1,val2,valn..] //初始化 或者直接在声明时初始化： 1var array_name[:data type] = [val1,val2…valn] 如果数组声明时未设置类型，则会被认为是 any 类型，在初始化时根据第一个元素的类型来推断数组的类型。 实例 创建一个 number 类型的数组： 1var numlist:number[] = [2,4,6,8] 整个数组结构如下所示： 索引值第一个为 0，我们可以根据索引值来访问数组元素： 以下实例我们在先声明数组在初始化： 1234var sites:string[]; sites = [&quot;Google&quot;,&quot;Buubiu&quot;,&quot;Taobao&quot;] console.log(sites[0]); console.log(sites[1]); 编译以上代码得到如下 JavaScript 代码： 1234var sites;sites = [&quot;Google&quot;, &quot;Buubiu&quot;, &quot;Taobao&quot;];console.log(sites[0]);console.log(sites[1]); 执行以上 JavaScript 代码，输出结果为： 12GoogleBuubiu 以下实例我们在声明时直接初始化： 12345var nums:number[] = [1,2,3,4] console.log(nums[0]); console.log(nums[1]); console.log(nums[2]); console.log(nums[3]); 编译以上代码得到如下 JavaScript 代码： 12345var nums = [1, 2, 3, 4];console.log(nums[0]);console.log(nums[1]);console.log(nums[2]);console.log(nums[3]); 执行以上 JavaScript 代码，输出结果为： 12341 2 3 4 Array 对象我们也可以使用 Array 对象创建数组。 Array 对象的构造函数接受以下两种值： 表示数组大小的数值。 初始化的数组列表，元素使用逗号分隔值。 实例 指定数组初始化大小： 123456var arr_names:number[] = new Array(4) for(var i = 0; i&lt;arr_names.length; i++) { arr_names[i] = i * 2 console.log(arr_names[i]) } 编译以上代码得到如下 JavaScript 代码： 12345var arr_names = new Array(4);for (var i = 0; i &lt; arr_names.length; i++) { arr_names[i] = i * 2; console.log(arr_names[i]);} 执行以上 JavaScript 代码，输出结果为： 12340246 以下实例我们直接初始化数组元素： 12345var sites:string[] = new Array(&quot;Google&quot;,&quot;Buubiu&quot;,&quot;Taobao&quot;,&quot;Facebook&quot;) for(var i = 0;i&lt;sites.length;i++) { console.log(sites[i]) } 编译以上代码得到如下 JavaScript 代码： 1234var sites = new Array(&quot;Google&quot;, &quot;Buubiu&quot;, &quot;Taobao&quot;, &quot;Facebook&quot;);for (var i = 0; i &lt; sites.length; i++) { console.log(sites[i]);} 执行以上 JavaScript 代码，输出结果为： 1234GoogleBuubiuTaobaoFacebook 数组解构我们也可以把数组元素赋值给变量，如下所示： 实例 1234var arr:number[] = [12,13] var[x,y] = arr // 将数组的两个元素赋值给变量 x 和 yconsole.log(x) console.log(y) 编译以上代码得到如下 JavaScript 代码： 1234var arr = [12, 13];var x = arr[0], y = arr[1]; // 将数组的两个元素赋值给变量 x 和 yconsole.log(x);console.log(y); 执行以上 JavaScript 代码，输出结果为： 121213 数组迭代我们可以使用 for 语句来循环输出数组的各个元素： 实例 123456var j:any; var nums:number[] = [1001,1002,1003,1004] for(j in nums) { console.log(nums[j]) } 编译以上代码得到如下 JavaScript 代码： 12345var j;var nums = [1001, 1002, 1003, 1004];for (j in nums) { console.log(nums[j]);} 执行以上 JavaScript 代码，输出结果为： 12341001100210031004 多维数组一个数组的元素可以是另外一个数组，这样就构成了多维数组（Multi-dimensional Array）。 最简单的多维数组是二维数组，定义方式如下： 1var arr_name:datatype[][]=[ [val1,val2,val3],[v1,v2,v3] ] 实例 定义一个二维数组，每一个维度的数组有三个元素。 1234567var multi:number[][] = [[1,2,3],[23,24,25]] console.log(multi[0][0]) console.log(multi[0][1]) console.log(multi[0][2]) console.log(multi[1][0]) console.log(multi[1][1]) console.log(multi[1][2]) 编译以上代码得到如下 JavaScript 代码： 1234567var multi = [[1, 2, 3], [23, 24, 25]];console.log(multi[0][0]);console.log(multi[0][1]);console.log(multi[0][2]);console.log(multi[1][0]);console.log(multi[1][1]);console.log(multi[1][2]); 执行以上 JavaScript 代码，输出结果为： 123456123232425 数组在函数中的使用作为参数传递给函数实例 12345678var sites:string[] = new Array(&quot;Google&quot;,&quot;Buubiu&quot;,&quot;Taobao&quot;,&quot;Facebook&quot;) function disp(arr_sites:string[]) { for(var i = 0;i&lt;arr_sites.length;i++) { console.log(arr_sites[i]) } } disp(sites); 编译以上代码得到如下 JavaScript 代码： 1234567var sites = new Array(&quot;Google&quot;, &quot;Buubiu&quot;, &quot;Taobao&quot;, &quot;Facebook&quot;);function disp(arr_sites) { for (var i = 0; i &lt; arr_sites.length; i++) { console.log(arr_sites[i]); }}disp(sites); 执行以上 JavaScript 代码，输出结果为： 1234GoogleBuubiuTaobaoFacebook 作为函数的返回值实例 12345678function disp():string[] { return new Array(&quot;Google&quot;, &quot;Buubiu&quot;, &quot;Taobao&quot;, &quot;Facebook&quot;);} var sites:string[] = disp() for(var i in sites) { console.log(sites[i]) } 编译以上代码得到如下 JavaScript 代码： 1234567function disp() { return new Array(&quot;Google&quot;, &quot;Buubiu&quot;, &quot;Taobao&quot;, &quot;Facebook&quot;);}var sites = disp();for (var i in sites) { console.log(sites[i]);} 执行以上 JavaScript 代码，输出结果为： 1234GoogleBuubiuTaobaoFacebook 数组方法concat()描述：连接两个或更多的数组，并返回结果。 实例 12345var alpha = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]; var numeric = [1, 2, 3];var alphaNumeric = alpha.concat(numeric); console.log(&quot;alphaNumeric : &quot; + alphaNumeric ); // a,b,c,1,2,3 every()描述：检测数值元素的每个元素是否都符合条件。 实例 123456function isBigEnough(element, index, array) { return (element &gt;= 10); } var passed = [12, 5, 8, 130, 44].every(isBigEnough); console.log(&quot;Test Value : &quot; + passed ); // false filter()描述：检测数值元素，并返回符合条件所有元素的数组。 实例 123456function isBigEnough(element, index, array) { return (element &gt;= 10); } var passed = [12, 5, 8, 130, 44].filter(isBigEnough); console.log(&quot;Test Value : &quot; + passed ); // 12,130,44 forEach()描述：数组每个元素都执行一次回调函数。 实例 1234let num = [7, 8, 9];num.forEach(function (value) { console.log(value);}); 编译成 JavaScript 代码： 1234var num = [7, 8, 9];num.forEach(function (value) { console.log(value); // 7 8 9}); indexOf()描述：搜索数组中的元素，并返回它所在的位置。如果搜索不到，返回值 -1，代表没有此项。 实例 12var index = [12, 5, 8, 130, 44].indexOf(8); console.log(&quot;index is : &quot; + index ); // 2 join()描述：把数组的所有元素放入一个字符串。 实例 12345678910var arr = new Array(&quot;Google&quot;,&quot;Buubiu&quot;,&quot;Taobao&quot;); var str = arr.join(); console.log(&quot;str : &quot; + str ); // Google,Buubiu,Taobao var str = arr.join(&quot;, &quot;); console.log(&quot;str : &quot; + str ); // Google, Buubiu, Taobao var str = arr.join(&quot; + &quot;); console.log(&quot;str : &quot; + str ); // Google + Buubiu + Taobao lastIndexOf()描述：返回一个指定的字符串值最后出现的位置，在一个字符串中的指定位置从后向前搜索。 实例 12var index = [12, 5, 8, 130, 44].lastIndexOf(8); console.log(&quot;index is : &quot; + index ); // 2 map()描述：通过指定函数处理数组的每个元素，并返回处理后的数组。 实例 123var numbers = [1, 4, 9]; var roots = numbers.map(Math.sqrt); console.log(&quot;roots is : &quot; + roots ); // 1,2,3 pop()描述：删除数组的最后一个元素并返回删除的元素。 实例 1234567var numbers = [1, 4, 9]; var element = numbers.pop(); console.log(&quot;element is : &quot; + element ); // 9 var element = numbers.pop(); console.log(&quot;element is : &quot; + element ); // 4 push()描述：向数组的末尾添加一个或更多元素，并返回新的长度。 实例 12345var numbers = new Array(1, 4, 9); var length = numbers.push(10); console.log(&quot;new numbers is : &quot; + numbers ); // 1,4,9,10 length = numbers.push(20); console.log(&quot;new numbers is : &quot; + numbers ); // 1,4,9,10,20 reduce()描述：将数组元素计算为一个值（从左到右）。 实例 12var total = [0, 1, 2, 3].reduce(function(a, b){ return a + b; }); console.log(&quot;total is : &quot; + total ); // 6 reduceRight()描述：将数组元素计算为一个值（从右到左）。 实例 12var total = [0, 1, 2, 3].reduceRight(function(a, b){ return a + b; }); console.log(&quot;total is : &quot; + total ); // 6 reverse()描述：反转数组的元素顺序。 实例 12var arr = [0, 1, 2, 3].reverse(); console.log(&quot;Reversed array is : &quot; + arr ); // 3,2,1,0 shift()描述：删除并返回数组的第一个元素。 实例 12var arr = [10, 1, 2, 3].shift(); console.log(&quot;Shifted value is : &quot; + arr ); // 10 slice()描述：选取数组的的一部分，并返回一个新数组。 实例 123var arr = [&quot;orange&quot;, &quot;mango&quot;, &quot;banana&quot;, &quot;sugar&quot;, &quot;tea&quot;]; console.log(&quot;arr.slice( 1, 2) : &quot; + arr.slice( 1, 2) ); // mangoconsole.log(&quot;arr.slice( 1, 3) : &quot; + arr.slice( 1, 3) ); // mango,banana some()描述：检测数组元素中是否有元素符合指定条件。 实例 12345678910function isBigEnough(element, index, array) { return (element &gt;= 10); } var retval = [2, 5, 8, 1, 4].some(isBigEnough);console.log(&quot;Returned value is : &quot; + retval ); // false var retval = [12, 5, 8, 1, 4].some(isBigEnough); console.log(&quot;Returned value is : &quot; + retval ); // true sort()描述：对数组的元素进行排序。 实例 123var arr = new Array(&quot;orange&quot;, &quot;mango&quot;, &quot;banana&quot;, &quot;sugar&quot;); var sorted = arr.sort(); console.log(&quot;Returned string is : &quot; + sorted ); // banana,mango,orange,sugar splice()描述：从数组中添加或删除元素。 实例 12345678var arr = [&quot;orange&quot;, &quot;mango&quot;, &quot;banana&quot;, &quot;sugar&quot;, &quot;tea&quot;]; var removed = arr.splice(2, 0, &quot;water&quot;); console.log(&quot;After adding 1: &quot; + arr ); // orange,mango,water,banana,sugar,tea console.log(&quot;removed is: &quot; + removed); removed = arr.splice(3, 1); console.log(&quot;After removing 1: &quot; + arr ); // orange,mango,water,sugar,tea console.log(&quot;removed is: &quot; + removed); // banana toString()描述：把数组转换为字符串，并返回结果。 实例 123var arr = new Array(&quot;orange&quot;, &quot;mango&quot;, &quot;banana&quot;, &quot;sugar&quot;); var str = arr.toString(); console.log(&quot;Returned string is : &quot; + str ); // orange,mango,banana,sugar unshift()描述：向数组的开头添加一个或更多元素，并返回新的长度。 实例 1234var arr = new Array(&quot;orange&quot;, &quot;mango&quot;, &quot;banana&quot;, &quot;sugar&quot;); var length = arr.unshift(&quot;water&quot;); console.log(&quot;Returned array is : &quot; + arr ); // water,orange,mango,banana,sugar console.log(&quot;Length of the array is : &quot; + length ); // 5","link":"/TypeScript-Array%EF%BC%88%E6%95%B0%E7%BB%84%EF%BC%89/"},{"title":"TypeScript Map 对象","text":"Map 对象保存键值对，并且能够记住键的原始插入顺序。 任何值(对象或者原始值) 都可以作为一个键或一个值。 Map 是 ES6 中引入的一种新的数据结构。 创建 MapTypeScript 使用 Map 类型和 new 关键字来创建 Map： 1let myMap = new Map(); 初始化 Map，可以以数组的格式来传入键值对： 1234let myMap = new Map([ [&quot;key1&quot;, &quot;value1&quot;], [&quot;key2&quot;, &quot;value2&quot;] ]); Map 相关的函数与属性： map.clear() – 移除 Map 对象的所有键/值对 。 map.set() – 设置键值对，返回该 Map 对象。 map.get() – 返回键对应的值，如果不存在，则返回 undefined。 map.has() – 返回一个布尔值，用于判断 Map 中是否包含键对应的值。 map.delete() – 删除 Map 中的元素，删除成功返回 true，失败返回 false。 map.size – 返回 Map 对象键/值对的数量。 map.keys() - 返回一个 Iterator 对象， 包含了 Map 对象中每个元素的键 。 map.values() – 返回一个新的Iterator对象，包含了Map对象中每个元素的值 。 实例 test.ts1234567891011121314151617181920212223let nameSiteMapping = new Map(); // 设置 Map 对象nameSiteMapping.set(&quot;Google&quot;, 1);nameSiteMapping.set(&quot;Buubiu&quot;, 2);nameSiteMapping.set(&quot;Taobao&quot;, 3); // 获取键对应的值console.log(nameSiteMapping.get(&quot;Buubiu&quot;)); // 2 // 判断 Map 中是否包含键对应的值console.log(nameSiteMapping.has(&quot;Taobao&quot;)); // trueconsole.log(nameSiteMapping.has(&quot;Zhihu&quot;)); // false // 返回 Map 对象键/值对的数量console.log(nameSiteMapping.size); // 3 // 删除 Runoobconsole.log(nameSiteMapping.delete(&quot;Buubiu&quot;)); // trueconsole.log(nameSiteMapping);// 移除 Map 对象的所有键/值对nameSiteMapping.clear(); // 清除 Mapconsole.log(nameSiteMapping); 使用 es6 编译： 1tsc --target es6 test.ts 编译以上代码得到如下 JavaScript 代码： 123456789101112131415161718let nameSiteMapping = new Map();// 设置 Map 对象nameSiteMapping.set(&quot;Google&quot;, 1);nameSiteMapping.set(&quot;Buubiu&quot;, 2);nameSiteMapping.set(&quot;Taobao&quot;, 3);// 获取键对应的值console.log(nameSiteMapping.get(&quot;Buubiu&quot;)); //40// 判断 Map 中是否包含键对应的值console.log(nameSiteMapping.has(&quot;Taobao&quot;)); //trueconsole.log(nameSiteMapping.has(&quot;Zhihu&quot;)); //false// 返回 Map 对象键/值对的数量console.log(nameSiteMapping.size); //3// 删除 Runoobconsole.log(nameSiteMapping.delete(&quot;Buubiu&quot;)); // trueconsole.log(nameSiteMapping);// 移除 Map 对象的所有键/值对nameSiteMapping.clear(); //清除 Mapconsole.log(nameSiteMapping); 执行以上 JavaScript 代码，输出结果为： 12345672truefalse3trueMap { 'Google' =&gt; 1, 'Taobao' =&gt; 3 }Map {} 迭代 MapMap 对象中的元素是按顺序插入的，我们可以迭代 Map 对象，每一次迭代返回 [key, value] 数组。 TypeScript使用 for...of 来实现迭代： 实例 test.ts12345678910111213141516171819202122232425let nameSiteMapping = new Map(); nameSiteMapping.set(&quot;Google&quot;, 1);nameSiteMapping.set(&quot;Buubiu&quot;, 2);nameSiteMapping.set(&quot;Taobao&quot;, 3); // 迭代 Map 中的 keyfor (let key of nameSiteMapping.keys()) { console.log(key); } // 迭代 Map 中的 valuefor (let value of nameSiteMapping.values()) { console.log(value); } // 迭代 Map 中的 key =&gt; valuefor (let entry of nameSiteMapping.entries()) { console.log(entry[0], entry[1]); } // 使用对象解析for (let [key, value] of nameSiteMapping) { console.log(key, value); } 使用 es6 编译： 1tsc --target es6 test.ts 编译以上代码得到如下 JavaScript 代码： 1234567891011121314151617181920let nameSiteMapping = new Map();nameSiteMapping.set(&quot;Google&quot;, 1);nameSiteMapping.set(&quot;Buubiu&quot;, 2);nameSiteMapping.set(&quot;Taobao&quot;, 3);// 迭代 Map 中的 keyfor (let key of nameSiteMapping.keys()) { console.log(key);}// 迭代 Map 中的 valuefor (let value of nameSiteMapping.values()) { console.log(value);}// 迭代 Map 中的 key =&gt; valuefor (let entry of nameSiteMapping.entries()) { console.log(entry[0], entry[1]);}// 使用对象解析for (let [key, value] of nameSiteMapping) { console.log(key, value);} 执行以上 JavaScript 代码，输出结果为： 123456789101112GoogleBuubiuTaobao123Google 1Buubiu 2Taobao 3Google 1Buubiu 2Taobao 3","link":"/TypeScript-Map-%E5%AF%B9%E8%B1%A1/"},{"title":"TypeScript Number（数值）","text":"TypeScript 与 JavaScript 类似，支持 Number 对象。 Number 对象是原始数值的包装对象。 语法 1var num = new Number(value); 注意： 如果一个参数值不能转换为一个数字将返回 NaN (非数字值)。 Number 对象属性下表列出了 Number 对象支持的属性： 序号 属性 &amp; 描述 1. MAX_VALUE可表示的最大的数，MAX_VALUE 属性值接近于 1.79E+308。大于 MAX_VALUE 的值代表 “Infinity”。 2. MIN_VALUE可表示的最小的数，即最接近 0 的正数 (实际上不会变成 0)。最大的负数是 -MIN_VALUE，MIN_VALUE 的值约为 5e-324。小于 MIN_VALUE (“underflow values”) 的值将会转换为 0。 3. NaN非数字值（Not-A-Number）。 4. NEGATIVE_INFINITY负无穷大，溢出时返回该值。该值小于 MIN_VALUE。 5. POSITIVE_INFINITY正无穷大，溢出时返回该值。该值大于 MAX_VALUE。 6. prototypeNumber 对象的静态属性。使您有能力向对象添加属性和方法。 7. constructor返回对创建此对象的 Number 函数的引用。 实例 12345console.log(&quot;TypeScript Number 属性: &quot;); console.log(&quot;最大值为: &quot; + Number.MAX_VALUE); console.log(&quot;最小值为: &quot; + Number.MIN_VALUE); console.log(&quot;负无穷大: &quot; + Number.NEGATIVE_INFINITY); console.log(&quot;正无穷大:&quot; + Number.POSITIVE_INFINITY); 编译以上代码得到如下 JavaScript 代码： 12345console.log(&quot;TypeScript Number 属性: &quot;);console.log(&quot;最大值为: &quot; + Number.MAX_VALUE);console.log(&quot;最小值为: &quot; + Number.MIN_VALUE);console.log(&quot;负无穷大: &quot; + Number.NEGATIVE_INFINITY);console.log(&quot;正无穷大:&quot; + Number.POSITIVE_INFINITY); 执行以上 JavaScript 代码，输出结果为： 12345TypeScript Number 属性:最大值为: 1.7976931348623157e+308最小值为: 5e-324负无穷大: -Infinity正无穷大:Infinity NaN 实例1234567var month = 0 if( month&lt;=0 || month &gt;12) { month = Number.NaN console.log(&quot;月份是：&quot;+ month) } else { console.log(&quot;输入月份数值正确。&quot;) } 编译以上代码得到如下 JavaScript 代码： 12345678var month = 0;if (month &lt;= 0 || month &gt; 12) { month = Number.NaN; console.log(&quot;月份是：&quot; + month);}else { console.log(&quot;输入月份数值正确。&quot;);} 执行以上 JavaScript 代码，输出结果为： 1月份是：NaN prototype 实例1234567891011function employee(id:number,name:string) { this.id = id this.name = name } var emp = new employee(123,&quot;admin&quot;) employee.prototype.email = &quot;admin@buubiu.com&quot; console.log(&quot;员工号: &quot;+emp.id) console.log(&quot;员工姓名: &quot;+emp.name) console.log(&quot;员工邮箱: &quot;+emp.email) 编译以上代码得到如下 JavaScript 代码： 123456789function employee(id, name) { this.id = id; this.name = name;}var emp = new employee(123, &quot;admin&quot;);employee.prototype.email = &quot;admin@buubiu.com&quot;;console.log(&quot;员工号: &quot; + emp.id);console.log(&quot;员工姓名: &quot; + emp.name);console.log(&quot;员工邮箱: &quot; + emp.email); 执行以上 JavaScript 代码，输出结果为： 123员工号: 123员工姓名: admin员工邮箱: admin@buubiu.com Number 对象方法Number对象 支持以下方法： toExponential()描述：把对象的值转换为指数计数法。 实例 1234//toExponential() var num1 = 1225.30 var val = num1.toExponential(); console.log(val) // 输出： 1.2253e+3 toFixed()描述：把数字转换为字符串，并对小数点指定位数。 实例 1234var num3 = 177.234 console.log(&quot;num3.toFixed() 为 &quot;+num3.toFixed()) // 输出：177console.log(&quot;num3.toFixed(2) 为 &quot;+num3.toFixed(2)) // 输出：177.23console.log(&quot;num3.toFixed(6) 为 &quot;+num3.toFixed(6)) // 输出：177.234000 toLocaleString()描述：把数字转换为字符串，使用本地数字格式顺序。 实例 12var num = new Number(177.1234); console.log( num.toLocaleString()); // 输出：177.1234 toPrecision()描述：把数字格式化为指定的长度。 实例 1234var num = new Number(7.123456); console.log(num.toPrecision()); // 输出：7.123456 console.log(num.toPrecision(1)); // 输出：7console.log(num.toPrecision(2)); // 输出：7.1 toString()描述：把数字转换为字符串，使用指定的基数。数字的基数是 2 ~ 36 之间的整数。若省略该参数，则使用基数 10。 实例 1234var num = new Number(10); console.log(num.toString()); // 输出10进制：10console.log(num.toString(2)); // 输出2进制：1010console.log(num.toString(8)); // 输出8进制：12 valueOf()描述：返回一个 Number 对象的原始数字值。 实例 12var num = new Number(10); console.log(num.valueOf()); // 输出：10","link":"/TypeScript-Number%EF%BC%88%E6%95%B0%E5%80%BC%EF%BC%89/"},{"title":"TypeScript String（字符串）","text":"String 对象用于处理文本（字符串）。 语法 123var txt = new String(&quot;string&quot;);//或者更简单方式：var txt = &quot;string&quot;; String 对象属性constructor描述：对创建该对象的函数的引用。 实例 12var str = new String( &quot;This is string&quot; ); console.log(&quot;str.constructor is:&quot; + str.constructor) 输出结果为： 1str.constructor is:function String() { [native code] } length描述：返回字符串的长度。 实例 12var uname = new String(&quot;Hello World&quot;) console.log(&quot;Length &quot;+uname.length) // 输出 11 prototype描述：允许您向对象添加属性和方法。 实例 123456789function employee(id:number,name:string) { this.id = id this.name = name } var emp = new employee(123,&quot;admin&quot;) employee.prototype.email=&quot;admin@buubiu.com&quot; // 添加属性 email console.log(&quot;员工号: &quot;+emp.id) console.log(&quot;员工姓名: &quot;+emp.name) console.log(&quot;员工邮箱: &quot;+emp.email) String 对象方法charAt()描述：返回在指定位置的字符。 实例 1234567var str = new String(&quot;BUUBIU&quot;); console.log(&quot;str.charAt(0) 为:&quot; + str.charAt(0)); // Bconsole.log(&quot;str.charAt(1) 为:&quot; + str.charAt(1)); // U console.log(&quot;str.charAt(2) 为:&quot; + str.charAt(2)); // U console.log(&quot;str.charAt(3) 为:&quot; + str.charAt(3)); // B console.log(&quot;str.charAt(4) 为:&quot; + str.charAt(4)); // I console.log(&quot;str.charAt(5) 为:&quot; + str.charAt(5)); // U charCodeAt()描述：返回在指定的位置的字符的 Unicode 编码。 实例 1234567var str = new String(&quot;BUUBIU&quot;); console.log(&quot;str.charCodeAt(0) 为:&quot; + str.charCodeAt(0)); // 66console.log(&quot;str.charCodeAt(1) 为:&quot; + str.charCodeAt(1)); // 85 console.log(&quot;str.charCodeAt(2) 为:&quot; + str.charCodeAt(2)); // 85 console.log(&quot;str.charCodeAt(3) 为:&quot; + str.charCodeAt(3)); // 66 console.log(&quot;str.charCodeAt(4) 为:&quot; + str.charCodeAt(4)); // 73console.log(&quot;str.charCodeAt(5) 为:&quot; + str.charCodeAt(5)); // 85 concat()描述：连接两个或更多字符串，并返回新的字符串。 实例 1234var str1 = new String( &quot;BUUBIU&quot; ); var str2 = new String( &quot;GOOGLE&quot; ); var str3 = str1.concat( str2 ); console.log(&quot;str1 + str2 : &quot;+str3) // BUUBIUGOOGLE indexOf()描述：返回某个指定的字符串值在字符串中首次出现的位置。 实例 1234var str1 = new String( &quot;BUUBIU&quot; ); var index = str1.indexOf( &quot;BI&quot; ); console.log(&quot;查找的字符串位置 :&quot; + index ); // 3 lastIndexOf()描述：从后向前搜索字符串，并从起始位置（0）开始计算返回字符串最后出现的位置。 实例 123456var str1 = new String( &quot;This is string one and again string&quot; ); var index = str1.lastIndexOf( &quot;string&quot; );console.log(&quot;lastIndexOf 查找到的最后字符串位置 :&quot; + index ); // 29 index = str1.lastIndexOf( &quot;one&quot; ); console.log(&quot;lastIndexOf 查找到的最后字符串位置 :&quot; + index ); // 15 localeCompare()描述：用本地特定的顺序来比较两个字符串。 实例 12345var str1 = new String( &quot;This is beautiful string&quot; ); var index = str1.localeCompare( &quot;This is beautiful string&quot;); console.log(&quot;localeCompare first :&quot; + index ); // 0 match()描述：查找找到一个或多个正则表达式的匹配。 实例 12var str=&quot;The rain in SPAIN stays mainly in the plain&quot;; var n=str.match(/ain/g); // ain,ain,ain replace()描述：替换与正则表达式匹配的子串 实例 1234var re = /(\\w+)\\s(\\w+)/; var str = &quot;zara ali&quot;; var newstr = str.replace(re, &quot;$2, $1&quot;); console.log(newstr); // ali, zara search()描述：检索与正则表达式相匹配的值 实例 1234567var re = /apples/gi; var str = &quot;Apples are round, and apples are juicy.&quot;;if (str.search(re) == -1 ) { console.log(&quot;Does not contain Apples&quot; ); } else { console.log(&quot;Contains Apples&quot; ); } slice()描述：提取字符串的片断，并在新的字符串中返回被提取的部分。 split()描述：把字符串分割为子字符串数组。 实例 123var str = &quot;Apples are round, and apples are juicy.&quot;; var splitted = str.split(&quot; &quot;, 3); console.log(splitted) // [ 'Apples', 'are', 'round,' ] substr()描述：从起始索引号提取字符串中指定数目的字符。 substring()描述：提取字符串中两个指定的索引号之间的字符。 实例 1234var str = &quot;BUUBIU GOOGLE TAOBAO FACEBOOK&quot;; console.log(&quot;(1,2): &quot; + str.substring(1,2)); // Uconsole.log(&quot;(0,10): &quot; + str.substring(0, 10)); // BUUBIU GOOconsole.log(&quot;(5): &quot; + str.substring(5)); // B GOOGLE TAOBAO FACEBOOK toLocaleLowerCase()描述：根据主机的语言环境把字符串转换为小写，只有几种语言（如土耳其语）具有地方特有的大小写映射。 实例 12var str = &quot;Buubiu Google&quot;; console.log(str.toLocaleLowerCase( )); // buubiu google toLocaleUpperCase()描述：据主机的语言环境把字符串转换为大写，只有几种语言（如土耳其语）具有地方特有的大小写映射。 实例 12var str = &quot;Buubiu Google&quot;; console.log(str.toLocaleUpperCase( )); // BUUBIU GOOGLE toLowerCase()描述：把字符串转换为小写。 实例 12var str = &quot;Buubiu Google&quot;; console.log(str.toLowerCase( )); // buubiu google toUpperCase()描述：把字符串转换为大写。 实例 12var str = &quot;Buubiu Google&quot;; console.log(str.toUpperCase( )); // BUUBIU GOOGLE toString()描述：返回字符串。 实例 12var str = &quot;Buubiu&quot;; console.log(str.toString( )); // Buubiu valueOf()描述：返回指定字符串对象的原始值。 实例 12var str = new String(&quot;Buubiu&quot;); console.log(str.valueOf( )); // Buubiu","link":"/TypeScript-String%EF%BC%88%E5%AD%97%E7%AC%A6%E4%B8%B2%EF%BC%89/"},{"title":"TypeScript 元组","text":"数组中元素的数据类型都一般是相同的（any[] 类型的数组可以不同），如果存储的元素数据类型不同，则需要使用元组。 元组中允许存储不同类型的元素，元组可以作为参数传递给函数。 创建元组的语法格式如下： 1var tuple_name = [value1,value2,value3,…value n] 声明元组声明一个元组并初始化： 1var mytuple = [10,&quot;Buubiu&quot;]; 或者我们可以先声明一个空元组，然后再初始化： 123var mytuple = []; mytuple[0] = 120 mytuple[1] = 234 访问元组元组中元素使用索引来访问，第一个元素的索引值为 0，第二个为 1，以此类推第 n 个为 n-1，语法格式如下: 1tuple_name[index] 实例 以下实例定义了元组，包含了数字和字符串两种类型的元素： 123var mytuple = [10,&quot;Buubiu&quot;]; // 创建元组console.log(mytuple[0]) console.log(mytuple[1]) 编译以上代码得到如下 JavaScript 代码： 123var mytuple = [10, &quot;Buubiu&quot;]; // 创建元组console.log(mytuple[0]);console.log(mytuple[1]); 执行以上 JavaScript 代码，输出结果为： 1210Buubiu 元组运算我们可以使用以下两个函数向元组添加新元素或者删除元素： push() 向元组添加元素，添加在最后面。 pop() 从元组中移除元素（最后一个），并返回移除的元素。 实例 123456789var mytuple = [10,&quot;Hello&quot;,&quot;World&quot;,&quot;typeScript&quot;]; console.log(&quot;添加前元素个数：&quot;+mytuple.length) // 返回元组的大小 mytuple.push(12) // 添加到元组中console.log(&quot;添加后元素个数：&quot;+mytuple.length) console.log(&quot;删除前元素个数：&quot;+mytuple.length) console.log(mytuple.pop()+&quot; 元素从元组中删除&quot;) // 删除并返回删除的元素 console.log(&quot;删除后元素个数：&quot;+mytuple.length) 编译以上代码得到如下 JavaScript 代码： 1234567var mytuple = [10, &quot;Hello&quot;, &quot;World&quot;, &quot;typeScript&quot;];console.log(&quot;添加前元素个数：&quot; + mytuple.length); // 返回元组的大小mytuple.push(12); // 添加到元组中console.log(&quot;添加后元素个数：&quot; + mytuple.length);console.log(&quot;删除前元素个数：&quot; + mytuple.length);console.log(mytuple.pop() + &quot; 元素从元组中删除&quot;); // 删除并返回删除的元素console.log(&quot;删除后元素个数：&quot; + mytuple.length); 执行以上 JavaScript 代码，输出结果为： 12345添加前元素个数：4添加后元素个数：5删除前元素个数：512 元素从元组中删除删除后元素个数：4 更新元组元组是可变的，这意味着我们可以对元组进行更新操作： 实例 123456var mytuple = [10, &quot;Buubiu&quot;, &quot;Taobao&quot;, &quot;Google&quot;]; // 创建一个元组console.log(&quot;元组的第一个元素为：&quot; + mytuple[0]) // 更新元组元素mytuple[0] = 121 console.log(&quot;元组中的第一个元素更新为：&quot;+ mytuple[0]) 编译以上代码得到如下 JavaScript 代码： 12345var mytuple = [10, &quot;Buubiu&quot;, &quot;Taobao&quot;, &quot;Google&quot;]; // 创建一个元组console.log(&quot;元组的第一个元素为：&quot; + mytuple[0]);// 更新元组元素mytuple[0] = 121;console.log(&quot;元组中的第一个元素更新为：&quot; + mytuple[0]); 执行以上 JavaScript 代码，输出结果为： 12元组的第一个元素为：10元组中的第一个元素更新为：121 解构元组我们也可以把元组元素赋值给变量，如下所示： 实例 1234var a =[10,&quot;Buubiu&quot;] var [b,c] = a console.log( b ) console.log( c ) 编译以上代码得到如下 JavaScript 代码： 1234var a = [10, &quot;Buubiu&quot;];var b = a[0], c = a[1];console.log(b);console.log(c); 执行以上 JavaScript 代码，输出结果为： 1210Buubiu","link":"/TypeScript-%E5%85%83%E7%BB%84/"},{"title":"TypeScript 函数","text":"函数是一组一起执行一个任务的语句。 您可以把代码划分到不同的函数中。如何划分代码到不同的函数中是由您来决定的，但在逻辑上，划分通常是根据每个函数执行一个特定的任务来进行的。 函数声明告诉编译器函数的名称、返回类型和参数。函数定义提供了函数的实际主体。 函数定义函数就是包裹在花括号中的代码块，前面使用了关键词 function： 语法格式如下所示： 1234function function_name(){ // 执行代码} 实例 1234function () { // 函数定义 console.log(&quot;调用函数&quot;) } 调用函数函数只有通过调用才可以执行函数内的代码。 语法格式如下所示： 1function_name() 实例 1234function test() { // 函数定义 console.log(&quot;调用函数&quot;) } test() // 调用函数 函数返回值有时，我们会希望函数将执行的结果返回到调用它的地方。 通过使用 return 语句就可以实现。 在使用 return 语句时，函数会停止执行，并返回指定的值。 语法格式如下所示： 1234function function_name():return_type { // 语句 return value; } return_type 是返回值的类型。 return 关键词后跟着要返回的结果。 一般情况下，一个函数只有一个 return 语句。 返回值的类型需要与函数定义的返回类型(return_type)一致。 实例 123456789101112// 函数定义function greet():string { // 返回一个字符串 return &quot;Hello World&quot; } function caller() { var msg = greet() // 调用 greet() 函数 console.log(msg) } // 调用函数caller() 实例中定义了函数 *greet()*，返回值的类型为 string。 greet() 函数通过 return 语句返回给调用它的地方，即变量 msg，之后输出该返回值。。 编译以上代码，得到以下 JavaScript 代码： 12345678910// 函数定义function greet() { return &quot;Hello World&quot;;}function caller() { var msg = greet(); // 调用 greet() 函数 console.log(msg);}// 调用函数caller(); 带参数函数在调用函数时，您可以向其传递值，这些值被称为参数。 这些参数可以在函数中使用。 您可以向函数发送多个参数，每个参数使用逗号 , 分隔： 语法格式如下所示： 12function func_name( param1 [:datatype], param2 [:datatype]) { } param1、param2 为参数名。 datatype 为参数类型。 实例 1234function add(x: number, y: number): number { return x + y;}console.log(add(1,2)) 实例中定义了函数 *add()*，返回值的类型为 number。 add() 函数中定义了两个 number 类型的参数，函数内将两个参数相加并返回。 编译以上代码得到如下 JavaScript 代码： 1234function add(x, y) { return x + y;}console.log(add(1, 2)); 执行以上 JavaScript 代码，输出结果为： 13 可选参数和默认参数可选参数在 TypeScript 函数里，如果我们定义了参数，则我们必须传入这些参数，除非将这些参数设置为可选，可选参数使用问号标识 ？。 实例 1234567function buildName(firstName: string, lastName: string) { return firstName + &quot; &quot; + lastName;} let result1 = buildName(&quot;Bob&quot;); // 错误，缺少参数let result2 = buildName(&quot;Bob&quot;, &quot;Adams&quot;, &quot;Sr.&quot;); // 错误，参数太多了let result3 = buildName(&quot;Bob&quot;, &quot;Adams&quot;); // 正确 以下实例，我们将 lastName 设置为可选参数： 12345678910function buildName(firstName: string, lastName?: string) { if (lastName) return firstName + &quot; &quot; + lastName; else return firstName;} let result1 = buildName(&quot;Bob&quot;); // 正确let result2 = buildName(&quot;Bob&quot;, &quot;Adams&quot;, &quot;Sr.&quot;); // 错误，参数太多了let result3 = buildName(&quot;Bob&quot;, &quot;Adams&quot;); // 正确 可选参数必须跟在必需参数后面。 如果上例我们想让 firstName 是可选的，lastName 必选，那么就要调整它们的位置，把 firstName 放在后面。 如果都是可选参数就没关系。 默认参数我们也可以设置参数的默认值，这样在调用函数的时候，如果不传入该参数的值，则使用默认参数，语法格式为： 12function function_name(param1[:type],param2[:type] = default_value) { } 注意：参数不能同时设置为可选和默认。 123456function calculate_discount(price:number,rate:number = 0.50) { var discount = price * rate; console.log(&quot;计算结果: &quot;,discount); } calculate_discount(1000) calculate_discount(1000,0.30) 编译以上代码得到如下 JavaScript 代码： 1234567function calculate_discount(price, rate) { if (rate === void 0) { rate = 0.50; } var discount = price * rate; console.log(&quot;计算结果: &quot;, discount);}calculate_discount(1000);calculate_discount(1000, 0.30); 执行以上 JavaScript 代码，输出结果为： 12计算结果: 500计算结果: 300 剩余参数有一种情况，我们不知道要向函数传入多少个参数，这时候我们就可以使用剩余参数来定义。 剩余参数语法允许我们将一个不确定数量的参数作为一个数组传入。 语法格式为： 12345function buildName(firstName: string, ...restOfName: string[]) { return firstName + &quot; &quot; + restOfName.join(&quot; &quot;);} let employeeName = buildName(&quot;Joseph&quot;, &quot;Samuel&quot;, &quot;Lucas&quot;, &quot;MacKinzie&quot;); 函数的最后一个命名参数 restOfName 以 ... 为前缀，它将成为一个由剩余参数组成的数组，索引值从0（包括）到 restOfName.length（不包括）。 实例 1234567891011function addNumbers(...nums:number[]) { var i; var sum:number = 0; for(i = 0;i&lt;nums.length;i++) { sum = sum + nums[i]; } console.log(&quot;和为：&quot;,sum) } addNumbers(1,2,3) addNumbers(10,10,10,10,10) 编译以上代码得到如下 JavaScript 代码： 1234567891011121314function addNumbers() { var nums = []; for (var _i = 0; _i &lt; arguments.length; _i++) { nums[_i] = arguments[_i]; } var i; var sum = 0; for (i = 0; i &lt; nums.length; i++) { sum = sum + nums[i]; } console.log(&quot;和为：&quot;, sum);}addNumbers(1, 2, 3);addNumbers(10, 10, 10, 10, 10); 执行以上 JavaScript 代码，输出结果为： 12和为： 6和为： 50 匿名函数匿名函数是一个没有函数名的函数。 匿名函数在程序运行时动态声明，除了没有函数名外，其他的与标准函数一样。 我们可以将匿名函数赋值给一个变量，这种表达式就成为函数表达式。 语法格式如下： 1var res = function( [arguments] ) { ... } 不带参数匿名函数1234var msg = function() { return &quot;hello world&quot;; } console.log(msg()) 编译以上代码得到如下 JavaScript 代码： 1234var msg = function () { return &quot;hello world&quot;;};console.log(msg()); 执行以上 JavaScript 代码，输出结果为： 1hello world 带参数匿名函数1234var res = function(a:number,b:number) { return a*b; }; console.log(res(12,2)) 编译以上代码得到如下 JavaScript 代码： 1234var res = function (a, b) { return a * b;};console.log(res(12, 2)); 执行以上 JavaScript 代码，输出结果为： 124 匿名函数自调用匿名函数自调用在函数后使用 () 即可： 实例 1234(function () { var x = &quot;Hello!!&quot;; console.log(x) })() 编译以上代码得到如下 JavaScript 代码： 1234(function () { var x = &quot;Hello!!&quot;; console.log(x) })() 执行以上 JavaScript 代码，输出结果为： 1Hello!! 构造函数TypeScript 也支持使用 JavaScript 内置的构造函数 Function() 来定义函数： 语法格式如下： 1var res = new Function ([arg1[, arg2[, ...argN]],] functionBody) 参数说明： arg1, arg2, … argN：参数列表。 functionBody：一个含有包括函数定义的 JavaScript 语句的字符串。 实例 123var myFunction = new Function(&quot;a&quot;, &quot;b&quot;, &quot;return a * b&quot;); var x = myFunction(4, 3); console.log(x); 编译以上代码得到如下 JavaScript 代码： 123var myFunction = new Function(&quot;a&quot;, &quot;b&quot;, &quot;return a * b&quot;); var x = myFunction(4, 3); console.log(x); 执行以上 JavaScript 代码，输出结果为： 112 递归函数递归函数即在函数内调用函数本身。 举个例子：从前有座山，山里有座庙，庙里有个老和尚，正在给小和尚讲故事呢！故事是什么呢？”从前有座山，山里有座庙，庙里有个老和尚，正在给小和尚讲故事呢！故事是什么呢？’从前有座山，山里有座庙，庙里有个老和尚，正在给小和尚讲故事呢！故事是什么呢？……’” 实例 12345678function factorial(number) { if (number &lt;= 0) { // 停止执行 return 1; } else { return (number * factorial(number - 1)); // 调用自身 } }; console.log(factorial(6)); // 输出 720 编译以上代码得到如下 JavaScript 代码： 12345678910function factorial(number) { if (number &lt;= 0) { // 停止执行 return 1; } else { return (number * factorial(number - 1)); // 调用自身 }};console.log(factorial(6)); // 输出 720 执行以上 JavaScript 代码，输出结果为： 1720 Lambda 函数Lambda 函数也称之为箭头函数。 箭头函数表达式的语法比函数表达式更短。 函数只有一行语句1( [param1, parma2,…param n] )=&gt;statement; 实例 以下实例声明了 lambda 表达式函数，函数返回两个数的和： 12var foo = (x:number)=&gt;10 + x console.log(foo(100)) //输出结果为 110 编译以上代码得到如下 JavaScript 代码： 12var foo = function (x) { return 10 + x; };console.log(foo(100)); //输出结果为 110 执行以上 JavaScript 代码，输出结果为： 1110 函数是一个语句块1234( [param1, parma2,…param n] )=&gt; { // 代码块} 实例 以下实例声明了 lambda 表达式函数，函数返回两个数的和： 12345var foo = (x:number)=&gt; { x = 10 + x console.log(x) } foo(100) 编译以上代码得到如下 JavaScript 代码： 12345var foo = function (x) { x = 10 + x; console.log(x);};foo(100); 执行以上 JavaScript 代码，输出结果为： 1110 不指定函数的参数类型我们可以不指定函数的参数类型，通过函数内来推断参数类型: 实例 123456789var func = (x)=&gt; { if(typeof x==&quot;number&quot;) { console.log(x+&quot; 是一个数字&quot;) } else if(typeof x==&quot;string&quot;) { console.log(x+&quot; 是一个字符串&quot;) } } func(12) func(&quot;Tom&quot;) 编译以上代码得到如下 JavaScript 代码： 12345678910var func = function (x) { if (typeof x == &quot;number&quot;) { console.log(x + &quot; 是一个数字&quot;); } else if (typeof x == &quot;string&quot;) { console.log(x + &quot; 是一个字符串&quot;); }};func(12);func(&quot;Tom&quot;); 执行以上 JavaScript 代码，输出结果为： 1212 是一个数字Tom 是一个字符串 单个参数 () 是可选的实例 1234var display = x =&gt; { console.log(&quot;输出为 &quot;+x) } display(12) 编译以上代码得到如下 JavaScript 代码： 1234var display = function (x) { console.log(&quot;输出为 &quot; + x);};display(12); 执行以上 JavaScript 代码，输出结果为： 1输出为 12 无参数时可以设置空括号实例 1234var disp =()=&gt; { console.log(&quot;Function invoked&quot;); } disp(); 编译以上代码得到如下 JavaScript 代码： 1234var disp = function () { console.log(&quot;调用函数&quot;);};disp(); 执行以上 JavaScript 代码，输出结果为： 1调用函数 函数重载重载是方法名字相同，而参数不同，返回类型可以相同也可以不同。 每个重载的方法（或者构造函数）都必须有一个独一无二的参数类型列表。 参数类型不同： 12function disp(string):void; function disp(number):void; 参数数量不同： 12function disp(n1:number):void; function disp(x:number,y:number):void; 参数类型顺序不同： 12function disp(n1:number,s1:string):void; function disp(s:string,n:number):void; 如果参数类型不同，则参数类型应设置为 any。 参数数量不同你可以将不同的参数设置为可选。 实例 以下实例定义了参数类型与参数数量不同： 123456789function disp(s1:string):void; function disp(n1:number,s1:string):void; function disp(x:any,y?:any):void { console.log(x); console.log(y); } disp(&quot;abc&quot;) disp(1,&quot;xyz&quot;); 编译以上代码得到如下 JavaScript 代码： 123456function disp(x, y) { console.log(x); console.log(y);}disp(&quot;abc&quot;);disp(1, &quot;xyz&quot;); 执行以上 JavaScript 代码，输出结果为： 1234abcundefined1xyz","link":"/TypeScript-%E5%87%BD%E6%95%B0/"},{"title":"TypeScript 变量声明","text":"变量是一种使用方便的占位符，用于引用计算机内存地址。 我们可以把变量看做存储数据的容器。 TypeScript 变量的命名规则： 变量名称可以包含数字和字母。 除了下划线 _ 和美元 $符号外，不能包含其他特殊字符，包括空格。 变量名不能以数字开头。 变量使用前必须先声明，我们可以使用 var 来声明变量。 我们可以使用以下四种方式来声明变量： 四种方式来声明变量声明变量的类型及初始值声明变量的类型及初始值： 1var [变量名] : [类型] = 值; 例如： 1var uname:string = &quot;buubiu&quot;; 声明变量的类型，但没有初始值声明变量的类型，但没有初始值，变量值会设置为 undefined： 1var [变量名] : [类型]; 例如： 1var uname:string; 声明变量并初始值，但不设置类型声明变量并初始值，但不设置类型，该变量可以是任意类型： 1var [变量名] = 值; 例如： 1var uname = &quot;buubiu&quot;; 声明变量没有设置类型和初始值声明变量没有设置类型和初始值，类型可以是任意类型，默认初始值为 undefined： 1var [变量名]; 例如： 1var uname; 实例12345678var uname:string = &quot;buubiu&quot;;var score1:number = 50;var score2:number = 42.50var sum = score1 + score2console.log(&quot;名字: &quot;+uname)console.log(&quot;第一个科目成绩: &quot;+score1)console.log(&quot;第二个科目成绩: &quot;+score2)console.log(&quot;总成绩: &quot;+sum) 注意：变量不要使用 name 否则会与 DOM 中的全局 window 对象下的 name 属性出现了重名。 使用 tsc 命令编译以上代码，得到如下 JavaScript 代码： 12345678var uname = &quot;buubiu&quot;;var score1 = 50;var score2 = 42.50;var sum = score1 + score2;console.log(&quot;名字: &quot; + uname);console.log(&quot;第一个科目成绩: &quot; + score1);console.log(&quot;第二个科目成绩: &quot; + score2);console.log(&quot;总成绩: &quot; + sum); 执行该 JavaScript 代码输出结果为： 1234名字: buubiu第一个科目成绩: 50第二个科目成绩: 42.5总成绩: 92.5 TypeScript 遵循强类型，如果将不同的类型赋值给变量会编译错误，如下实例： 1var num:number = &quot;hello&quot; // 这个代码会编译错误 类型断言（Type Assertion）类型断言可以用来手动指定一个值的类型，即允许变量从一种类型更改为另一种类型。 语法格式： 1&lt;类型&gt;值 或: 1值 as 类型 实例123var str = '1' var str2:number = &lt;number&gt; &lt;any&gt; str //str、str2 是 string 类型console.log(str2) TypeScript 是怎么确定单个断言是否足够当 S 类型是 T 类型的子集，或者 T 类型是 S 类型的子集时，S 能被成功断言成 T。这是为了在进行类型断言时提供额外的安全性，完全毫无根据的断言是危险的，如果你想这么做，你可以使用 any。 它之所以不被称为类型转换，是因为转换通常意味着某种运行时的支持。但是，类型断言纯粹是一个编译时语法，同时，它也是一种为编译器提供关于如何分析代码的方法。 编译后，以上代码会生成如下 JavaScript 代码： 123var str = '1';var str2 = str; //str、str2 是 string 类型console.log(str2); 执行输出结果为： 11 类型推断当类型没有给出时，TypeScript 编译器利用类型推断来推断类型。 如果由于缺乏声明而不能推断出类型，那么它的类型被视作默认的动态 any 类型。 1234var num = 2; // 类型推断为 numberconsole.log(&quot;num 变量的值为 &quot;+num); num = &quot;12&quot;; // 编译错误console.log(num); 第一行代码声明了变量 num 并=设置初始值为 2。 注意变量声明没有指定类型。因此，程序使用类型推断来确定变量的数据类型，第一次赋值为 2，num 设置为 number 类型。 第三行代码，当我们再次为变量设置字符串类型的值时，这时编译会错误。因为变量已经设置为了 number 类型。 1error TS2322: Type '&quot;12&quot;' is not assignable to type 'number'. 变量作用域变量作用域指定了变量定义的位置。 程序中变量的可用性由变量作用域决定。 TypeScript 有以下几种作用域： 全局作用域 − 全局变量定义在程序结构的外部，它可以在你代码的任何位置使用。 类作用域 − 这个变量也可以称为 字段。类变量声明在一个类里头，但在类的方法外面。 该变量可以通过类的对象来访问。类变量也可以是静态的，静态的变量可以通过类名直接访问。 局部作用域 − 局部变量，局部变量只能在声明它的一个代码块（如：方法）中使用。 以下实例说明了三种作用域的使用： 12345678910111213var global_num = 12 // 全局变量class Numbers { num_val = 13; // 实例变量 static sval = 10; // 静态变量 storeNum():void { var local_num = 14; // 局部变量 } } console.log(&quot;全局变量为: &quot;+global_num) console.log(Numbers.sval) // 静态变量var obj = new Numbers(); console.log(&quot;实例变量: &quot;+obj.num_val) 以上代码使用 tsc 命令编译为 JavaScript 代码为： 123456789101112131415var global_num = 12; // 全局变量var Numbers = /** @class */ (function () { function Numbers() { this.num_val = 13; // 实例变量 } Numbers.prototype.storeNum = function () { var local_num = 14; // 局部变量 }; Numbers.sval = 10; // 静态变量 return Numbers;}());console.log(&quot;全局变量为: &quot; + global_num);console.log(Numbers.sval); // 静态变量var obj = new Numbers();console.log(&quot;实例变量: &quot; + obj.num_val); 执行以上 JavaScript 代码，输出结果为： 123全局变量为: 1210实例变量: 13 如果我们在方法外部调用局部变量 local_num，会报错： 1error TS2322: Could not find symbol 'local_num'.","link":"/TypeScript-%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E/"},{"title":"TypeScript 命名空间","text":"命名空间一个最明确的目的就是解决重名问题。 假设这样一种情况，当一个班上有两个名叫小明的学生时，为了明确区分它们，我们在使用名字之外，不得不使用一些额外的信息，比如他们的姓（王小明，李小明），或者他们父母的名字等等。 命名空间定义了标识符的可见范围，一个标识符可在多个名字空间中定义，它在不同名字空间中的含义是互不相干的。这样，在一个新的名字空间中可定义任何标识符，它们不会与任何已有的标识符发生冲突，因为已有的定义都处于其他名字空间中。 定义命名空间TypeScript 中命名空间使用 namespace 来定义，语法格式如下： 1234namespace SomeNameSpaceName { export interface ISomeInterfaceName { } export class SomeClassName { } } 以上定义了一个命名空间 SomeNameSpaceName，如果我们需要在外部可以调用 SomeNameSpaceName 中的类和接口，则需要在类和接口添加 export 关键字。 使用命名空间要在另外一个命名空间调用语法格式为： 1SomeNameSpaceName.SomeClassName; 如果一个命名空间在一个单独的 TypeScript 文件中，则应使用三斜杠 /// 引用它，语法格式如下： 1/// &lt;reference path = &quot;SomeFileName.ts&quot; /&gt; 实例 以下实例演示了命名空间的使用，定义在不同文件中： IShape.ts12345namespace Drawing { export interface IShape { draw(); }} Circle.ts12345678/// &lt;reference path = &quot;IShape.ts&quot; /&gt; namespace Drawing { export class Circle implements IShape { public draw() { console.log(&quot;Circle is drawn&quot;); } }} Triangle.ts12345678/// &lt;reference path = &quot;IShape.ts&quot; /&gt; namespace Drawing { export class Triangle implements IShape { public draw() { console.log(&quot;Triangle is drawn&quot;); } } } TestShape.ts12345678/// &lt;reference path = &quot;IShape.ts&quot; /&gt; /// &lt;reference path = &quot;Circle.ts&quot; /&gt; /// &lt;reference path = &quot;Triangle.ts&quot; /&gt; function drawAllShapes(shape:Drawing.IShape) { shape.draw(); } drawAllShapes(new Drawing.Circle());drawAllShapes(new Drawing.Triangle()); 使用 tsc 命令编译以上代码： 1tsc --out app.js TestShape.ts 得到以下 JavaScript 代码： 12345678910111213141516171819202122232425262728293031323334/// &lt;reference path = &quot;IShape.ts&quot; /&gt; var Drawing;(function (Drawing) { var Circle = /** @class */ (function () { function Circle() { } Circle.prototype.draw = function () { console.log(&quot;Circle is drawn&quot;); }; return Circle; }()); Drawing.Circle = Circle;})(Drawing || (Drawing = {}));/// &lt;reference path = &quot;IShape.ts&quot; /&gt; var Drawing;(function (Drawing) { var Triangle = /** @class */ (function () { function Triangle() { } Triangle.prototype.draw = function () { console.log(&quot;Triangle is drawn&quot;); }; return Triangle; }()); Drawing.Triangle = Triangle;})(Drawing || (Drawing = {}));/// &lt;reference path = &quot;IShape.ts&quot; /&gt; /// &lt;reference path = &quot;Circle.ts&quot; /&gt; /// &lt;reference path = &quot;Triangle.ts&quot; /&gt; function drawAllShapes(shape) { shape.draw();}drawAllShapes(new Drawing.Circle());drawAllShapes(new Drawing.Triangle()); 使用 node 命令查看输出结果为： 123$ node app.jsCircle is drawnTriangle is drawn 嵌套命名空间命名空间支持嵌套，即你可以将命名空间定义在另外一个命名空间里头，语法为： 12345namespace namespace_name1 { export namespace namespace_name2 { export class class_name { } } } 成员的访问使用点号 . 来实现，如下实例： 实例 Invoice.ts123456789namespace Buubiu { export namespace invoiceApp { export class Invoice { public calculateDiscount(price: number) { return price * .40; } } } } InvoiceTest.ts123/// &lt;reference path = &quot;Invoice.ts&quot; /&gt;var invoice = new Buubiu.invoiceApp.Invoice(); console.log(invoice.calculateDiscount(500)); 使用 tsc 命令编译以上代码： 1tsc --out app.js InvoiceTest.ts 得到以下JavaScript代码： 123456789101112131415161718var Runoob;(function (Runoob) { var invoiceApp; (function (invoiceApp) { var Invoice = /** @class */ (function () { function Invoice() { } Invoice.prototype.calculateDiscount = function (price) { return price * .40; }; return Invoice; }()); invoiceApp.Invoice = Invoice; })(invoiceApp = Runoob.invoiceApp || (Runoob.invoiceApp = {}));})(Runoob || (Runoob = {}));/// &lt;reference path = &quot;Invoice.ts&quot; /&gt;var invoice = new Runoob.invoiceApp.Invoice();console.log(invoice.calculateDiscount(500)); 使用 node 命令查看输出结果为： 12$ node app.js200","link":"/TypeScript-%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4/"},{"title":"TypeScript 基础类型","text":"TypeScript 包含的数据类型包含： 任意类型、数字类型、字符串类型、布尔类型、数组类型、元组、枚举、void、null、undefined、never 注意：TypeScript 和 JavaScript 没有整数类型。 Any 任意类型声明为 any 的变量可以赋予任意类型的值。 任意值是 TypeScript 针对编程时类型不明确的变量使用的一种数据类型，它常用于以下三种情况。 变量的值会动态改变时，比如来自用户的输入，任意值类型可以让这些变量跳过编译阶段的类型检查，示例代码如下： 123let x: any = 1; // 数字类型x = 'I am who I am'; // 字符串类型x = false; // 布尔类型 改写现有代码时，任意值允许在编译时可选择地包含或移除类型检查，示例代码如下： 123let x: any = 4;x.ifItExists(); // 正确，ifItExists方法在运行时可能存在，但这里并不会检查x.toFixed(); // 正确 定义存储各种类型数据的数组时，示例代码如下： 12let arrayList: any[] = [1, false, 'fine'];arrayList[1] = 100; number 数字类型双精度 64 位浮点值。它可以用来表示整数和分数。 1234let binaryLiteral: number = 0b1010; // 二进制let octalLiteral: number = 0o744; // 八进制let decLiteral: number = 6; // 十进制let hexLiteral: number = 0xf00d; // 十六进制 string 字符串类型一个字符系列，使用单引号（'）或双引号（&quot;）来表示字符串类型。反引号（`）来定义多行文本和内嵌表达式。 123let name: string = &quot;buubiu&quot;;let years: number = 5;let words: string = `您好，今年是 ${ name } 发布 ${ years + 1} 周年`; boolean 布尔类型表示逻辑值：true 和 false。 1let flag: boolean = true; 数组类型声明变量为数组。 12345// 在元素类型后面加上[]let arr: number[] = [1, 2];// 或者使用数组泛型let arr: Array&lt;number&gt; = [1, 2]; 元组类型元组类型用来表示已知元素数量和类型的数组，各元素的类型不必相同，对应位置的类型需要相同。 1234let x: [string, number];x = ['buubiu', 1]; // 运行正常x = [1, 'buubiu']; // 报错console.log(x[0]); // 输出 buubiu enum 枚举类型枚举类型用于定义数值集合。 123enum Color {Red, Green, Blue};let c: Color = Color.Blue;console.log(c); // 输出 2 void 类型用于标识方法返回值的类型，表示该方法没有返回值。 123function hello(): void { alert(&quot;Hello buubiu&quot;);} Null 和 Undefined 类型null表示对象值缺失。 在 JavaScript 中 null 表示 “什么都没有”。 null是一个只有一个值的特殊类型。表示一个空对象引用。 用 typeof 检测 null 返回是 object。 undefined用于初始化变量为一个未定义的值 在 JavaScript 中, undefined 是一个没有设置值的变量。 typeof 一个没有值的变量会返回 undefined。 Null 和 Undefined 是其他任何类型（包括 void）的子类型，可以赋值给其它类型，如数字类型，此时，赋值后的类型会变成 null 或 undefined。而在TypeScript中启用严格的空校验（–strictNullChecks）特性，就可以使得null 和 undefined 只能被赋值给 void 或本身对应的类型，示例代码如下： 12345// 启用 --strictNullCheckslet x: number;x = 1; // 运行正确x = undefined; // 运行错误x = null; // 运行错误 上面的例子中变量 x 只能是数字类型。如果一个类型可能出现 null 或 undefined， 可以用 | 来支持多种类型，示例代码如下： 12345// 启用 --strictNullCheckslet x: number | null | undefined;x = 1; // 运行正确x = undefined; // 运行正确x = null; // 运行正确 never 类型never 是其它类型（包括 null 和 undefined）的子类型，代表从不会出现的值。这意味着声明为 never 类型的变量只能被 never 类型所赋值，在函数中它通常表现为抛出异常或无法执行到终止点（例如无限循环），示例代码如下： 123456789101112131415161718192021let x: never;let y: number;// 运行错误，数字类型不能转为 never 类型x = 123;// 运行正确，never 类型可以赋值给 never类型x = (()=&gt;{ throw new Error('exception')})();// 运行正确，never 类型可以赋值给 数字类型y = (()=&gt;{ throw new Error('exception')})();// 返回值为 never 的函数可以是抛出异常的情况function error(message: string): never { throw new Error(message);}// 返回值为 never 的函数可以是无法被执行到的终止点的情况function loop(): never { while (true) {}}","link":"/TypeScript-%E5%9F%BA%E7%A1%80%E7%B1%BB%E5%9E%8B/"},{"title":"TypeScript 基础语法","text":"TypeScript 程序由以下几个部分组成： 模块 函数 变量 语句和表达式 注释 第一个 TypeScript 程序可以使用以下 TypeScript 程序来输出 “Hello World” ： buubiu.ts12const hello : string = &quot;Hello World!&quot;console.log(hello) 以上代码首先通过 tsc 命令编译： 1$ tsc buubiu.ts 得到如下 js 代码： buubiu.js12var hello = &quot;Hello World!&quot;;console.log(hello); 最后我们使用 node 命令来执行该 js 代码。 12$ node buubiu.jsHello World 整个流程如下图所示： 可以同时编译多个 ts 文件： 1$ tsc file1.ts file2.ts file3.ts tsc 常用编译参数如下表所示： 序号 编译参数说明 1. –help显示帮助信息 2. –module载入扩展模块 3. –target设置 ECMA 版本 4. –declaration额外生成一个 .d.ts 扩展名的文件。tsc ts-hw.ts --declaration以上命令会生成 ts-hw.d.ts、ts-hw.js 两个文件。 5. –removeComments删除文件的注释 6. –out编译多个文件并合并到一个输出的文件 7. –sourcemap生成一个 sourcemap (.map) 文件。sourcemap 是一个存储源代码与编译代码对应位置映射的信息文件。 8. –module noImplicitAny在表达式和声明上有隐含的 any 类型时报错 9. –watch在监视模式下运行编译器。会监视输出文件，在它们改变时重新编译。 TypeScript 保留关键字保留关键字 break as catch switch case if throw else var number string get module type instanceof typeof public private enum export finally for while void null super this new in return true false any extends static let package implements interface function new try yield const continue do 空白和换行TypeScript 会忽略程序中出现的空格、制表符和换行符。 空格、制表符通常用来缩进代码，使代码易于阅读和理解。 TypeScript 区分大小写TypeScript 区分大写和小写字符。 分号是可选的每行指令都是一段语句，你可以使用分号或不使用， 分号在 TypeScript 中是可选的，建议使用。 以下代码都是合法的： 12console.log(&quot;buubiu&quot;)console.log(&quot;Google&quot;); 如果语句写在同一行则一定需要使用分号来分隔，否则会报错，如： 1console.log(&quot;buubiu&quot;);console.log(&quot;Google&quot;); TypeScript 注释注释是一个良好的习惯，虽然很多程序员讨厌注释，但还是建议你在每段代码写上文字说明。 注释可以提高程序的可读性。 注释可以包含有关程序一些信息，如代码的作者，有关函数的说明等。 编译器会忽略注释。 TypeScript 支持两种类型的注释 单行注释 ( // ) − 在 // 后面的文字都是注释内容。 多行注释 (/* */) − 这种注释可以跨越多行。 注释实例： 1234567// 这是一个单行注释 /* 这是一个多行注释 这是一个多行注释 这是一个多行注释 */ TypeScript 与面向对象面向对象是一种对现实世界理解和抽象的方法。 TypeScript 是一种面向对象的编程语言。 面向对象主要有两个概念：对象和类。 对象：对象是类的一个实例（对象不是找个女朋友），有状态和行为。例如，一条狗是一个对象，它的状态有：颜色、名字、品种；行为有：摇尾巴、叫、吃等。 类：类是一个模板，它描述一类对象的行为和状态。 方法：方法是类的操作的实现步骤。 TypeScript 面向对象编程实例： 12345678class Site { name(): void { console.log(&quot;buubiu&quot;); }}const obj = new Site();obj.name(); 以上实例定义了一个类 Site，该类有一个方法 name()，该方法在终端上输出字符串 Runoob。 new 关键字创建类的对象，该对象调用方法 name()。 编译后生成的 JavaScript 代码如下： 12345678910var Site = /** @class */ (function () { function Site() { } Site.prototype.name = function () { console.log(&quot;buubiu&quot;); }; return Site;}());var obj = new Site();obj.name(); 执行以上 JavaScript 代码，输出结果如下: 1buubiu","link":"/TypeScript-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"title":"TypeScript 声明文件","text":"TypeScript 作为 JavaScript 的超集，在开发过程中不可避免要引用其他第三方的 JavaScript 的库。虽然通过直接引用可以调用库的类和方法，但是却无法使用TypeScript 诸如类型检查等特性功能。为了解决这个问题，需要将这些库里的函数和方法体去掉后只保留导出类型声明，而产生了一个描述 JavaScript 库和模块信息的声明文件。通过引用这个声明文件，就可以借用 TypeScript 的各种特性来使用库文件了。 假如我们想使用第三方库，比如 jQuery，我们通常这样获取一个 id 是 foo 的元素： 123$('#foo');// 或jQuery('#foo'); 但是在 TypeScript 中，我们并不知道 $ 或 jQuery 是什么东西： 123jQuery('#foo');// index.ts(1,1): error TS2304: Cannot find name 'jQuery'. 这时，我们需要使用 declare 关键字来定义它的类型，帮助 TypeScript 判断我们传入的参数类型对不对： 123declare var jQuery: (selector: string) =&gt; any;jQuery('#foo'); declare 定义的类型只会用于编译时的检查，编译结果中会被删除。 上例的编译结果是： 1jQuery('#foo'); 声明文件声明文件以 .d.ts 为后缀，例如： 1buubiu.d.ts 声明文件或模块的语法格式如下： 12declare module Module_Name {} TypeScript 引入声明文件语法格式： 1/// &lt;reference path = &quot;buubiu.d.ts&quot; /&gt; 当然，很多流行的第三方库的声明文件不需要我们定义了，比如 jQuery 已经有人帮我们定义好了：jQuery in DefinitelyTyped。 实例以下定义一个第三方库来演示： CalcThirdPartyJsLib.js123456789101112131415161718var Buubiu; (function(Buubiu) { var Calc = (function () { function Calc() { } }) Calc.prototype.doSum = function (limit) { var sum = 0; for (var i = 0; i &lt;= limit; i++) { sum = sum + i; } return sum; } Buubiu.Calc = Calc; return Calc; })(Buubiu || (Buubiu = {})); var test = new Buubiu.Calc(); 如果我们想在 TypeScript 中引用上面的代码，则需要设置声明文件 Calc.d.ts，代码如下： Calc.d.ts12345declare module Buubiu { export class Calc { doSum(limit:number) : number; }} 声明文件不包含实现，它只是类型声明，把声明文件加入到 TypeScript 中： CalcTest.ts123/// &lt;reference path = &quot;Calc.d.ts&quot; /&gt; var obj = new Buubiu.Calc(); console.log(obj.doSum(10)); 使用 tsc 命令来编译以上代码文件： 1$ tsc CalcTest.ts 编译以上代码得到如下 JavaScript 代码： CalcTest.js123/// &lt;reference path = &quot;Calc.d.ts&quot; /&gt; var obj = new Runoob.Calc();console.log(obj.doSum(10)); 最后我们编写一个 buubiu.html 文件，引入 CalcTest.js 文件及第三方库 CalcThirdPartyJsLib.js： index.html12345678910111213&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;TypeScript教程(buubiu.com)&lt;/title&gt;&lt;script src = &quot;CalcThirdPartyJsLib.js&quot;&gt;&lt;/script&gt; &lt;script src = &quot;CalcTest.js&quot;&gt;&lt;/script&gt; &lt;/head&gt;&lt;body&gt; &lt;h1&gt;声明文件测试&lt;/h1&gt; &lt;p&gt;测试一下。&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 浏览器打开该文件输出结果如下：","link":"/TypeScript-%E5%A3%B0%E6%98%8E%E6%96%87%E4%BB%B6/"},{"title":"TypeScript安装","text":"NPM 安装 TypeScript使用国内镜像： 1$ npm config set registry https://registry.npm.taobao.org 安装 typescript： 1$ npm install -g typescript 安装完成后我们可以使用 tsc 命令来执行 TypeScript 的相关代码，以下是查看版本号： 12$ tsc -vVersion 4.3.5 测试新建一个 app.ts 的文件，代码如下： 12var message:string = &quot;Hello World&quot; console.log(message) 通常使用 .ts 作为 TypeScript 代码文件的扩展名。 然后执行以下命令将 TypeScript 转换为 JavaScript 代码： 1tsc app.ts 这时候再当前目录下（与 app.ts 同一目录）就会生成一个 app.js 文件，代码如下： 12var message = &quot;Hello World&quot;;console.log(message); 使用 node 命令来执行 app.js 文件： 12$ node app.js Hello World TypeScript 转换为 JavaScript 过程如下图：","link":"/TypeScript-%E5%AE%89%E8%A3%85/"},{"title":"TypeScript 对象","text":"TypeScript对象是包含一组键值对的实例。 值可以是标量、函数、数组、对象等。 如下实例： 12345678var object_name = { key1: &quot;value1&quot;, // 标量 key2: &quot;value&quot;, key3: function() { // 函数 }, key4:[&quot;content1&quot;, &quot;content2&quot;] //集合} 以上对象包含了标量，函数，集合(数组或元组)。 声明并使用对象实例 1234567var sites = { site1:&quot;buubiu&quot;, site2:&quot;Google&quot; }; // 访问对象的值console.log(sites.site1) console.log(sites.site2) 编译以上代码得到如下 JavaScript 代码： 1234567var sites = { site1:&quot;buubiu&quot;, site2:&quot;Google&quot; }; // 访问对象的值console.log(sites.site1) console.log(sites.site2) 执行以上 JavaScript 代码，输出结果为： 12buubiuGoogle TypeScript 类型模板假如我们在 JavaScript 定义了一个对象： 1234var sites = { site1:&quot;Buubiu&quot;, site2:&quot;Google&quot; }; 这时如果我们想在对象中添加方法，可以做以下修改： 1sites.sayHello = function(){ return &quot;hello&quot;;} 如果在 TypeScript 中使用以上方式则会出现编译错误，因为Typescript 中的对象必须是特定类型的实例。 123456789var sites = { site1: &quot;Buubiu&quot;, site2: &quot;Google&quot;, sayHello: function () { } // 类型模板};sites.sayHello = function () { console.log(&quot;hello &quot; + sites.site1);};sites.sayHello(); 编译以上代码得到如下 JavaScript 代码： 123456789var sites = { site1: &quot;Buubiu&quot;, site2: &quot;Google&quot;, sayHello: function () { } // 类型模板};sites.sayHello = function () { console.log(&quot;hello &quot; + sites.site1);};sites.sayHello(); 执行以上 JavaScript 代码，输出结果为： 1hello Buubiu 传递对象此外对象也可以作为一个参数传递给函数，如下实例： 123456789var sites = { site1:&quot;Buubiu&quot;, site2:&quot;Google&quot;,}; var invokesites = function(obj: { site1:string, site2 :string }) { console.log(&quot;site1 :&quot;+obj.site1) console.log(&quot;site2 :&quot;+obj.site2) } invokesites(sites) 编译以上代码，得到以下 JavaScript 代码： 123456789var sites = { site1: &quot;Buubiu&quot;, site2: &quot;Google&quot;};var invokesites = function (obj) { console.log(&quot;site1 :&quot; + obj.site1); console.log(&quot;site2 :&quot; + obj.site2);};invokesites(sites); 输出结果为： 12site1 :Buubiusite2 :Google 鸭子类型(Duck Typing)鸭子类型（英语：duck typing）是动态类型的一种风格，是多态(polymorphism)的一种形式。 在这种风格中，一个对象有效的语义，不是由继承自特定的类或实现特定的接口，而是由”当前方法和属性的集合”决定。 可以这样表述： “当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。” 在鸭子类型中，关注点在于对象的行为，能作什么；而不是关注对象所属的类型。例如，在不使用鸭子类型的语言中，我们可以编写一个函数，它接受一个类型为”鸭子”的对象，并调用它的”走”和”叫”方法。在使用鸭子类型的语言中，这样的一个函数可以接受一个任意类型的对象，并调用它的”走”和”叫”方法。如果这些需要被调用的方法不存在，那么将引发一个运行时错误。任何拥有这样的正确的”走”和”叫”方法的对象都可被函数接受的这种行为引出了以上表述，这种决定类型的方式因此得名。 实例 123456789101112131415interface IPoint { x:number y:number } function addPoints(p1:IPoint,p2:IPoint):IPoint { var x = p1.x + p2.x var y = p1.y + p2.y return {x:x,y:y} } // 正确var newPoint = addPoints({x:3,y:4},{x:5,y:1}) // 错误 var newPoint2 = addPoints({x:1},{x:4,y:3})","link":"/TypeScript-%E5%AF%B9%E8%B1%A1/"},{"title":"TypeScript 循环","text":"有的时候，我们可能需要多次执行同一块代码。一般情况下，语句是按顺序执行的：函数中的第一个语句先执行，接着是第二个语句，依此类推。 编程语言提供了更为复杂执行路径的多种控制结构。 循环语句允许我们多次执行一个语句或语句组，下面是大多数编程语言中循环语句的\b流程图： for 循环TypeScript for 循环用于多次执行一个语句序列，简化管理循环变量的代码。 语法语法格式如下所示： 123for ( init; condition; increment ){ statement(s);} 下面是 for 循环的控制流程解析： init 会首先被执行，且只会执行一次。这一步允许您声明并初始化任何循环控制变量。您也可以不在这里写任何语句，只要有一个分号出现即可。 接下来，会判断 condition。如果为 true，则执行循环主体。如果为 false，则不执行循环主体，且控制流会跳转到紧接着 for 循环的下一条语句。 在执行完 for 循环主体后，控制流会跳回上面的 increment 语句。该语句允许您更新循环控制变量。该语句可以留空，只要在条件后有一个分号出现即可。 条件再次被判断。如果为 true，则执行循环，这个过程会不断重复（循环主体，然后增加步值，再然后重新判断条件）。在条件变为 false 时，for 循环终止。 在这里，statement(s) 可以是一个单独的语句，也可以是几个语句组成的代码块。 condition 可以是任意的表达式，当条件为 true 时执行循环，当条件为 false 时，退出循环。 流程图 实例 以下实例计算 5 的阶乘， for 循环生成从 5 到 1 的数字，并计算每次循环数字的乘积。 12345678var num:number = 5; var i:number; var factorial = 1; for(i = num;i&gt;=1;i--) { factorial *= i;}console.log(factorial) 编译以上代码得到如下 JavaScript 代码： 1234567var num = 5;var i;var factorial = 1;for (i = num; i &gt;= 1; i--) { factorial *= i;}console.log(factorial); 执行以上 JavaScript 代码，输出结果为： 1120 for…in 循环for…in 语句用于一组值的集合或列表进行迭代输出。 语法语法格式如下所示： 123for (var val in list) { //语句 } val 需要为 string 或 any 类型。 实例 123456var j:any; var n:any = &quot;a b c&quot; for(j in n) { console.log(n[j]) } 编译以上代码得到如下 JavaScript 代码： 12345var j;var n = &quot;a b c&quot;;for (j in n) { console.log(n[j]);} 执行以上 JavaScript 代码，输出结果为： 12345abc for…of 、forEach、every 和 some 循环此外，TypeScript 还支持 for…of 、forEach、every 和 some 循环。 for…of 语句创建一个循环来迭代可迭代的对象。在 ES6 中引入的 for…of 循环，以替代 for…in 和 forEach() ，并支持新的迭代协议。for…of 允许你遍历 Arrays（数组）, Strings（字符串）, Maps（映射）, Sets（集合）等可迭代的数据结构等。 for…of 循环实例 12345let someArray = [1, &quot;string&quot;, false]; for (let entry of someArray) { console.log(entry); // 1, &quot;string&quot;, false} forEach、every 和 some 是 JavaScript 的循环语法，TypeScript 作为 JavaScript 的语法超集，当然默认也是支持的。 因为 forEach 在 iteration 中是无法返回的，所以可以使用 every 和 some 来取代 forEach。 forEach 循环实例 123456let list = [4, 5, 6];list.forEach((val, idx, array) =&gt; { // val: 当前值 // idx：当前index // array: Array}); every 循环实例 12345678let list = [4, 5, 6];list.every((val, idx, array) =&gt; { // val: 当前值 // idx：当前index // array: Array return true; // Continues // Return false will quit the iteration}); while 循环while 语句在给定条件为 true 时，重复执行语句或语句组。循环主体执行之前会先测试条件。 语法语法格式如下所示： 1234while(condition){ statement(s);} 在这里，statement(s) 可以是一个单独的语句，也可以是几个语句组成的代码块。 condition 可以是任意的表达式，当条件为 true 时执行循环。 当条件为 false 时，程序流将退出循环。 流程图 图表中，while 循环的关键点是循环可能一次都不会执行。当条件为 false 时，会跳过循环主体，直接执行紧接着 while 循环的下一条语句。 实例 12345678var num:number = 5; var factorial:number = 1; while(num &gt;=1) { factorial = factorial * num; num--; } console.log(&quot;5 的阶乘为：&quot;+factorial); 编译以上代码得到如下 JavaScript 代码： 1234567var num = 5;var factorial = 1;while (num &gt;= 1) { factorial = factorial * num; num--;}console.log(&quot;5 的阶乘为：&quot; + factorial); 执行以上 JavaScript 代码，输出结果为： 15 的阶乘为：120 do…while 循环不像 for 和 while 循环，它们是在循环头部测试循环条件。do…while 循环是在循环的尾部检查它的条件。 语法语法格式如下所示： 1234do{ statement(s);}while( condition ); 请注意，条件表达式出现在循环的尾部，所以循环中的 statement(s) 会在条件被测试之前至少执行一次。 如果条件为 true，控制流会跳转回上面的 do，然后重新执行循环中的 statement(s)。这个过程会不断重复，直到给定条件变为 false 为止。 流程图 实例 12345var n:number = 10;do { console.log(n); n--; } while(n&gt;=0); 编译以上代码得到如下 JavaScript 代码： 123456var num = 5;var n = 10;do { console.log(n); n--;} while (n &gt;= 0); 执行以上 JavaScript 代码，输出结果为： 1234567891011109876543210 break 语句break 语句有以下两种用法： 当 break 语句出现在一个循环内时，循环会立即终止，且程序流将继续执行紧接着循环的下一条语句。 它可用于终止 switch 语句中的一个 case。 如果您使用的是嵌套循环（即一个循环内嵌套另一个循环），break 语句会停止执行最内层的循环，然后开始执行该块之后的下一行代码。 语法语法格式如下所示： 1break; 流程图 实例 12345678var i:number = 1 while(i&lt;=10) { if (i % 5 == 0) { console.log (&quot;在 1~10 之间第一个被 5 整除的数为 : &quot;+i) break // 找到一个后退出循环 } i++ } // 输出 5 然后程序执行结束 编译以上代码得到如下 JavaScript 代码： 12345678var i = 1;while (i &lt;= 10) { if (i % 5 == 0) { console.log(&quot;在 1~10 之间第一个被 5 整除的数为 : &quot; + i); break; // 找到一个后退出循环 } i++;} // 输出 5 然后程序执行结束 执行以上 JavaScript 代码，输出结果为： 1在 1~10 之间第一个被 5 整除的数为 : 5 continue 语句continue 语句有点像 break 语句。但它不是强制终止，continue 会跳过当前循环中的代码，强迫开始下一次循环。 对于 for 循环，continue 语句执行后自增语句仍然会执行。对于 while 和 do…while 循环，continue 语句\b重新执行条件判断语句。 语法语法格式如下所示： 1continue; 流程图 实例 12345678910var num:number = 0var count:number = 0; for(num=0;num&lt;=20;num++) { if (num % 2==0) { continue } count++}console.log (&quot;0 ~20 之间的奇数个数为: &quot;+count) //输出10个偶数 编译以上代码得到如下 JavaScript 代码： 123456789var num = 0;var count = 0;for (num = 0; num &lt;= 20; num++) { if (num % 2 == 0) { continue; } count++;}console.log(&quot;0 ~20 之间的奇数个数为: &quot; + count); //输出 10 执行以上 JavaScript 代码，输出结果为： 10 ~20 之间的奇数个数为: 10 无限循环无限循环就是一直在运行不会停止的循环。 for 和 while 循环都可以创建无限循环。 for 创建无限循环语法格式： 123for(;;) { // 语句} 实例 123for(;;) { console.log(&quot;这段代码会不停的执行&quot;) } while 创建无限循环语法格式： 123while(true) { // 语句} 实例 123while(true) { console.log(&quot;这段代码会不停的执行&quot;) }","link":"/TypeScript-%E5%BE%AA%E7%8E%AF/"},{"title":"TypeScript 接口","text":"接口是一系列抽象方法的声明，是一些方法特征的集合，这些方法都应该是抽象的，需要由具体的类去实现，然后第三方就可以通过这组抽象方法调用，让具体的类执行具体的方法。 TypeScript 接口定义如下： 12interface interface_name { } 声明接口并使用实例 以下实例中，我们定义了一个接口 IPerson，接着定义了一个变量 customer，它的类型是 IPerson。 customer 实现了接口 IPerson 的属性和方法。 1234567891011121314151617181920212223242526interface IPerson { firstName:string, lastName:string, sayHi: ()=&gt;string } var customer:IPerson = { firstName:&quot;Tom&quot;, lastName:&quot;Hanks&quot;, sayHi: ():string =&gt;{return &quot;Hi there&quot;} } console.log(&quot;Customer 对象 &quot;) console.log(customer.firstName) console.log(customer.lastName) console.log(customer.sayHi()) var employee:IPerson = { firstName:&quot;Jim&quot;, lastName:&quot;Blakes&quot;, sayHi: ():string =&gt;{return &quot;Hello!!!&quot;} } console.log(&quot;Employee 对象 &quot;) console.log(employee.firstName) console.log(employee.lastName) 需要注意接口不能转换为 JavaScript。 它只是 TypeScript 的一部分。 编译以上代码得到如下 JavaScript 代码： 1234567891011121314151617var customer = { firstName: &quot;Tom&quot;, lastName: &quot;Hanks&quot;, sayHi: function () { return &quot;Hi there&quot;; }};console.log(&quot;Customer 对象 &quot;);console.log(customer.firstName);console.log(customer.lastName);console.log(customer.sayHi());var employee = { firstName: &quot;Jim&quot;, lastName: &quot;Blakes&quot;, sayHi: function () { return &quot;Hello!!!&quot;; }};console.log(&quot;Employee 对象 &quot;);console.log(employee.firstName);console.log(employee.lastName); 执行以上 JavaScript 代码，输出结果为： 1234567Customer 对象TomHanksHi thereEmployee 对象JimBlakes 联合类型和接口以下实例演示了如何在接口中使用联合类型： 实例 12345678910111213141516171819interface RunOptions { program:string; commandline:string[]|string|(()=&gt;string); } // commandline 是字符串var options:RunOptions = {program:&quot;test1&quot;,commandline:&quot;Hello&quot;}; console.log(options.commandline) // commandline 是字符串数组options = {program:&quot;test1&quot;,commandline:[&quot;Hello&quot;,&quot;World&quot;]}; console.log(options.commandline[0]); console.log(options.commandline[1]); // commandline 是一个函数表达式options = {program:&quot;test1&quot;,commandline:()=&gt;{return &quot;**Hello World**&quot;;}}; var fn:any = options.commandline; console.log(fn()); 编译以上代码得到如下 JavaScript 代码： 1234567891011// commandline 是字符串var options = { program: &quot;test1&quot;, commandline: &quot;Hello&quot; };console.log(options.commandline);// commandline 是字符串数组options = { program: &quot;test1&quot;, commandline: [&quot;Hello&quot;, &quot;World&quot;] };console.log(options.commandline[0]);console.log(options.commandline[1]);// commandline 是一个函数表达式options = { program: &quot;test1&quot;, commandline: function () { return &quot;**Hello World**&quot;; } };var fn = options.commandline;console.log(fn()); 执行以上 JavaScript 代码，输出结果为： 1234HelloHelloWorld**Hello World** 接口和数组接口中我们可以将数组的索引值和元素设置为不同类型，索引值可以是数字或字符串。 123456789101112interface namelist { [index:number]:string } var list2:namelist = [&quot;John&quot;,1,&quot;Bran&quot;] // 错误元素 1 不是 string 类型interface ages { [index:string]:number } var agelist:ages; agelist[&quot;John&quot;] = 15 // 正确 agelist[2] = &quot;nine&quot; // 错误 接口继承接口继承就是说接口可以通过其他接口来扩展自己。 Typescript 允许接口继承多个接口。 继承使用关键字 **extends**。 单接口继承语法格式： 1Child_interface_name extends super_interface_name 多接口继承语法格式： 1Child_interface_name extends super_interface1_name, super_interface2_name,…,super_interfaceN_name 继承的各个接口使用逗号 , 分隔。 单继承实例实例 12345678910111213interface Person { age:number } interface Musician extends Person { instrument:string } var drummer = &lt;Musician&gt;{}; drummer.age = 27 drummer.instrument = &quot;Drums&quot; console.log(&quot;年龄: &quot;+drummer.age)console.log(&quot;喜欢的乐器: &quot;+drummer.instrument) 编译以上代码得到如下 JavaScript 代码： 12345var drummer = {};drummer.age = 27;drummer.instrument = &quot;Drums&quot;;console.log(&quot;年龄: &quot; + drummer.age);console.log(&quot;喜欢的乐器: &quot; + drummer.instrument); 执行以上 JavaScript 代码，输出结果为： 12年龄: 27喜欢的乐器: Drums 多继承实例实例 1234567891011interface IParent1 { v1:number } interface IParent2 { v2:number } interface Child extends IParent1, IParent2 { } var Iobj:Child = { v1:12, v2:23} console.log(&quot;value 1: &quot;+Iobj.v1+&quot; value 2: &quot;+Iobj.v2) 编译以上代码得到如下 JavaScript 代码： 12var Iobj = { v1: 12, v2: 23 };console.log(&quot;value 1: &quot; + Iobj.v1 + &quot; value 2: &quot; + Iobj.v2); 执行以上 JavaScript 代码，输出结果为： 1value 1: 12 value 2: 23","link":"/TypeScript-%E6%8E%A5%E5%8F%A3/"},{"title":"TypeScript 条件语句","text":"条件语句用于基于不同的条件来执行不同的动作。 TypeScript 条件语句是通过一条或多条语句的执行结果（True 或 False）来决定执行的代码块。 可以通过下图来简单了解条件语句的执行过程: 条件语句通常在写代码时，您总是需要为不同的决定来执行不同的动作。您可以在代码中使用条件语句来完成该任务。 在 TypeScript 中，我们可使用以下条件语句： if 语句 - 只有当指定条件为 true 时，使用该语句来执行代码 if…else 语句 - 当条件为 true 时执行代码，当条件为 false 时执行其他代码 if…else if….else 语句- 使用该语句来选择多个代码块之一来执行 switch 语句 - 使用该语句来选择多个代码块之一来执行 if 语句TypeScript if 语句由一个布尔表达式后跟一个或多个语句组成。 语法语法格式如下所示： 123if(boolean_expression){ # 在布尔表达式 boolean_expression 为 true 执行} 如果布尔表达式 boolean_expression为 true，则 if 语句内的代码块将被执行。如果布尔表达式为 false，则 if 语句结束后的第一组代码（闭括号后）将被执行。 流程图 实例 1234var num:number = 5if (num &gt; 0) { console.log(&quot;数字是正数&quot;) } 编译以上代码得到如下 JavaScript 代码： 1234var num = 5;if (num &gt; 0) { console.log(&quot;数字是正数&quot;);} 执行以上 JavaScript 代码，输出结果为： 1数字是正数 if…else 语句一个 if 语句后可跟一个可选的 else 语句，else 语句在布尔表达式为 false 时执行。 语法语法格式如下所示： 12345if(boolean_expression){ # 在布尔表达式 boolean_expression 为 true 执行}else{ # 在布尔表达式 boolean_expression 为 false 执行} 如果布尔表达式 boolean_expression 为 true，则执行 if 块内的代码。如果布尔表达式为 false，则执行 else 块内的代码。 流程图 实例 123456var num:number = 12; if (num % 2==0) { console.log(&quot;偶数&quot;); } else { console.log(&quot;奇数&quot;); } 编译以上代码得到如下 JavaScript 代码： 1234567var num = 12;if (num % 2 == 0) { console.log(&quot;偶数&quot;);}else { console.log(&quot;奇数&quot;);} 执行以上 JavaScript 代码，输出结果为： 1偶数 if…else if….else 语句if…else if….else 语句在执行多个判断条件的时候很有用。 语法语法格式如下所示： 123456789101112if(boolean_expression 1){ # 在布尔表达式 boolean_expression 1 为 true 执行}else if( boolean_expression 2){ # 在布尔表达式 boolean_expression 2 为 true 执行}else if(( boolean_expression 3){ # 在布尔表达式 boolean_expression 3 为 true 执行}else{ # 布尔表达式的条件都为 false 时执行} 需要注意以下几点： 一个 if 判断语句可以有 0 或 1 个 else 语句，她必需在 else..if 语句后面。 一个 if 判断语句可以有 0 或多个 else..if，这些语句必需在 else 之前。 一旦执行了 else..if 内的代码，后面的 else..if 或 else 将不再执行。 实例 12345678var num:number = 2 if(num &gt; 0) { console.log(num+&quot; 是正数&quot;) } else if(num &lt; 0) { console.log(num+&quot; 是负数&quot;) } else { console.log(num+&quot; 不是正数也不是负数&quot;) } 编译以上代码得到如下 JavaScript 代码： 12345678910var num = 2;if (num &gt; 0) { console.log(num + &quot; 是正数&quot;);}else if (num &lt; 0) { console.log(num + &quot; 是负数&quot;);}else { console.log(num + &quot; 不是正数也不是负数&quot;);} 执行以上 JavaScript 代码，输出结果为： 12 是正数 switch…case 语句一个 switch 语句允许测试一个变量等于多个值时的情况。每个值称为一个 case，且被测试的变量会对每个 switch case 进行检查。 语法：123456789101112switch(expression){ case constant-expression : statement(s); break; /* 可选的 */ case constant-expression : statement(s); break; /* 可选的 */ /* 您可以有任意数量的 case 语句 */ default : /* 可选的 */ statement(s);} switch 语句必须遵循下面的规则： switch 语句中的 expression 是一个常量表达式，必须是一个整型或枚举类型。 在一个 switch 中可以有任意数量的 case 语句。每个 case 后跟一个要比较的值和一个冒号。 case 的 constant-expression 必须与 switch 中的变量具有相同的数据类型，且必须是一个常量或字面量。 当被测试的变量等于 case 中的常量时，case 后跟的语句将被执行，直到遇到 break 语句为止。 当遇到 break 语句时，switch 终止，控制流将跳转到 switch 语句后的下一行。 不是每一个 case 都需要包含 break。如果 case 语句不包含 break，控制流将会 继续 后续的 case，直到遇到 break 为止。 一个 switch 语句可以有一个可选的 default case，出现在 switch 的结尾。default case 可用于在上面所有 case 都不为真时执行一个任务。default case 中的 break 语句不是必需的。 流程图 实例 1234567891011121314151617181920212223var grade:string = &quot;A&quot;; switch(grade) { case &quot;A&quot;: { console.log(&quot;优&quot;); break; } case &quot;B&quot;: { console.log(&quot;良&quot;); break; } case &quot;C&quot;: { console.log(&quot;及格&quot;); break; } case &quot;D&quot;: { console.log(&quot;不及格&quot;); break; } default: { console.log(&quot;非法输入&quot;); break; } } 编译以上代码得到如下 JavaScript 代码： 1234567891011121314151617181920212223var grade = &quot;A&quot;;switch (grade) { case &quot;A&quot;: { console.log(&quot;优&quot;); break; } case &quot;B&quot;: { console.log(&quot;良&quot;); break; } case &quot;C&quot;: { console.log(&quot;及格&quot;); break; } case &quot;D&quot;: { console.log(&quot;不及格&quot;); break; } default: { console.log(&quot;非法输入&quot;); break; }} 执行以上 JavaScript 代码，输出结果为： 1优","link":"/TypeScript-%E6%9D%A1%E4%BB%B6%E8%AF%AD%E5%8F%A5/"},{"title":"TypeScript 模块","text":"TypeScript 模块的设计理念是可以更换的组织代码。 模块是在其自身的作用域里执行，并不是在全局作用域，这意味着定义在模块里面的变量、函数和类等在模块外部是不可见的，除非明确地使用 export 导出它们。类似地，我们必须通过 import 导入其他模块导出的变量、函数、类等。 两个模块之间的关系是通过在文件级别上使用 import 和 export 建立的。 模块使用模块加载器去导入其它的模块。 在运行时，模块加载器的作用是在执行此模块代码前去查找并执行这个模块的所有依赖。 大家最熟知的JavaScript模块加载器是服务于 Node.js 的 CommonJS 和服务于 Web 应用的 Require.js。 此外还有有 SystemJs 和 Webpack。 声明与使用模块模块导出使用关键字 export 关键字，语法格式如下： SomeInterface.ts1234// 文件名 : SomeInterface.ts export interface SomeInterface { // 代码部分} 要在另外一个文件使用该模块就需要使用 import 关键字来导入: 1import someInterfaceRef = require(&quot;./SomeInterface&quot;); 案例实例 IShape.ts123export interface IShape { draw(); } Circle.ts123456import shape = require(&quot;./IShape&quot;); export class Circle implements shape.IShape { public draw() { console.log(&quot;Circle is drawn (external module)&quot;); } } Triangle.ts123456import shape = require(&quot;./IShape&quot;); export class Triangle implements shape.IShape { public draw() { console.log(&quot;Triangle is drawn (external module)&quot;); } } TestShape.ts12345678910import shape = require(&quot;./IShape&quot;); import circle = require(&quot;./Circle&quot;); import triangle = require(&quot;./Triangle&quot;); function drawAllShapes(shapeToDraw: shape.IShape) { shapeToDraw.draw(); } drawAllShapes(new circle.Circle()); drawAllShapes(new triangle.Triangle()); 使用 tsc 命令编译以上代码（Commonjs）(默认）： 123$ tsc --module commonjs TestShape.ts# 等同于$ tsc TestShape.ts ​ 得到如下 JavaScript 代码： IShape.js12&quot;use strict&quot;;exports.__esModule = true; Circle.js12345678910111213&quot;use strict&quot;;exports.__esModule = true;exports.Circle = void 0;var Circle = /** @class */ (function () { function Circle() { } Circle.prototype.draw = function () { console.log(&quot;Circle is drawn (external module)&quot;); }; return Circle;}());exports.Circle = Circle; Triangle.js12345678910111213&quot;use strict&quot;;exports.__esModule = true;exports.Triangle = void 0;var Triangle = /** @class */ (function () { function Triangle() { } Triangle.prototype.draw = function () { console.log(&quot;Triangle is drawn (external module)&quot;); }; return Triangle;}());exports.Triangle = Triangle; TestShape.js12345678910&quot;use strict&quot;;exports.__esModule = true;var circle = require(&quot;./Circle&quot;);var triangle = require(&quot;./Triangle&quot;);function drawAllShapes(shapeToDraw) { shapeToDraw.draw();}drawAllShapes(new circle.Circle());drawAllShapes(new triangle.Triangle()); 执行以上 JavaScript 代码，输出结果为： 12Cirlce is drawn (external module)Triangle is drawn (external module) 使用 tsc 命令编译以上代码（AMD）： 1$ tsc --module amd TestShape.ts ​ 得到如下 JavaScript 代码： IShape.js1234define([&quot;require&quot;, &quot;exports&quot;], function (require, exports) { &quot;use strict&quot;; exports.__esModule = true;}); Circle.js123456789101112131415define([&quot;require&quot;, &quot;exports&quot;], function (require, exports) { &quot;use strict&quot;; exports.__esModule = true; exports.Circle = void 0; var Circle = /** @class */ (function () { function Circle() { } Circle.prototype.draw = function () { console.log(&quot;Circle is drawn (external module)&quot;); }; return Circle; }()); exports.Circle = Circle;}); Triangle.js123456789101112131415define([&quot;require&quot;, &quot;exports&quot;], function (require, exports) { &quot;use strict&quot;; exports.__esModule = true; exports.Triangle = void 0; var Triangle = /** @class */ (function () { function Triangle() { } Triangle.prototype.draw = function () { console.log(&quot;Triangle is drawn (external module)&quot;); }; return Triangle; }()); exports.Triangle = Triangle;}); TestShape.js12345678910define([&quot;require&quot;, &quot;exports&quot;, &quot;./Circle&quot;, &quot;./Triangle&quot;], function (require, exports, circle, triangle) { &quot;use strict&quot;; exports.__esModule = true; function drawAllShapes(shapeToDraw) { shapeToDraw.draw(); } drawAllShapes(new circle.Circle()); drawAllShapes(new triangle.Triangle());});","link":"/TypeScript-%E6%A8%A1%E5%9D%97/"},{"title":"TypeScript简介","text":"介绍 TypeScript 是 JavaScript 的一个超集，支持 ECMAScript 6 标准。 TypeScript 由微软开发的自由和开源的编程语言。 TypeScript 设计目标是开发大型应用，它可以编译成纯 JavaScript，编译出来的 JavaScript 可以运行在任何浏览器上。 语言特性TypeScript 是一种给 JavaScript 添加特性的语言扩展。增加的功能包括： 类型批注和编译时类型检查 类型推断 类型擦除 接口 枚举 Mixin 泛型编程 名字空间 元组 Await 以下功能是从 ECMA 2015 反向移植而来： 类 模块 lambda 函数的箭头语法 可选参数以及默认参数 JavaScript 与 TypeScript 的区别TypeScript 是 JavaScript 的超集，扩展了 JavaScript 的语法，因此现有的 JavaScript 代码可与 TypeScript 一起工作无需任何修改，TypeScript 通过类型注解提供编译时的静态类型检查。 TypeScript 可处理已有的 JavaScript 代码，并只对其中的 TypeScript 代码进行编译。","link":"/TypeScript-%E7%AE%80%E4%BB%8B/"},{"title":"TypeScript 类","text":"TypeScript 是面向对象的 JavaScript。 类描述了所创建的对象共同的属性和方法。 TypeScript 支持面向对象的所有特性，比如 类、接口等。 TypeScript 类定义方式如下： 123class class_name { // 类作用域} 定义类的关键字为 class，后面紧跟类名，类可以包含以下几个模块（类的数据成员）： 字段 − 字段是类里面声明的变量。字段表示对象的有关数据。 构造函数 − 类实例化时调用，可以为类的对象分配内存。 方法 − 方法为对象要执行的操作。 创建一个类实例 创建一个 Person 类： 12class Person {} 编译以上代码得到如下 JavaScript 代码： 12345var Person = /** @class */ (function () { function Person() { } return Person;}()); 创建类的数据成员实例 以下实例我们声明了类 Car，包含字段为 engine，构造函数在类实例化后初始化字段 engine。 this 关键字表示当前类实例化的对象。注意构造函数的参数名与字段名相同，this.engine 表示类的字段。 此外我们也在类中定义了一个方法 disp()。 1234567891011121314class Car { // 字段 engine:string; // 构造函数 constructor(engine:string) { this.engine = engine } // 方法 disp():void { console.log(&quot;发动机为 : &quot;+this.engine) } } 编译以上代码得到如下 JavaScript 代码： 1234567891011var Car = /** @class */ (function () { // 构造函数 function Car(engine) { this.engine = engine; } // 方法 Car.prototype.disp = function () { console.log(&quot;发动机为 : &quot; + this.engine); }; return Car;}()); 创建实例化对象我们使用 new 关键字来实例化类的对象，语法格式如下： 1var object_name = new class_name([ arguments ]) 类实例化时会调用构造函数，例如： 1var obj = new Car(&quot;Engine 1&quot;) 类中的字段属性和方法可以使用 . 号来访问： 12345// 访问属性obj.field_name // 访问方法obj.function_name() 完整实例 以下实例创建来一个 Car 类，然后通过关键字 new 来创建一个对象并访问属性和方法： 1234567891011121314151617181920212223class Car { // 字段 engine:string; // 构造函数 constructor(engine:string) { this.engine = engine } // 方法 disp():void { console.log(&quot;函数中显示发动机型号 : &quot;+this.engine) } } // 创建一个对象var obj = new Car(&quot;XXSY1&quot;) // 访问字段console.log(&quot;读取发动机型号 : &quot;+obj.engine) // 访问方法obj.disp() 编译以上代码得到如下 JavaScript 代码： 1234567891011121314151617var Car = /** @class */ (function () { // 构造函数 function Car(engine) { this.engine = engine; } // 方法 Car.prototype.disp = function () { console.log(&quot;函数中显示发动机型号 : &quot; + this.engine); }; return Car;}());// 创建一个对象var obj = new Car(&quot;XXSY1&quot;);// 访问字段console.log(&quot;读取发动机型号 : &quot; + obj.engine);// 访问方法obj.disp(); 执行以上 JavaScript 代码，输出结果为： 12读取发动机型号 : XXSY1函数中显示发动机型号 : XXSY1 类的继承TypeScript 支持继承类，即我们可以在创建类的时候继承一个已存在的类，这个已存在的类称为父类，继承它的类称为子类。 类继承使用关键字 **extends**，子类除了不能继承父类的私有成员(方法和属性)和构造函数，其他的都可以继承。 TypeScript 一次只能继承一个类，不支持继承多个类，但 TypeScript 支持多重继承（A 继承 B，B 继承 C）。 语法格式如下： 1class child_class_name extends parent_class_name 实例 类的继承：实例中创建了 Shape 类，Circle 类继承了 Shape 类，Circle 类可以直接使用 Area 属性： 12345678910111213141516class Shape { Area:number constructor(a:number) { this.Area = a } } class Circle extends Shape { disp():void { console.log(&quot;圆的面积: &quot;+this.Area) } } var obj = new Circle(223); obj.disp() 编译以上代码得到如下 JavaScript 代码： 12345678910111213141516171819202122232425262728293031var __extends = (this &amp;&amp; this.__extends) || (function () { var extendStatics = function (d, b) { extendStatics = Object.setPrototypeOf || ({ __proto__: [] } instanceof Array &amp;&amp; function (d, b) { d.__proto__ = b; }) || function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; }; return extendStatics(d, b); }; return function (d, b) { extendStatics(d, b); function __() { this.constructor = d; } d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __()); };})();var Shape = /** @class */ (function () { function Shape(a) { this.Area = a; } return Shape;}());var Circle = /** @class */ (function (_super) { __extends(Circle, _super); function Circle() { return _super !== null &amp;&amp; _super.apply(this, arguments) || this; } Circle.prototype.disp = function () { console.log(&quot;圆的面积: &quot; + this.Area); }; return Circle;}(Shape));var obj = new Circle(223);obj.disp(); 执行以上 JavaScript 代码，输出结果为： 1圆的面积: 223 需要注意的是子类只能继承一个父类，TypeScript 不支持继承多个类，但支持多重继承，如下实例： 实例 12345678910class Root { str:string; } class Child extends Root {} class Leaf extends Child {} // 多重继承，继承了 Child 和 Root 类 var obj = new Leaf(); obj.str =&quot;hello&quot; console.log(obj.str) 编译以上代码得到如下 JavaScript 代码： 1234567891011121314151617181920212223242526272829303132333435var __extends = (this &amp;&amp; this.__extends) || (function () { var extendStatics = function (d, b) { extendStatics = Object.setPrototypeOf || ({ __proto__: [] } instanceof Array &amp;&amp; function (d, b) { d.__proto__ = b; }) || function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; }; return extendStatics(d, b); }; return function (d, b) { extendStatics(d, b); function __() { this.constructor = d; } d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __()); };})();var Root = /** @class */ (function () { function Root() { } return Root;}());var Child = /** @class */ (function (_super) { __extends(Child, _super); function Child() { return _super !== null &amp;&amp; _super.apply(this, arguments) || this; } return Child;}(Root));var Leaf = /** @class */ (function (_super) { __extends(Leaf, _super); function Leaf() { return _super !== null &amp;&amp; _super.apply(this, arguments) || this; } return Leaf;}(Child)); // 多重继承，继承了 Child 和 Root 类var obj = new Leaf();obj.str = &quot;hello&quot;;console.log(obj.str); 执行以上 JavaScript 代码，输出结果为： 1hello 继承类的方法重写类继承后，子类可以对父类的方法重新定义，这个过程称之为方法的重写。 其中 super 关键字是对父类的直接引用，该关键字可以引用父类的属性和方法。 实例 123456789101112class PrinterClass { doPrint():void { console.log(&quot;父类的 doPrint() 方法。&quot;) } } class StringPrinter extends PrinterClass { doPrint():void { super.doPrint() // 调用父类的函数 console.log(&quot;子类的 doPrint()方法。&quot;) } } 编译以上代码得到如下 JavaScript 代码： 12345678910111213141516171819202122232425262728293031323334353637var obj = new StringPrinter() obj.doPrint() var __extends = (this &amp;&amp; this.__extends) || (function () { var extendStatics = function (d, b) { extendStatics = Object.setPrototypeOf || ({ __proto__: [] } instanceof Array &amp;&amp; function (d, b) { d.__proto__ = b; }) || function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; }; return extendStatics(d, b); }; return function (d, b) { extendStatics(d, b); function __() { this.constructor = d; } d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __()); };})();var PrinterClass = /** @class */ (function () { function PrinterClass() { } PrinterClass.prototype.doPrint = function () { console.log(&quot;父类的 doPrint() 方法。&quot;); }; return PrinterClass;}());var StringPrinter = /** @class */ (function (_super) { __extends(StringPrinter, _super); function StringPrinter() { return _super !== null &amp;&amp; _super.apply(this, arguments) || this; } StringPrinter.prototype.doPrint = function () { _super.prototype.doPrint.call(this); // 调用父类的函数 console.log(&quot;子类的 doPrint()方法。&quot;); }; return StringPrinter;}(PrinterClass));var obj = new StringPrinter();obj.doPrint(); 执行以上 JavaScript 代码，输出结果为： 12父类的 doPrint() 方法。子类的 doPrint()方法。 static 关键字static 关键字用于定义类的数据成员（属性和方法）为静态的，静态成员可以直接通过类名调用。 实例 12345678910class StaticMem { static num:number; static disp():void { console.log(&quot;num 值为 &quot;+ StaticMem.num) } } StaticMem.num = 12 // 初始化静态变量StaticMem.disp() // 调用静态方法 编译以上代码得到如下 JavaScript 代码： 12345678910var StaticMem = /** @class */ (function () { function StaticMem() { } StaticMem.disp = function () { console.log(&quot;num 值为 &quot; + StaticMem.num); }; return StaticMem;}());StaticMem.num = 12; // 初始化静态变量StaticMem.disp(); // 调用静态方法 执行以上 JavaScript 代码，输出结果为： 1num 值为 12 instanceof 运算符instanceof 运算符用于判断对象是否是指定的类型，如果是返回 true，否则返回 false。 实例 1234class Person{ } var obj = new Person() var isPerson = obj instanceof Person; console.log(&quot;obj 对象是 Person 类实例化来的吗？ &quot; + isPerson); 编译以上代码得到如下 JavaScript 代码： 12345678var Person = /** @class */ (function () { function Person() { } return Person;}());var obj = new Person();var isPerson = obj instanceof Person;console.log(&quot; obj 对象是 Person 类实例化来的吗？ &quot; + isPerson); 执行以上 JavaScript 代码，输出结果为： 1obj 对象是 Person 类实例化来的吗？ true 访问控制修饰符TypeScript 中，可以使用访问控制符来保护对类、变量、方法和构造方法的访问。TypeScript 支持 3 种不同的访问权限。 public（默认） : 公有，可以在任何地方被访问。 protected : 受保护，可以被其自身以及其子类和父类访问。 private : 私有，只能被其定义所在的类访问。 实例 以下实例定义了两个变量 str1 和 str2，str1 为 public，str2 为 private，实例化后可以访问 str1，如果要访问 str2 则会编译错误。 12345678class Encapsulate { str1:string = &quot;hello&quot; private str2:string = &quot;world&quot; } var obj = new Encapsulate() console.log(obj.str1) // 可访问 console.log(obj.str2) // 编译错误， str2 是私有的 类和接口类可以实现接口，使用关键字 **implements**，并将接口的字段作为类的属性使用。 实例 以下实例红 AgriLoan 类实现了 ILoan 接口，并将 interest 字段作为类的属性使用。 12345678910111213141516interface ILoan { interest:number } class AgriLoan implements ILoan { interest:number rebate:number constructor(interest:number,rebate:number) { this.interest = interest this.rebate = rebate } } var obj = new AgriLoan(10,1) console.log(&quot;利润为 : &quot;+obj.interest+&quot;，抽成为 : &quot;+obj.rebate ) 编译以上代码得到如下 JavaScript 代码： 123456789var AgriLoan = /** @class */ (function () { function AgriLoan(interest, rebate) { this.interest = interest; this.rebate = rebate; } return AgriLoan;}());var obj = new AgriLoan(10, 1);console.log(&quot;利润为 : &quot; + obj.interest + &quot;，抽成为 : &quot; + obj.rebate); 执行以上 JavaScript 代码，输出结果为： 1利润为 : 10，抽成为 : 1","link":"/TypeScript-%E7%B1%BB/"},{"title":"TypeScript 联合类型","text":"联合类型（Union Types）可以通过管道|将变量设置多种类型，赋值时可以根据设置的类型来赋值。 注意：只能赋值指定的类型，如果赋值其它类型就会报错。 创建联合类型的语法格式如下： 1Type1|Type2|Type3 声明联合类型实例 声明一个联合类型： 12345var val:string|number val = 12 console.log(&quot;数字为 &quot;+ val) val = &quot;Buubiu&quot; console.log(&quot;字符串为 &quot; + val) ​ 编译以上代码得到如下 JavaScript 代码： 12345var val;val = 12;console.log(&quot;数字为 &quot; + val);val = &quot;Buubiu&quot;;console.log(&quot;字符串为 &quot; + val); ​ 执行以上 JavaScript 代码，输出结果为： 12数字为 12字符串为 Buubiu 如果赋值其它类型就会报错： 12var val:string|number val = true 也可以将联合类型作为函数参数使用： 12345678910111213function disp(name:string|string[]) { if(typeof name == &quot;string&quot;) { console.log(name) } else { var i; for(i = 0;i&lt;name.length;i++) { console.log(name[i]) } } } disp(&quot;Buubiu&quot;) console.log(&quot;输出数组....&quot;) disp([&quot;Buubiu&quot;,&quot;Google&quot;,&quot;Taobao&quot;,&quot;Facebook&quot;]) 编译以上代码得到如下 JavaScript 代码： 1234567891011121314function disp(name) { if (typeof name == &quot;string&quot;) { console.log(name); } else { var i; for (i = 0; i &lt; name.length; i++) { console.log(name[i]); } }}disp(&quot;Buubiu&quot;);console.log(&quot;输出数组....&quot;);disp([&quot;Buubiu&quot;, &quot;Google&quot;, &quot;Taobao&quot;, &quot;Facebook&quot;]); 执行以上 JavaScript 代码，输出结果为： 123456Buubiu输出数组....BuubiuGoogleTaobaoFacebook 联合类型数组我们也可以将数组声明为联合类型： 实例 123456789101112131415var arr:number[]|string[]; var i:number; arr = [1,2,4] console.log(&quot;**数字数组**&quot;) for(i = 0;i&lt;arr.length;i++) { console.log(arr[i]) } arr = [&quot;Buubiu&quot;,&quot;Google&quot;,&quot;Taobao&quot;] console.log(&quot;**字符串数组**&quot;) for(i = 0;i&lt;arr.length;i++) { console.log(arr[i]) } 编译以上代码得到如下 JavaScript 代码： 123456789101112var arr;var i;arr = [1, 2, 4];console.log(&quot;**数字数组**&quot;);for (i = 0; i &lt; arr.length; i++) { console.log(arr[i]);}arr = [&quot;Buubiu&quot;, &quot;Google&quot;, &quot;Taobao&quot;];console.log(&quot;**字符串数组**&quot;);for (i = 0; i &lt; arr.length; i++) { console.log(arr[i]);} 执行以上 JavaScript 代码，输出结果为： 12345678**数字数组**124**字符串数组**BuubiuGoogleTaobao","link":"/TypeScript-%E8%81%94%E5%90%88%E7%B1%BB%E5%9E%8B/"},{"title":"TypeScript 运算符","text":"运算符用于执行程序代码运算，会针对一个以上操作数项目来进行运算。 考虑以下计算： 17 + 5 = 12 以上实例中 7、5 和 12 是操作数。 运算符 + 用于加值。 运算符 = 用于赋值。 TypeScript 主要包含以下几种运算： 算术运算符 关系运算符 逻辑运算符 短路运算符 按位运算符 赋值运算符 三元/条件运算符 类型运算符 其他运算符(负号运算符与字符串运算符） 算术运算符假定 y=5，下面的表格解释了这些算术运算符的操作： 运算符 描述 例子 x 运算结果 y 运算结果 + 加法 x=y+2 7 5 - 减法 x=y-2 3 5 * 乘法 x=y*2 10 5 / 除法 x=y/2 2.5 5 % 取模（余数） x=y%2 1 5 ++ 自增 x=++y 6 6 ++ 自增 x=y++ 5 6 – 自减 x=–y 4 4 – 自减 x=y– 5 4 实例： 123456789101112131415161718192021222324var num1:number = 10var num2:number = 2var res:number = 0 res = num1 + num2console.log(&quot;加: &quot;+res);res = num1 - num2;console.log(&quot;减: &quot;+res)res = num1*num2console.log(&quot;乘: &quot;+res)res = num1/num2console.log(&quot;除: &quot;+res) res = num1%num2console.log(&quot;余数: &quot;+res)num1++console.log(&quot;num1 自增运算: &quot;+num1)num2--console.log(&quot;num2 自减运算: &quot;+num2) 使用 tsc 命令编译以上代码得到如下 JavaScript 代码： 1234567891011121314151617var num1 = 10;var num2 = 2;var res = 0;res = num1 + num2;console.log(&quot;加: &quot; + res);res = num1 - num2;console.log(&quot;减: &quot; + res);res = num1 * num2;console.log(&quot;乘: &quot; + res);res = num1 / num2;console.log(&quot;除: &quot; + res);res = num1 % num2;console.log(&quot;余数: &quot; + res);num1++;console.log(&quot;num1 自增运算: &quot; + num1);num2--;console.log(&quot;num2 自减运算: &quot; + num2); 执行以上 JavaScript 代码，输出结果为： 1234567加: 12减: 8乘: 20除: 5余数: 0num1 自增运算: 11num2 自减运算: 1 关系运算符关系运算符用于计算结果是否为 true 或者 false。 x=5，下面的表格解释了关系运算符的操作： 运算符 描述 比较 返回值 == 等于 x==8 false == 等于 x==5 true != 不等于 x!=8 true &gt; 大于 x&gt;8 false &lt; 小于 x&lt;8 true &gt;= 大于或等于 x&gt;=8 false &lt;= 小于或等于 x&lt;=8 true 实例 1234567891011121314151617181920212223var num1:number = 5;var num2:number = 9; console.log(&quot;num1 的值为: &quot;+num1); console.log(&quot;num2 的值为:&quot;+num2); var res = num1&gt;num2 console.log(&quot;num1 大于n num2: &quot;+res) res = num1&lt;num2 console.log(&quot;num1 小于 num2: &quot;+res) res = num1&gt;=num2 console.log(&quot;num1 大于或等于 num2: &quot;+res) res = num1&lt;=num2console.log(&quot;num1 小于或等于 num2: &quot;+res) res = num1==num2 console.log(&quot;num1 等于 num2: &quot;+res) res = num1!=num2 console.log(&quot;num1 不等于 num2: &quot;+res) 使用 tsc 命令编译以上代码得到如下 JavaScript 代码： 12345678910111213141516var num1 = 5;var num2 = 9;console.log(&quot;num1 的值为: &quot; + num1);console.log(&quot;num2 的值为:&quot; + num2);var res = num1 &gt; num2;console.log(&quot;num1 大于n num2: &quot; + res);res = num1 &lt; num2;console.log(&quot;num1 小于 num2: &quot; + res);res = num1 &gt;= num2;console.log(&quot;num1 大于或等于 num2: &quot; + res);res = num1 &lt;= num2;console.log(&quot;num1 小于或等于 num2: &quot; + res);res = num1 == num2;console.log(&quot;num1 等于 num2: &quot; + res);res = num1 != num2;console.log(&quot;num1 不等于 num2: &quot; + res); 执行以上 JavaScript 代码，输出结果为： 12345678num1 的值为: 5num2 的值为:9num1 大于n num2: falsenum1 小于 num2: truenum1 大于或等于 num2: falsenum1 小于或等于 num2: truenum1 等于 num2: falsenum1 不等于 num2: true 逻辑运算符逻辑运算符用于测定变量或值之间的逻辑。 给定 x=6 以及 y=3，下表解释了逻辑运算符： 运算符 描述 例子 &amp;&amp; and (x &lt; 10 &amp;&amp; y &gt; 1) 为 true || or (x==5 || y==5) 为 false ! not !(x==y) 为 true 实例 12345678910111213var avg:number = 20; var percentage:number = 90; console.log(&quot;avg 值为: &quot;+avg+&quot; ,percentage 值为: &quot;+percentage); var res:boolean = ((avg&gt;50)&amp;&amp;(percentage&gt;80)); console.log(&quot;(avg&gt;50)&amp;&amp;(percentage&gt;80): &quot;,res); var res:boolean = ((avg&gt;50)||(percentage&gt;80)); console.log(&quot;(avg&gt;50)||(percentage&gt;80): &quot;,res); var res:boolean=!((avg&gt;50)&amp;&amp;(percentage&gt;80)); console.log(&quot;!((avg&gt;50)&amp;&amp;(percentage&gt;80)): &quot;,res); 使用 tsc 命令编译以上代码得到如下 JavaScript 代码： 123456789var avg = 20;var percentage = 90;console.log(&quot;avg 值为: &quot; + avg + &quot; ,percentage 值为: &quot; + percentage);var res = ((avg &gt; 50) &amp;&amp; (percentage &gt; 80));console.log(&quot;(avg&gt;50)&amp;&amp;(percentage&gt;80): &quot;, res);var res = ((avg &gt; 50) || (percentage &gt; 80));console.log(&quot;(avg&gt;50)||(percentage&gt;80): &quot;, res);var res = !((avg &gt; 50) &amp;&amp; (percentage &gt; 80));console.log(&quot;!((avg&gt;50)&amp;&amp;(percentage&gt;80)): &quot;, res); 执行以上 JavaScript 代码，输出结果为： 1234avg 值为: 20 ,percentage 值为: 90(avg&gt;50)&amp;&amp;(percentage&gt;80): false(avg&gt;50)||(percentage&gt;80): true!((avg&gt;50)&amp;&amp;(percentage&gt;80)): true 短路运算符(&amp;&amp; 与 ||)&amp;&amp; 与 || 运算符可用于组合表达式。 &amp;&amp; 运算符只有在左右两个表达式都为 true 时才返回 true。 考虑以下实例： 12var a = 10 var result = ( a&lt;10 &amp;&amp; a&gt;5) 以上实例中 a &lt; 10 与 a &gt; 5 是使用了 &amp;&amp; 运算符的组合表达式，第一个表达式返回了 false，由于 &amp;&amp; 运算需要两个表达式都为 true，所以如果第一个为 false，就不再执行后面的判断(a &gt; 5 跳过计算)，直接返回 false。 || 运算符只要其中一个表达式为 true ，则该组合表达式就会返回 true。 考虑以下实例： 12var a = 10 var result = ( a&gt;5 || a&lt;10) 以上实例中 a &gt; 5 与 a &lt; 10 是使用了 || 运算符的组合表达式，第一个表达式返回了 true，由于 || 组合运算只需要一个表达式为 true，所以如果第一个为 true，就不再执行后面的判断(a &lt; 10 跳过计算)，直接返回 true。 按位运算符位操作是程序设计中对位模式按位或二进制数的一元和二元操作。 运算符 描述 例子 类似于 结果 十进制 &amp; AND，按位与处理两个长度相同的二进制数，两个相应的二进位都为 1，该位的结果值才为 1，否则为 0。 x = 5 &amp; 1 0101 &amp; 0001 0001 1 | OR，按位或处理两个长度相同的二进制数，两个相应的二进位中只要有一个为 1，该位的结果值为 1。 x = 5 | 1 0101 | 0001 0101 5 ~ 取反，取反是一元运算符，对一个二进制数的每一位执行逻辑反操作。使数字 1 成为 0，0 成为 1。 x = ~ 5 ~0101 1010 -6 ^ 异或，按位异或运算，对等长二进制模式按位或二进制数的每一位执行逻辑异按位或操作。操作的结果是如果某位不同则该位为 1，否则该位为 0。 x = 5 ^ 1 0101 ^ 0001 0100 4 &lt;&lt; 有符号左移，把 &lt;&lt; 左边的运算数的各二进位全部左移若干位，由 &lt;&lt; 右边的数指定移动的位数，高位丢弃，低位补 0。 x = 5 &lt;&lt; 1 0101 &lt;&lt; 1 1010 10 &gt;&gt; 有符号右移，把 &gt;&gt; 左边的运算数的各二进位全部右移若干位，&gt;&gt; 右边的数指定移动的位数，低位丢弃，高位补0。 x = 5 &gt;&gt; 1 0101 &gt;&gt; 1 0010 2 &gt;&gt;&gt; 无符号右移，与有符号右移位类似（对于正数来说相同，对于负数来说不同），除了左边一律使用0 补位。 x = 2 &gt;&gt;&gt; 1 0010 &gt;&gt;&gt; 1 0001 1 实例 12345678910111213141516171819202122232425var a:number = 2; // 二进制 10 var b:number = 3; // 二进制 11 var result; result = (a &amp; b); console.log(&quot;(a &amp; b) =&gt; &quot;,result) result = (a | b); console.log(&quot;(a | b) =&gt; &quot;,result) result = (a ^ b); console.log(&quot;(a ^ b) =&gt; &quot;,result); result = (~b); console.log(&quot;(~b) =&gt; &quot;,result); result = (a &lt;&lt; b); console.log(&quot;(a &lt;&lt; b) =&gt; &quot;,result); result = (a &gt;&gt; b); console.log(&quot;(a &gt;&gt; b) =&gt; &quot;,result); result = (a &gt;&gt;&gt; 1); console.log(&quot;(a &gt;&gt;&gt; 1) =&gt; &quot;,result); 使用 tsc 命令编译以上代码得到如下 JavaScript 代码： 1234567891011121314151617var a = 2; // 二进制 10 var b = 3; // 二进制 11var result;result = (a &amp; b);console.log(&quot;(a &amp; b) =&gt; &quot;, result);result = (a | b);console.log(&quot;(a | b) =&gt; &quot;, result);result = (a ^ b);console.log(&quot;(a ^ b) =&gt; &quot;, result);result = (~b);console.log(&quot;(~b) =&gt; &quot;, result);result = (a &lt;&lt; b);console.log(&quot;(a &lt;&lt; b) =&gt; &quot;, result);result = (a &gt;&gt; b);console.log(&quot;(a &gt;&gt; b) =&gt; &quot;, result);result = (a &gt;&gt;&gt; 1);console.log(&quot;(a &gt;&gt;&gt; 1) =&gt; &quot;, result); 执行以上 JavaScript 代码，输出结果为： 1234567(a &amp; b) =&gt; 2(a | b) =&gt; 3(a ^ b) =&gt; 1(~b) =&gt; -4(a &lt;&lt; b) =&gt; 16(a &gt;&gt; b) =&gt; 0(a &gt;&gt;&gt; 1) =&gt; 1 赋值运算符赋值运算符用于给变量赋值。 给定 x=10 和 y=5，下面的表格解释了赋值运算符： 运算符 例子 实例 x 值 = (赋值) x = y x = y x = 5 += (先进行加运算后赋值) x += y x = x + y x = 15 -= (先进行减运算后赋值) x -= y x = x - y x = 5 *= (先进行乘运算后赋值) x *= y x = x * y x = 50 /= (先进行除运算后赋值) x /= y x = x / y x = 2 %= (先进行取模（余数）运算后赋值) x %= y x = x % y x = 0 类似的逻辑运算符也可以与赋值运算符联合使用：&lt;&lt;=, &gt;&gt;=, &gt;&gt;&gt;=, &amp;=, |= 与 ^=。 实例 1234567891011121314151617181920var a: number = 12 var b:number = 10 a = b console.log(&quot;a = b: &quot;+a) a += bconsole.log(&quot;a+=b: &quot;+a) a -= b console.log(&quot;a-=b: &quot;+a) a *= b console.log(&quot;a*=b: &quot;+a) a /= b console.log(&quot;a/=b: &quot;+a) a %= b console.log(&quot;a%=b: &quot;+a) 使用 tsc 命令编译以上代码得到如下 JavaScript 代码： 1234567891011121314var a = 12;var b = 10;a = b;console.log(&quot;a = b: &quot; + a);a += b;console.log(&quot;a+=b: &quot; + a);a -= b;console.log(&quot;a-=b: &quot; + a);a *= b;console.log(&quot;a*=b: &quot; + a);a /= b;console.log(&quot;a/=b: &quot; + a);a %= b;console.log(&quot;a%=b: &quot; + a); 执行以上 JavaScript 代码，输出结果为： 123456a = b: 10a+=b: 20a-=b: 10a*=b: 100a/=b: 10a%=b: 0 三元运算符 (?)三元运算有 3 个操作数，并且需要判断布尔表达式的值。该运算符的主要是决定哪个值应该赋值给变量。 1Test ? expr1 : expr2 Test − 指定的条件语句 expr1 − 如果条件语句 Test 返回 true 则返回该值 expr2 − 如果条件语句 Test 返回 false 则返回该值 让我们看下以下实例： 123var num:number = -2 var result = num &gt; 0 ? &quot;大于 0&quot; : &quot;小于 0，或等于 0&quot; console.log(result) 实例中用于判断变量是否大于 0。 使用 tsc 命令编译以上代码得到如下 JavaScript 代码： 123var num = -2;var result = num &gt; 0 ? &quot;大于 0&quot; : &quot;小于 0，或等于 0&quot;;console.log(result); 以上实例输出结果如下： 1小于 0，或等于 0 类型运算符typeof 运算符typeof 是一元运算符，返回操作数的数据类型。 查看以下实例: 12var num = 12 console.log(typeof num); //输出结果: number 使用 tsc 命令编译以上代码得到如下 JavaScript 代码： 12var num = 12;console.log(typeof num); //输出结果: number 以上实例输出结果如下： 1number instanceof 运算符instanceof 运算符用于判断对象是否为指定的类型，后面章节我们会具体介绍它。 其他运算符负号运算符(-)更改操作数的符号，查看以下实例： 1234var x:number = 4 var y = -x; console.log(&quot;x 值为: &quot;,x); // 输出结果 4 console.log(&quot;y 值为: &quot;,y); // 输出结果 -4 使用 tsc 命令编译以上代码得到如下 JavaScript 代码： 1234var x = 4;var y = -x;console.log(&quot;x 值为: &quot;, x); // 输出结果 4 console.log(&quot;y 值为: &quot;, y); // 输出结果 -4 以上实例输出结果如下： 12x 值为: 4y 值为: -4 字符串运算符:连接运算符 (+)+ 运算符可以拼接两个字符串，查看以下实例： 12var msg:string = &quot;buubiu&quot;+&quot;.com&quot; console.log(msg) 使用 tsc 命令编译以上代码得到如下 JavaScript 代码： 12var msg = &quot;buubiu&quot; + &quot;.com&quot;;console.log(msg); 以上实例输出结果如下： 1buubiu.com","link":"/TypeScript-%E8%BF%90%E7%AE%97%E7%AC%A6/"},{"title":"WebLogic 安装补丁","text":"Oracle 官方于美国时间 2020 年 7 月 14 日将发布大规模的季度补丁更新，以修补多达 433 个的新安全漏洞。 本次以 WebLogic 安装补丁为例 执行命令之前做好代码的备份 解压对应的压缩包从官方找到对应的漏洞补丁压缩包，如：p31178516_121300_Generic.zip,并解压到目录。 授权目录对解压后的补丁目录和 weblogic 目录赋予 weblogic 权限 停止服务停止服务并做好相关备份 执行 attachHome.sh 文件切换 weblogic 用户，执行: /opt/weblogic/oui/bin/attachHome.sh（如果之前执行过，就不需要执行了） 说明： /opt/weblogic/ 为我的安装目录。 执行 opatch 命令进入补丁解压后的目录，执行：/opt/weblogic/OPatch/opatch apply -jdk /opt/java/jdk1.7.0_79 验证补丁是否安装成功验证版本：/opt/weblogic/OPatch/opatch lsinventory","link":"/WebLogic-%E5%AE%89%E8%A3%85%E8%A1%A5%E4%B8%81/"},{"title":"Zookeeper的Java客户端操作","text":"Java客户端操作zk非常简单，只需要引入zkclient依赖就可以了，然后编写代码，不过一般项目中不需要我们原生操作zk，一些框架都自带了对zk的操作。 引入依赖1234567891011121314&lt;!--junit--&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;!--引入zkclient依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt;&lt;/dependency&gt; 编写测试类初始化客户端对象12345678910111213141516171819202122232425262728293031323334353637package com.buubiu.test;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.junit.After;import org.junit.Before;/** * @author buubiu **/public class TestZKClient { private ZkClient zkClient; /** * 初始化客户端对象 */ @Before public void before() { /** * 参数1：zkserver服务器的ip地址和端口号 * 参数2：会话超时时间 毫秒 * 参数3：连接超时时间 毫秒 * 参数4：序列化方式 我们创建的对象是怎么样的方式存储在zk中的，一般采用zk提供的jdk的方式 new SerializableSerializer() */ zkClient = new ZkClient(&quot;192.168.91.4:2181&quot;, 60000 * 30, 60000, new SerializableSerializer()); } /** * 释放资源 */ @After public void after() { zkClient.close(); }} 创建zk节点12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.buubiu.test;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.apache.zookeeper.CreateMode;import org.junit.After;import org.junit.Before;import org.junit.Test;/** * @author buubiu **/public class TestZKClient { private ZkClient zkClient; /** * 初始化客户端对象 */ @Before public void before() { /** * 参数1：zkserver服务器的ip地址和端口号 * 参数2：会话超时时间 毫秒 * 参数3：连接超时时间 毫秒 * 参数4：序列化方式 我们创建的对象是怎么样的方式存储在zk中的，一般采用zk提供的jdk的方式 new SerializableSerializer() */ zkClient = new ZkClient(&quot;192.168.91.4:2181&quot;, 60000 * 30, 60000, new SerializableSerializer()); } /** * 释放资源 */ @After public void after() throws InterruptedException { Thread.sleep(5000); zkClient.close(); } /** * 在zk创建节点 */ @Test public void testCreateNode() { //1.持久节点 zkClient.create(&quot;/node&quot;, &quot;q_buubiu&quot;, CreateMode.PERSISTENT); //2.持久顺序节点 zkClient.create(&quot;/node/qs_node&quot;, &quot;qs_buubiu&quot;, CreateMode.PERSISTENT_SEQUENTIAL); //3.临时节点 zkClient.create(&quot;/node/e_node&quot;, &quot;e_buubiu&quot;, CreateMode.EPHEMERAL); //4.临时顺序节点 zkClient.create(&quot;/node/es_node&quot;, &quot;es_buubiu&quot;, CreateMode.EPHEMERAL_SEQUENTIAL); }} 1234567[zk: localhost:2181(CONNECTED) 22] ls /[node, zookeeper][zk: localhost:2181(CONNECTED) 23] ls /node[e_node, es_node0000000002, qs_node0000000000][zk: localhost:2181(CONNECTED) 24] ls /node[qs_node0000000000][zk: localhost:2181(CONNECTED) 25] 删除zk节点12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.buubiu.test;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.apache.zookeeper.CreateMode;import org.junit.After;import org.junit.Before;import org.junit.Test;/** * @author buubiu **/public class TestZKClient { private ZkClient zkClient; /** * 初始化客户端对象 */ @Before public void before() { /** * 参数1：zkserver服务器的ip地址和端口号 * 参数2：会话超时时间 毫秒 * 参数3：连接超时时间 毫秒 * 参数4：序列化方式 我们创建的对象是怎么样的方式存储在zk中的，一般采用zk提供的jdk的方式 new SerializableSerializer() */ zkClient = new ZkClient(&quot;192.168.91.4:2181&quot;, 60000 * 30, 60000, new SerializableSerializer()); } /** * 释放资源 */ @After public void after() throws InterruptedException { //Thread.sleep(5000); zkClient.close(); } /** * 删除zk节点 */ @Test public void testDeleteNode() { //删除没有子节点的节点 返回值：是否删除成功 //boolean delete = zkClient.delete(&quot;/node&quot;); //System.out.println(delete); //递归删除节点信息 返回值：是否删除成功 boolean recursive = zkClient.deleteRecursive(&quot;/node&quot;); System.out.println(recursive); }}/**truetrue**/ 查询当前节点下的所有子节点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.buubiu.test;import java.util.List;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.apache.zookeeper.CreateMode;import org.junit.After;import org.junit.Before;import org.junit.Test;/** * @author buubiu **/public class TestZKClient { private ZkClient zkClient; /** * 初始化客户端对象 */ @Before public void before() { /** * 参数1：zkserver服务器的ip地址和端口号 * 参数2：会话超时时间 毫秒 * 参数3：连接超时时间 毫秒 * 参数4：序列化方式 我们创建的对象是怎么样的方式存储在zk中的，一般采用zk提供的jdk的方式 new SerializableSerializer() */ zkClient = new ZkClient(&quot;192.168.91.4:2181&quot;, 60000 * 30, 60000, new SerializableSerializer()); } /** * 释放资源 */ @After public void after() throws InterruptedException { //Thread.sleep(5000); zkClient.close(); } /** * 查询当前节点下的所有子节点 */ @Test public void testFindNodes() { //获取指定路径的节点信息 返回值：当前节点下的所有子节点信息 List&lt;String&gt; children = zkClient.getChildren(&quot;/&quot;); for (String child : children) { System.out.println(child); } }}/**node4nodenode2node3zookeepernode1**/ 查看某个节点数据注意：通过Java客户端操作需要保证节点存储的数据和获取节点时的数据序列化方式必须一致 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.buubiu.test;import java.util.List;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.apache.zookeeper.CreateMode;import org.junit.After;import org.junit.Before;import org.junit.Test;/** * @author buubiu **/public class TestZKClient { private ZkClient zkClient; /** * 初始化客户端对象 */ @Before public void before() { /** * 参数1：zkserver服务器的ip地址和端口号 * 参数2：会话超时时间 毫秒 * 参数3：连接超时时间 毫秒 * 参数4：序列化方式 我们创建的对象是怎么样的方式存储在zk中的，一般采用zk提供的jdk的方式 new SerializableSerializer() */ zkClient = new ZkClient(&quot;192.168.91.4:2181&quot;, 60000 * 30, 60000, new SerializableSerializer()); } /** * 释放资源 */ @After public void after() throws InterruptedException { //Thread.sleep(5000); zkClient.close(); } /** * 查看某个节点数据 */ @Test public void testFindNodeData() { Object readData = zkClient.readData(&quot;/node&quot;); System.out.println(readData); }}/**q_buubiu**/ 查看节点状态信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.buubiu.test;import java.util.List;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.data.Stat;import org.junit.After;import org.junit.Before;import org.junit.Test;/** * @author buubiu **/public class TestZKClient { private ZkClient zkClient; /** * 初始化客户端对象 */ @Before public void before() { /** * 参数1：zkserver服务器的ip地址和端口号 * 参数2：会话超时时间 毫秒 * 参数3：连接超时时间 毫秒 * 参数4：序列化方式 我们创建的对象是怎么样的方式存储在zk中的，一般采用zk提供的jdk的方式 new SerializableSerializer() */ zkClient = new ZkClient(&quot;192.168.91.4:2181&quot;, 60000 * 30, 60000, new SerializableSerializer()); } /** * 释放资源 */ @After public void after() throws InterruptedException { //Thread.sleep(5000); zkClient.close(); } /** * 查看节点数据和状态信息 */ @Test public void testFindNodeDataAndStat() { Stat stat = new Stat(); Object readData = zkClient.readData(&quot;/node&quot;, stat); System.out.println(readData); System.out.println(stat); System.out.println(stat.getAversion()); System.out.println(stat.getCtime()); System.out.println(stat.getCzxid()); }}/**q_buubiu62,62,1618705866499,1618705866499,0,5,0,0,15,1,660161870586649962**/ 修改节点信息注意：必须修改通过Java客户端创建的节点，通过命令行创建的节点无法修改成功 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.buubiu.test;import com.buubiu.entity.User;import java.util.Date;import java.util.List;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.data.Stat;import org.junit.After;import org.junit.Before;import org.junit.Test;/** * @author buubiu **/public class TestZKClient { private ZkClient zkClient; /** * 初始化客户端对象 */ @Before public void before() { /** * 参数1：zkserver服务器的ip地址和端口号 * 参数2：会话超时时间 毫秒 * 参数3：连接超时时间 毫秒 * 参数4：序列化方式 我们创建的对象是怎么样的方式存储在zk中的，一般采用zk提供的jdk的方式 new SerializableSerializer() */ zkClient = new ZkClient(&quot;192.168.91.4:2181&quot;, 60000 * 30, 60000, new SerializableSerializer()); } /** * 释放资源 */ @After public void after() throws InterruptedException { //Thread.sleep(5000); zkClient.close(); } /** * 修改节点信息 * 注意：必须修改通过Java客户端创建的节点，通过命令行创建的节点无法修改成功 */ @Test public void testWriteData() { User user = new User(); user.setId(1); user.setName(&quot;buubiu&quot;); user.setAge(22); user.setBir(new Date()); zkClient.writeData(&quot;/node&quot;, user); User readData = zkClient.readData(&quot;/node&quot;); System.out.println(readData.toString()); }}/**User{id=1, name='buubiu', age=22, bir=Sun Apr 18 00:49:29 CST 2021}**/ 监听节点数据变化注意： Java客户端监听跟命令行监听不一样，Java客户端是一直监听着 Java程序必须一直运行着才能监听到 必须通过Java代码进行修改节点数据才能被监听到，通过命令行修改是无法监听的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package com.buubiu.test;import com.buubiu.entity.User;import java.io.IOException;import java.util.Date;import java.util.List;import org.I0Itec.zkclient.IZkDataListener;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.data.Stat;import org.junit.After;import org.junit.Before;import org.junit.Test;/** * @author buubiu **/public class TestZKClient { private ZkClient zkClient; /** * 初始化客户端对象 */ @Before public void before() { /** * 参数1：zkserver服务器的ip地址和端口号 * 参数2：会话超时时间 毫秒 * 参数3：连接超时时间 毫秒 * 参数4：序列化方式 我们创建的对象是怎么样的方式存储在zk中的，一般采用zk提供的jdk的方式 new SerializableSerializer() */ zkClient = new ZkClient(&quot;192.168.91.4:2181&quot;, 60000 * 30, 60000, new SerializableSerializer()); } /** * 释放资源 */ @After public void after() throws InterruptedException { //Thread.sleep(5000); zkClient.close(); } /** * 监听节点数据变化 * 注意：1. Java客户端监听跟命令行监听不一样，Java客户端是一直监听着 * 2. Java程序必须一直运行着才能监听到 * 3. 必须通过Java代码进行修改节点数据才能被监听到，通过命令行修改是无法监听的 */ @Test public void testWatchDataChange() throws IOException { zkClient.subscribeDataChanges(&quot;/node&quot;, new IZkDataListener() { //当前节点数据变化时触发这个方法 public void handleDataChange(String dataPath, Object data) throws Exception { System.out.println(&quot;节点数据被修改了：&quot;); System.out.println(&quot;当前节点路径：&quot; + dataPath); System.out.println(&quot;当前节点变化后数据：&quot; + data); } //当前节点删除数据时，触发这个方法 public void handleDataDeleted(String dataPath) throws Exception { System.out.println(&quot;节点数据被删除了：&quot;); System.out.println(&quot;当前节点路径：&quot; + dataPath); } }); //阻塞客户端 System.in.read(); }}/**节点数据被修改了：当前节点路径：/node当前节点变化后数据：User{id=1, name='buubiu', age=22, bir=Sun Apr 18 23:14:59 CST 2021}节点数据被删除了：当前节点路径：/node**/ 监听节点目录的变化注意： Java客户端监听跟命令行监听不一样，Java客户端是一直监听着 Java程序必须一直运行着才能监听到 监听目录既可以监听通过Java客户端操作，也可以监听通过命令行的操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package com.buubiu.test;import com.buubiu.entity.User;import java.io.IOException;import java.util.Date;import java.util.List;import org.I0Itec.zkclient.IZkChildListener;import org.I0Itec.zkclient.IZkDataListener;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.data.Stat;import org.junit.After;import org.junit.Before;import org.junit.Test;/** * @author buubiu **/public class TestZKClient { private ZkClient zkClient; /** * 初始化客户端对象 */ @Before public void before() { /** * 参数1：zkserver服务器的ip地址和端口号 * 参数2：会话超时时间 毫秒 * 参数3：连接超时时间 毫秒 * 参数4：序列化方式 我们创建的对象是怎么样的方式存储在zk中的，一般采用zk提供的jdk的方式 new SerializableSerializer() */ zkClient = new ZkClient(&quot;192.168.91.4:2181&quot;, 60000 * 30, 60000, new SerializableSerializer()); } /** * 释放资源 */ @After public void after() throws InterruptedException { //Thread.sleep(5000); zkClient.close(); } /** * 监听节点目录的变化 * 注意：1. Java客户端监听跟命令行监听不一样，Java客户端是一直监听着 * 2. Java程序必须一直运行着才能监听到 * 3.监听目录既可以监听通过Java客户端操作，也可以监听通过命令行的操作 */ @Test public void testOnNodesChange() throws IOException { zkClient.subscribeChildChanges(&quot;/node&quot;, new IZkChildListener() { //当节点目录发生变化时调用这个方法 //参数1：父节点路径 //参数2：父节点中的所有子节点名称 public void handleChildChange(String parentPath, List&lt;String&gt; currentChilds) throws Exception { System.out.println(&quot;父节点路径：&quot; + parentPath); System.out.println(&quot;发生变更后，所有子节点的路径：&quot;); for (String currentChild : currentChilds) { System.out.println(currentChild); } } }); //阻塞客户端 System.in.read(); }}/**父节点路径：/node发生变更后，所有子节点的路径：qs_node0000000003qs_node0000000000node1qs_node0000000006**/","link":"/Zookeeper%E7%9A%84Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/"},{"title":"Zookeeper的安装","text":"安装分为两种： Linux系统原生安装 Docker方式安装 Linux系统安装安装jdk并配置环境变量 将jdk的rpm包传入到Linux服务器中，并执行以下命令： 123456789101112131415[root@localhost software]# rpm -ivh jdk-8u281-linux-x64.rpm警告：jdk-8u281-linux-x64.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID ec551f03: NOKEY准备中... ################################# [100%]正在升级/安装... 1:jdk1.8-2000:1.8.0_281-fcs ################################# [100%]Unpacking JAR files... tools.jar... plugin.jar... javaws.jar... deploy.jar... rt.jar... jsse.jar... charsets.jar... localedata.jar...[root@localhost software]# 默认安装目录在/usr/java/jdk1.8.0_281-amd64 12345678910[root@localhost bin]# find / -name java/etc/pki/ca-trust/extracted/java/etc/pki/java/etc/alternatives/java/var/lib/alternatives/java/usr/bin/java/usr/java/usr/java/jdk1.8.0_281-amd64/bin/java/usr/java/jdk1.8.0_281-amd64/jre/bin/java[root@localhost bin]# 配置环境变量 在文件/etc/profile最后加上如下命令： 12export JAVA_HOME=/usr/java/jdk1.8.0_281-amd64export PATH=$PATH:$JAVA_HOME/bin 让环境变量生效： 1source /etc/profile 安装ZK下载zk安装包https://mirrors.bfsu.edu.cn/apache/zookeeper/zookeeper-3.7.0/apache-zookeeper-3.7.0-bin.tar.gz 上传到服务器中并解压缩1tar -zxvf apache-zookeeper-3.7.0.tar.gz 重命名安装目录1mv apache-zookeeper-3.7.0-bin apache-zookeeper-3.7.0 修改配置文件路径：/opt/software/apache-zookeeper-3.7.0/conf/zoo_sample.cfg，修改完后重命名为zoo.cfg 确保路径dataDir=/tmp/zookeeper存在即可 12345678910111213141516171819202122232425262728# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/tmp/zookeeper# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1 启动zk在zk的bin目录下，指定配置文件运行zkServer.sh 12345[root@localhost apache-zookeeper-3.7.0]# ./bin/zkServer.sh start ./conf/zoo.cfgZooKeeper JMX enabled by defaultUsing config: ./conf/zoo.cfgStarting zookeeper ... STARTED[root@localhost apache-zookeeper-3.7.0]# 使用jps查看启动是否成功1234[root@localhost apache-zookeeper-3.7.0]# jps3148 QuorumPeerMain3182 Jps[root@localhost apache-zookeeper-3.7.0]# 启动客户端连接到zk在bin目录下，使用zkCli.sh 命令：``./bin/zkCli.sh -server 192.168.91.4:2181` 本机可不写-server 注意：可以通过./bin/zkCli.sh help查看客户端所有可执行的命令 123456789root@localhost apache-zookeeper-3.7.0]# ./bin/zkCli.sh -server 192.168.91.4:2181Connecting to 192.168.91.4:2181.......WATCHER::WatchedEvent state:SyncConnected type:None path:null[zk: 192.168.91.4:2181(CONNECTED) 0] ls /[zookeeper][zk: 192.168.91.4:2181(CONNECTED) 1] Docker安装zk获取镜像1docker pull zookeeper:3.7.0 启动zk服务1docker run -d -p 2181:2181 --name zookeeper zookeeper:3.7.0 检查是否启动成功进入docker进程查看 12345➜ docker exec -it 2c bashroot@2c5ea7b1d406:/apache-zookeeper-3.7.0-bin# pwd/apache-zookeeper-3.7.0-binroot@2c5ea7b1d406:/apache-zookeeper-3.7.0-bin# cd bin/root@2c5ea7b1d406:/apache-zookeeper-3.7.0-bin/bin# ./zkCli.sh","link":"/Zookeeper%E7%9A%84%E5%AE%89%E8%A3%85/"},{"title":"Zookeeper的客户端基本命令","text":"进入客户端操作如下常用指令 ls path查看特定节点下面的子节点，比如 1234567891011[root@localhost bin]# ./zkCli.sh -server 192.168.91.4:2181.....[zk: 192.168.91.4:2181(CONNECTED) 1] ls /[zookeeper][zk: 192.168.91.4:2181(CONNECTED) 2] ls /zookeeper[config, quota][zk: 192.168.91.4:2181(CONNECTED) 3] ls /zookeeper/config[][zk: 192.168.91.4:2181(CONNECTED) 4] ls /zookeeper/quota[][zk: 192.168.91.4:2181(CONNECTED) 5] create path data创建一个节点，并给节点绑定数据（默认是持久性节点） create path data 创建持久性节点(默认是持久性节点) create -s path data 创建持久性顺序节点 create -e path data 创建临时性节点(注意：临时节点不能含有任何子节点) create -e -s path data 创建临时顺序节点(注意：临时节点不能含有任何子节点) 123456789101112131415161718192021222324252627282930313233343536373839[zk: 192.168.91.4:2181(CONNECTED) 5] create /q_node q_buubiuCreated /q_node[zk: 192.168.91.4:2181(CONNECTED) 6] ls /[q_node, zookeeper][zk: 192.168.91.4:2181(CONNECTED) 7] create -s /qs_node qs_buubiuCreated /qs_node0000000002[zk: 192.168.91.4:2181(CONNECTED) 8] create -s /qs_node qs_buubiuCreated /qs_node0000000003[zk: 192.168.91.4:2181(CONNECTED) 9] create -s /qs_node qs_buubiuCreated /qs_node0000000004[zk: 192.168.91.4:2181(CONNECTED) 10] ls /[q_node, qs_node0000000002, qs_node0000000003, qs_node0000000004, zookeeper][zk: 192.168.91.4:2181(CONNECTED) 11] create -e /e_node e_buubiuCreated /e_node[zk: 192.168.91.4:2181(CONNECTED) 12] ls /[e_node, q_node, qs_node0000000002, qs_node0000000003, qs_node0000000004, zookeeper][zk: 192.168.91.4:2181(CONNECTED) 13] create -e -s /es_node es_buubiuCreated /es_node0000000006[zk: 192.168.91.4:2181(CONNECTED) 14] create -e -s /es_node es_buubiuCreated /es_node0000000007[zk: 192.168.91.4:2181(CONNECTED) 15] create -e -s /es_node es_buubiuCreated /es_node0000000008[zk: 192.168.91.4:2181(CONNECTED) 16] ls /[e_node, es_node0000000006, es_node0000000007, es_node0000000008, q_node, qs_node0000000002, qs_node0000000003, qs_node0000000004, zookeeper][zk: 192.168.91.4:2181(CONNECTED) 17] create /e_node/aaEphemerals cannot have children: /e_node/aa[zk: 192.168.91.4:2181(CONNECTED) 18] quitWATCHER::WatchedEvent state:Closed type:None path:null2021-04-17 07:00:27,673 [myid:] - INFO [main:ZooKeeper@1232] - Session: 0x1000009ace20001 closed2021-04-17 07:00:27,675 [myid:] - ERROR [main:ServiceUtils@42] - Exiting JVM with code 12021-04-17 07:00:27,675 [myid:] - INFO [main-EventThread:ClientCnxn$EventThread@570] - EventThread shut down for session: 0x1000009ace20001[root@localhost bin]# ./zkCli.sh -server 192.168.91.4:2181.....[zk: 192.168.91.4:2181(CONNECTED) 0] ls /[q_node, qs_node0000000002, qs_node0000000003, qs_node0000000004, zookeeper][zk: 192.168.91.4:2181(CONNECTED) 1] stat path查看节点状态 12345678910111213[zk: 192.168.91.4:2181(CONNECTED) 1] stat /q_nodecZxid = 0x8 #创建节点的事物idctime = Sat Apr 17 06:46:26 CST 2021 #创建节点时间mZxid = 0x8 #修改节点的事物idmtime = Sat Apr 17 06:46:26 CST 2021 #修改节点时间pZxid = 0x8 #父节点的事物idcversion = 0 #节点创建时的版本号dataVersion = 0 #节点数据的版本号aclVersion = 0 #acl的版本号ephemeralOwner = 0x0 #临时节点的节点所有者，因为不是临时节点，所以值为十六进制的0dataLength = 8 #节点中存储数据的长度numChildren = 0 #所含有子节点的数量[zk: 192.168.91.4:2181(CONNECTED) 2] get path获得（查看）节点上绑定的数据信息 123[zk: 192.168.91.4:2181(CONNECTED) 2] get /q_nodeq_buubiu[zk: 192.168.91.4:2181(CONNECTED) 3] set path data修改节点数据 12345678910111213141516[zk: 192.168.91.4:2181(CONNECTED) 3] set /q_node q_buubiu1[zk: 192.168.91.4:2181(CONNECTED) 4] get /q_nodeq_buubiu1[zk: 192.168.91.4:2181(CONNECTED) 5] stat /q_nodecZxid = 0x8ctime = Sat Apr 17 06:46:26 CST 2021mZxid = 0x13mtime = Sat Apr 17 07:12:10 CST 2021pZxid = 0x8cversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 9numChildren = 0[zk: 192.168.91.4:2181(CONNECTED) 6] ls2 path(3.5.9版本开始弃用)查看节点下孩子和当前节点的状态，相当于ls path和stat path的组合命令 12345678910111213141516171819202122232425262728[zk: 192.168.91.4:2181(CONNECTED) 6] ls /[q_node, qs_node0000000002, qs_node0000000003, qs_node0000000004, zookeeper][zk: 192.168.91.4:2181(CONNECTED) 7] stat /cZxid = 0x0ctime = Thu Jan 01 08:00:00 CST 1970mZxid = 0x0mtime = Thu Jan 01 08:00:00 CST 1970pZxid = 0x11cversion = 13dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 5[zk: 192.168.91.4:2181(CONNECTED) 8] ls2 /[q_node, qs_node0000000002, qs_node0000000003, qs_node0000000004, zookeeper]cZxid = 0x0ctime = Thu Jan 01 08:00:00 CST 1970mZxid = 0x0mtime = Thu Jan 01 08:00:00 CST 1970pZxid = 0x11cversion = 13dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 5[zk: 192.168.91.4:2181(CONNECTED) 9] history查看操作历史 123456789101112[zk: 192.168.91.4:2181(CONNECTED) 9] history0 - ls /1 - stat /q_node2 - get /q_node3 - set /q_node q_buubiu14 - get /q_node5 - stat /q_node6 - ls /7 - stat /8 - ls2 /9 - history[zk: 192.168.91.4:2181(CONNECTED) 10] delete path删除节点（注意：删除的节点不能包含子节点） 12345678910[zk: 192.168.91.4:2181(CONNECTED) 10] delete /qs_node0000000002[zk: 192.168.91.4:2181(CONNECTED) 11] ls /[q_node, qs_node0000000003, qs_node0000000004, zookeeper][zk: 192.168.91.4:2181(CONNECTED) 15] create /qs_node0000000003/name buubiuCreated /qs_node0000000003/name[zk: 192.168.91.4:2181(CONNECTED) 16] ls /qs_node0000000003[name][zk: 192.168.91.4:2181(CONNECTED) 17] delete /qs_node0000000003Node not empty: /qs_node0000000003[zk: 192.168.91.4:2181(CONNECTED) 18] rmr path(3.7.0版本开始弃用)递归删除节点（注意：会将当前节点下的所有子节点删除，谨慎操作） 123456[zk: 192.168.91.4:2181(CONNECTED) 18] ls /qs_node0000000003[name][zk: 192.168.91.4:2181(CONNECTED) 19] rmr /qs_node0000000003[zk: 192.168.91.4:2181(CONNECTED) 20] ls /[q_node, qs_node0000000004, zookeeper][zk: 192.168.91.4:2181(CONNECTED) 21] deleteall path递归删除节点（注意：会将当前节点下的所有子节点删除，谨慎操作） 123456[zk: 192.168.91.4:2181(CONNECTED) 18] ls /qs_node0000000003[name][zk: 192.168.91.4:2181(CONNECTED) 19] deleteall /qs_node0000000003[zk: 192.168.91.4:2181(CONNECTED) 20] ls /[q_node, qs_node0000000004, zookeeper][zk: 192.168.91.4:2181(CONNECTED) 22] quit退出当前会话（会话失效） 1234567891011121314[zk: 192.168.91.4:2181(CONNECTED) 22] quit2021-04-17 07:34:47,636 [myid:192.168.91.4:2181] - WARN [main-SendThread(192.168.91.4:2181):ClientCnxn$SendThread@1284] - An exception was thrown while closing send thread for session 0x1000009ace20002.EndOfStreamException: Unable to read additional data from server sessionid 0x1000009ace20002, likely server has closed socket at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77) at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350) at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1280)WATCHER::WatchedEvent state:Closed type:None path:null2021-04-17 07:34:47,743 [myid:] - INFO [main:ZooKeeper@1232] - Session: 0x1000009ace20002 closed2021-04-17 07:34:47,745 [myid:] - ERROR [main:ServiceUtils@42] - Exiting JVM with code 02021-04-17 07:34:47,745 [myid:] - INFO [main-EventThread:ClientCnxn$EventThread@570] - EventThread shut down for session: 0x1000009ace20002[root@localhost bin]#","link":"/Zookeeper%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"title":"Zookeeper的配置文件详细说明","text":"配置文件解释路径：/opt/software/apache-zookeeper-3.7.0/conf/zoo.cfg 123456789101112131415161718192021222324252627282930313233343536# The number of milliseconds of each tick# 集群节点之间的心跳时间 2秒tickTime=2000# The number of ticks that the initial# synchronization phase can take# 初始化集群时，集群节点之间同步超时时间：10*2s=20秒initLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgement# 集群在运行过程中同步数据超时时间：5*2s=10秒syncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.# 默认数据存储位置dataDir=/tmp/zookeeper# the port at which the clients will connect# zk服务监听端口号clientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients# 最大连接数量，即线程池线程数量#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir# 数据时存在内存里面的，zk会根据事物id机制进行做快照，当快照达到多少个后进行合并#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature# 多久进行一个合并，为0:不进行自动合并 为1:一个小时进行一次判断快照个数是否大于等于3，如果满足则进行合并#autopurge.purgeInterval=1","link":"/Zookeeper%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E/"},{"title":"Zookeeper的集群","text":"简介概念集群(cluster)：集合同一种软件服务的多个节点同时提供服务。 解决的问题 解决了单节点的并发访问的压力问题 解决了单节点故障问题（如硬件老化、自然灾害等） 集群架构zk集群节点有两种角色： leader：领导节点，zk集群中的主节点 follower：仲裁节点，除了主节点之外的节点 集群搭建这里在一台机器上模拟三台机器 创建三个dataDir 1[root@localhost ~]# mkdir zkdata1 zkdata2 zkdata3 分别在三个dataDir目录下面创建myid文件，并且依次赋值为1，2，3 myid的内容：是服务器的标识 1234[root@localhost ~]# touch zkdata1/myid zkdata2/myid zkdata3/myid[root@localhost ~]# echo &quot;1&quot; &gt;&gt; zkdata1/myid[root@localhost ~]# echo &quot;2&quot; &gt;&gt; zkdata2/myid[root@localhost ~]# echo &quot;3&quot; &gt;&gt; zkdata3/myid 在/conf目录下创建三个zk配置文件，分别为zoo1.cfg，zoo2.cfg，zoo3.cfg 参数说明： server.X：x为服务器的唯一标识 192.168.91.4：服务器所在的ip地址 3002,4002,5002：数据同步使用的端口 3003,4003,5003：选举使用的端口 zoo1.cfg vi /root/zkdata1/zoo1.cfg 12345678tickTime=2000initLimit=10syncLimit=5dataDir=/root/zkdata1clientPort=3001server.1=192.168.91.4:3002:3003server.2=192.168.91.4:4002:4003server.3=192.168.91.4:5002:5003 zoo2.cfg vi /root/zkdata2/zoo2.cfg 12345678tickTime=2000initLimit=10syncLimit=5dataDir=/root/zkdata2clientPort=4001server.1=192.168.91.4:3002:3003server.2=192.168.91.4:4002:4003server.3=192.168.91.4:5002:5003 zoo3.cfg vi /root/zkdata3/zoo3.cfg 12345678tickTime=2000initLimit=10syncLimit=5dataDir=/root/zkdata3clientPort=5001server.1=192.168.91.4:3002:3003server.2=192.168.91.4:4002:4003server.3=192.168.91.4:5002:5003 分别启动各个zk服务器 123456789101112131415161718[root@localhost apache-zookeeper-3.7.0]# ./bin/zkServer.sh start /root/zkdata1/zoo1.cfgZooKeeper JMX enabled by defaultUsing config: /root/zkdata1/zoo1.cfgStarting zookeeper ... STARTED[root@localhost apache-zookeeper-3.7.0]# ./bin/zkServer.sh start /root/zkdata2/zoo2.cfgZooKeeper JMX enabled by defaultUsing config: /root/zkdata2/zoo2.cfgStarting zookeeper ... STARTED[root@localhost apache-zookeeper-3.7.0]# ./bin/zkServer.sh start /root/zkdata3/zoo3.cfgZooKeeper JMX enabled by defaultUsing config: /root/zkdata3/zoo3.cfgStarting zookeeper ... STARTED[root@localhost apache-zookeeper-3.7.0]# jps2386 Jps2325 QuorumPeerMain2186 QuorumPeerMain2251 QuorumPeerMain[root@localhost apache-zookeeper-3.7.0]# 查看各个zk服务器的角色信息 12345678910111213141516[root@localhost apache-zookeeper-3.7.0]# ./bin/zkServer.sh status /root/zkdata1/zoo1.cfgZooKeeper JMX enabled by defaultUsing config: /root/zkdata1/zoo1.cfgClient port found: 3001. Client address: localhost. Client SSL: false.Mode: follower[root@localhost apache-zookeeper-3.7.0]# ./bin/zkServer.sh status /root/zkdata2/zoo2.cfgZooKeeper JMX enabled by defaultUsing config: /root/zkdata2/zoo2.cfgClient port found: 4001. Client address: localhost. Client SSL: false.Mode: leader[root@localhost apache-zookeeper-3.7.0]# ./bin/zkServer.sh status /root/zkdata3/zoo3.cfgZooKeeper JMX enabled by defaultUsing config: /root/zkdata3/zoo3.cfgClient port found: 5001. Client address: localhost. Client SSL: false.Mode: follower[root@localhost apache-zookeeper-3.7.0]# 客户端连接任意zk服务器进行节点操作 123[root@localhost apache-zookeeper-3.7.0]# ./bin/zkCli.sh -server 192.168.91.4:3001[root@localhost apache-zookeeper-3.7.0]# ./bin/zkCli.sh -server 192.168.91.4:4001[root@localhost apache-zookeeper-3.7.0]# ./bin/zkCli.sh -server 192.168.91.4:5001 停止特定zk服务器 1[root@localhost apache-zookeeper-3.7.0]# ./bin/zkServer.sh stop /root/zkdata2/zoo2.cfg Java客户端操作zk集群1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.buubiu.test;import com.buubiu.entity.User;import java.io.IOException;import java.util.Date;import java.util.List;import org.I0Itec.zkclient.IZkChildListener;import org.I0Itec.zkclient.IZkDataListener;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.data.Stat;import org.junit.After;import org.junit.Before;import org.junit.Test;/** * @author buubiu **/public class TestZKClient { private ZkClient zkClient; /** * 初始化客户端对象 */ @Before public void before() { /** * 参数1：zkserver服务器的ip地址和端口号 * 参数2：会话超时时间 毫秒 * 参数3：连接超时时间 毫秒 * 参数4：序列化方式 我们创建的对象是怎么样的方式存储在zk中的，一般采用zk提供的jdk的方式 new SerializableSerializer() */ zkClient = new ZkClient(&quot;192.168.91.4:3001,192.168.91.4:4001,192.168.91.4:5001&quot;, 60000 * 30, 60000, new SerializableSerializer()); } /** * 释放资源 */ @After public void after() throws InterruptedException { //Thread.sleep(5000); zkClient.close(); }}","link":"/Zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4/"},{"title":"Zookeeper简介","text":"ZK简介 Zookeeper(动物园管理者)简称ZK，一个分布式的，开放源码的分布式应用协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件，Zookeeper使用Java编写，但支持java和C两种编程语言。 ZK内存数据模型模型结构 模型的特点 每个子目录如/app1都被称作一个znode(节点)。这个znode是被它所在的路径唯一标识 znode可以有子节点目录，并且每个znode可以存储数据 znode是有版本的，每个znode中存储的数据可以有多个版本，也就是一个访问路径中可以存储多份数据 znode可以被监控，包括这个目录节点中存储的数据的修改，子节点目录的变化等，一旦变化可以i通知设置监控的客户端 ZK节点的分类持久节点(PERSISTENT)是指在节点创建后，就一直存在，直到有删除操作来主动删除这个节点，不会因为创建该节点的客户端会话失效而消失。 持久顺序节点(PERSISTENT_SEQUENTIAL)这类节点的基本特性和上面的节点类型是一致的。额外的特性是，在ZK中，每个父节点会为他的第一级子节点维护一份时序，会记录每个子节点创建的先后顺序。基于这个特性，在创建子节点的时候，可以设置这个属性，那么在创建节点的过程中，ZK会自动为给定节点名加上一个数字后缀，作为新的节点名。这个数字后缀的范围是整形的最大值。 临时节点(EPHEMERAL)和持久化节点不同的是，临时节点的生命周期和客户端会话绑定。也就是说，如果客户端会话失效，那么这个节点就会自动被清除掉。注意，这里提到的是会话失效，而非连接断开。另外，在临时节点下面不能创建子节点。 临时顺序节点(EPHEMERAL_SEQUENTIAL)具有临时节点特点额外的特性是，每个父节点会为它的第一级子节点维护一份时序，这点和刚才提到的持久顺序节点类似。","link":"/Zookeeper%E7%AE%80%E4%BB%8B/"},{"title":"Zookeeper节点监听机制(Watch)","text":"介绍客户端可以检测znode节点的变化。Znode节点的变化触发相应的事件，然后清除对节点的检测。当检测一个znode节点的时候，Zookeeper会发送通知给检测节点。一个Watch事件是一个一次性的触发器，当被设置了Watch的数据和目录发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端以便通知它们。 zk的监听机制包含两种： 目录监听 数据监听 目录监听命令：ls /path true 监听节点目录的变化 数据监听命令：get /path true 监听节点数据的变化","link":"/Zookeeper%E8%8A%82%E7%82%B9%E7%9B%91%E5%90%AC%E6%9C%BA%E5%88%B6(Watchj)/"},{"title":"centos7设置hostname","text":"查看原名称1hostnamectl status 修改1hostnamectl set-hostname centos","link":"/centos7%E8%AE%BE%E7%BD%AEhostname/"},{"title":"centos7防火墙设置firewalld-cmd","text":"常用命令 1234567systemctl start firewalld # 启动systemctl stop firewalld # 停止systemctl enable firewalld # 启用自动启动systemctl disable firewalld # 禁用自动启动systemctl status firewalld # 查看状态 或者firewall-cmd --state #查看状态firewall-cmd --list-ports #查看端口开放列表 添加端口 12firewall-cmd --permanent --zone=public --add-port=7001/tcpfirewall-cmd --permanent --zone=public --add-port=8080/udp 删除端口 1firewall-cmd --permanent --zone=public --remove-port=8080/tcp 生效 1firewall-cmd --reload","link":"/centos7%E9%98%B2%E7%81%AB%E5%A2%99%E8%AE%BE%E7%BD%AEfirewalld-cmd/"},{"title":"consul导入导出的使用","text":"介绍官方地址：https://www.consul.io/commands/kv 命令：consul kv 该kv命令用于通过命令行与 Consul 的 KV 存储进行交互。它公开了用于从存储中插入、更新、读取和删除的顶级命令。此命令在 Consul 0.7.1 及更高版本中可用。 KV 存储也可以通过 HTTP API访问。 1234567891011$ consul kv -h用法：consul kv &lt;subcommand&gt; [options] [args] Subcommands： delete 从 KV 存储中删除数据 export 以 JSON 格式导出部分 KV 树 get 从 KV 存储中检索或列出数据 import 导入部分JSON 格式的 KV 树 put 设置或更新 KV 存储中的数据 Delete(删除)命令：consul kv delete [options] [KEY_OR_PREFIX] 该kv delete命令从给定路径的 Consul 的 KV 存储中删除值。如果路径中不存在键，则不采取任何操作。 例子： 删除 KV 存储中名为“config/buubiu/serviceconfig”的键的值： 1234567891011# 无 acl$ consul kv delete config/buubiu/serviceconfigSuccess! Deleted key: config/buubiu/serviceconfig# 有 acl$ consul kv delete -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfigSuccess! Deleted key: config/buubiu/serviceconfig# docker exec执行$ docker exec -i consul consul kv delete -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfigSuccess! Deleted key: config/buubiu/serviceconfig 删除多个(-recurse) 12# 删除已 config/buubiu 前缀开头key的所有键$ consul kv delete -recurse -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/ Export(导出)命令：consul kv export [options] [PREFIX] 该kv export命令用于从 Consul 的 KV 存储中检索给定前缀的 KV 对，并将 JSON 表示写入标准输出。这可以与命令“consul kv import”一起使用，在 Consul 集群之间移动整个树。 例子： 1234567891011121314151617181920# 导出到当前界面为JSON$ consul kv export -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig[ { &quot;key&quot;: &quot;config/buubiu/serviceconfig&quot;, &quot;flags&quot;: 0, &quot;value&quot;: &quot;c2VydmljZS5wb3J0OiA4MDgwCmFwcGxpY2F0aW9uOgoJbmFtZTogZGVtbw==&quot; }, { &quot;key&quot;: &quot;config/buubiu/serviceconfig1&quot;, &quot;flags&quot;: 0, &quot;value&quot;: &quot;c2VydmljZS5wb3J0OiA4MDgwCmFwcGxpY2F0aW9uOgoJbmFtZTogZGVtbw==&quot; }]# 导出为一个JSON文件$ consul kv export -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig &gt; config_buubiu_serviceconfig.json# docker exec执行$ docker exec -i consul consul kv export -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig &gt; config_buubiu_serviceconfig.json Get(查看)命令：consul kv get [options] [KEY_OR_PREFIX] 该kv get命令用于从给定键名的 Consul 的 KV 存储中检索值。如果不存在具有该名称的键，则返回错误。如果存在具有该名称但没有数据的键，则不返回任何内容。需要键名或前缀。 例子： 查看KEY内容123456789101112131415# 查看某一个 KEY 的值$ consul kv get -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfigservice.port: 8080application: name: demo # 查看某一个 KEY 的值,转为base64$ consul kv get -base64 -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfigc2VydmljZS5wb3J0OiA4MDgwCmFwcGxpY2F0aW9uOgoJbmFtZTogZGVtbw==# 查看某一个 KEY 的值，并保存在一个JSON文件中$ consul kv get -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig &gt; config_buubiu_serviceconfig.json# docker exec执行$ docker exec -i consul consul kv get -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig &gt; config_buubiu_serviceconfig.json 查看详细KEY要查看有关密钥的详细信息，请指定-detailed标志。这将输出有关密钥的所有已知元数据，包括ModifyIndex 和任何用户提供的标志： 1234567891011# 详细查看某个KEY$ consul kv get -detailed -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfigCreateIndex 580Flags 0Key config/buubiu/serviceconfigLockIndex 0ModifyIndex 594Session -Value service.port: 8080application: name: demo 按前缀查看要将路径视为前缀并列出以给定前缀开头的所有条目，请指定-recurse标志： 123456789101112131415161718192021222324252627282930# 查看所有KEY前缀为 ‘config/buubiu/‘的条目$ consul kv get -recurse -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/config/buubiu/serviceconfig:service.port: 8080application: name: democonfig/buubiu/serviceconfig1:service.port: 8080application: name: demo # 查看所有KEY前缀为 ‘config/buubiu/‘的条目详细信息$ consul kv get -recurse -detailed -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/CreateIndex 580Flags 0Key config/buubiu/serviceconfigLockIndex 0ModifyIndex 594Session -Value service.port: 8080application: name: demoCreateIndex 600Flags 0Key config/buubiu/serviceconfig1LockIndex 0ModifyIndex 600Session -Value service.port: 8080application: name: demo 只查看KEY12345678# 要仅列出以指定前缀开头的键，请改用该-keys 选项。这会提高性能并产生更小的有效负载：$ consul kv get -keys -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/config/buubiu/serviceconfigconfig/buubiu/serviceconfig1# 要列出根目录下的所有键$ consul kv get -keys -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot;config/ Import(导入)命令：consul kv import [options] [DATA] 该kv import命令用于从该kv export命令生成的 JSON 文件中导入 KV 对。 例子： 适用于从kv export命令生成的 JSON 文件中导入 KV 对 文件示例： config_buubiu_serviceconfig.json123456789101112[ { &quot;key&quot;: &quot;config/buubiu/serviceconfig1&quot;, &quot;flags&quot;: 0, &quot;value&quot;: &quot;c2VydmljZS5wb3J0OiA4MDgwCmFwcGxpY2F0aW9uOgoJbmFtZTogZGVtbw==&quot; }, { &quot;key&quot;: &quot;config/buubiu/serviceconfig2&quot;, &quot;flags&quot;: 0, &quot;value&quot;: &quot;c2VydmljZS5wb3J0OiA4MDgwCmFwcGxpY2F0aW9uOgoJbmFtZTogZGVtbw==&quot; }] 12345678910111213141516171819202122232425262728# 从文件导入，文件名前添加 @$ consul kv import -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; @config_buubiu_serviceconfig.jsonImported: config/buubiu/serviceconfig# 从标准输入导入$ cat config_buubiu_serviceconfig.json | consul kv import -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; -Imported: config/buubiu/serviceconfig3Imported: config/buubiu/serviceconfig4# 可以直接传递 JSON，但必须注意 shell 转义$ consul kv import -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; &quot;$(cat config_buubiu_serviceconfig.json)&quot;Imported: config/buubiu/serviceconfig7Imported: config/buubiu/serviceconfig8# docker exec 从标准输入导入$ cat config_buubiu_serviceconfig.json | docker exec -i consul consul kv import -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; -Imported: config/buubiu/serviceconfig5Imported: config/buubiu/serviceconfig6# docker exec 直接传递 JSONdocker exec -i consul consul kv import -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; &quot;$(cat config_buubiu_serviceconfig.json)&quot;Imported: config/buubiu/serviceconfig9Imported: config/buubiu/serviceconfig10# 要在前缀下导入，请使用-prefix选项# -prefix- 导入数据的键前缀。默认值为空，表示根。在 Consul 1.10 中添加。$ cat config_buubiu_serviceconfig.json | consul kv import -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; -prefix=sub/dir/ - Put(更新)命令：consul kv put [options] KEY [DATA] 会覆盖原有的值 该kv put命令将数据写入 KV 存储中的给定路径。一次写入多个条目时，请改用kv import 例子： 普通字符串1234567891011121314151617181920212223242526# 要在 KV 存储中为名为“config/buubiu/serviceconfig”的键插入值“test”$ consul kv put -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig &quot;test&quot;Success! Data written to: config/buubiu/serviceconfig# 或者放到前面,通过指定符号-从标准输入读取值$ echo &quot;test&quot; | consul kv put -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig -# 或者监听键盘录入$ consul kv put -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig -hello world buubiu 我是谁&lt;CTRL+D&gt;Success! Data written to: config/buubiu/serviceconfig# docker exec 执行以上命令# 要在 KV 存储中为名为“config/buubiu/serviceconfig”的键插入值“test”$ docker exec -i consul consul kv put -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig &quot;test&quot;Success! Data written to: config/buubiu/serviceconfig# 或者放到前面,通过指定符号-从标准输入读取值$ echo &quot;test&quot; | docker exec -i consul consul kv put -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig -# 或者监听键盘录入$ docker exec -i consul consul kv put -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig -hello world buubiu 我是谁&lt;CTRL+D&gt;Success! Data written to: config/buubiu/serviceconfig Base64编码的值如果-base64设置了标志，则给定数据将在写入之前进行 Base64 解码： 123456$ consul kv put -base64 -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig &quot;c2VydmljZS5wb3J0OiA4MDgwCmFwcGxpY2F0aW9uOgoJbmFtZTogZGVtbw==&quot;Success! Data written to: config/buubiu/serviceconfig# docker exec$ docker exec -i consul consul kv put -base64 -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig &quot;c2VydmljZS5wb3J0OiA4MDgwCmFwcGxpY2F0aW9uOgoJbmFtZTogZGVtbw==&quot;Success! Data written to: config/buubiu/serviceconfig 较长字符不推荐，格式可能会出现问题 1234567891011121314$ consul kv put -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig - &lt;&lt;EOFservice.port: 8080application: name: demoEOFSuccess! Data written to: config/buubiu/serviceconfig# docker exec $ docker exec -i consul consul kv put -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig - &lt;&lt;EOFservice.port: 8080application: name: demoEOFSuccess! Data written to: config/buubiu/serviceconfig 读取文件也可以通过 有符号 @的标识来读取文件，支持 JSON YAML YML 文件示例： config_buubiu_serviceconfig.yml123service.port: 8080application: name: demo 1234$ consul kv put -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/buubiu/serviceconfig @config_buubiu_serviceconfig.ymlSuccess! Data written to: config/buubiu/serviceconfig# docker exec不支持 扩展导入文件夹下面所有yml文件1$ for i in $(ls *); do var=$i; filename=${var%*.yml}; cat ${filename}.yml | docker exec -i consul consul kv put -http-addr=&quot;http://127.0.0.1:8500&quot; -token=&quot;p2BE1AtpwPbrxZdC6k+eXA==&quot; config/${filename}/serviceconfig -; done","link":"/consul%E5%91%BD%E4%BB%A4%E8%A1%8Ckv%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"debian9安装shadowsocks libev版","text":"123456789101112131415[root@vultr ~]# sh -c 'printf &quot;deb http://deb.debian.org/debian stretch-backports main&quot; &gt; /etc/apt/sources.list.d/stretch-backports.list'[root@vultr ~]# apt update[root@vultr ~]# apt -t stretch-backports install shadowsocks-libev -y[root@vultr ~]# curl -sL https://deb.nodesource.com/setup_10.x | bash -[root@vultr ~]# apt-get install -y nodejs[root@host ~]# npm i -g shadowsocks-manager --unsafe-perm[root@host ~]# npm i -g pm2[root@vultr ~]# ss-manager -m aes-256-cfb -u --manager-address 127.0.0.1:6001[root@host ~]# pm2 --name &quot;ssmanger&quot; -f start ss-manager -x -- -m aes-256-cfb -u --manager-address 127.0.0.1:6001[root@host ~]# mkdir ~/.ssmgr[root@host ~]# vi ~/.ssmgr/ss.json 1234567891011{ &quot;type&quot;: &quot;s&quot;, &quot;shadowsocks&quot;: { &quot;address&quot;: &quot;127.0.0.1:6001&quot; }, &quot;manager&quot;: { &quot;address&quot;: &quot;0.0.0.0:6002&quot;, &quot;password&quot;: &quot;123456&quot; }, &quot;db&quot;: &quot;ss.sqlite&quot;} 123[root@host .ssmgr]# ssmgr -c ~/.ssmgr/ss.json[root@host ~]# pm2 --name &quot;ss-json&quot; -f start ssmgr -x -- -c ~/.ssmgr/ss.json[root@host .ssmgr]# vi ~/.ssmgr/webgui.json 1234567891011121314151617181920212223242526272829303132333435363738394041424344{ &quot;type&quot;: &quot;m&quot;, &quot;manager&quot;: { &quot;address&quot;: &quot;47.244.162.218:6002&quot;, &quot;password&quot;: &quot;123456&quot; }, &quot;plugins&quot;: { &quot;flowSaver&quot;: { &quot;use&quot;: true }, &quot;user&quot;: { &quot;use&quot;: true }, &quot;account&quot;: { &quot;use&quot;: true }, &quot;email&quot;: { &quot;use&quot;: true, &quot;type&quot;: &quot;smtp&quot;, &quot;username&quot;: &quot;bufx@qq.com&quot;, &quot;password&quot;: &quot;iczgevxiljllccai&quot;, &quot;host&quot;: &quot;smtp.qq.com&quot; }, &quot;webgui&quot;: { &quot;use&quot;: true, &quot;host&quot;: &quot;0.0.0.0&quot;, &quot;port&quot;: &quot;80&quot;, &quot;site&quot;: &quot;http://ssmgr.pryhub.com&quot;, &quot;gcmSenderId&quot;: &quot;456102641793&quot;, &quot;gcmAPIKey&quot;: &quot;AAAAGzzdqrE:XXXXXXXXXXXXXX&quot; }, &quot;webgui_telegram&quot;: { &quot;use&quot;: false, &quot;token&quot;: &quot;191374681:AAw6oaVPR4nnY7T4CtW78QX-Xy2Q5WD3wmZ&quot; } }, &quot;db&quot;: &quot;webgui.sqlite&quot;, &quot;redis&quot;: { &quot;host&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 6379, &quot;password&quot;: &quot;&quot;, &quot;db&quot;: 0 }} 12[root@host .ssmgr]# ssmgr -c ~/.ssmgr/webgui.json[root@host ~]# pm2 --name &quot;webguiyml&quot; -f start ssmgr -x -- -c ~/.ssmgr/webgui.json","link":"/debian9%E5%AE%89%E8%A3%85shadowsocks-libev%E7%89%88/"},{"title":"docker解锁网易云音乐所有音乐","text":"概述解锁网易云音乐客户端变灰歌曲 特性 使用 QQ / 虾米 / 百度 / 酷狗 / 酷我 / 咪咕 / JOOX 音源替换变灰歌曲链接 (默认仅启用一、五、六) 为请求增加 X-Real-IP 参数解锁海外限制，支持指定网易云服务器 IP，支持设置上游 HTTP / HTTPS 代理 完整的流量代理功能 (HTTP / HTTPS)，可直接作为系统代理 (同时支持 PAC) 服务端安装并使用镜像下载镜像1$ docker pull nondanee/unblockneteasemusic 使用镜像生成私钥为了支持https，这里需要生成密钥对： 12345678910111213141516171819202122232425262728# 生成 CA 私钥$ mkdir -p /data/docker_volumes/netease-music$ cd /data/docker_volumes/netease-music$ openssl genrsa -out ca.key 2048# 生成 CA 证书 (&quot;buubiu&quot; 处填上你自己的名字)$ openssl req -x509 -new -nodes -key ca.key -sha256 -days 1825 -out ca.crt -subj &quot;/C=CN/CN=UnblockNeteaseMusic Root CA/O=buubiu&quot;# 生成服务器私钥$ openssl genrsa -out server.key 2048# 生成证书签发请求$ openssl req -new -sha256 -key server.key -out server.csr -subj &quot;/C=CN/L=Hangzhou/O=NetEase (Hangzhou) Network Co., Ltd/OU=IT Dept./CN=*.music.163.com&quot;# 使用 CA 签发服务器证书$ openssl x509 -req -extfile &lt;(printf &quot;extendedKeyUsage=serverAuth\\nsubjectAltName=DNS:music.163.com,DNS:*.music.163.com&quot;) -sha256 -days 365 -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt[root@VM-4-6-centos netease-music]# lltotal 24-rw-r--r-- 1 root root 1245 Oct 21 09:28 ca.crt-rw------- 1 root root 1679 Oct 21 09:28 ca.key-rw-r--r-- 1 root root 41 Oct 21 09:29 ca.srl-rw-r--r-- 1 root root 1294 Oct 21 09:29 server.crt-rw-r--r-- 1 root root 1029 Oct 21 09:29 server.csr-rw------- 1 root root 1679 Oct 21 09:28 server.key 上述步骤完成后 将服务器私钥 (server.key) 和服务器证书 (server.crt) 拷贝到仓库中覆盖原有文件 (若使用 docker，可通过添加 -v /path/to/server.crt:/usr/src/app/server.crt -v /path/to/server.key:/usr/src/app/server.key 参数映射本地路径覆盖原有文件)，再将 CA 证书 (ca.crt) 安装到系统；如果不自行签发，直接安装仓库里的 CA 证书 (ca.crt) 即可 启动容器12345$ docker run -d -p 28080:8080 -p 28081:8081 \\ -v /data/docker_volumes/netease-music/server.crt:/usr/src/app/server.crt \\ -v /data/docker_volumes/netease-music/server.key:/usr/src/app/server.key \\ --name neteas-music \\ --restart always nondanee/unblockneteasemusic -p 8080:8081 客户端使用 注意：记得防火墙开放端口 28080 方法一：修改 hosts（不推荐）向 hosts 文件添加两条规则 12&lt;Server IP&gt; music.163.com&lt;Server IP&gt; interface.music.163.com 使用此方法必须监听 80 端口 -p 80 若在本机运行程序，请指定网易云服务器 IP -f xxx.xxx.xxx.xxx (可在修改 hosts 前通过 ping music.163.com 获得) 或 使用代理 -u http(s)://xxx.xxx.xxx.xxx:xxx，以防请求死循环 Android 客户端下修改 hosts 无法直接使用，原因和解决方法详见云音乐安卓又搞事啦，安卓免 root 绕过网易云音乐 IP 限制 方法二：设置代理（推荐）PAC 自动代理脚本地址 http://&lt;Server Name:PORT&gt;/proxy.pac 全局代理地址填写服务器地址和端口号即可 平台 基础设置 Windows 设置 &gt; 工具 &gt; 自定义代理 (客户端内) UWP Windows 设置 &gt; 网络和 Internet &gt; 代理 Linux 系统设置 &gt; 网络 &gt; 网络代理 macOS 系统偏好设置 &gt; 网络 &gt; 高级 &gt; 代理 Android WLAN &gt; 修改网络 &gt; 高级选项 &gt; 代理 iOS 无线局域网 &gt; HTTP 代理 &gt; 配置代理 代理工具和方法有很多请自行探索，欢迎在 评论处 讨论 方法三：调用接口（开发人员使用）作为依赖库使用 1$ npm install @nondanee/unblockneteasemusic 123456789101112131415const match = require('@nondanee/unblockneteasemusic')/** * Set proxy or hosts if needed */global.proxy = require('url').parse('http://127.0.0.1:1080')global.hosts = {'i.y.qq.com': '59.37.96.220'}/** * Find matching song from other platforms * @param {Number} id netease song id * @param {Array&lt;String&gt;||undefined} source support qq, xiami, baidu, kugou, kuwo, migu, joox * @return {Promise&lt;Object&gt;} */match(418602084, ['qq', 'kuwo', 'migu']).then(console.log) 效果Windows 客户端 UWP 客户端 Linux 客户端 macOS 客户端 Android 客户端 iOS 客户端 致谢UnblockNeteaseMusic 本次教程仅限于自己测试使用，禁止传播商业化使用，否则后果自负。","link":"/docker%E8%A7%A3%E9%94%81%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E6%89%80%E6%9C%89%E9%9F%B3%E4%B9%90/"},{"title":"open ldap 创建只读用户","text":"1.生成密码12[root@ldap01 opt]# slappasswd -s 123456{SSHA}abZPY3cWgMMtnNqtFyuX64xq7Mm0TNFd 2.创建 ldif 文件12345678[root@ldap01 opt]# cat test.ldifdn: cn=uservpn,dc=bufx,dc=gov,dc=cncn: uservpnsn: vpnuserPassword: {SSHA}abZPY3cWgMMtnNqtFyuX64xq7Mm0TNFdobjectClass: inetOrgPersonobjectClass: organizationalPerson[root@ldap01 opt]# 3.执行 ldif 文件1234[root@ldap01 opt]# ldapadd -x -D &quot;cn=admin,dc=bufx,dc=gov,dc=cn&quot; -W -f test.ldifEnter LDAP Password: admin的密码adding new entry &quot;cn=uservpn,dc=bufx,dc=gov,dc=cn&quot;[root@ldap01 opt]#","link":"/open-ldap-%E5%88%9B%E5%BB%BA%E5%8F%AA%E8%AF%BB%E7%94%A8%E6%88%B7/"},{"title":"oracle ACL 操作","text":"123456789101112131415161718192021222324252627282930313233begin dbms_network_acl_admin.create_acl ( -- 创建访问控制文件（CL） acl =&gt; 'httprequestpermission.xml', -- 文件名称 description =&gt; 'HTTP Access', -- 描述 principal =&gt; 'user', -- 授权或者取消授权账号，大小写敏感 is_grant =&gt; TRUE, -- 授权还是取消授权 privilege =&gt; 'connect', -- 授权或者取消授权的权限列表 start_date =&gt; null, -- 起始日期 end_date =&gt; null -- 结束日期 ); commit;end;begin dbms_network_acl_admin.add_privilege ( -- 添加访问权限列表项 acl =&gt; 'httprequestpermission.xml', -- 刚才创建的cl名称 principal =&gt; 'user', -- 授权或取消授权用户 is_grant =&gt; TRUE, -- 与上同 privilege =&gt; 'resolve', -- 权限列表 start_date =&gt; null, end_date =&gt; null ); commit;end;begin dbms_network_acl_admin.assign_acl ( -- 该段命令意思是允许访问cl名为tl_http.xml下授权的用户，使用racle网络访问包，所允许访问的目的主机，及其端口范围。 acl =&gt; 'httprequestpermission.xml', host =&gt; '127.0.0.1', -- ip地址或者域名，填写ttps://localhost:9000/hello与ttps://localhost:9000/是会报ost无效的 -- 且建议使用p地址或者使用域名，若用ocalhost，当racle不是安装在本机上的情况下，会出现问题 lower_port =&gt; 389, -- 允许访问的起始端口号 upper_port =&gt; Null -- 允许访问的截止端口号 ); commit;end;","link":"/oracle-ACL-%E6%93%8D%E4%BD%9C/"},{"title":"oracle 创建存储过程包（触发器同步用户到LDAP）","text":"1. 创建存储过程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433CREATE OR REPLACE PACKAGE BODY LDAP_SYNC_EAC IS MY_SESSION DBMS_LDAP.SESSION; -- session对象，用于事务处理 CONNECT_RETVAL PLS_INTEGER := -1; --用于接收异常代码 CLOSE_CONNECT_RETVAL PLS_INTEGER := -1; --用于接收异常代码 --查询未同步的人，00条一处理 /*CURSOR SELECT_DATA_TABLE(IDNUMBER VARCHAR2) IS SELECT S.ID_NUMBER, S.USER_PWD, S.MOBILE FROM SYS_UICM_USER S WHERE S.IS_ACTIVE = '1' AND S.ID_NUMBER = IDNUMBER AND ROWNUM &lt;= 500 ORDER BY S.ID_NUMBER ASC; REC_SELECT_DATA_TABLE SELECT_DATA_TABLE%ROWTYPE;*/ LDAP_BASE_ITT VARCHAR(256) := 'ou=people,dc=bufx,dc=edu,dc=cn'; --用户的根节点 ERR_MSG VARCHAR2(1000) := ''; --连接dap,生成ession FUNCTION CONNECT_LDAP RETURN PLS_INTEGER IS LDAP_HOST VARCHAR(256) := '127.0.0.1'; --LDAP服务器P地址 LDAP_PORT VARCHAR(256) := '389'; --LDAP服务器端口 LDAP_USER VARCHAR(256) := 'cn=admin,dc=bufx,dc=edu,dc=cn'; --管理员n; LDAP_PASSWD VARCHAR(256) := '123456'; --管理员密码 RETVAL PLS_INTEGER := -1; --用于接受异常代码 BEGIN DBMS_LDAP.USE_EXCEPTION := FALSE; --打开异常 MY_SESSION := DBMS_LDAP.INIT(LDAP_HOST, LDAP_PORT); --管理员登陆 RETVAL := DBMS_LDAP.SIMPLE_BIND_S(MY_SESSION, LDAP_USER, LDAP_PASSWD); RETURN RETVAL; END CONNECT_LDAP; FUNCTION INSERT_LDAP(IN_USER_ID VARCHAR2, IN_USER_PWD VARCHAR2, IN_USER_MOBILE VARCHAR2) RETURN PLS_INTEGER IS MOD_USER VARCHAR2(500); --需要操作的用户帐号 MY_ARRAY DBMS_LDAP.MOD_ARRAY; MY_VALS DBMS_LDAP.STRING_COLLECTION; RETVAL PLS_INTEGER := -1; --用于接受异常代码 LDAP_BASE_USE VARCHAR2(500); BEGIN LDAP_BASE_USE := LDAP_BASE_ITT; MOD_USER := 'cn=' || IN_USER_ID || ',' || LDAP_BASE_USE; MY_ARRAY := DBMS_LDAP.CREATE_MOD_ARRAY(20); MY_VALS(1) := IN_USER_ID; DBMS_LDAP.POPULATE_MOD_ARRAY(MY_ARRAY, DBMS_LDAP.MOD_ADD, 'cn', MY_VALS); MY_VALS(1) := IN_USER_ID; DBMS_LDAP.POPULATE_MOD_ARRAY(MY_ARRAY, DBMS_LDAP.MOD_ADD, 'sn', MY_VALS); MY_VALS(1) := PwdToLdap(IN_USER_PWD); DBMS_LDAP.POPULATE_MOD_ARRAY(MY_ARRAY, DBMS_LDAP.MOD_ADD, 'userPassword', MY_VALS); MY_VALS(1) := IN_USER_MOBILE; DBMS_LDAP.POPULATE_MOD_ARRAY(MY_ARRAY, DBMS_LDAP.MOD_ADD, 'mobile', MY_VALS); MY_VALS(1) := 'inetOrgPerson'; DBMS_LDAP.POPULATE_MOD_ARRAY(MY_ARRAY, DBMS_LDAP.MOD_ADD, 'objectClass', MY_VALS); /* my_vals(1) := 'organizationalPerson'; dbms_ldap.populate_mod_array(my_array, dbms_ldap.MOD_ADD, 'objectClass', my_vals);*/ --设置用户的dap对象类这个是在建立epole节点时scc设置的 --my_vals(1) := 'top'; --my_vals(2) := 'person'; --my_vals(3) := 'organizationalPerson'; --my_vals(4) := 'inetOrgPerson'; --my_vals(5) := 'dcpPerson'; /*my_vals(1) := 'inetOrgPerson'; dbms_ldap.populate_mod_array(my_array, dbms_ldap.MOD_ADD, 'objectclass', my_vals);*/ --添加操作 RETVAL := DBMS_LDAP.ADD_S(MY_SESSION, MOD_USER, MY_ARRAY); --retval如果返回8，代表已经存在此用户 --释放数组 DBMS_LDAP.FREE_MOD_ARRAY(MY_ARRAY); RETURN RETVAL; END INSERT_LDAP; FUNCTION DELETE_LDAP(IN_USER_ID VARCHAR2) RETURN PLS_INTEGER IS MOD_USER VARCHAR2(500); --需要操作的用户帐号 RETVAL PLS_INTEGER := -1; --用于接受异常代码 LDAP_BASE_USE VARCHAR2(500); BEGIN LDAP_BASE_USE := LDAP_BASE_ITT; MOD_USER := 'cn=' || IN_USER_ID || ',' || LDAP_BASE_USE; RETVAL := DBMS_LDAP.DELETE_S(MY_SESSION, MOD_USER); RETURN RETVAL; END DELETE_LDAP; FUNCTION UPDATE_LDAP(IN_USER_ID VARCHAR2, IN_USER_PWD VARCHAR2, IN_USER_MOBILE VARCHAR2) RETURN PLS_INTEGER IS MOD_USER VARCHAR2(500); --需要操作的用户帐号 MY_ARRAY DBMS_LDAP.MOD_ARRAY; MY_VALS DBMS_LDAP.STRING_COLLECTION; RETVAL PLS_INTEGER := -1; --用于接受异常代码 LDAP_BASE_USE VARCHAR2(500); BEGIN LDAP_BASE_USE := LDAP_BASE_ITT; MOD_USER := 'cn=' || IN_USER_ID || ',' || LDAP_BASE_USE; MY_ARRAY := DBMS_LDAP.CREATE_MOD_ARRAY(14); MY_VALS(1) := IN_USER_ID; DBMS_LDAP.POPULATE_MOD_ARRAY(MY_ARRAY, DBMS_LDAP.MOD_REPLACE, 'cn', MY_VALS); MY_VALS(1) := IN_USER_ID; DBMS_LDAP.POPULATE_MOD_ARRAY(MY_ARRAY, DBMS_LDAP.MOD_REPLACE, 'sn', MY_VALS); MY_VALS(1) := PwdToLdap(IN_USER_PWD); DBMS_LDAP.POPULATE_MOD_ARRAY(MY_ARRAY, DBMS_LDAP.MOD_REPLACE, 'userPassword', MY_VALS); MY_VALS(1) := IN_USER_MOBILE; DBMS_LDAP.POPULATE_MOD_ARRAY(MY_ARRAY, DBMS_LDAP.MOD_REPLACE, 'mobile', MY_VALS); --修改操作 RETVAL := DBMS_LDAP.MODIFY_S(MY_SESSION, MOD_USER, MY_ARRAY); --释放数组 DBMS_LDAP.FREE_MOD_ARRAY(MY_ARRAY); RETURN RETVAL; END UPDATE_LDAP; ---USER_ID 用户登录账号 ---USER_ACTIVE 是否有效 ---OP_TYPE 操作类型 PROCEDURE SYNC_PERSON(USER_ID VARCHAR2, USER_PWD VARCHAR2, USER_MOBILE VARCHAR2, OP_TYPE VARCHAR2) AS RETVAL PLS_INTEGER := -1; --用于接受异常代码 BEGIN --开始连接dap，生成ession，如果连接不成功，则退出程序 CONNECT_RETVAL := CONNECT_LDAP; --DBMS_OUTPUT.PUT_LINE('开始连接ldap'); IF CONNECT_RETVAL = 0 THEN IF OP_TYPE = 'INT' THEN RETVAL := INSERT_LDAP(USER_ID, USER_PWD, USER_MOBILE); ELSIF OP_TYPE = 'UPT' THEN RETVAL := UPDATE_LDAP(USER_ID, USER_PWD, USER_MOBILE); ELSIF OP_TYPE = 'DEL' THEN RETVAL := DELETE_LDAP(USER_ID); END IF; ELSE DBMS_OUTPUT.PUT_LINE('ldap连接失败); END IF; --关闭dap连接的ession CLOSE_CONNECT_RETVAL := DBMS_LDAP.UNBIND_S(MY_SESSION); EXCEPTION WHEN OTHERS THEN ERR_MSG := 'ERR:' || TO_CHAR(SQLCODE) || ' ' || SQLERRM; DBMS_OUTPUT.PUT_LINE('系统出错的日志为' || ERR_MSG); END SYNC_PERSON;/*PROCEDURE SYNC_PERSON(USER_ID VARCHAR2, OP_TYPE VARCHAR2) AS --记数器 I NUMBER := 0; RETVAL PLS_INTEGER := -1; --用于接受异常代码 BEGIN --开始读数据 IF SELECT_DATA_TABLE%ISOPEN THEN CLOSE SELECT_DATA_TABLE; END IF; OPEN SELECT_DATA_TABLE(USER_ID); LOOP FETCH SELECT_DATA_TABLE INTO REC_SELECT_DATA_TABLE; IF SELECT_DATA_TABLE%NOTFOUND THEN CLOSE SELECT_DATA_TABLE; EXIT; ELSE --首次读数据开始连接ldap，生成ession，如果连接不成功，则退出程序 IF I = 0 THEN CONNECT_RETVAL := CONNECT_LDAP; DBMS_OUTPUT.PUT_LINE('开始连接ldap'); END IF; IF CONNECT_RETVAL = 0 THEN DBMS_OUTPUT.PUT_LINE('开始进行业务操作 || I); IF OP_TYPE = 'INT' THEN RETVAL := INSERT_LDAP(REC_SELECT_DATA_TABLE); ELSIF OP_TYPE = 'UPT' THEN RETVAL := UPDATE_LDAP(REC_SELECT_DATA_TABLE); ELSIF OP_TYPE = 'DEL' THEN RETVAL := DELETE_LDAP(REC_SELECT_DATA_TABLE); END IF; ELSE DBMS_OUTPUT.PUT_LINE('ldap连接失败); EXIT; END IF; \\*sync_person_over(rec_select_data_table, retval);*\\ I := I + 1; END IF; END LOOP; IF I &gt; 0 THEN --关闭dap连接的ession CLOSE_CONNECT_RETVAL := DBMS_LDAP.UNBIND_S(MY_SESSION); END IF; EXCEPTION WHEN OTHERS THEN ERR_MSG := 'ERR:' || TO_CHAR(SQLCODE) || ' ' || SQLERRM; DBMS_OUTPUT.PUT_LINE('系统出错的日志为' || ERR_MSG); END SYNC_PERSON;*/END LDAP_SYNC_EAC; 2.创建存储过程（初始化用户到 LDAP）12345678910CREATE OR REPLACE PACKAGE LDAP_SYNC_EAC IS PROCEDURE SYNC_PERSON(USER_ID VARCHAR2, USER_PWD VARCHAR2, USER_MOBILE VARCHAR2, OP_TYPE VARCHAR2);END LDAP_SYNC_EAC; 3.添加触发器1234567891011121314151617181920212223242526272829303132333435363738394041create or replace trigger tr_sys_uicm_user_eac after insert or update or DELETEon sys_uicm_user FOR EACH ROWDECLARE --这里是关键的地方，在变量申明的地方，指定自定义事务处理。 PRAGMA AUTONOMOUS_TRANSACTION;BEGIN IF INSERTING THEN --INSERT触发 --启用插入DAP IF :NEW.IS_ACTIVE = '1' THEN LDAP_SYNC_EAC.SYNC_PERSON(:NEW.ID_NUMBER, :NEW.USER_PWD, :NEW.MOBILE, 'INT'); END IF; ELSIF UPDATING THEN --UPDATE触发 IF :NEW.IS_ACTIVE = '1' AND :NEW.IS_DEL = '0' THEN IF :OLD.IS_ACTIVE = '1' AND :OLD.IS_DEL = '0' THEN LDAP_SYNC_EAC.SYNC_PERSON(:NEW.ID_NUMBER, :NEW.USER_PWD, :NEW.MOBILE, 'UPT'); ELSE LDAP_SYNC_EAC.SYNC_PERSON(:NEW.ID_NUMBER, :NEW.USER_PWD, :NEW.MOBILE, 'INT'); END IF; ELSE LDAP_SYNC_EAC.SYNC_PERSON(:NEW.ID_NUMBER, '', '', 'DEL'); END IF; ELSIF DELETING THEN --DELETE触发 LDAP_SYNC_EAC.SYNC_PERSON(:OLD.ID_NUMBER,'','', 'DEL'); END IF;END;","link":"/oracle-%E5%88%9B%E5%BB%BA%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E5%8C%85%EF%BC%88%E8%A7%A6%E5%8F%91%E5%99%A8%E5%90%8C%E6%AD%A5%E7%94%A8%E6%88%B7%E5%88%B0LDAP%EF%BC%89/"},{"title":"oracle 存储过程执行java进行密码加密成LDAP方式","text":"步骤1.先写 java1234567891011121314151617181920212223242526import sun.misc.BASE64Encoder;public class PwdToLdap { public static String ldapSHA(String pwd) { byte[] md = hexStringTobyteArray(pwd); return &quot;{SHA}&quot; + (new BASE64Encoder()).encode(md); } public static byte[] hexStringTobyteArray(String str) { if(str == null || str.trim().equals(&quot;&quot;)) { return new byte[0]; } byte[] bytes = new byte[str.length() / 2]; for(int i = 0; i &lt; str.length() / 2; i++) { String subStr = str.substring(i * 2, i * 2 + 2); bytes[i] = (byte) Integer.parseInt(subStr, 16); } return bytes; }} 2.把相关包拷贝到当前目录下（rt.jar）3.查询 oracle 的 jdk 版本123456CREATE OR REPLACE FUNCTION get_java_property (prop IN VARCHAR2)RETURN VARCHAR2 IS LANGUAGE JAVAname 'java.lang.System.getProperty(java.lang.String) return java.lang.String';SELECT get_java_property('java.version') FROM dual; 4.javac 执行编译（要用 oracle 自带的 jdk，因为版本不一致的话 loadjava 报错）12D:\\app\\oracle\\Administrator\\product\\11.2.0\\dbhome_1\\jdk\\bin&gt;javac -classpath F:\\bufx\\rt.jar F:\\bufx\\PwdToLdap.java 5.loadjava 导入到 oracle 中1F:\\bufx&gt;loadjava -r -f -u sys/123456@192.168.2.110:1521/orcl -v PwdToLdap.class 6.sql 查询是否存在 Java1SELECT * FROM USER_OBJECTS WHERE OBJECT_TYPE ='JAVA CLASS'order by created desc; 7.写存储过程1CREATE OR REPLACE FUNCTION PwdToLdap(str in varchar2) RETURN VARCHAR2 AS LANGUAGE JAVA NAME 'PwdToLdap.ldapSHA (java.lang.String) return java.lang.String'; 8.执行存储过程（两种方法）8.1 直接查询1SELECT PwdToLdap('18dacbf7db89381473a754b4d76b0c3f03749ecc') FROM dual; 8.2 sqlplus 执行123456789101112131415SQL&gt; VARIABLE myString VARCHAR2(20);SQL&gt; CALL PwdToLdap('18dacbf7db89381473a754b4d76b0c3f03749ecc') INTO :myString;Method calledmyString---------{SHA}GNrL99uJOBRzp1S012sMPwN0nsw=SQL&gt; PRINT myString;myString---------{SHA}GNrL99uJOBRzp1S012sMPwN0nsw=SQL&gt; 9.删除 java 类1dropjava -u sys/123456@192.168.2.110:1521/orcl -v -resolve PwdToLdap.class","link":"/oracle-%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E6%89%A7%E8%A1%8Cjava%E8%BF%9B%E8%A1%8C%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86%E6%88%90LDAP%E6%96%B9%E5%BC%8F/"},{"title":"oracle 存储过程执行java进行密码加密成LDAP方式2","text":"步骤1.先写 java1234567891011121314151617181920212223242526import sun.misc.BASE64Encoder;public class PwdToLdap { public static String ldapSHA(String pwd) { byte[] md = hexStringTobyteArray(pwd); return &quot;{SHA}&quot; + (new BASE64Encoder()).encode(md); } public static byte[] hexStringTobyteArray(String str) { if(str == null || str.trim().equals(&quot;&quot;)) { return new byte[0]; } byte[] bytes = new byte[str.length() / 2]; for(int i = 0; i &lt; str.length() / 2; i++) { String subStr = str.substring(i * 2, i * 2 + 2); bytes[i] = (byte) Integer.parseInt(subStr, 16); } return bytes; }} 2.把相关包拷贝到当前目录下（rt.jar）3.查询 oracle 的 jdk 版本123456CREATE OR REPLACE FUNCTION get_java_property (prop IN VARCHAR2)RETURN VARCHAR2 IS LANGUAGE JAVAname 'java.lang.System.getProperty(java.lang.String) return java.lang.String';SELECT get_java_property('java.version') FROM dual; 4.loadjava 导入到 oracle 中1F:\\bufx&gt;loadjava -r -f -u sys/123456@192.168.2.110:1521/orcl -v PwdToLdap.java 5.sql 查询是否存在 Java1SELECT * FROM USER_OBJECTS WHERE OBJECT_TYPE ='JAVA CLASS'order by created desc; 6.写存储过程1CREATE OR REPLACE FUNCTION PwdToLdap(str in varchar2) RETURN VARCHAR2 AS LANGUAGE JAVA NAME 'PwdToLdap.ldapSHA (java.lang.String) return java.lang.String'; 7.执行存储过程（两种方法）7.1 直接查询1SELECT PwdToLdap('18dacbf7db89381473a754b4d76b0c3f03749ecc') FROM dual; 7.2 sqlplus 执行123456789101112131415SQL&gt; VARIABLE myString VARCHAR2(20);SQL&gt; CALL PwdToLdap('18dacbf7db89381473a754b4d76b0c3f03749ecc') INTO :myString;Method calledmyString---------{SHA}GNrL99uJOBRzp1S012sMPwN0nsw=SQL&gt; PRINT myString;myString---------{SHA}GNrL99uJOBRzp1S012sMPwN0nsw=SQL&gt; 9.删除 java 类1dropjava -u sys/123456@192.168.2.110:1521/orcl -v -resolve PwdToLdap.class","link":"/oracle-%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E6%89%A7%E8%A1%8Cjava%E8%BF%9B%E8%A1%8C%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86%E6%88%90LDAP%E6%96%B9%E5%BC%8F2/"},{"title":"oracle创建表空间和用户","text":"创建表空间1create tablespace tp datafile '/opt/app/oracle/oradata/orcl/orclpdb/tp.dbf' size 200 m autoextend on next 10 m maxsize unlimited ; 创建用户和赋予相关权限123456789101112131415161718192021222324252627282930313233-- Create the usercreate user 用户名default tablespace TPtemporary tablespace TEMPidentified by 密码profile DEFAULT;-- Grant/Revoke role privilegesgrant connect to 用户名;-- grant dba to 用户名;grant resource to 用户名;-- Grant/Revoke system privilegesgrant create session to 用户名;grant delete any table to 用户名;grant execute any class to 用户名;grant execute any procedure to 用户名;grant insert any table to 用户名;grant select any dictionary to 用户名;grant select any sequence to 用户名;grant select any table to 用户名;grant select any transaction to 用户名;grant under any table to 用户名;grant under any type to 用户名;grant under any view to 用户名;grant unlimited tablespace to 用户名;grant update any table to 用户名;GRANT IMP_FULL_DATABASE to 用户名;GRANT EXP_FULL_DATABASE to 用户名;grant create any table to 用户名;grant drop any table to 用户名;GRANT debug any procedure, debug connect session TO 用户名;","link":"/oracle%E5%88%9B%E5%BB%BA%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%92%8C%E7%94%A8%E6%88%B7/"},{"title":"oracle数据库导入导出cmd命令","text":"先切换为 oracle 用户 1su - oracle 1.导出 如果是 plsql developer 导出，需要先执行下面语句，让空表可以导出： 1select 'alter table '||table_name||' allocate extent;' from user_tables where num_rows=0; 如果是命令 dmp 的导出 1exp 用户/密码@127.0.0.1:1521/orcl file=/opt/data_bak/用户.dmp owner=用户1,用户2 tables=\\(table1,table2\\) 2.导入1imp 用户/密码@127.0.0.1:1521/shec file=/opt/data_bak/用户.dmp ignore=y full=y fromuser=用户1,用户2 tables=(table1)","link":"/oracle%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BAcmd%E5%91%BD%E4%BB%A4/"},{"title":"seata AT模式方案解决分布式事务问题","text":"seata主推的是AT模式强一致性解决方案，所以我们采用这个方案来解决前面案例的分布式问题。 下载和运行seata serverseata server地址：https://github.com/seata/seata/releases 最新版本 v1.4.2 用macOS或者Linux的下载：seata-server-1.4.2.tar.gz 用windows的下载seata-server-1.4.2.zip 编辑seata-server配置文件seata server所有的配置都在conf文件夹内，该文件夹内有两个文件我们必须要详细介绍下。 seata server默认使用file（文件方式）进行存储事务日志、事务运行信息，我们可以通过-m db脚本参 数的形式来指定，目前仅支持file、db这两种方式。 file.conf 该文件用于配置存储方式、透传事务信息的NIO等信息，默认对应registry.conf文件内的file方式配置。 registry.conf seata server核心配置文件，可以通过该文件配置服务注册方式、配置读取方式。 注册方式目前支持file 、nacos 、eureka、redis、zk、consul、etcd3、sofa等方式，默认为file，对应读取file.conf内的注册方式信息。 读取配置信息的方式支持file、nacos 、apollo、zk、consul、etcd3等方式，默认为file，对应读取file.conf文件内的配置。 file.conf 加一个service 配置： 12345678910111213service { #vgroup-&gt;rgroup 服务分组 集群分组默认为&quot;default&quot; vgroupMapping.my_test_tx_group = &quot;default&quot; #only support single node default.grouplist = &quot;127.0.0.1:8091&quot; #degrade current not support 服务降级达到多次错误不走seata enableDegrade = false #disable disable = false #unit ms,s,m,h,d represents milliseconds, seconds, minutes, hours, days,default permanent max.commit.retry.timeout = &quot;-1&quot; max.rollback.retry.timeout = &quot;-1&quot;} 这里事务分组概念，另外单独讲，主要是为了集群故障的时候，能快速切换，实现高可用； 配置分组映射，集群分组再配置grouplist，暴露server地址，提供给seata-client调用； 最后运行bin目录下的seata-server.sh启动seata-server，启动OK，监听端口8091 每个数据库都建一个undo_log回滚日志表根据seata AT模式规范，我们新建undo_log表，db_account和db_order都要建; 12345678910111213CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `context` varchar(128) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, `ext` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 项目里添加seata-client maven依赖我们只需要在seata-common公共模块项目里添加seata依赖，其他子模块都有了，方便； 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt;&lt;/dependency&gt; 项目里配置seata分布式事务首先是每个项目都要配置seata支持，请求seata-server，根据配置； 再通过@GlobalTransactional注解，开启全局分布式事务； 修改配置文件seata-order子项目 application.yml配置改下，主要多了服务分组和集群分组的配置： seata-order/application.yml123456789101112131415161718192021222324252627282930313233server: port: 8081 servlet: context-path: /mybatis: mapper-locations: classpath:mybatis/mapper/*.xmlspring: application: name: seata-order datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/db_order?serverTimezone=Asia/Shanghai username: root password: root cloud: nacos: discovery: server-addr: 127.0.0.1:8848 alibaba: seata: tx-service-group: my_test_tx_groupseata: service: vgroup-mapping: my_test_tx_group: default grouplist: default: 127.0.0.1:8091 enable-degrade: false disable-global-transaction: false 同理，seata-account下的application.yml配置： seata-account/application.yml1234567891011121314151617181920212223242526272829303132server: port: 8082 servlet: context-path: /mybatis: mapper-locations: classpath:mybatis/mapper/*.xmlspring: application: name: seata-account datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/db_order?serverTimezone=Asia/Shanghai username: root password: root cloud: nacos: discovery: server-addr: 127.0.0.1:8848 alibaba: seata: tx-service-group: my_test_tx_groupseata: service: vgroup-mapping: my_test_tx_group: default grouplist: default: 127.0.0.1:8091 enable-degrade: false disable-global-transaction: false seata-web下的application.yml配置： seata-web/application.yml1234567891011121314151617181920212223server: port: 80 servlet: context-path: /spring: application: name: seata-web cloud: nacos: discovery: server-addr: 127.0.0.1:8848 alibaba: seata: tx-service-group: my_test_tx_groupseata: service: vgroup-mapping: my_test_tx_group: default grouplist: default: 127.0.0.1:8091 enable-degrade: false disable-global-transaction: false 添加@GlobalTransactional注解seata-web项目-&gt;WebController-&gt;shopping方法，添加@GlobalTransactional注解 分布式案例测试三个子项目一起运行； seata-server日志显示：两个RM在seata-server注册成功； seata-web项目的RM，TM注册成功： seata-order项目的TM注册成功： seata-account项目的TM注册成功： setata二阶段提交过程剖析因为是执行是一瞬间的，很多人根本无法感受到内部的二阶段提交过程。 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。 二阶段： 提交异步化，非常快速地完成。 回滚通过一阶段的回滚日志进行反向补偿。 所以我们在再seata-account项目里搞个断点，来看下回滚的一个流程； seata-account项目debug启动； 再次postman测试，我们立刻查看db_order数据库表信息（比较难捕获，因为提交事务超时就立刻回滚，看不到信息） 订单服务执行完的时候，db_order有数据 undo_log也有数据 说明一阶段业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。 然后： 如果提交事务超时或者有接口调用异常，则分支事务立刻根据回滚日志，立刻进行反向补偿，最后回滚日志会被清空； 如果接口调用一切正常，日志清空，全局事务提交，完成本次事务操作；","link":"/seata-AT%E6%A8%A1%E5%BC%8F%E6%96%B9%E6%A1%88%E8%A7%A3%E5%86%B3%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E9%97%AE%E9%A2%98/"},{"title":"seata事务分组","text":"事务分组是什么？事务分组是seata的资源逻辑，类似于服务实例。在file.conf中的my_test_tx_group就是一个事务分组。 通过事务分组如何找到后端集群？ 首先程序中配置了事务分组（GlobalTransactionScanner 构造方法的txServiceGroup参数） 程序会通过用户配置的配置中心去寻找service.vgroupMapping .[事务分组配置项]，取得配置项的值就是TC集群的名称 拿到集群名称程序通过一定的前后缀+集群名称去构造服务名，各配置中心的服务名实现不同 拿到服务名去相应的注册中心去拉取相应服务名的服务列表，获得后端真实的TC服务列表 为什么这么设计，不直接取服务名？这里多了一层获取事务分组到映射集群的配置。这样设计后，事务分组可以作为资源的逻辑隔离单位，出现某集群故障时可以快速failover，只切换对应分组，可以把故障缩减到服务级别，但前提也是你有足够server集群。 事务分组使用案例seata注册、配置中心分为两类，内置file、第三方注册（配置）中心如nacos等等，注册中心和配置中心之间没有约束，可各自使用不同类型。 file注册中心和配置中心Server端registry.conf1234567891011registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = &quot;file&quot; ---------------&gt; 使用file作为注册中心}config { # file、nacos 、apollo、zk、consul、etcd3 type = &quot;file&quot; ---------------&gt; 使用file作为配置中心 file { name = &quot;file.conf&quot; }} file、db模式启动server，见文章上方节点：启动Server Client端1234567891011121314151617registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = &quot;file&quot; ---------------&gt; 使用file作为注册中心}config { # file、nacos 、apollo、zk、consul、etcd3 type = &quot;file&quot; ---------------&gt; 使用file作为配置中心 file { name = &quot;file.conf&quot; ---------------&gt; 配置参数存储文件 }}spring.cloud.alibaba.seata.tx-service-group=my_test_tx_group ---------------&gt; 事务分组配置file.conf: service { vgroupMapping.my_test_tx_group = &quot;default&quot; default.grouplist = &quot;127.0.0.1:8091&quot; } 读取配置 通过FileConfiguration本地加载file.conf的配置参数 获取事务分组 spring配置，springboot可配置在yml、properties中，服务启动时加载配置，对应的值”my_test_tx_group”即为一个事务分组名，若不配置，默认获取属性spring.application.name的值+”-fescar-service-group” 查找TC集群名 拿到事务分组名”my_test_tx_group”拼接成”service.vgroupMapping.my_test_tx_group”查找TC集群名clusterName为”default” 查询TC服务 拼接”service.”+clusterName+”.grouplist”找到真实TC服务地址127.0.0.1:8091 nacos注册中心和配置中心Server端registry.conf123456789101112131415161718registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = &quot;nacos&quot; ---------------&gt; 使用nacos作为注册中心 nacos { serverAddr = &quot;localhost&quot; ---------------&gt; nacos注册中心所在ip namespace = &quot;&quot; ---------------&gt; nacos命名空间id，&quot;&quot;为nacos保留public空间控件，用户勿配置namespace = &quot;public&quot; cluster = &quot;default&quot; ---------------&gt; seata-server在nacos的集群名 }}config { # file、nacos 、apollo、zk、consul、etcd3 type = &quot;nacos&quot; ---------------&gt; 使用nacos作为配置中心 nacos { serverAddr = &quot;localhost&quot; namespace = &quot;&quot; cluster = &quot;default&quot; }} 脚本 script–&gt;config-center下的3个文件nacos-config.py、nacos-config.sh、config.txttxt为参数明细（包含Server和Client），sh为linux脚本，windows可下载git来操作，py为python脚本。 导入配置 用命令执行脚本导入seata配置参数至nacos，在nacos控制台查看配置确认是否成功 注册TC 启动seata-server注册至nacos，查看nacos控制台服务列表确认是否成功 Client端1234567891011121314151617spring.cloud.alibaba.seata.tx-service-group=my_test_tx_group ---------------&gt; 事务分组配置registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = &quot;nacos&quot; ---------------&gt; 从nacos获取TC服务 nacos { serverAddr = &quot;localhost&quot; namespace = &quot;&quot; }}config { # file、nacos 、apollo、zk、consul、etcd3 type = &quot;nacos&quot; ---------------&gt; 使用nacos作为配置中心 nacos { serverAddr = &quot;localhost&quot; namespace = &quot;&quot; }} 读取配置 通过NacosConfiguration远程读取seata配置参数 获取事务分组 springboot可配置在yml、properties中，服务启动时加载配置，对应的值”my_test_tx_group”即为一个事务分组名，若不配置，默认获取属性spring.application.name的值+”-fescar-service-group” 查找TC集群名 拿到事务分组名”my_test_tx_group”拼接成”service.vgroupMapping.my_test_tx_group”从配置中心查找到TC集群名clusterName为”default” 查找TC服务 根据serverAddr和namespace以及clusterName在注册中心找到真实TC服务列表 注：serverAddr和namespace与Server端一致，clusterName与Server端cluster一致","link":"/seata%E4%BA%8B%E5%8A%A1%E5%88%86%E7%BB%84/"},{"title":"seata事务日志mysql持久化配置","text":"seata默认事务支持是file文件存储，不怎么好，不方便查看和管理；所以我们一般是db存储； 修改配置文件修改conf下的file.conf配置文件 把mode改成”db”， 下方mysql配置改成你们对应的配置即可，数据库要自己先建立，比如我这边定义是db_seata 还有三个表，global_table，branch_table，lock_table分别是全局事务会话表，分支事务会话表，锁数据表； 建数据库和表结构建表语句获取：db.sql mysql.sql1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556-- -------------------------------- The script used when storeMode is 'db' ---------------------------------- the table to store GlobalSession dataCREATE TABLE IF NOT EXISTS `global_table`( `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `status` TINYINT NOT NULL, `application_id` VARCHAR(32), `transaction_service_group` VARCHAR(32), `transaction_name` VARCHAR(128), `timeout` INT, `begin_time` BIGINT, `application_data` VARCHAR(2000), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`xid`), KEY `idx_gmt_modified_status` (`gmt_modified`, `status`), KEY `idx_transaction_id` (`transaction_id`)) ENGINE = InnoDB DEFAULT CHARSET = utf8;-- the table to store BranchSession dataCREATE TABLE IF NOT EXISTS `branch_table`( `branch_id` BIGINT NOT NULL, `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `resource_group_id` VARCHAR(32), `resource_id` VARCHAR(256), `branch_type` VARCHAR(8), `status` TINYINT, `client_id` VARCHAR(64), `application_data` VARCHAR(2000), `gmt_create` DATETIME(6), `gmt_modified` DATETIME(6), PRIMARY KEY (`branch_id`), KEY `idx_xid` (`xid`)) ENGINE = InnoDB DEFAULT CHARSET = utf8;-- the table to store lock dataCREATE TABLE IF NOT EXISTS `lock_table`( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(96), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_branch_id` (`branch_id`)) ENGINE = InnoDB DEFAULT CHARSET = utf8; 因为都是临时数据，最终提交事务会被清理，我们要看数据的话，还是需要服务代码里打断点，debug 进行捕获； 下面这个是捕获到的一个数据；","link":"/seata%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97mysql%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE/"},{"title":"seata原理详解","text":"Seata 是什么?Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。 Seata术语 TC (Transaction Coordinator) - 事务协调者 维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器 定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器 管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 Seata管理分布式事务的典型生命周期 TM要求TC开始新的全局事务。 TC生成表示全局事务的XID。 XID通过微服务的调用链传播。 RM将本地事务注册为XID到TC的相应全局事务的分支。 TM要求TC提交或回滚XID的相应全局事务。 TC在XID的相应全局事务下驱动所有分支事务，以完成分支提交或回滚。 分布式事务是由一批分支事务组成的全局事务，通常分支事务就是本地事务。 AT 模式前提 基于支持本地 ACID 事务的关系型数据库。 Java 应用，通过 JDBC 访问数据库。 整体机制两阶段提交协议的演变： 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。 二阶段： 提交异步化，非常快速地完成。 回滚通过一阶段的回滚日志进行反向补偿。 写隔离 一阶段本地事务提交前，需要确保先拿到 全局锁 。 拿不到 全局锁 ，不能提交本地事务。 拿 全局锁 的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁。 以一个示例来说明： 两个全局事务 tx1 和 tx2，分别对 a 表的 m 字段进行更新操作，m 的初始值 1000。 tx1 先开始，开启本地事务，拿到本地锁，更新操作 m = 1000 - 100 = 900。本地事务提交前，先拿到该记录的 全局锁 ，本地提交释放本地锁。 tx2 后开始，开启本地事务，拿到本地锁，更新操作 m = 900 - 100 = 800。本地事务提交前，尝试拿该记录的 全局锁 ，tx1 全局提交前，该记录的全局锁被 tx1 持有，tx2 需要重试等待 全局锁 。 tx1 二阶段全局提交，释放 全局锁 。tx2 拿到 全局锁 提交本地事务。 如果 tx1 的二阶段全局回滚，则 tx1 需要重新获取该数据的本地锁，进行反向补偿的更新操作，实现分支的回滚。 此时，如果 tx2 仍在等待该数据的 全局锁，同时持有本地锁，则 tx1 的分支回滚会失败。分支的回滚会一直重试，直到 tx2 的 全局锁 等锁超时，放弃 全局锁 并回滚本地事务释放本地锁，tx1 的分支回滚最终成功。 因为整个过程 全局锁 在 tx1 结束前一直是被 tx1 持有的，所以不会发生 脏写 的问题。 读隔离在数据库本地事务隔离级别 读已提交（Read Committed） 或以上的基础上，Seata（AT 模式）的默认全局隔离级别是 读未提交（Read Uncommitted） 。 如果应用在特定场景下，必需要求全局的 读已提交 ，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。 SELECT FOR UPDATE 语句的执行会申请 全局锁 ，如果 全局锁 被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到 全局锁 拿到，即读取的相关数据是 已提交 的，才返回。 出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。 工作机制以一个示例来说明整个 AT 分支的工作过程。 业务表：product Field Type Key id bigint(20) PRI name varchar(100) since varchar(100) AT 分支事务的业务逻辑： 1update product set name = 'GTS' where name = 'TXC'; 一阶段过程： 解析 SQL：得到 SQL 的类型（UPDATE），表（product），条件（where name = ‘TXC’）等相关的信息。 查询前镜像：根据解析得到的条件信息，生成查询语句，定位数据。 1select id, name, since from product where name = 'TXC'; 得到前镜像： id name since 1 TXC 2014 执行业务 SQL：更新这条记录的 name 为 ‘GTS’。 查询后镜像：根据前镜像的结果，通过 主键 定位数据。 1select id, name, since from product where id = 1`; 得到后镜像： id name since 1 GTS 2014 插入回滚日志：把前后镜像数据以及业务 SQL 相关的信息组成一条回滚日志记录，插入到 UNDO_LOG 表中。 12345678910111213141516171819202122232425262728293031323334353637383940414243{ &quot;branchId&quot;: 641789253, &quot;undoItems&quot;: [{ &quot;afterImage&quot;: { &quot;rows&quot;: [{ &quot;fields&quot;: [{ &quot;name&quot;: &quot;id&quot;, &quot;type&quot;: 4, &quot;value&quot;: 1 }, { &quot;name&quot;: &quot;name&quot;, &quot;type&quot;: 12, &quot;value&quot;: &quot;GTS&quot; }, { &quot;name&quot;: &quot;since&quot;, &quot;type&quot;: 12, &quot;value&quot;: &quot;2014&quot; }] }], &quot;tableName&quot;: &quot;product&quot; }, &quot;beforeImage&quot;: { &quot;rows&quot;: [{ &quot;fields&quot;: [{ &quot;name&quot;: &quot;id&quot;, &quot;type&quot;: 4, &quot;value&quot;: 1 }, { &quot;name&quot;: &quot;name&quot;, &quot;type&quot;: 12, &quot;value&quot;: &quot;TXC&quot; }, { &quot;name&quot;: &quot;since&quot;, &quot;type&quot;: 12, &quot;value&quot;: &quot;2014&quot; }] }], &quot;tableName&quot;: &quot;product&quot; }, &quot;sqlType&quot;: &quot;UPDATE&quot; }], &quot;xid&quot;: &quot;xid:xxx&quot;} 提交前，向 TC 注册分支：申请 product 表中，主键值等于 1 的记录的 全局锁 。 本地事务提交：业务数据的更新和前面步骤中生成的 UNDO LOG 一并提交。 将本地事务提交的结果上报给 TC。 二阶段-回滚 收到 TC 的分支回滚请求，开启一个本地事务，执行如下操作。 通过 XID 和 Branch ID 查找到相应的 UNDO LOG 记录。 数据校验：拿 UNDO LOG 中的后镜与当前数据进行比较，如果有不同，说明数据被当前全局事务之外的动作做了修改。这种情况，需要根据配置策略来做处理，详细的说明在另外的文档中介绍。 根据 UNDO LOG 中的前镜像和业务 SQL 的相关信息生成并执行回滚的语句： 1update product set name = 'TXC' where id = 1; 提交本地事务。并把本地事务的执行结果（即分支事务回滚的结果）上报给 TC。 二阶段-提交 收到 TC 的分支提交请求，把请求放入一个异步任务的队列中，马上返回提交成功的结果给 TC。 异步任务阶段的分支提交请求将异步和批量地删除相应 UNDO LOG 记录。 附录回滚日志表UNDO_LOG Table：不同数据库在类型上会略有差别。 以 MySQL 为例： Field Type branch_id bigint PK xid varchar(100) context varchar(128) rollback_info longblob log_status tinyint log_created datetime log_modified datetime 12345678910111213-- 注意此处0.7.0+ 增加字段 contextCREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `context` varchar(128) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; TCC 模式回顾总览中的描述：一个分布式的全局事务，整体是 两阶段提交 的模型。全局事务是由若干分支事务组成的，分支事务要满足 两阶段提交 的模型要求，即需要每个分支事务都具备自己的： 一阶段 prepare 行为 二阶段 commit 或 rollback 行为 根据两阶段行为模式的不同，我们将分支事务划分为 Automatic (Branch) Transaction Mode 和 TCC (Branch) Transaction Mode. AT 模式（参考链接 TBD）基于 支持本地 ACID 事务 的 关系型数据库： 一阶段 prepare 行为：在本地事务中，一并提交业务数据更新和相应回滚日志记录。 二阶段 commit 行为：马上成功结束，自动 异步批量清理回滚日志。 二阶段 rollback 行为：通过回滚日志，自动 生成补偿操作，完成数据回滚。 相应的，TCC 模式，不依赖于底层数据资源的事务支持： 一阶段 prepare 行为：调用 自定义 的 prepare 逻辑。 二阶段 commit 行为：调用 自定义 的 commit 逻辑。 二阶段 rollback 行为：调用 自定义 的 rollback 逻辑。 所谓 TCC 模式，是指支持把 自定义 的分支事务纳入到全局事务的管理中。 Saga 模式概述Saga模式是SEATA提供的长事务解决方案，在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者，一阶段正向服务和二阶段补偿服务都由业务开发实现。 理论基础：Hector &amp; Kenneth 发表论⽂ Sagas （1987） 适用场景： 业务流程长、业务流程多 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口 优势： 一阶段提交本地事务，无锁，高性能 事件驱动架构，参与者可异步执行，高吞吐 补偿服务易于实现 缺点： 不保证隔离性（应对方案见后面文档） XA 模式前提 支持XA 事务的数据库。 Java 应用，通过 JDBC 访问数据库。 整体机制在 Seata 定义的分布式事务框架内，利用事务资源（数据库、消息服务等）对 XA 协议的支持，以 XA 协议的机制来管理分支事务的一种 事务模式。 执行阶段： 可回滚：业务 SQL 操作放在 XA 分支中进行，由资源对 XA 协议的支持来保证 可回滚 持久化：XA 分支完成后，执行 XA prepare，同样，由资源对 XA 协议的支持来保证 持久化（即，之后任何意外都不会造成无法回滚的情况） 完成阶段： 分支提交：执行 XA 分支的 commit 分支回滚：执行 XA 分支的 rollback 工作机制整体运行机制XA 模式 运行在 Seata 定义的事务框架内： 执行阶段（E xecute）： XA start/XA end/XA prepare + SQL + 注册分支 完成阶段（F inish）： XA commit/XA rollback 数据源代理XA 模式需要 XAConnection。 获取 XAConnection 两种方式： 方式一：要求开发者配置 XADataSource 方式二：根据开发者的普通 DataSource 来创建 第一种方式，给开发者增加了认知负担，需要为 XA 模式专门去学习和使用 XA 数据源，与 透明化 XA 编程模型的设计目标相违背。 第二种方式，对开发者比较友好，和 AT 模式使用一样，开发者完全不必关心 XA 层面的任何问题，保持本地编程模型即可。 我们优先设计实现第二种方式：数据源代理根据普通数据源中获取的普通 JDBC 连接创建出相应的 XAConnection。 类比 AT 模式的数据源代理机制，如下： 但是，第二种方法有局限：无法保证兼容的正确性。 实际上，这种方法是在做数据库驱动程序要做的事情。不同的厂商、不同版本的数据库驱动实现机制是厂商私有的，我们只能保证在充分测试过的驱动程序上是正确的，开发者使用的驱动程序版本差异很可能造成机制的失效。 这点在 Oracle 上体现非常明显。参见 Druid issue：https://github.com/alibaba/druid/issues/3707 综合考虑，XA 模式的数据源代理设计需要同时支持第一种方式：基于 XA 数据源进行代理。 类比 AT 模式的数据源代理机制，如下： 分支注册XA start 需要 Xid 参数。 这个 Xid 需要和 Seata 全局事务的 XID 和 BranchId 关联起来，以便由 TC 驱动 XA 分支的提交或回滚。 目前 Seata 的 BranchId 是在分支注册过程，由 TC 统一生成的，所以 XA 模式分支注册的时机需要在 XA start 之前。 将来一个可能的优化方向： 把分支注册尽量延后。类似 AT 模式在本地事务提交之前才注册分支，避免分支执行失败情况下，没有意义的分支注册。 这个优化方向需要 BranchId 生成机制的变化来配合。BranchId 不通过分支注册过程生成，而是生成后再带着 BranchId 去注册分支。 XA 模式的使用从编程模型上，XA 模式与 AT 模式保持完全一致。 可以参考 Seata 官网的样例：seata-xa 样例场景是 Seata 经典的，涉及库存、订单、账户 3 个微服务的商品订购业务。 在样例中，上层编程模型与 AT 模式完全相同。只需要修改数据源代理，即可实现 XA 模式与 AT 模式之间的切换。 12345678@Bean(&quot;dataSource&quot;)public DataSource dataSource(DruidDataSource druidDataSource) { // DataSourceProxy for AT mode // return new DataSourceProxy(druidDataSource); // DataSourceProxyXA for XA mode return new DataSourceProxyXA(druidDataSource);}","link":"/seata%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/"},{"title":"seata支持nacos注册中心和配置中心","text":"Seata支持注册服务到Nacos，以及支持Seata所有配置放到Nacos配置中心，在Nacos中统一维护； 具体步骤如下： 项目里添加nacos-client依赖只需要在seata-common公共模块项目里添加maven依赖，其他子模块都有了，方便； pom.xml1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt;&lt;/dependency&gt; 集成Nacos注册中心seata的TM和RM修改配置seata-order/seata-account/seata-web子项目 application.yml配置改下，主要修改服务分组和集群分组的配置： 把： application.yml12345678seata: service: vgroup-mapping: my_test_tx_group: default grouplist: default: 127.0.0.1:8091 enable-degrade: false disable-global-transaction: false 改为： application.yml1234567891011seata: registry: type: nacos nacos: application: seata-server #seata-server端注册到nacos上到名称 server-addr: 127.0.0.1:8848 group: &quot;SEATA_GROUP&quot; namespace: &quot;9961be45-128a-4e89-a16b-646131fb2c3a&quot; username: &quot;&quot; password: &quot;&quot; cluster: &quot;default&quot; seata-server端修改配置在registry.conf中修改registry-type为nacos，并且修改相应的nacos信息 registry.conf1234567891011121314registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = &quot;nacos&quot; nacos { application = &quot;seata-server&quot; serverAddr = &quot;127.0.0.1:8848&quot; group = &quot;SEATA_GROUP&quot; namespace = &quot;9961be45-128a-4e89-a16b-646131fb2c3a&quot; cluster = &quot;default&quot; username = &quot;&quot; password = &quot;&quot; } } 集成Nacos配置中心seata的TM和RM修改配置seata-order/seata-account/seata-web子项目 application.yml配置添加config信息： application.yml123456789101112131415161718seata: registry: type: nacos nacos: application: seata-server #seata-server端注册到nacos上到名称 server-addr: 127.0.0.1:8848 group: &quot;SEATA_GROUP&quot; namespace: &quot;9961be45-128a-4e89-a16b-646131fb2c3a&quot; username: &quot;&quot; password: &quot;&quot; cluster: &quot;default&quot; config: nacos: server-addr: 127.0.0.1:8848 group: &quot;SEATA_GROUP&quot; namespace: &quot;9961be45-128a-4e89-a16b-646131fb2c3a&quot; username: &quot;&quot; password: &quot;&quot; seata-server端修改配置在registry.conf中修改config-type为nacos，并且修改相应的nacos信息 registry.conf123456789101112config { # file、nacos 、apollo、zk、consul、etcd3 type = &quot;nacos&quot; nacos { serverAddr = &quot;127.0.0.1:8848&quot; namespace = &quot;9961be45-128a-4e89-a16b-646131fb2c3a&quot; group = &quot;SEATA_GROUP&quot; username = &quot;&quot; password = &quot;&quot; }} 初始化seata配置作为Nacos配置中心，需要把seata的一些配置上传到Nacos，配置比较多，官方给了一个config.txt，修改后，通过脚本上传到Nacos。 下载config.txt下载地址：config.txt 修改部分配置config.txt1234567891011......service.vgroupMapping.my_test_tx_group=defaultservice.default.grouplist=127.0.0.1:8091service.enableDegrade=falseservice.disableGlobalTransaction=false......store.mode=db......store.db.url=jdbc:mysql://127.0.0.1:3306/db_seata?useUnicode=true&amp;rewriteBatchedStatements=truestore.db.user=rootstore.db.password=root 执行初始化脚本nacos提供了执行脚本：nacos-config.sh 执行命令： 1sh nacos-config.sh -h localhost -p 8848 -g SEATA_GROUP -t 9961be45-128a-4e89-a16b-646131fb2c3a -u username -w password 参数说明： -h：host，nacos的地址，默认值是localhost。 -p：端口，nacos的端口，默认值为8848。 -g：配置分组，默认值为“seata_group”。 -t：租户信息，对应于NACOS的NAMESPACE ID字段，默认值为“”。 -u：用户名，Nacos 1.2.0+在权限控制上，默认值为’’“。 -w：密码，Nacos 1.2.0+在权限控制上，默认值为“”。","link":"/seata%E6%94%AF%E6%8C%81nacos%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"title":"skywalking从7.0升级到8.2.0分析","text":"boms与skw7.0调用的流程12graph TD start(开始) --&gt; 结束(结束) 以获取拓扑图为例: 页面选择具体的应用，可以多选 调用broker工程后台接口：/apm/topo/global_topology 具体通过这里和skw通信： 这里做了以下主要操作： 封装请求体body 根据服务关联的skw版本选择对应的GrapHQL 参数放到variables里面 HQL放到query里面 调用skw接口 根据服务关联的skw的OAP地址来进行拼接URL 这一步完成后就没有broker工程的事情了，接下来去skw源码看看 通过第三步调用到了skw 通过了doPost，根据定制的GrapHQL找到对应的方法 最后一张图做了以下操作： 根据查询条件（开始时间，结束时间）调用原生skw接口从ES获取所有服务的拓扑图数据 在根据boms传过来的参数（appids,appnames）对结果进行过滤，只保留我们需要的服务拓扑图数据 最后返回给boms 最后显示在页面上 boms与sky8.2.0调用的流程以获取拓扑图为例: 页面选择具体的应用，可以多选 调用broker工程后台接口：/apm/topo/global_topology_new 该接口做了以下操作： 获取前台传入的参数（主要是application.name） 调用skw接口获取所有的服务列表 123public List&lt;Service&gt; getAllServices(final Duration duration) throws IOException, ParseException { return getMetadataQueryService().getAllServices(duration.getStartTimestamp(), duration.getEndTimestamp()); } 返回值包含了label（application.name)和key，并结合传入的参数做交集，获取对应的key 调用skw接口获取选择服务的拓扑图数据，serviceIds就是上一步获取的交集keys 1234public Topology getServicesTopology(final List&lt;String&gt; serviceIds, final Duration duration) throws IOException { return getQueryService().getServiceTopology( duration.getStartTimeBucket(), duration.getEndTimeBucket(), serviceIds);} 最后显示在页面上 分析两种方法的区别 第二种方法不需要定制查询接口 第二种方法是先查询所有列表在进行筛选，而第一种是先查询拓扑图在进行筛选，相较于第一种，查询速度会快一些。 不需要做新增应用时，进行手动补偿 sky8.2.0相较于老版本新增的可用功能 从7.1.0开始，概要分析跟踪自动收集Tomcat和SpringMVC Controller的HTTP请求参数。 https://github.com/apache/skywalking/blob/v8.2.0/docs/en/ui/README.md 从6.5.0开始，可以通过动态配置在运行时动态更新报警设置 , 它将覆盖 alarm-settings.yml 中的设置. 为了确定是否触发告警规则, SkyWalking 需要为每个告警规则缓存时间窗的指标, 如果任何属性 (metrics-name, op, threshold, period, count, etc.) 的规则改变, 滑动窗口将会毁坏和重建, 导致此告警规则重新启动. https://github.com/apache/skywalking/blob/v8.2.0/docs/en/setup/backend/backend-alarm.md 8.0版本以后 oal脚本存放目录 ‘/config/oal/*.oal’ 你可以修改相关内容，重启OAP服务，即可生效。 此脚本中命名的所有指标都可以用于报警和UI查询. 注意！ 建议基于自定义指标构建的自定义UI功能才能添加或删除一些指标，否则UI可能会有问题。 https://github.com/apache/skywalking/blob/v8.2.0/docs/en/guides/backend-oal-scripts.md 6.3版本以后, OAL引擎嵌入在OAP服务器运行时中，称为“OAL -rt”(OAL运行时)。 OAL脚本现在位于’ /config ‘文件夹，用户可以简单地改变和重新启动服务器，使其有效。 但是，OAL脚本仍然是编译语言，OAL运行时动态生成java代码。 您可以在system env上打开set ‘ SW_OAL_ENGINE_DEBUG=Y ‘，查看生成了哪些类。 https://github.com/apache/skywalking/blob/v8.2.0/docs/en/concepts-and-designs/oal.md#observability-analysis-language 百分位是自7.0版本引入的第一个多值度量。由于有多个值，可以通过’ getMultipleLinearIntValues ‘ GraphQL查询进行查询。 在本例中，所有传入请求的“p99”、“p95”、“p90”、“p75”、“p50”。参数是p99延迟计算的精度，如在上述情况下，120ms和124被认为是相同的。 在7.0.0之前，使用’ p99 ‘、’ p95 ‘、’ p90 ‘、’ p75 ‘、’ p50 ‘函数分别计算指标。在7.x版本仍然支持，但不推荐且不包括在正式脚本。 All_p99 = from(All.latency).p99(10); 在本例中，p99为所有传入请求的值。参数是p99延迟计算的精度，如在上述情况下，120ms和124被认为是相同的。 https://github.com/apache/skywalking/blob/v8.2.0/docs/en/concepts-and-designs/oal.md#aggregation-function 7.0.0 以上支持令牌认证 https://github.com/apache/skywalking/blob/v8.2.0/docs/en/setup/backend/backend-token-auth.md","link":"/skywalking%E4%BB%8E7-0%E5%8D%87%E7%BA%A7%E5%88%B08-2-0%E5%88%86%E6%9E%90/"},{"title":"spring框架的注解式开发","text":"注解（Annotation）式开发 定义：通过Spring框架提供的一系列相关注解完成项目中快速开发 注解：Annotation 是Java中一种特殊类，类似于interface 使用：@注解类名(属性=参数) Spring中注解前置条件：必须在工厂配置文件中完成注解扫描 1&lt;context:componet-scan base-package=&quot;com.buubiu&quot; /&gt; 创建对象相关注解 @Componet注解（通用组件创建注解或者最顶层的父注解） 作用：用来负责创建对象（相当于 &lt;bean id=&quot;&quot; class=&quot;&quot; /&gt; ） 修饰范围：只能用在类上 注意：默认使用这个注解在工厂中创建的对象的唯一标识为 类名首字母小写，比如UserDAOImpl==&gt;userDAOImpl value属性作用：用来指定创建的对象在工厂中唯一标识 推荐：如果存在实现接口，则设置为接口首字母小写；若不存在，则默认 注意：若参数只有一个时，可以省略 value，比如：@Component(“userDAO”)等价于@Component(value = “userDAO”) 接下来讲的注解都是 子类注解，具有父类注解的一切特性，都是用来创建组件对象的 @Repository 作用：一般用来创建DAO组件中的注解 注意：由于使用Spring+Mybatis整合时，在spring.xml配置文件中已经批量注入了，所以在DAO层我们一般不使用注解。 @Service 作用：一般用来创建Service中组件的注解 @Controller 作用：一般用来创建Action中组件的注解 控制对象在工厂中创建次数 配置文件修改 1&lt;bean class=&quot;&quot; id=&quot;&quot; scope=&quot;singleton|prototype&quot;/&gt; 注解如何控制 @Scope 作用：用来指定对象的创建次数，默认单例 修饰范围：只能加在类上 value属性：singleton(单例，默认)和prototype(多例) 注意：在管理struts的action时必须加入@Scope注解，值必须为prototype 属性注入的相关注解​ 有两种 Spring框架提供的 @Autowired [推荐] 注意：默认根据类型进行注入 JavaEE中本身提供的 @Resource 注意：默认根据名称注入，名称找不到时自动根据类型注入 作用：用来完成成员变量的赋值（注入）操作 修饰范围：用在类中的成员变量，或者是类中成员变量的SET方法上 注意：使用注解进行注入时，日后注入的成员变量可以不再提供SET方法，Spring底层通过反射给处理过了 控制事务注解@Transactional 作用：用来给类中方法加入事务控制，简化配置文件中的两段配置 事务环绕通知及事务细粒度控制 123456789&lt;!--基于事务管理器创建环绕通知对象并配置事务细粒度控制--&gt;&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;save*&quot;/&gt; &lt;tx:method name=&quot;update*&quot;/&gt; &lt;tx:method name=&quot;delete*&quot;/&gt; &lt;tx:method name=&quot;find*&quot; propagation=&quot;SUPPORTS&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 简化事务切面配置 12345&lt;!--配置切面--&gt;&lt;aop:config&gt; &lt;aop:pointcut id=&quot;pc&quot; expression=&quot;execution(* com.buubiu.service.*ServiceImpl.*(..))&quot;/&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;pc&quot;/&gt;&lt;/aop:config&gt; 修饰范围：类、方法上，并且 局部优先原则 加在类上：代表类中所有方法都加入事务控制 加在方法上：代表当前方法加入事务控制 类和方法同时存在：方法优先 使用要求：如果想要让@Transactional这个注解生效，必须在配置文件中加入如下配置： 12&lt;!--开启注解式事务生效--&gt;&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt; 注解属性： propagation 用来控制传播属性 isolation 用来控制隔离级别 rollbackFor 用来设置什么异常回滚 noRollbackFor 用来设置什么异常不回滚 readOnly 用来设置事务读写性 timeout 用来设置超时性","link":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%B3%A8%E8%A7%A3%E5%BC%8F%E5%BC%80%E5%8F%91/"},{"title":"spring的事务属性","text":"spring的事务属性包括： propagation isolation no-rollback-for read-only rollback-for timeout propagation事务传播属性 定义：就是在多个业务层之间相互调用时传递事务的过程称之为事务传播(将事务对象在业务层之间进行传递的过程) 属性值的区别： propagation的值 释义 具体描述 REQUIRED 需要事务 如果外层没有事务，则开启新的事务；如果外层存在事务，则融入当前事务 SUPPORTS 支持事务 如果外层没有事务，则不会开启新的事务；如果外层存在事务，则融入当前事务 REQUIRES_NEW 每次开启新的事务 如果外层没有事务，则开启新的事务；如果外层存在事务，则外层事务挂起，自己开启新的事务执行，执行完成后，恢复外层事务 NOT_SUPPORTED 不支持事务 如果外层没有事务，则不会开启新的事务；如果外层存在事务，则外层事务挂起，自己以非事务的方式执行，执行完后，恢复外层事务 NEVER 不能有事务 存在事务则报错 MANDATORY 强制事务 没有事务则报错 NESTED 嵌套事务 事务之间可以嵌套运行，不过目前数据库 oracle mysql 支持不太友好 isolation事务隔离级别 属性值的区别： isolation的值/隔离级别 释义 具体描述 DEFAULT [推荐]使用数据库默认的隔离级别 READ_UNCOMMITTED/最低 读未提交 脏读现象:一个客户端读到了另一个客户端没有提交的数据 READ_COMMITTED 读已提交 避免脏读现象:一个客户端只能读到另一个客户端提交的数据 REPEATABLE_READ 可重复读 行锁: 主要是用来避免不可重复读现象的出现 SERIALIZABLE/最高 序列化读 表锁: 主要是用来避免幻影读现象的出现 注意： oracle 默认使用 READ_COMMITTED mysql 默认使用 REPEATABLE_READ 隔离级别越高，查询效率越低，一般推荐使用数据库默认隔离级别 read-only事务读写性 属性值的区别： read-only的值 释义 具体描述 true 只读 不能执行增删改操作 false 可读可写 能执行增删改操作 注意： mysql支持，oracle不支持 rollback-for出现什么类型异常回滚 默认出现RuntimeException及其 子类 异常回滚 no-rollback-for出现什么类型异常不回滚 比如：设置了 java.lang.RuntimeException 则报RuntimeException异常后，事务不回滚 timeout事务超时性 默认-1：代表永不超时 设置 &gt;=0正整数：代表设置超时时间为多少秒，比如 设置为1，则就是1秒后超时","link":"/spring%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%B1%9E%E6%80%A7/"},{"title":"windowns2012server安装AD(LDAP)","text":"介绍AD属于LDAP的一种，其中微软AD在系统中可以直接启动安装，无需下载其它软件。 安装AD 设置静态IP 设置计算机名称，并自动重启系统 命令行执行 1$ net user administrator /passwordreq:yes 添加角色，一直下一步，直到选择角色 继续一直下一步，直到选择安装 安装完成后，当前页面选择升级为域控制器 继续下一步，输入密码 继续一直下一步，直到 “先决条件检查”，点击安装 提示注销，重新登录 直接登录，或者用域登录都可以 打开电脑属性会发现变了，安装成功 配置AD新增域组织单位 创建域用户组织创建完成后，在该组织下创建域用户","link":"/windowns2012server%E5%AE%89%E8%A3%85AD-LDAP/"},{"title":"windows配置oracle监听","text":"如图所示：","link":"/windows%E9%85%8D%E7%BD%AEoracle%E7%9B%91%E5%90%AC/"},{"title":"zuul组件的使用","text":"简介官方：https://github.com/Netflix/zuul/wiki Zuul is the front door for all requests from devices and web sites to the backend of the Netflix streaming application. As an edge service application, Zuul is built to enable dynamic routing, monitoring, resiliency and security. 翻译：zul是从设备和网站到Netflix流媒体应用程序后端的所有请求的前门。作为一个边缘服务应用程序，zul被构建为支持动态路由、监视、弹性和安全性。 zuul版本说明目前zuul组件已经从1.0更新到2.0，但是作为springcloud官方不再推荐使用zuul2.0，但是依然支持zuul2. SpringCloud 官方集成zuul文档https://cloud.spring.io/spring-cloud-netflix/2.2.x/reference/html/#netflix-zuul-starter","link":"/zuul%E7%BB%84%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"书写数据库文档辅助SQL","text":"快速生成类似表格 代码 数据类型 数据长度 是否为空 默认值 备注 RESOURCE_ID VARCHAR2 32 N 流水号 12345678910111213SELECT tt.column_name 代码, tt.data_type 数据类型, tt.data_length 数据长度, tt.nullable 是否为空, tt.data_default 默认值, t.comments 备注FROM (select * from dba_col_comments where Table_Name = '表名' AND OWNER = '数据库用户名') t, (SELECT a.column_name, a.data_type, a.data_length, a.nullable, a.data_default FROM dba_tab_columns a WHERE a.Table_Name = '表名' AND OWNER = '数据库用户名' ORDER BY a.column_id) ttWHERE t.column_name = tt.column_name; 创建字典表12345678910111213141516171819202122CREATE TABLE DICT_XXX( CODEVALUE VARCHAR2(4) NOT NULL, CODENAME VARCHAR2(200), EXT1 VARCHAR2(200), EXT2 VARCHAR2(200), IS_VALID VARCHAR2(1) DEFAULT 1, ORDERATTR NUMBER, CONSTRAINT DICT_XXX_PK PRIMARY KEY ( CODEVALUE ) ENABLE)TABLESPACE 表空间;COMMENT ON TABLE DICT_XXX IS '表备注';COMMENT ON COLUMN DICT_XXX.CODEVALUE IS '码值';COMMENT ON COLUMN DICT_XXX.CODENAME IS '码名';COMMENT ON COLUMN DICT_XXX.EXT1 IS '扩展字段1';COMMENT ON COLUMN DICT_XXX.EXT2 IS '扩展字段2';COMMENT ON COLUMN DICT_XXX.IS_VALID IS '是否有效1:有';COMMENT ON COLUMN DICT_XXX.ORDERATTR IS '排序字段'; 生成常用字段12345678ALTER TABLE 用户名.表名 ADD CREATE_USER VARCHAR2(32) ;COMMENT ON COLUMN 用户名.表名.CREATE_USER IS '创建人' ;ALTER TABLE 用户名.表名 ADD CREATE_TIME DATE;COMMENT ON COLUMN 用户名.表名.CREATE_TIME IS '创建时间' ;ALTER TABLE 用户名.表名 ADD MODIFY_USER VARCHAR2(32) ;COMMENT ON COLUMN 用户名.表名.MODIFY_USER IS '修改人' ;ALTER TABLE 用户名.表名 ADD MODIFY_TIME DATE ;COMMENT ON COLUMN 用户名.表名.MODIFY_TIME IS '修改时间’ ; 生成表所有字段的创建 SQL 语句123456789SELECT 'alter table 现表名 add ' || tt.column_name || ' '|| tt.data_type || '('|| tt.data_length ||');' as colum, 'comment on column 现表名.' || tt.column_name || ' is ' || '''' || t.comments ||''';' as commFROM (select * from dba_col_comments where Table_Name = '原表名' AND OWNER = '用户名') t, (SELECT a.column_name, a.data_type, a.data_length, a.nullable, a.data_default FROM dba_tab_columns a WHERE a.Table_Name = '原表名' AND OWNER = '用户名' ORDER BY a.column_id) ttWHERE t.column_name = tt.column_name;","link":"/%E4%B9%A6%E5%86%99%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E6%A1%A3%E8%BE%85%E5%8A%A9SQL/"},{"title":"云服务器搭建Bitwarden","text":"准备 已按照章节 云服务器部署博客部署 安装镜像1$ docker pull vaultwarden/server:latest 运行镜像1234567$ docker run -d -p 8000:80 \\ -v /data/docker_volumes/vw-data/:/data/ \\ -v /etc/localtime:/etc/localtime \\ -e ADMIN_TOKEN=some_random_token_as_per_above_explanation \\ --restart=always \\ --name buubiu_vaultwarden \\ vaultwarden/server:latest 配置域名证书由于需要https，所以需要从厂商下载域名证书到服务器中。 创建相关目录 1$ mkdir -p /data/docker_volumes/nginx/config/conf.d/pki/bitwarden.buubiu.com 把bitwarden.buubiu.pem、bitwarden.buubiu.key拷贝到/data/docker_volumes/nginx/congfig/conf.d/pki/bitwarden.buubiu.com中 新建nginx配置在目录/data/docker_volumes/nginx/conf.d创建配置： 注意：配置文件中不要把注释单独放在一行，一定要放在行尾 bitwarden.buubiu.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# Define the server IP and ports here.upstream vaultwarden-default { server 10.xx.xx.xx:8000 }upstream vaultwarden-ws { server 10.xx.xx.xx:3012; }server { listen 80; server_name bitwarden.buubiu.com; #需要将yourdomain.com替换成证书绑定的域名。 return 301 https://$host$request_uri;}server { listen 443 ssl; server_name bitwarden.buubiu.com; #需要将yourdomain.com替换成证书绑定的域名。 ssl_certificate &quot;/etc/nginx/conf.d/pki/bitwarden.buubiu.com/bitwarden.buubiu.com.pem&quot;; #需要将cert-file-name.pem替换成已上传的证书文件的名称。 ssl_certificate_key &quot;/etc/nginx/conf.d/pki/bitwarden.buubiu.com/bitwarden.buubiu.com.key&quot;; #需要将cert-file-name.key替换成已上传的证书密钥文件的名称。 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #表示使用的TLS协议的类型。 ssl_prefer_server_ciphers on; client_max_body_size 128M; location / { proxy_pass http://vaultwarden-default; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } location /notifications/hub { proxy_pass http://vaultwarden-ws; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_set_header X-Real-IP $remote_addr; } location /notifications/hub/negotiate { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://vaultwarden-default; } # Optionally add extra authentication besides the ADMIN_TOKEN # If you don't want this, leave this part out location /admin { # See: https://docs.nginx.com/nginx/admin-guide/security-controls/configuring-http-basic-authentication/ # auth_basic &quot;Private&quot;; # auth_basic_user_file /path/to/htpasswd_file; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://vaultwarden-default; }} 重启nginx1$ docker restart buubiu_nginx 访问 前端：https://bitwarden.buubiu.com 后端：https://bitwarden.buubiu.com/admin","link":"/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BABitwarden/"},{"title":"云服务器部署博客","text":"这里主要记录一下我的博客部署在腾讯云的全过程。 安装docker见docker的安装 安装nginx 先启动一个基础容器 1$ docker run -d -p 80:80 --name buubiu_nginx nginx 在宿主机创建映射目录和网站目录 12$ mkdir -p /data/docker_volumes/nginx/config$ mkdir -p /data/docker_volumes/nginx/data 复制容器内的配置文件到宿主机映射目录 123$ docker cp buubiu_nginx:/etc/nginx/conf.d /data/docker_volumes/nginx/config$ docker cp buubiu_nginx:/etc/nginx/nginx.conf /data/docker_volumes/nginx/config$ docker cp buubiu_nginx:/usr/share/nginx/html /data/docker_volumes/nginx/data/ 删除容器，并重建映射的容器 123456789$ docker rm -f buubiu_nginx$ docker run -d -p 80:80 -p 443:443\\ --restart=always \\ --name buubiu_nginx \\ -v /data/docker_volumes/nginx/config/conf.d:/etc/nginx/conf.d \\ -v /data/docker_volumes/nginx/config/nginx.conf:/etc/nginx/nginx.conf \\ -v /data/docker_volumes/nginx/data:/usr/share/nginx \\ -v /etc/localtime:/etc/localtime \\ nginx 配置域名证书由于需要https，所以需要从厂商下载域名证书到服务器中。 创建相关目录 1$ mkdir -p /data/docker_volumes/nginx/config/conf.d/pki/buubiu.com 把buubiu.pem、buubiu.key拷贝到/data/docker_volumes/nginx/congfig/conf.d/pki/buubiu.com中 配置网站页面 创建网站目录 12$ mkdir -p /data/docker_volumes/nginx/data/buubiu$ chmod -R 757 /data/docker_volumes/nginx/data/buubiu 把工程通过hexo编译后打包，把public目录下的文件部署到服务器中的/data/docker_volumes/data/buubiu目录中 新建nginx配置在目录/data/docker_volumes/nginx/conf.d创建配置： 注意：配置文件中不要把注释单独放在一行，一定要放在行尾 buubiu.conf12345678910111213141516171819202122232425262728293031323334353637server { listen 80; server_name buubiu.com; #需要将yourdomain.com替换成证书绑定的域名。 return 301 https://buubiu.com$request_uri;}server { listen 80; listen 443 ssl; server_name www.buubiu.com; #需要将yourdomain.com替换成证书绑定的域名。 ssl_certificate &quot;/etc/nginx/conf.d/pki/buubiu.com/buubiu.pem&quot;; #需要将cert-file-name.pem替换成已上传的证书文件的名称。 ssl_certificate_key &quot;/etc/nginx/conf.d/pki/buubiu.com/buubiu.key&quot;; #需要将cert-file-name.key替换成已上传的证书密钥文件的名称。 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #表示使用的TLS协议的类型。 ssl_prefer_server_ciphers on; return 301 https://buubiu.com$request_uri;}server { listen 443 ssl; server_name buubiu.com; #需要将yourdomain.com替换成证书绑定的域名。 ssl_certificate &quot;/etc/nginx/conf.d/pki/buubiu.com/buubiu.pem&quot;; #需要将cert-file-name.pem替换成已上传的证书文件的名称。 ssl_certificate_key &quot;/etc/nginx/conf.d/pki/buubiu.com/buubiu.key&quot;; #需要将cert-file-name.key替换成已上传的证书密钥文件的名称。 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #表示使用的TLS协议的类型。 ssl_prefer_server_ciphers on; location / { root /usr/share/nginx/buubiu; index index.html index.htm; }} 重启nginx1$ docker restart buubiu_nginx 安装配置git(拓展)hexo支持通过git自动发布到服务器中，所以要想实时的发布博客，只需要让服务器支持git即可。 安装123$ yum -y install git$ git --versiongit version 2.27.0 配置 创建git账号和密码 12$ adduser git$ passwd git 创建git仓库，并初始化博客目录 123$ su git$ mkdir -p /home/git/blog &amp; cd /home/git/blog$ git init --bare buubiu.git 创建git钩子（hook） 目的：当我们用hexo通过git上传代码到这个仓库时，让该仓库的代码与我们的nginx指定的博客数据保持一致。 123456# 创建钩子文件 目录/home/git/blog/buubiu.git/hook/post-receive$ vi post-receive#!/bin/shgit --work-tree=/data/docker_volumes/nginx/data/buubiu --git-dir=/home/git/blog/buubiu.git checkout -f &amp;&amp; cd /data/docker_volumes/nginx/data/buubiu &amp;&amp; chmod -R 755 *# 保存并退出后, 给该文件添加可执行权限$ chmod +x /home/git/blog/buubiu.git/hooks/post-receive 配置客户端免密码登录 创建.ssh目录 123$ su git$ cd /home/git$ mkdir .ssh 创建校验公钥的配置文件 12$ cd /home/git/.ssh$ touch authorized_keys 设置权限 12$ chmod 700 /home/git/.ssh/$ chmod 600 /home/git/.ssh/authorized_keys 打开RSA认证（centos7.4及以下使用) 切换回 root 用户 1$ su root 进入 /etc/ssh 目录，编辑 sshd_config 123456$ cd /etc/ssh$ vi ssh_config#打开以下三个配置的注释（带 # 为注释）RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys 保存后重启 sshd 服务 1$ systemctl restart sshd 禁止客户端 shell 登录 如果 git 客户端可以直接通过 shell 使用 git 账户来远程登录服务器，这样是不安全的 在 /home/git 下面创建 git-shell-commands 目录，并把目录的拥有者设置为 git 账户 12$ su git$ mkdir /home/git/git-shell-commands 修改 /etc/passwd 文件 12$ su root$ vim /etc/passwd 找到下图所示内容，其中 1000 可能是别的数字 将 1git:x:1001:1001::/home/git:/bin/bash 改为 1git:x:1001:1001::/home/git:/bin/git-shell 在本地（客户端）创建公钥私钥 创建ssh-keys 123# -f 指定目录和文件名# 碰到需要输入到地方直接回车即可$ ssh-keygen -t rsa -f ~/.ssh/git_key/tencent_buubiu/id_rsa -C &quot;xxxxxxxx@gmail.com&quot; 将公钥（.pub)添加到服务器当中 将文件 ~/.ssh/git_key/tencent_buubiu/id_rsa.pub的内容复制到服务器的 /home/git/.ssh/authorized_keys文件中 配置hexo 在本机的config 配置 12345# 路径：/Users/xxxxx/.ssh/config 追加以下内容 Host blog.buubiu.com HostName 服务器IP User git IdentityFile /Users/xxxxx/.ssh/git_key/tencent_buubiu/id_rsa 去hexo项目的_config.yml文件最后追加一条git记录 _config.yml1234deploy:- type: git repo: git@blog.buubiu.com:/home/git/blog/buubiu.git branch: master","link":"/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2/"},{"title":"亚马逊aws 安装docker 和ssr","text":"选择 Red Hat 设置安全组 终端命令 12345678910#sudo su#yum -y update#yum -y install wget#yum install -y yum-utils device-mapper-persistent-data lvm2#yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo# wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.2.6-3.3.el7.x86_64.rpm# yum install -y containerd.io-1.2.6-3.3.el7.x86_64.rpm# yum install -y docker-ce# systemctl start docker# sudo bash -c &quot;$(wget -qO- https://raw.githubusercontent.com/Jigsaw-Code/outline-server/master/src/server_manager/install_scripts/install_server.sh)&quot;","link":"/%E4%BA%9A%E9%A9%AC%E9%80%8Aaws-%E5%AE%89%E8%A3%85docker-%E5%92%8Cssr/"},{"title":"使用Docker buildx构建多平台的镜像","text":"介绍官网：Docker Buildx 在日常的开发中，我们会有让程序在不同平台运行的需求。除了常用的Windows系统，Linux系统以及Mac OS系统外，我们甚至还希望让程序运行在以树莓派为代表的ARM平台下，或者是跑在嵌入式设备的路由器上。要构建出适合不同平台的镜像并不是一件容易的事情，除非你直接到目标平台下构建，或者模拟出目标平台下的环境来进行构建。 幸好，新版的Docker从版本19.03后已经开始支持一个新的命令行工具，叫做buildx，目地就是为了解决我们在一个平台下，一次性构建出多个平台可用镜像的需求。BuildKit 是下一代的 Docker 镜像构建工具，来源于 Moby/BuildKit。在最新的 Docker Desktop 和 Docker CE 中，官方以 Buildx 形式集成到 Docker CLI 中，不再需要额外构建添加。buildx是一个基于命令行的Docker扩展插件。 本章以macOS示例 安装根据不同系统可选择以下几种安装方式 macOS和WindowsDocker Buildx 包含在适用于 Windows 和 macOS的Docker Desktop中。 Linux若物理机使用DEB 或 RPM 包安装的，则 Docker Linux 包含了 Docker Buildx。 手动安装 不推荐，因为用这种方式安装，因为它不会使用安全更新自动更新。 从GitHub 上的发布页面下载最新的二进制文件 重命名相关二进制文件并将其复制到与您的操作系统匹配的目标位置： 系统 二进制名称 目标文件夹 Linux docker-buildx $HOME/.docker/cli-plugins macOS docker-buildx $HOME/.docker/cli-plugins Windows docker-buildx.exe %USERPROFILE%\\.docker\\cli-plugins 或者将其复制到这些文件夹之一以在系统范围内安装它： 在 Unix 环境中： /usr/local/lib/docker/cli-plugins或者/usr/local/libexec/docker/cli-plugins /usr/lib/docker/cli-plugins或者/usr/libexec/docker/cli-plugins 在 Unix 环境中，可能还需要使用以下命令使其可执行chmod +x： 1&gt;$ chmod +x ~/.docker/cli-plugins/docker-buildx 在 Windows 上： C:\\ProgramData\\Docker\\cli-plugins C:\\Program Files\\Docker\\cli-plugins Dockerfile以下是如何通过镜像在 Dockerfile 中安装和使用 Buildx docker/buildx-bin： 123FROM dockerCOPY --from=docker/buildx-bin:latest /buildx /usr/libexec/docker/cli-plugins/docker-buildxRUN docker buildx version 验证安装结果执行命令验证：（查询版本） 12$ docker buildx versiongithub.com/docker/buildx v0.7.1 05846896d149da05f3d6fd1e7770da187b52a247 看到显示的版本号，表示buildx已经启用成功。 构建多平台镜像使用构建器实例创建构建器默认情况下，Docker不会启用多平台架构的构建器，需要我们自己创建一个新的构建器，并激活和启动这个新的构建器: 123456789101112# 创建构建器$ docker buildx create --name mybuildermybuilder# 查看构建器$ docker buildx lsNAME/NODE DRIVER/ENDPOINT STATUS PLATFORMSmybuilder docker-container mybuilder0 unix:///var/run/docker.sock inactivedesktop-linux docker desktop-linux desktop-linux running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6default * docker default default running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 构建器的生命周期检查构建器并启动 用法：docker buildx inspect [NAME] 选项： 名称，简写 默认 描述 --bootstrap 在检查之前确保构建器已启动 --builder 覆盖配置的构建器实例 123456789101112131415161718192021222324# 检查并启动$ docker buildx inspect mybuilder --bootstrap[+] Building 15.9s (1/1) FINISHED =&gt; [internal] booting buildkit 15.9s =&gt; =&gt; pulling image moby/buildkit:buildx-stable-1 14.7s =&gt; =&gt; creating container buildx_buildkit_mybuilder0 1.2sName: mybuilderDriver: docker-containerNodes:Name: mybuilder0Endpoint: unix:///var/run/docker.sockStatus: runningPlatforms: linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/mips64le, linux/mips64, linux/arm/v7, linux/arm/v6# 这时查看构建器列表$ docker buildx lsNAME/NODE DRIVER/ENDPOINT STATUS PLATFORMSmybuilder docker-container mybuilder0 unix:///var/run/docker.sock running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/mips64le, linux/mips64, linux/arm/v7, linux/arm/v6desktop-linux docker desktop-linux desktop-linux running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6default * docker default default running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 默认情况下，inspect显示有关当前构造器的信息。 123456789$ docker buildx inspect mybuilderName: mybuilderDriver: docker-containerNodes:Name: mybuilder0Endpoint: unix:///var/run/docker.sockStatus: runningPlatforms: linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/mips64le, linux/mips64, linux/arm/v7, linux/arm/v6 停止构建器用法： docker buildx stop [NAME] 1234567891011121314151617181920212223# 停止构建器$ docker buildx stop mybuilder# 查看构建器列表$ docker buildx lsNAME/NODE DRIVER/ENDPOINT STATUS PLATFORMSmybuilder docker-container mybuilder0 unix:///var/run/docker.sock stoppeddesktop-linux docker desktop-linux desktop-linux running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6default * docker default default running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6# 查询详情$ docker buildx inspect mybuilderName: mybuilderDriver: docker-containerNodes:Name: mybuilder0Endpoint: unix:///var/run/docker.sockStatus: stoppedPlatforms: 删除构建器用法：docker buildx rm [NAME] 选项： 名称，简写 默认 描述 --keep-state 保持 BuildKit 状态 --builder 覆盖配置的构建器实例 1234567891011121314# 删除构建器$ docker buildx rm mybuilder# 查看构建器列表$ docker buildx lsNAME/NODE DRIVER/ENDPOINT STATUS PLATFORMSdesktop-linux docker desktop-linux desktop-linux running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6default * docker default default running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 # 查看详情$ docker buildx inspect mybuildererror: no builder &quot;mybuilder&quot; found 切换构建器用法： docker buildx use [OPTIONS] NAME 选项 名称，简写 默认 描述 --default 将构建器设置为当前上下文的默认值 --global 生成器持久化上下文更改 --builder 覆盖配置的构建器实例 123456789101112# 切换构建器$ docker buildx use mybuilder# 查看构建器列表，带 * 号的就是当前启用的构建器,在此可以看到，新的构建器已经支持其他多种平台。$ docker buildx lsNAME/NODE DRIVER/ENDPOINT STATUS PLATFORMSmybuilder * docker-container mybuilder0 unix:///var/run/docker.sock running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/mips64le, linux/mips64, linux/arm/v7, linux/arm/v6desktop-linux docker desktop-linux desktop-linux running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6default docker default default running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 构建镜像因为镜像仓库支持一个仓库上传多种架构，并且会根据构建平台pull相匹配架构的镜像，所以我们可以在一个Dockerfile，并且通过一个命令打包镜像并push。 创建 Dockerfile12345FROM openjdk:8-jdk-alpine AS buildMAINTAINER buubiu.comENV TZ=Asia/ShanghaiRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezoneENTRYPOINT [&quot;java&quot; &quot;-version&quot;] 打包构建1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# --platform 参数表示：以指定构建输出的目标平台（例如，linux/amd64、linux/arm64或 darwin/amd64）。# -f 指定Dockerfile文件# -t 指定镜像的名称和标签# --push 参数表示：构建完成之后，并push到镜像仓库当中$ docker buildx build \\--platform linux/386,linux/amd64,linux/arm/v6,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x \\-f Dockerfile \\-t buubiu/hello-world-test-jdk . \\--push[+] Building 237.9s (28/28) FINISHED =&gt; [internal] load build definition from Dockerfile 0.0s =&gt; =&gt; transferring dockerfile: 227B 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 2B 0.0s =&gt; [linux/s390x internal] load metadata for docker.io/library/openjdk:8-jdk-alpine 8.9s =&gt; [linux/arm/v6 internal] load metadata for docker.io/library/openjdk:8-jdk-alpine 8.7s =&gt; [linux/386 internal] load metadata for docker.io/library/openjdk:8-jdk-alpine 8.7s =&gt; [linux/amd64 internal] load metadata for docker.io/library/openjdk:8-jdk-alpine 8.6s =&gt; [linux/arm64 internal] load metadata for docker.io/library/openjdk:8-jdk-alpine 8.6s =&gt; [linux/arm/v7 internal] load metadata for docker.io/library/openjdk:8-jdk-alpine 8.6s =&gt; [linux/ppc64le internal] load metadata for docker.io/library/openjdk:8-jdk-alpine 8.5s =&gt; [auth] library/openjdk:pull token for registry-1.docker.io 0.0s =&gt; [auth] library/openjdk:pull token for registry-1.docker.io 0.0s =&gt; [linux/arm/v7 1/2] FROM docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 17.5s =&gt; =&gt; resolve docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.1s =&gt; =&gt; sha256:43ff02e0daa55f3a4df7eab4f7128e6b39b03ece75dfeedb53bf646fce03529c 67.40MB / 67.40MB 16.2s =&gt; =&gt; sha256:962e53e3f8337e63290eb26703e31f0e87d70db371afae581ad3898b1dccb972 238B / 238B 0.5s =&gt; =&gt; sha256:856f4240f8dba160c5323506c1e9a4dbaaca840bf1b0c244af3b8d1b42b0f43b 2.35MB / 2.35MB 4.1s =&gt; =&gt; extracting sha256:856f4240f8dba160c5323506c1e9a4dbaaca840bf1b0c244af3b8d1b42b0f43b 0.1s =&gt; =&gt; extracting sha256:962e53e3f8337e63290eb26703e31f0e87d70db371afae581ad3898b1dccb972 0.0s =&gt; =&gt; extracting sha256:43ff02e0daa55f3a4df7eab4f7128e6b39b03ece75dfeedb53bf646fce03529c 1.4s =&gt; [linux/386 1/2] FROM docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 19.6s =&gt; =&gt; resolve docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.0s =&gt; =&gt; sha256:c5e66a33dcf8b38a71f0e9f16f03244e3d4cee8e4fec285fc521bd315d0b2e0e 71.35MB / 71.35MB 18.1s =&gt; =&gt; sha256:78a94db5087f7f8bcd0cadca9c6d446a22a96182ec9c08d67fda830b278e8dc2 236B / 236B 0.5s =&gt; =&gt; sha256:d0c434c0359e2da36b788ae4f5a3a70015d83ee20070aa412e714c7feecca465 2.75MB / 2.75MB 2.1s =&gt; =&gt; extracting sha256:d0c434c0359e2da36b788ae4f5a3a70015d83ee20070aa412e714c7feecca465 0.1s =&gt; =&gt; extracting sha256:78a94db5087f7f8bcd0cadca9c6d446a22a96182ec9c08d67fda830b278e8dc2 0.0s =&gt; =&gt; extracting sha256:c5e66a33dcf8b38a71f0e9f16f03244e3d4cee8e4fec285fc521bd315d0b2e0e 1.4s =&gt; [linux/amd64 1/2] FROM docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.1s =&gt; =&gt; resolve docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.1s =&gt; [linux/ppc64le 1/2] FROM docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 41.8s =&gt; =&gt; resolve docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.1s =&gt; =&gt; sha256:026710fda3bf73cee7ded1ff99dccbbd0077f65b00a4ebd331ef777fc7dfecf4 71.45MB / 71.45MB 38.5s =&gt; =&gt; sha256:a97b7b4784d132b1e215acf6612c7852271c10c4ff9f096f9847f16559741c5e 238B / 238B 1.4s =&gt; =&gt; sha256:221c32b360a801e69a8aac598d495aaac3512642f967704a9d9bc5d6b4b4709e 2.78MB / 2.78MB 4.6s =&gt; =&gt; extracting sha256:221c32b360a801e69a8aac598d495aaac3512642f967704a9d9bc5d6b4b4709e 0.1s =&gt; =&gt; extracting sha256:a97b7b4784d132b1e215acf6612c7852271c10c4ff9f096f9847f16559741c5e 0.0s =&gt; =&gt; extracting sha256:026710fda3bf73cee7ded1ff99dccbbd0077f65b00a4ebd331ef777fc7dfecf4 1.3s =&gt; [linux/arm64 1/2] FROM docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.1s =&gt; =&gt; resolve docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.1s =&gt; [linux/s390x 1/2] FROM docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 31.4s =&gt; =&gt; resolve docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.1s =&gt; =&gt; sha256:bea4f04d8b33c5bd68ccb34849e615333c5ef00958b400841a03970dd2d5e9ae 2.54MB / 2.54MB 1.1s =&gt; =&gt; sha256:beaa0ca3e410795baed0978b91dcb428e9f31c46e39a429f31aa4c833592476a 237B / 237B 0.9s =&gt; =&gt; extracting sha256:bea4f04d8b33c5bd68ccb34849e615333c5ef00958b400841a03970dd2d5e9ae 0.2s =&gt; =&gt; sha256:4bdb8ad98e9071bff3dbd2263a56ae1de6725a1128df43c7a69289bce1db0e17 69.50MB / 69.50MB 11.1s =&gt; =&gt; extracting sha256:beaa0ca3e410795baed0978b91dcb428e9f31c46e39a429f31aa4c833592476a 0.0s =&gt; =&gt; extracting sha256:4bdb8ad98e9071bff3dbd2263a56ae1de6725a1128df43c7a69289bce1db0e17 1.2s =&gt; [linux/arm/v6 1/2] FROM docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 42.2s =&gt; =&gt; resolve docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.1s =&gt; =&gt; sha256:0d7a17c0e68e2e4ed5efa96d2888beead64d70d841b73187cfa278d342a29e70 68.21MB / 68.21MB 29.8s =&gt; =&gt; sha256:ab2b204f0fc5c4fd136771b708ddfd60e2bdc3cc56eff6e6e3d4ee5440b4c930 239B / 239B 2.0s =&gt; =&gt; sha256:6e39823df636e42cc4ea056843af98c9bec31b5ae0a75cdc5628cd19b589189c 2.54MB / 2.54MB 0.9s =&gt; =&gt; extracting sha256:6e39823df636e42cc4ea056843af98c9bec31b5ae0a75cdc5628cd19b589189c 0.2s =&gt; =&gt; extracting sha256:ab2b204f0fc5c4fd136771b708ddfd60e2bdc3cc56eff6e6e3d4ee5440b4c930 0.0s =&gt; =&gt; extracting sha256:0d7a17c0e68e2e4ed5efa96d2888beead64d70d841b73187cfa278d342a29e70 1.3s =&gt; CACHED [linux/arm64 2/2] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo Asia/Shanghai &gt; /etc/timezone 0.1s =&gt; CACHED [linux/amd64 2/2] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo Asia/Shanghai &gt; /etc/timezone 0.1s =&gt; [linux/arm/v7 2/2] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo Asia/Shanghai &gt; /etc/timezone 0.5s =&gt; [linux/386 2/2] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo Asia/Shanghai &gt; /etc/timezone 0.3s =&gt; [linux/s390x 2/2] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo Asia/Shanghai &gt; /etc/timezone 0.4s =&gt; [linux/ppc64le 2/2] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo Asia/Shanghai &gt; /etc/timezone 0.4s =&gt; [linux/arm/v6 2/2] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo Asia/Shanghai &gt; /etc/timezone 0.1s =&gt; exporting to image 186.2s =&gt; =&gt; exporting layers 0.4s =&gt; =&gt; exporting manifest sha256:3d85b151f5f22dc5fbe3851564cc816ca4b36049ef5edcc475ca7047e6d635a0 0.0s =&gt; =&gt; exporting config sha256:edaa346ce8b806050015142d18e03052aadf71e1013ccc6eef841db3c5093b8d 0.0s =&gt; =&gt; exporting manifest sha256:07771acce85e1cfc09d385ad1d517abb52f7294e0cace55b8da2dab8ddf96089 0.0s =&gt; =&gt; exporting config sha256:3835fddec92484e9132560d7068beb63c092c45807ccd80327aa6c1068d22c2e 0.0s =&gt; =&gt; exporting manifest sha256:ecdd2b0b85c5ccb01b2544ca33377c28512b99c26f9c547cc959553de0882833 0.0s =&gt; =&gt; exporting config sha256:1c5637a825e6b43e40abfb7b24bd6c2a3c3d5582b09dfcc83987d7e991cc909e 0.0s =&gt; =&gt; exporting manifest sha256:f3902428ada57cf7a8502a8350a4bd69d173198611bafcc78ebf6e535ffd913e 0.0s =&gt; =&gt; exporting config sha256:3fd7577f19874b0dfb0465c49ed83b8bc94d70d7cac43697d144b5fb11384a94 0.0s =&gt; =&gt; exporting manifest sha256:26b7e8fadc2b0515128c542ce88c5fc711ff25c4ed2072b4f3a32b918265c572 0.0s =&gt; =&gt; exporting config sha256:7dfd783dceb22b57104bea5999dde9a0719dd55b855a1f0704b94b797ee26964 0.0s =&gt; =&gt; exporting manifest sha256:79a7545c8fa29cb079127335db5b8649d7e64ef1287d5ed90351ef98801e990c 0.0s =&gt; =&gt; exporting config sha256:29484984460def9cb40530dd64249c1c1bec05069c60e3fa5368f830156437a2 0.0s =&gt; =&gt; exporting manifest sha256:2f76320dc27291a3f13673d4e1a6626e1aacee1d53d87196a24a0396bf8e4d37 0.0s =&gt; =&gt; exporting config sha256:5f061b0e8947c64db8457482fc3b01fb6ac044b382cedb769c91de5ff03b691b 0.0s =&gt; =&gt; exporting manifest list sha256:3a75883a8cfa7d68aff237c60b944e907478df03a31ffb05b110803f417f1977 0.0s =&gt; =&gt; pushing layers 180.2s =&gt; =&gt; pushing manifest for docker.io/buubiu/hello-world-test-jdk:latest@sha256:3a75883a8cfa7d68aff237c60b944e907478df03a31ffb05b110803f417f1977 5.4s =&gt; [auth] buubiu/hello-world-test-jdk:pull,push token for registry-1.docker.io 0.0s =&gt; [auth] buubiu/hello-world-test-jdk:pull,push token for registry-1.docker.io 去 DockerHub 上看，可以看到多平台的镜像了： 如果想将构建好的镜像保存在本地，可以将 type 指定为 docker，但必须分别为不同的 CPU 架构构建不同的镜像，不能合并成一个镜像，即： 123456789101112131415161718192021222324252627282930313233343536373839$ docker buildx build --platform=linux/arm64 -f Dockerfile -t buubiu/hello-world-test-jdk-arm64 -o type=docker .[+] Building 8.0s (7/7) FINISHED =&gt; [internal] load build definition from Dockerfile 0.0s =&gt; =&gt; transferring dockerfile: 227B 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 2B 0.0s =&gt; [internal] load metadata for docker.io/library/openjdk:8-jdk-alpine 1.8s =&gt; [1/2] FROM docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.0s =&gt; =&gt; resolve docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.0s =&gt; CACHED [2/2] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo Asia/Shanghai &gt; /etc/timezone 0.0s =&gt; exporting to oci image format 6.1s =&gt; =&gt; exporting layers 0.0s =&gt; =&gt; exporting manifest sha256:26b7e8fadc2b0515128c542ce88c5fc711ff25c4ed2072b4f3a32b918265c572 0.0s =&gt; =&gt; exporting config sha256:7dfd783dceb22b57104bea5999dde9a0719dd55b855a1f0704b94b797ee26964 0.0s =&gt; =&gt; sending tarball 6.0s =&gt; importing to docker $ docker buildx build --platform=linux/amd64 -f Dockerfile -t buubiu/hello-world-test-jdk-amd64 -o type=docker .[+] Building 4.9s (7/7) FINISHED =&gt; [internal] load build definition from Dockerfile 0.0s =&gt; =&gt; transferring dockerfile: 227B 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 2B 0.0s =&gt; [internal] load metadata for docker.io/library/openjdk:8-jdk-alpine 1.4s =&gt; [1/2] FROM docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.0s =&gt; =&gt; resolve docker.io/library/openjdk:8-jdk-alpine@sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3 0.0s =&gt; CACHED [2/2] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo Asia/Shanghai &gt; /etc/timezone 0.0s =&gt; exporting to oci image format 3.3s =&gt; =&gt; exporting layers 0.0s =&gt; =&gt; exporting manifest sha256:07771acce85e1cfc09d385ad1d517abb52f7294e0cace55b8da2dab8ddf96089 0.0s =&gt; =&gt; exporting config sha256:3835fddec92484e9132560d7068beb63c092c45807ccd80327aa6c1068d22c2e 0.0s =&gt; =&gt; sending tarball 3.3s =&gt; importing to docker $ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEbuubiu/hello-world-test-jdk-arm64 latest 7dfd783dceb2 3 minutes ago 103MBbuubiu/hello-world-test-jdk-amd64 latest 3835fddec924 4 minutes ago 105MB","link":"/%E4%BD%BF%E7%94%A8Docker-buildx%E6%9E%84%E5%BB%BA%E5%A4%9A%E5%B9%B3%E5%8F%B0%E7%9A%84%E9%95%9C%E5%83%8F/"},{"title":"分布式事务常见解决方案","text":"分布式事务问题模拟当多个服务调用过程中，其中一个或者多个服务执行失败，出现异常情况的时候，导致数据不一致性， 这样就出现了分布式事务问题； 我们来模拟下这个问题，我们运行过程中，让账户扣钱操作执行失败； 我们修改seata-account 里面AccountController 类的decrease 方法： 1234567891011121314151617181920/** * 给指定用户账户扣钱 * @param amount * @param userId * @return */ @PostMapping(&quot;/decrease&quot;) public boolean decrease(@RequestParam(&quot;amount&quot;)Integer amount,@RequestParam(&quot;userId&quot;)Integer userId) throws Exception{ System.out.println(&quot;amount:&quot;+amount+&quot;,userId:&quot;+userId); if(userId==null || userId==1){ throw new Exception(&quot;模拟异常&quot;); } Map&lt;String,Object&gt; map=new HashMap&lt;&gt;(); map.put(&quot;amount&quot;,amount); map.put(&quot;userId&quot;,userId); accountService.decrease(map); return true; } 当userId=1的时候，模拟抛出异常，这时候我们去查看数据库发现，t_order表有数据，订单已经生成了； 再看t_account表，数据没变化； 这样的话，就导致了业务上的数据不一致性问题，也就是分布式事务问题，我们需要解决这个问题； 分布式事务常见解决方案CAP理论CAP理论：一个分布式系统不可能同时满足一致性，可用性和分区容错性这个三个基本需求，最多只能 同时满足其中两项 一致性(C)：数据在多个副本之间是否能够保持一致的特性。 可用性(A)：是指系统提供的服务必须一致处于可用状态，对于每一个用户的请求总是在有限的时间内返 回结果，超过时间就认为系统是不可用的 分区容错性(P)：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和 可用性的服务，除非整个网络环境都发生故障。 CAP定理的应用 放弃P(CA)：如果希望能够避免系统出现分区容错性问题，一种较为简单的做法就是将所有的数据(或者 是与事物先相关的数据)都放在一个分布式节点上，这样虽然无法保证100%系统不会出错，但至少不会 碰到由于网络分区带来的负面影响 放弃A(CP):其做法是一旦系统遇到网络分区或其他故障时，那受到影响的服务需要等待一定的时间，应 用等待期间系统无法对外提供正常的服务，即不可用 放弃C(AP):这里说的放弃一致性，并不是完全不需要数据一致性，是指放弃数据的强一致性，保留数据 的最终一致性 BASE理论BASE是基本可用，软状态，最终一致性。是对CAP中一致性和可用性权限的结果，是基于CAP定理演化而来的，核心思想是即使无法做到强一致性，但每个应用都可以根据自身的业务特定，采用适当的方式来使系统达到最终一致性 2PC提交二阶段提交协议是将事务的提交过程分成提交事务请求和执行事务提交两个阶段进行处理。 阶段一：提交事务请求 事务询问：协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应 执行事务：各参与者节点执行事务操作，并将Undo和Redo信息记入事务日志中 如果参与者成功执事务操作，就反馈给协调者Yes响应，表示事物可以执行，如果没有成功执行事务，就反馈给协调者No响应，表示事务不可以执行 二阶段提交一些的阶段一夜被称为投票阶段，即各参与者投票票表明是否可以继续执行接下去的事务提交操作 阶段二：执行事务提交 假如协调者从所有的参与者或得反馈都是Yes响应，那么就会执行事务提交。 发送提交请求：协调者向所有参与者节点发出Commit请求 事务提交：参与者接受到Commit请求后，会正式执行事务提交操作，并在完成提交之后放弃整个事务执行期间占用的事务资源 反馈事务提交结果:参与者在完成事物提交之后，向协调者发送ACK消息 完成事务：协调者接收到所有参与者反馈的ACK消息后，完成事务 中断事务 假如任何一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就中断事务。 发送回滚请求：协调者向所有参与者节点发出Rollback请求 事务回滚：参与者接收到Rollback请求后，会利用其在阶段一种记录的Undo信息执行事物回滚操作，并在完成回滚之后释放事务执行期间占用的资源。 反馈事务回滚结果：参与则在完成事务回滚之后，向协调者发送ACK消息 中断事务：协调者接收到所有参与者反馈的ACk消息后，完成事务中断 优缺点 优点：原理简单，实现方便 缺点：同步阻塞，单点问题，脑裂，保守 3PC提交 三阶段提交，也叫三阶段提交协议，是二阶段提交（2PC）的改进版本。 与两阶段提交不同的是，三阶段提交有两个改动点。 引入超时机制：同时在协调者和参与者中都引入超时机制。 在第一阶段和第二阶段中插入一个准备阶段：保证了在最后提交阶段之前各参与节点的状态是一致的。 三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。 TCC分布式事务定义 TCC是服务化的两阶段编程模型，其Try、Confirm、Cancel，3个方法均由业务编码实现 TCC要求每个分支事务实现三个操作：预处理Try,确认Confirm,撤销Cancel。 Try操作做业务检查及资源预留, Confirm做业务确认操作 Cancel实现一个与Try相反的操作即回滚操作。 TM首先发起所有的分支事务Try操作，任何一个分支事务的Try操作执行失败，TM将会发起所有分支事务的Cancel操作，若Try操作全部成功，TM将会发起所有分支事务的Confirm操作,其中Confirm/Cancel操作若执行失败,TM会进行重试。 TCC的三个阶段 Try阶段是做业务检查(一致性)及资源预留(隔离),此阶段仅是一个初步操作，它和后续的Confirmy一起才能构成一个完整的业务逻辑 Confirm阶段是做确认提交，Try阶段所有分支事务执行成功后开始执行Confirm，通常情况下，采用TCC则认为Confirm阶段是不会出错的,即：只要Try成功，Confirm一定成功，若Confirm阶段真的出错，需要引入重试机制或人工处理 Cancel阶段是在业务执行错误需要回滚到状态下执行分支事务的取消，预留资源的释放，通常情况下，采用TCC则认为Cancel阶段也一定是真功的,若Cance阶段真的出错，需要引入重试机制或人工处理 TM事务管理器：TM事务管理器可以实现为独立的服务，也可以让全局事务发起方充当TM的角色,TM独立出来是为了公用组件，是为了考虑系统结构和软件的复用 TM在发起全局事务时生成全局事务记录，全局事务ID贯穿整个分布式事务调用链条，用来记录事务上下文，追踪和记录状态，用于Confirm和cacel失败需要进行重试,因此需要实现幂等 TCC的三种异常处理情况幂等处理 因为网络抖动等原因，分布式事务框架可能会重复调用同一个分布式事务中的一个分支事务的二阶段接口。所以分支事务的二阶段接口Confirm/Cancel需要能够保证幂等性。如果二阶段接口不能保证幂等性，则会产生严重的问题，造成资源的重复使用或者重复释放，进而导致业务故障。 对于幂等类型的问题，通常的手段是引入幂等字段进行防重放攻击。对于分布式事务框架中的幂等问题，同样可以祭出这一利器。 幂等记录的插入时机是参与者的Try方法，此时的分支事务状态会被初始化为INIT。然后当二阶段的Confirm/Cancel执行时会将其状态置为CONFIRMED/ROLLBACKED。 当TC重复调用二阶段接口时，参与者会先获取事务状态控制表的对应记录查看其事务状态。如果状态已经为CONFIRMED/ROLLBACKED，那么表示参与者已经处理完其分内之事，不需要再次执行，可以直接返回幂等成功的结果给TC，帮助其推进分布式事务。 空回滚 当没有调用参与方Try方法的情况下，就调用了二阶段的Cancel方法，Cancel方法需要有办法识别出此时Try有没有执行。如果Try还没执行，表示这个Cancel操作是无效的，即本次Cancel属于空回滚；如果Try已经执行，那么执行的是正常的回滚逻辑。 要应对空回滚的问题，就需要让参与者在二阶段的Cancel方法中有办法识别到一阶段的Try是否已经执行。很显然，可以继续利用事务状态控制表来实现这个功能。 当Try方法被成功执行后，会插入一条记录，标识该分支事务处于INIT状态。所以后续当二阶段的Cancel方法被调用时，可以通过查询控制表的对应记录进行判断。如果记录存在且状态为INIT，就表示一阶段已成功执行，可以正常执行回滚操作，释放预留的资源；如果记录不存在则表示一阶段未执行，本次为空回滚，不释放任何资源。 资源悬挂问题：TC回滚事务调用二阶段完成空回滚后，一阶段执行成功 解决：事务状态控制记录作为控制手段，二阶段发现无记录时插入记录，一阶段执行时检查记录是否存在 TCC和2PC比较 2PC通常都是在跨库的DB层面，而TCC则在应用层面处理，需要通过业务逻辑实现，这种分布式事务的实现方式优势在于，可以让应用自己定义数据操作的粒度，使得降低锁冲突，提高吞吐量成为可能 而不足之处则在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现Try，confirm,cancel三个操作。此外，其实现难度也比较大，需要按照网络状态，系统故障的不同失败原因实现不同的回滚策略 消息队列实现可靠消息最终一致性 可靠消息最终一致性就是保证消息从生产方经过消息中间件传递到消费方的一致性 RocketMQ主要解决了两个功能：本地事务与消息发送的原子性问题。事务参与方接收消息的可靠性 可靠消息最终一致性事务适合执行周期长且实时性要求不高的场景，引入消息机制后，同步的事务操作变为基于消息执行的异步操作，避免分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦 最大努力通知最大努力通知与可靠消息一致性有什么不同 可靠消息一致性，发起通知方需要保证将消息发出去，并且将消息发送到接收通知方，消息的可靠性由发起通知方保证 最大努力通知，发起通知方尽最大的努力将业务处理结果通知为接收通知方，但是消息可能接收不到，此时需要接收通知方主动调用发起通知方的接口查询业务，通知可靠性关键在于接收通知方 两者的应用场景 可靠消息一致性关注的是交易过程的事务一致，以异步的方式完成交易 最大努力通知关注的是交易后的通知事务，即将交易结果可靠的通知出去 基于MQ的ack机制实现最大努力通知方案一： 利用MQ的ack机制由MQ向接收通知方发送消息通知，发起方将普通消息发送到MQ 接收通知监听MQ，接收消息，业务处理完成回应ACK 接收通知方如果没有回应ACK则MQ会重复通知，按照时间间隔的方式，逐步拉大通知间隔 此方案适用于内部微服务之间的通知，不适应与通知外部平台 方案二：增加一个通知服务区进行通知，提供外部第三方时适用 分布式事务方案对比分析 2PC 最大的一个诟病是一个阻塞协议。RM在执行分支事务后需要等待TM的决定，此时服务会阻塞锁定资源。由于其阻塞机制和最差时间复杂度高，因此，这种设计不能适应随着事务涉及的服务数量增加而扩展的需要，很难用于并发较高以及子事务生命周期较长的分布式服务中 如果拿TCC事务的处理流程与2PC两阶段提交做比较，2PC通常都是在跨库的DB层面，而TCC则在应用层面处理，需要通过业务逻辑来实现。这种分布式事务的优势在于，可以让应用自定义数据操作的粒度，使得降低锁冲突，提高吞吐量成为可能。而不足之处在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现三个操作。此外，其实现难度也比较大，需要按照网络状态，系统故障等不同失败原因实现不同的策略。 可靠消息最终一致性事务适合执行周期长且实时性要求不高的场景。引入消息机制后，同步的事务操作变为基于消息执行的异步操作，避免了分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦，典型的场景：注册送积分，登陆送优惠券等 最大努力通知是分布式事务中要求最低的一种，适用于一些最终一致性时间敏感度低的业务，允许发起通知方业务处理失败，在接收通知方收到通知后积极进行失败处理，无论发起通知方如何处理结果都不会影响到接收通知方的后续处理，发起通知方需提供查询执行情况接口，用于接收通知方校对结果，典型的应用场景：银行通知，支付结果通知等。","link":"/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%B8%B8%E8%A7%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"title":"分布式基础案例搭建","text":"背景我们模拟一个简单下单业务，客户端调用rest对外服务，rest服务再调用订单服务实现创建订单和账户服 务实现账户扣钱操作，最终来完整下单业务； 案例架构设计所有服务都注册到nacos中，方便feign远程调用；订单服务，账户服务各自有独立数据库；架构设计如 下图： 整体项目结构如下图： seatatest 是父项目，主要是做一些依赖管理，依赖版本管理，管理所有子module项目； seata-common 子项目，主要是引入其他子项目需要的公共依赖，以及公共实体，工具类，配置类的统 一封装； seata-order 子项目，主要提供订单服务，生成订单； seata-account 子项目，主要提供账户服务，根据订单扣钱操作； seata-web 子项目，主要处理客户端下单请求，feign远程调用order，和account服务接口，最终完成 下单处理； 数据库设计我们新建两个数据库，分别是db_order （订单数据库）， db_account （账户数据库）， db_order 数据库里面新建表t_order 订单表： 123456789CREATE TABLE `t_order` (`id` int(11) NOT NULL AUTO_INCREMENT,`orderNo` varchar(100) DEFAULT NULL,`userId` int(11) DEFAULT NULL,`count` int(11) DEFAULT NULL,`amount` int(11) DEFAULT NULL,`remark` varchar(100) DEFAULT NULL,PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=21 DEFAULT CHARSET=utf8 db_account 数据库里面新建表t_account 用户账户表： 1234567CREATE TABLE `t_account` (`id` int(11) NOT NULL AUTO_INCREMENT,`userId` int(11) DEFAULT NULL,`balance` int(11) DEFAULT NULL,`remark` varchar(100) DEFAULT NULL,PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 插入数据： 1234insert into `t_account` (`id`, `userId`, `balance`, `remark`)values('1','1','2000','jack的账户');insert into `t_account` (`id`, `userId`, `balance`, `remark`)values('2','2','1000','marry的账户'); 项目搭建seatatest父项目搭建seatatest是父项目，主要是做一些依赖管理，依赖版本管理，管理所有子module项目； 注意，它的packaging 类型是pom pom.xml： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.buubiu&lt;/groupId&gt; &lt;artifactId&gt;seatatest&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt; &lt;druid.version&gt;1.1.10&lt;/druid.version&gt; &lt;spring-cloud.version&gt;Hoxton.SR8&lt;/spring-cloud.version&gt; &lt;springboot.version&gt;2.3.2.RELEASE&lt;/springboot.version&gt; &lt;springcloudalibaba.version&gt;2.2.4.RELEASE&lt;/springcloudalibaba.version&gt; &lt;fastjson.version&gt;1.2.73&lt;/fastjson.version&gt; &lt;commons-lang3.version&gt;3.10&lt;/commons-lang3.version&gt; &lt;mybatis.version&gt;2.1.0&lt;/mybatis.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${springboot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${springcloudalibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;${fastjson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;${commons-lang3.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; seata-common子项目搭建seata-common 子项目，主要是引入其他子项目需要的公共依赖，以及公共实体，工具类，配置类的统 一封装； 项目结构： seata-order子项目搭建seata-order 子项目，主要提供订单服务，生成订单； 项目结构： application.yml123456789101112131415161718192021server: port: 8081 servlet: context-path: /mybatis: mapper-locations: classpath:mybatis/mapper/*.xmlspring: application: name: seata-order datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/db_order?serverTimezone=Asia/Shanghai username: root password: root cloud: nacos: discovery: server-addr: 127.0.0.1:8848 seata-account子项目搭建seata-account 子项目，主要提供账户服务，根据订单扣钱操作； 项目结构： application.yml123456789101112131415161718192021server: port: 8082 servlet: context-path: /mybatis: mapper-locations: classpath:mybatis/mapper/*.xmlspring: application: name: seata-account datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/db_order?serverTimezone=Asia/Shanghai username: root password: root cloud: nacos: discovery: server-addr: 127.0.0.1:8848 seata-web子项目搭建seata-web 子项目，主要处理客户端下单请求，feign远程调用order，和account服务接口，最终完成 下单处理； 项目结构： application.yml1234567891011server: port: 80 servlet: context-path: /spring: application: name: seata-web cloud: nacos: discovery: server-addr: 127.0.0.1:8848","link":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80%E6%A1%88%E4%BE%8B%E6%90%AD%E5%BB%BA/"},{"title":"基础开发培训","text":"开发语言介绍前台 Bootstrap由 Twitter 开源的一个 CSS/HTML 框架， Bootstrap 是基于 HTML5 和 CSS3 开发的，它在 jQuery 的基础上进行了更为个性化和人性化的完善。 Bootstrap 自带丰富的 Web 组件，如：下拉菜单、按钮组、按钮下拉菜单、导航、导航条、路径导航、分页、排版、缩略图、警告对话框、进度条、媒体对象等。参见： http://v3.bootcss.com/components/ 后台 Java 代码 采用 JDK1.7 及其以上版本，下载地址： http://www.oracle.com/technetwork/java/javase/archive-139210.html 开发工具介绍开发工具使用 Eclipse 进行开发。下载地址： https://www.eclipse.org/downloads/eclipse-packages/ 中间件使用 Tomcat 作为开发 web 服务器进行开发，使用最新的 7 及其以上版本。下载地址： https://tomcat.apache.org/download-80.cgi 数据库MySQL 和 Oracle 都有兼容。 SVN 使用介绍版本控制工具，代码统一放在公司 SVN 服务器上。 常用的一些操作： 检出（ checkout ） 更新（update） 提交（ commit） 同步（sync） 数据库介绍为了使代码要同时兼容 Oracle 和 MySQL 两种数据库，所以在拼写 SQL 的时候尽量避免大量使用数据库自身特有的函数。为此需要了解哪些函数是 Oracle 的，哪些函数是 MySQL 的，如若避免不了使用这些函数，请在 SQL 的 XML 文件中使用&lt;mysql&gt;和&lt;oracle&gt;标签进行明确标出。这样在工程启动的时候，mybatis 会根据配置文件中指定的方言，解析为指定的 SQL 语句，装入到内存。 为什么使用 mybatis Hibernate 与 Mybatis 都是较为流行的 ORM 框架，且开发社区也相对活跃。 Hibernate 的真正掌握要比 Mybatis 来得难些。Mybatis 框架相对简单很容易上手，Hibernate 入门和优化的门槛较高。Hibernate 适用于中小企业需求变化不多的项目， mybatis 专注 sql 本身，程序员自己写 sql 语句，sql 的修改与优化比较方便，适用于需求变化较多的项目。 开发框架简介 开发组件简介后台目录结构 12345|--Java Resource |--api：存放所有的接口类 |--business：存放所有的Service业务逻辑 |--controller：存放所有的Action类 |--resources：存放所有的资源文件 前台目录结构 1234567891011resource：存放所有前台静态文件 |--css：存放所有样式文件 |--image：存放所有的图片文件 |--js：存放所有的JS文件 |--less：存放所有的less文件 |--plugin：存放所有的插件uploadfiles：文件上传附件的目录WEB-INF：存放页面和配置文件 |--conf：存放系统配置文件 |--lib：存放依赖的jar |--view：存放业务模块对应的JSP文件 配置文件介绍修改指定的配置文件，启动工程。修改如下几个重要的配置文件： 123456resource（资源目录） |-- applicationContext.xml（修改数据库的链接方式） |-- casFilterConfig.xml（指定使用的认证） |-- config.xml（修改具体的配置参数） |-- mybatis-config.xml（修改分页使用的方言） |-- redis-context.xml（修改使用的缓存服务器信息） 简单的增删改查 通过代码生成器可以快速的生成简单的代码样例，根据自己的业务逻辑需求在此基础上进行修改即可。点击 【创建】 按钮之前需要填写部分内容，填写说明如下： 应用：代码中划分为多个应用，此处填写应用对应的英文简称。 模块：填写在应用下对应的模块英文简称。 表名：填写模块对应的数据库中的业务表，填写后会生成简单的 SQL 语句。 生成前/后台代码复选框：选中指定的复选框生成对应的代码。 代码结构及其分布代码生成器究竟做了什么？ 生成 javascript 文件，会产生一个 WebContent/resource/js/应用/业务模块/模块名.js 文件。此文件中按照规则自动帮你生成了命名空间和一些 JS 样例代码。 生成一个 JSP 文件，会创建一个 WebContent/WEB-INF/view/应用/业务模块/模块名.jsp 文件。此文件中会自动引入 jstl、htmlcompressor 标签、common.jsp 和自身所依赖的 javascript 文件。jstl 是 JSP 的一个标准的标签库，启动能包括迭代和条件判断、数据管理格式化、XML 操作以及数据库访问。 Htmlcompressor 作用是将页面元素进行压缩，进来减少网络的 IO 传输。common.jsp 声明了一些公用的变量。 生成一个 Action 类， 创建一个 controller/com/应用/业务模块/action/业务模块 Action.java 的文件。该类中会自动继承 SecurityBaseAction 这个抽象类，为此其自身也就具有了 SecurityBaseAction 中的所有方法的功能。在继承该类的同时需要通过泛型传递两个参数，第一个参数指定自身所依赖的 Service，第二个参数指定查询结果的返回类型（默认是 Map，如果有特殊需要可以使用自定义实体）。 生成一个 Service 接口，创建一个 api/com/应用/业务模块/service/业务模块 Service.java 的文件，该 Service 继承 SecurityBaseService 接口。 生成 Service 的实现类，创建一个 business/com/应用/业务模块/service/业务模块名 ServiceImpl.java 的文件。该文件继承 BaseServiceImpl 基类并实现了自己的 Service 接口。继承基类的时候需要通过泛型传递两个参数，第一个为改 Service 中所依赖的 Mapper 接口类，第二个为查询的时候返回的类型（默认是 Map，如有特殊需求可以自己定义实体）。实现自己的 Service 接口的时候同样需要通过泛型传查询时返回的数据类型。 生成一个 Mapper 的接口，创建一个 business/com/应用/业务模块/mapper/业务模块名 Mapper.java 的文件。 生成一个 XML 文件，创建一个 business/com/应用/业务模块/mapper/业务模块名 Mapper.xml 的文件。在该文件中会根据前台输入的数据表自动生成 CRUD 的 SQL 语句。 几个基础的公共类开发时为了尽快排除和定位问题，为了使开发人员尽快上手，介绍如下几个基类： Cas20ProxyReceivingTicketValidationFilter：路径 tp-common-1.0.jar/com/tp/cas/ 登录成功之后 cas 回调该类中的 onSuccessfulValidation 方法，该方法会初始化当前登录人员的所有相关信息。 CommonAction: 路径 tp-common-1.0.jar/com/tp/base/action/ 存放了一些公共的方法，如：首页、404、500、403、注销、上传、下载、截图、获取 token。 SecurityBaseAction：路径 controller/com/tp/base/action/ 基础的 Action，所有业务模块的 Action 均继承了这个抽象类，该类中实现了公共的分页查询（page）、查询全部（list）、获取指定对象（get）、保存或修改（saveOrUpdate）、添加（add）、批量添加（addBatch）、修改（update）、批量修改（updateBatch）、删除（delete）、判断对象是否存在（exist）、记录的状态切换（toggle）、获取当前用户（getCurrentUser）等。 BaseServiceImpl：路径 tp-common-1.0.jar/com/tp/base/service/ 基础的 Service 实现类，所有业务模块的 Server 均继承该类，此类中实现了基础的 CRUD。 AuthenticationInterceptor：路径 tp-common-1.0.jar/com/tp/interceptor/ 判断当前用户是否有权限访问系统资源的一个拦截器（springmvc interceptor）。 LoggerInterceptor：路径 tp-common-1.0.jar/com/tp/interceptor/ 用于记录用户操作日志的拦截器（springmvc interceptor）。 ParameterInterceptor：路径 tp-common-1.0.jar/com/tp/interceptor/ 前台传递参数到后台执行 SQL 语句的拦截器（mybatis interceptor）。 SqlTimeInterceptor：路径 tp-common-1.0.jar/com/tp/interceptor/ 记录 SQL 日志信息的拦截器（mybatis interceptor）。 common.js：路径 resource/plugin/ 封装了很多公用的 JS 方法，封装的原因好比系统中的提示框，现在用的 layer，如果有一天不再用这个 layer 了，直接修改 common.js 里面的公共方法，则所有业务模块的提示框就全变了，而不用到每个业务模块中到处进行修改。便于统一管理和维护。 前台公共方法简介 获取 URL 上面的参数：$.getParameter(“参数名”)； 日志格式化：$.formatDate(“yyyy-MM-dd hh:mm:ss” , new Date())； 加载右侧页面：Util.load(加载的 URL 地址 , 加载前回调 , 加载后回调)； 分页获取列表：Util. getPageObjListByForm(参数)； 发送异步请求：Util. ajax(参数)； 渲染模板：Util. renderTemplet(参数)； 获取 token：Util. getToken(参数)； 删除记录：Util. deleteRecord(参数)； 渲染列表：Util. dataTables(参数)； 页面表单弹窗：Util. formModal(参数)； 字典转换：Util. convertSysDic(字典表名，key)； 设置浏览器的 hash 值：Util. setHash(hash 值)； 替换指定的 hash 值：Util. replaceHash(key , value)； 获取 hash 值：Util. getHash(hash , key , 默认值)； 判断对象是否为空：Util. isNotEmpty(值)； 截取字符串：Util. subStr(字符串，长度)； 联想：Util. autocomplete()； 设置 cookie：Util. setCookie(键，值，过期时间)； 获取 cookie：Util. getCookie(键)； 裁剪图片：Util.crop(回调，模块名字，操作类型，图片路径，宽度，高度，X 轴，Y 轴)； 系统提示，操作成功：Msg.success(提示信息)； 系统提示，操作失败：Msg.error(提示信息)； 系统提示，警告：Msg.warning(提示信息，回调函数)； 系统提示，信息：Msg.info(提示信息)； 系统提示，确认：Msg.confirm(提示信息，回调函数)； 加载条：Msg.load(); 关闭系统提示：Msg.close(提示对象)； 页面弹出层：Msg.open(配置参数); 页面中的公共依赖组件 日期 my97，具体功能参见：http://www.my97.net/ 树组件 zTree，具体功能参见：http://www.treejs.cn/ 系统弹出框 layer，具体功能参见：http://layer.layui.com/ 上传组件 webuploader，具体功能参见：http://fex.baidu.com/webuploader/ 页面图表 echart，具体功能参见：http://echarts.baidu.com/ 模板渲染 artTemplate，具体功能参见：https://github.com/aui/artTemplate 表格插件 datatables，具体功能参见：http://datatables.club/ 前台校验 jQuery Validation，具体功能参见：http://jqueryvalidation.org/ 网站使用的响应式布局框架 bootstrap，具体说明参见：http://www.bootcss.com/ 开发习惯养成前台编码注意事项 尽量减少 HTTP 请求个数：合并图片，CSS，JS，避免没有必要的数据请求； 避免空的 src 和 href：留意具有这两个属性的标签如 link，script，img，iframe 等； 使用 gzip 压缩内容：压缩所有可能的文件类型以来减少文件体积； 把 CSS 放到顶部，把 JS 放到底部：确保用户至少能早一点看到界面，让网站看起来至少反应快一点，所以应该把必须的 js 和 css 放顶部，把不那么重要的 css 和 js 放底部； 自己写的 JS 里面注意使用命名空间，在使用 hashchange 的时候注意不要产生多余的事件处理。在 JSP 中自定义页面 Id 的时候要尽量不要和其他页面中的 Id 重复。 后台编码注意事项 系统级别的配置请使用系统常量进行声明（见： SystemConstant ）； 如果想加日志的输出请使用 slf4j 按日志级别进行输出； 在自定义的 Action 当中无需自己重复注入自身所依赖的 Service，直接使用即可； 同理在自定义的 Service 之中无需自己重复注入自身所依赖的 Mapper，直接使用即可； 如果需要事务包裹，请在自己的 Service 方法上使用 @Transactional 注解； 为减少不必要的麻烦，请不要在 XML 文件的 SQL 语句中带有中文； 为了防止 SQL 注入，前台传递到 SQL 中的参数均进行了 SQL 关键字的特殊处理，如需忽略系统的转换，请在指定的 SQL 语句中使用“/ignoreParameter/”进行说明。为此出现的 SQL 攻击，请自行解决。 SQL 语句注意事项 获取唯一 一行时使用 limit 1： 1select user_id , user_name from sys_uicm_user where id_number =‘09901’ 与 1select user_id , user_name from sys_uicm_user where id_number =‘09901’ limit 1; 当你已经知道获取的记录只有一行时，请将 limit 1 添加到 where 语句后面。这样数据库引擎在找到第一个符合条件的记录后就停止扫描了，而不是遍历整个表或索引。 避免使用 select *：从表中读取的数据越多，查询速度越慢。增加了磁盘操作所需的时间，数据库与 web 服务器分开时，增加了网络传输的 IO，同理 web 服务器和客户端也存在网络的传输。也增加了服务器将查询出来的对象进行 json 序列化所需的时间。 数据库中的字段类型与所占空间大小适当（如：使用 INT 来存储 IP 地址）：一般存储一个 IP 字段至少是 varchar(15)，如果用 INT 只需要 4 个字节的空间，而且字段长度固定。 大表分页：当起始页较小时，查询没有性能问题。随着起始记录的增加，时间也随着增大。 1234select * from user limit 10, 20 0.016 秒select * from user limit 10000, 20 0.094 秒select * from user limit 400000, 20 3.229 秒SELECT * FROM user a JOIN (select id from user limit 400000, 20) b ON a.id = b.id 0.2 秒 SQL 语句调优基本原则 避免全表扫描； 建立索引（合理使用索引，索引一定不是越多越好）； 尽量避免大事务操作（事务时间尽可能短），提高系统并发能力； 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理； 语句中字段比较的时候，请使用同类型比较； 尽量避免在 where 子句中对字段进行表达式操作和函数操作； 应尽量避免在 where 子句中使用 or 来连接条件,可以考虑使用 union 代替； 使用 union all 替代 union ，因为 union 有去重开销； 应尽量避免在 where 子句中使用 != 或 &lt;&gt; 操作符，否则将引擎放弃使用索引而进行全表扫描； in 和 not in 也要慎用，对于连续的数值，能用 between 就不要用 in，exists 代替 in； 不用 select * ， 消耗 cpu，io，内存，带宽； 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销； 尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为变长字段存储空间小，对于查询来说，在一个相对较小的字段内搜索效率显然要高些；","link":"/%E5%9F%BA%E7%A1%80%E5%BC%80%E5%8F%91%E5%9F%B9%E8%AE%AD/"},{"title":"并发编程-ArrayBlockingQueue与LinkedBlockingQueue实现原理","text":"ArrayBlockingQueue简介在多线程编程过程中，为了业务解耦和架构设计，经常会使用并发容器用于存储多线程间的共享数据，这样不仅可以保证线程安全，还可以简化各个线程操作。例如在“生产者-消费者”问题中，会使用阻塞队列（BlockingQueue）作为数据容器，关于BlockingQueue可以看这篇文章。为了加深对阻塞队列的理解，唯一的方式是对其实验原理进行理解，这篇文章就主要来看看ArrayBlockingQueue和LinkedBlockingQueue的实现原理。 ArrayBlockingQueue实现原理阻塞队列最核心的功能是，能够可阻塞式的插入和删除队列元素。当前队列为空时，会阻塞消费数据的线程，直至队列非空时，通知被阻塞的线程；当队列满时，会阻塞插入数据的线程，直至队列未满时，通知插入数据的线程（生产者线程）。那么，多线程中消息通知机制最常用的是lock的condition机制，关于condition可以看这篇文章的详细介绍。那么ArrayBlockingQueue的实现是不是也会采用Condition的通知机制呢？下面来看看。 ArrayBlockingQueue的主要属性ArrayBlockingQueue的主要属性如下: 12345678910111213141516171819202122232425/** The queued items */final Object[] items;/** items index for next take, poll, peek or remove */int takeIndex;/** items index for next put, offer, or add */int putIndex;/** Number of elements in the queue */int count;/* * Concurrency control uses the classic two-condition algorithm * found in any textbook. *//** Main lock guarding all access */final ReentrantLock lock;/** Condition for waiting takes */private final Condition notEmpty;/** Condition for waiting puts */private final Condition notFull; 从源码中可以看出ArrayBlockingQueue内部是采用数组进行数据存储的（属性items），为了保证线程安全，采用的是ReentrantLock lock，为了保证可阻塞式的插入删除数据利用的是Condition，当获取数据的消费者线程被阻塞时会将该线程放置到notEmpty等待队列中，当插入数据的生产者线程被阻塞时，会将该线程放置到notFull等待队列中。而notEmpty和notFull等中要属性在构造方法中进行创建： 12345678public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();} 接下来，主要看看可阻塞式的put和take方法是怎样实现的。 put方法详解put(E e)方法源码如下： 1234567891011121314public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { //如果当前队列已满，将线程移入到notFull等待队列中 while (count == items.length) notFull.await(); //满足插入数据的要求，直接进行入队操作 enqueue(e); } finally { lock.unlock(); }} 该方法的逻辑很简单，当队列已满时（count == items.length）将线程移入到notFull等待队列中，如果当前满足插入数据的条件，就可以直接调用enqueue(e)插入数据元素。enqueue方法源码为： 123456789101112private void enqueue(E x) { // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; //插入数据 items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; //通知消费者线程，当前队列中有数据可供消费 notEmpty.signal();} enqueue方法的逻辑同样也很简单，先完成插入数据，即往数组中添加数据（items[putIndex] = x），然后通知被阻塞的消费者线程，当前队列中有数据可供消费（notEmpty.signal()）。 take方法详解take方法源码如下： 12345678910111213public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { //如果队列为空，没有数据，将消费者线程移入等待队列中 while (count == 0) notEmpty.await(); //获取数据 return dequeue(); } finally { lock.unlock(); }} take方法也主要做了两步：1. 如果当前队列为空的话，则将获取数据的消费者线程移入到等待队列中；2. 若队列不为空则获取数据，即完成出队操作dequeue。dequeue方法源码为： 1234567891011121314151617private E dequeue() { // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(&quot;unchecked&quot;) //获取数据 E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); //通知被阻塞的生产者线程 notFull.signal(); return x;} dequeue方法也主要做了两件事情：1. 获取队列中的数据，即获取数组中的数据元素（(E) items[takeIndex]）；2. 通知notFull等待队列中的线程，使其由等待队列移入到同步队列中，使其能够有机会获得lock，并执行完成功退出。 从以上分析，可以看出put和take方法主要是通过condition的通知机制来完成可阻塞式的插入数据和获取数据。在理解ArrayBlockingQueue后再去理解LinkedBlockingQueue就很容易了。 LinkedBlockingQueue实现原理LinkedBlockingQueue是用链表实现的有界阻塞队列，当构造对象时未指定队列大小时，队列默认大小为Integer.MAX_VALUE。从它的构造方法可以看出： 123public LinkedBlockingQueue() { this(Integer.MAX_VALUE);} LinkedBlockingQueue的主要属性LinkedBlockingQueue的主要属性有： 1234567891011121314151617181920212223242526/** Current number of elements */private final AtomicInteger count = new AtomicInteger();/** * Head of linked list. * Invariant: head.item == null */transient Node&lt;E&gt; head;/** * Tail of linked list. * Invariant: last.next == null */private transient Node&lt;E&gt; last;/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition(); 可以看出与ArrayBlockingQueue主要的区别是，LinkedBlockingQueue在插入数据和删除数据时分别是由两个不同的lock（takeLock和putLock）来控制线程安全的，因此，也由这两个lock生成了两个对应的condition（notEmpty和notFull）来实现可阻塞的插入和删除数据。并且，采用了链表的数据结构来实现队列，Node结点的定义为： 12345678910111213static class Node&lt;E&gt; { E item; /** * One of: * - the real successor Node * - this Node, meaning the successor is head.next * - null, meaning there is no successor (this is the last node) */ Node&lt;E&gt; next; Node(E x) { item = x; }} 接下来，我们也同样来看看put方法和take方法的实现。 put方法详解put方法源码为: 12345678910111213141516171819202122232425262728293031323334public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { /* * Note that count is used in wait guard even though it is * not protected by lock. This works because count can * only decrease at this point (all other puts are shut * out by lock), and we (or some other waiting put) are * signalled if it ever changes from capacity. Similarly * for all other uses of count in other wait guards. */ //如果队列已满，则阻塞当前线程，将其移入等待队列 while (count.get() == capacity) { notFull.await(); } //入队操作，插入数据 enqueue(node); c = count.getAndIncrement(); //若队列满足插入数据的条件，则通知被阻塞的生产者线程 if (c + 1 &lt; capacity) notFull.signal(); } finally { putLock.unlock(); } if (c == 0) signalNotEmpty();} put方法的逻辑也同样很容易理解，可见注释。基本上和ArrayBlockingQueue的put方法一样。 take方法详解take方法的源码如下： 123456789101112131415161718192021222324public E take() throws InterruptedException { E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { //当前队列为空，则阻塞当前线程，将其移入到等待队列中，直至满足条件 while (count.get() == 0) { notEmpty.await(); } //移除队头元素，获取数据 x = dequeue(); c = count.getAndDecrement(); //如果当前满足移除元素的条件，则通知被阻塞的消费者线程 if (c &gt; 1) notEmpty.signal(); } finally { takeLock.unlock(); } if (c == capacity) signalNotFull(); return x;} take方法的主要逻辑请见于注释，也很容易理解。 ArrayBlockingQueue与LinkedBlockingQueue的比较相同点：ArrayBlockingQueue和LinkedBlockingQueue都是通过condition通知机制来实现可阻塞式插入和删除元素，并满足线程安全的特性； 不同点： ArrayBlockingQueue底层是采用的数组进行实现，而LinkedBlockingQueue则是采用链表数据结构； ArrayBlockingQueue插入和删除数据，只采用了一个lock，而LinkedBlockingQueue则是在插入和删除分别采用了putLock和takeLock，这样可以降低线程由于线程无法获取到lock而进入WAITING状态的可能性，从而提高了线程并发执行的效率。","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-ArrayBlockingQueue%E4%B8%8ELinkedBlockingQueue%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"title":"并发编程-BlockingQueue介绍","text":"BlockingQueue简介在实际编程中，会经常使用到JDK中Collection集合框架中的各种容器类如实现List,Map,Queue接口的容器类，但是这些容器类基本上不是线程安全的，除了使用Collections可以将其转换为线程安全的容器，Doug Lea大师为我们都准备了对应的线程安全的容器，如实现List接口的CopyOnWriteArrayList（关于CopyOnWriteArrayList可以看这篇文章），实现Map接口的ConcurrentHashMap（关于ConcurrentHashMap可以看这篇文章），实现Queue接口的ConcurrentLinkedQueue（关于ConcurrentLinkedQueue可以看这篇文章）。 最常用的”生产者-消费者“问题中，队列通常被视作线程间操作的数据容器，这样，可以对各个模块的业务功能进行解耦，生产者将“生产”出来的数据放置在数据容器中，而消费者仅仅只需要在“数据容器”中进行获取数据即可，这样生产者线程和消费者线程就能够进行解耦，只专注于自己的业务功能即可。阻塞队列（BlockingQueue）被广泛使用在“生产者-消费者”问题中，其原因是BlockingQueue提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。 基本操作BlockingQueue基本操作总结如下（此图来源于JAVA API文档）： BlockingQueue继承于Queue接口，因此，对数据元素的基本操作有： 插入元素 add(E e) ：往队列插入数据，当队列满时，插入元素时会抛出IllegalStateException异常； offer(E e)：当往队列插入数据时，插入成功返回true，否则则返回false。当队列满时不会抛出异常； 删除元素 remove(Object o)：从队列中删除数据，成功则返回true，否则为false poll：删除数据，当队列为空时，返回null； 查看元素 element：获取队头元素，如果队列为空时则抛出NoSuchElementException异常； peek：获取队头元素，如果队列为空则抛出NoSuchElementException异常 BlockingQueue具有的特殊操作： 插入数据 put：当阻塞队列容量已经满时，往阻塞队列插入数据的线程会被阻塞，直至阻塞队列已经有空余的容量可供使用； offer(E e, long timeout, TimeUnit unit)：若阻塞队列已经满时，同样会阻塞插入数据的线程，直至阻塞队列已经有空余的地方，与put方法不同的是，该方法会有一个超时时间，若超过当前给定的超时时间，插入数据的线程会退出； 删除数据 take()：当阻塞队列为空时，获取队头数据的线程会被阻塞； poll(long timeout, TimeUnit unit)：当阻塞队列为空时，获取数据的线程会被阻塞，另外，如果被阻塞的线程超过了给定的时长，该线程会退出 常用的BlockingQueue实现BlockingQueue接口的有ArrayBlockingQueue, DelayQueue, LinkedBlockingDeque, LinkedBlockingQueue, LinkedTransferQueue, PriorityBlockingQueue, SynchronousQueue，而这几种常见的阻塞队列也是在实际编程中会常用的，下面对这几种常见的阻塞队列进行说明： ArrayBlockingQueueArrayBlockingQueue是由数组实现的有界阻塞队列。该队列命令元素FIFO（先进先出）。因此，队头元素是队列中存在时间最长的数据元素，而对尾数据则是当前队列最新的数据元素。ArrayBlockingQueue可作为“有界数据缓冲区”，生产者插入数据到队列容器中，并由消费者提取。ArrayBlockingQueue一旦创建，容量不能改变。 当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。 ArrayBlockingQueue默认情况下不能保证线程访问队列的公平性，所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到ArrayBlockingQueue。而非公平性则是指访问ArrayBlockingQueue的顺序不是遵守严格的时间顺序，有可能存在，一旦ArrayBlockingQueue可以被访问时，长时间阻塞的线程依然无法访问到ArrayBlockingQueue。如果保证公平性，通常会降低吞吐量。如果需要获得公平性的ArrayBlockingQueue，可采用如下代码： 1private static ArrayBlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(10,true); 关于ArrayBlockingQueue的实现原理，可以看这篇文章。 LinkedBlockingQueueLinkedBlockingQueue是用链表实现的有界阻塞队列，同样满足FIFO的特性，与ArrayBlockingQueue相比起来具有更高的吞吐量，为了防止LinkedBlockingQueue容量迅速增，损耗大量内存。通常在创建LinkedBlockingQueue对象时，会指定其大小，如果未指定，容量等于Integer.MAX_VALUE。 关于LinkedBlockingQueue的实现原理，可以看这篇文章。 PriorityBlockingQueuePriorityBlockingQueue是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现compareTo()方法来指定元素排序规则，或者初始化时通过构造器参数Comparator来指定排序规则。 SynchronousQueueSynchronousQueue每个插入操作必须等待另一个线程进行相应的删除操作，因此，SynchronousQueue实际上没有存储任何数据元素，因为只有线程在删除数据时，其他线程才能插入数据，同样的，如果当前有线程在插入数据时，线程才能删除数据。SynchronousQueue也可以通过构造器参数来为其指定公平性。 LinkedTransferQueueLinkedTransferQueue是一个由链表数据结构构成的无界阻塞队列，由于该队列实现了TransferQueue接口，与其他阻塞队列相比主要有以下不同的方法： transfer(E e)如果当前有线程（消费者）正在调用take()方法或者可延时的poll()方法进行消费数据时，生产者线程可以调用transfer方法将数据传递给消费者线程。如果当前没有消费者线程的话，生产者线程就会将数据插入到队尾，直到有消费者能够进行消费才能退出； tryTransfer(E e)tryTransfer方法如果当前有消费者线程（调用take方法或者具有超时特性的poll方法）正在消费数据的话，该方法可以将数据立即传送给消费者线程，如果当前没有消费者线程消费数据的话，就立即返回false。因此，与transfer方法相比，transfer方法是必须等到有消费者线程消费数据时，生产者线程才能够返回。而tryTransfer方法能够立即返回结果退出。 tryTransfer(E e,long timeout,imeUnit unit)与transfer基本功能一样，只是增加了超时特性，如果数据才规定的超时时间内没有消费者进行消费的话，就返回false。 LinkedBlockingDequeLinkedBlockingDeque是基于链表数据结构的有界阻塞双端队列，如果在创建对象时未指定大小时，其默认大小为Integer.MAX_VALUE。与LinkedBlockingQueue相比，主要的不同点在于，LinkedBlockingDeque具有双端队列的特性。LinkedBlockingDeque基本操作如下图所示（来源于java文档） 如上图所示，LinkedBlockingDeque的基本操作可以分为四种类型：1.特殊情况，抛出异常；2.特殊情况，返回特殊值如null或者false；3.当线程不满足操作条件时，线程会被阻塞直至条件满足；4. 操作具有超时特性。 另外，LinkedBlockingDeque实现了BlockingDueue接口而LinkedBlockingQueue实现的是BlockingQueue，这两个接口的主要区别如下图所示（来源于java文档）： 从上图可以看出，两个接口的功能是可以等价使用的，比如BlockingQueue的add方法和BlockingDeque的addLast方法的功能是一样的。 DelayQueueDelayQueue是一个存放实现Delayed接口的数据的无界阻塞队列，只有当数据对象的延时时间达到时才能插入到队列进行存储。如果当前所有的数据都还没有达到创建时所指定的延时期，则队列没有队头，并且线程通过poll等方法获取数据元素则返回null。所谓数据延时期满时，则是通过Delayed接口的getDelay(TimeUnit.NANOSECONDS)来进行判定，如果该方法返回的是小于等于0则说明该数据元素的延时期已满。","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-BlockingQueue%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-ConcurrentHashMap(jdk1.8)介绍","text":"ConcurrentHashMap简介在使用HashMap时在多线程情况下扩容会出现CPU接近100%的情况，因为hashmap并不是线程安全的，通常我们可以使用在java体系中古老的hashtable类，该类基本上所有的方法都采用synchronized进行线程安全的控制，可想而知，在高并发的情况下，每次只有一个线程能够获取对象监视器锁，这样的并发性能的确不令人满意。 另外一种方式通过Collections的Map&lt;K,V&gt; synchronizedMap(Map&lt;K,V&gt; m)将hashmap包装成一个线程安全的map。比如SynchronzedMap的put方法源码为： 123public V put(K key, V value) { synchronized (mutex) {return m.put(key, value);}} 实际上SynchronizedMap实现依然是采用synchronized独占式锁进行线程安全的并发控制的。同样，这种方案的性能也是令人不太满意的。针对这种境况，Doug Lea大师不遗余力的为我们创造了一些线程安全的并发容器，让每一个java开发人员倍感幸福。相对于hashmap来说，ConcurrentHashMap就是线程安全的map，其中利用了锁分段的思想提高了并发度。 ConcurrentHashMap在JDK1.6的版本网上资料很多，有兴趣的可以去看看。JDK 1.6版本关键要素： segment继承了ReentrantLock充当锁的角色，为每一个segment提供了线程安全的保障； segment维护了哈希散列表的若干个桶，每个桶由HashEntry构成的链表。 而到了JDK 1.8的ConcurrentHashMap就有了很大的变化，光是代码量就足足增加了很多。1.8版本舍弃了segment，并且大量使用了synchronized，以及CAS无锁操作以保证ConcurrentHashMap操作的线程安全性。至于为什么不用ReentrantLock而是Synchronzied呢？实际上，synchronzied做了很多的优化，包括偏向锁，轻量级锁，重量级锁，可以依次向上升级锁状态，但不能降级（关于synchronized可以看这篇文章），因此，使用synchronized相较于ReentrantLock的性能会持平甚至在某些情况更优，具体的性能测试可以去网上查阅一些资料。另外，底层数据结构改变为采用数组+链表+红黑树的数据形式。 关键属性及类在了解ConcurrentHashMap的具体方法实现前，我们需要系统的来看一下几个关键的地方。 ConcurrentHashMap的关键属性 table 1volatile Node&lt;K,V&gt;[] table;//装载Node的数组 作为ConcurrentHashMap的数据容器，采用懒加载的方式，直到第一次插入数据的时候才会进行初始化操作，数组的大小总是为2的幂次方。 nextTable 1volatile Node&lt;K,V&gt;[] nextTable;//扩容时使用 平时为null，只有在扩容的时候才为非null sizeCtl 1volatile int sizeCtl; 该属性用来控制table数组的大小，根据是否初始化和是否正在扩容有几种情况：当值为负数时：如果为-1表示正在初始化，如果为-N则表示当前正有N-1个线程进行扩容操作；当值为正数时：如果当前数组为null的话表示table在初始化过程中，sizeCtl表示为需要新建数组的长度；若已经初始化了，表示当前数据容器（table数组）可用容量也可以理解成临界值（插入节点数超过了该临界值就需要扩容），具体指为数组的长度n 乘以 加载因子loadFactor；当值为0时：即数组长度为默认初始值。 sun.misc.Unsafe U在ConcurrentHashMapde的实现中可以看到大量的U.compareAndSwapXXXX的方法去修改ConcurrentHashMap的一些属性。这些方法实际上是利用了CAS算法保证了线程安全性，这是一种乐观策略，假设每一次操作都不会产生冲突，当且仅当冲突发生的时候再去尝试。而CAS操作依赖于现代处理器指令集，通过底层CMPXCHG指令实现。CAS(V,O,N)核心思想为：若当前变量实际值V与期望的旧值O相同，则表明该变量没被其他线程进行修改，因此可以安全的将新值N赋值给变量；若当前变量实际值V与期望的旧值O不相同，则表明该变量已经被其他线程做了处理，此时将新值N赋给变量操作就是不安全的，在进行重试。而在大量的同步组件和并发容器的实现中使用CAS是通过sun.misc.Unsafe类实现的，该类提供了一些可以直接操控内存和线程的底层操作，可以理解为java中的“指针”。该成员变量的获取是在静态代码块中： 12345678static { try { U = sun.misc.Unsafe.getUnsafe(); ....... } catch (Exception e) { throw new Error(e); }} ConcurrentHashMap中关键内部类 NodeNode类实现了Map.Entry接口，主要存放key-value对，并且具有next域 1234567static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; ......} 另外可以看出很多属性都是用volatile进行修饰的，也就是为了保证内存可见性。 TreeNode树节点，继承于承载数据的Node类。而红黑树的操作是针对TreeBin类的，从该类的注释也可以看出，也就是TreeBin会将TreeNode进行再一次封装 12345678static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; { TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; ......} TreeBin 这个类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象。 1234567891011static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; { TreeNode&lt;K,V&gt; root; volatile TreeNode&lt;K,V&gt; first; volatile Thread waiter; volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock ......} ForwardingNode 在扩容时才会出现的特殊节点，其key,value,hash全部为null。并拥有nextTable指针引用新的table数组。 12345678static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; { final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) { super(MOVED, null, null, null); this.nextTable = tab; } .....} CAS关键操作在上面我们提及到在ConcurrentHashMap中会大量使用CAS修改它的属性和一些操作。因此，在理解ConcurrentHashMap的方法前我们需要了解下面几个常用的利用CAS算法来保障线程安全的操作。 tabAt 1234// 该方法用来获取table数组中索引为i的Node元素。static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) { return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);} casTabAt 12345// 利用CAS操作设置table数组中索引为i的元素static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) { return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);} setTabAt 1234// 该方法用来设置table数组中索引为i的元素static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) { U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);} 重点方法讲解在熟悉上面的这核心信息之后，我们接下来就来依次看看几个常用的方法是怎样实现的。 实例构造器方法在使用ConcurrentHashMap第一件事自然而然就是new 出来一个ConcurrentHashMap对象，一共提供了如下几个构造器方法： 12345678910// 1. 构造一个空的map，即table数组还未初始化，初始化放在第一次插入数据时，默认大小为16ConcurrentHashMap()// 2. 给定map的大小ConcurrentHashMap(int initialCapacity) // 3. 给定一个mapConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m)// 4. 给定map的大小以及加载因子ConcurrentHashMap(int initialCapacity, float loadFactor)// 5. 给定map大小，加载因子以及并发度（预计同时操作数据的线程）ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel) ConcurrentHashMap一共给我们提供了5种构造器方法，具体使用请看注释，我们来看看第2种构造器，传入指定大小时的情况，该构造器源码为： 1234567891011public ConcurrentHashMap(int initialCapacity) { //1. 小于0直接抛异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(); //2. 判断是否超过了允许的最大值，超过了话则取最大值，否则再对该值进一步处理 int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); //3. 赋值给sizeCtl this.sizeCtl = cap;} 这段代码的逻辑请看注释，很容易理解，如果小于0就直接抛出异常，如果指定值大于了所允许的最大值的话就取最大值，否则，在对指定值做进一步处理。最后将cap赋值给sizeCtl，关于sizeCtl的说明请看上面的说明，当调用构造器方法之后，sizeCtl的大小应该就代表了ConcurrentHashMap的大小，即table数组长度。tableSizeFor做了哪些事情了？源码为： 12345678910111213/** * Returns a power of two table size for the given desired capacity. * See Hackers Delight, sec 3.2 */private static final int tableSizeFor(int c) { int n = c - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 通过注释就很清楚了，该方法会将调用构造器方法时指定的大小转换成一个2的幂次方数，也就是说ConcurrentHashMap的大小一定是2的幂次方，比如，当指定大小为18时，为了满足2的幂次方特性，实际上concurrentHashMapd的大小为2的5次方（32）。另外，需要注意的是，调用构造器方法的时候并未构造出table数组（可以理解为ConcurrentHashMap的数据容器），只是算出table数组的长度，当第一次向ConcurrentHashMap插入数据的时候才真正的完成初始化创建table数组的工作。 initTable方法直接上源码： 1234567891011121314151617181920212223242526private final Node&lt;K,V&gt;[] initTable() { Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) { if ((sc = sizeCtl) &lt; 0) // 1. 保证只有一个线程正在进行初始化操作 Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { if ((tab = table) == null || tab.length == 0) { // 2. 得出数组的大小 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) // 3. 这里才真正的初始化数组 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // 4. 计算数组中可用的大小：实际大小n*0.75（加载因子） sc = n - (n &gt;&gt;&gt; 2); } } finally { sizeCtl = sc; } break; } } return tab;} 代码的逻辑请见注释，有可能存在一个情况是多个线程同时走到这个方法中，为了保证能够正确初始化，在第1步中会先通过if进行判断，若当前已经有一个线程正在初始化即sizeCtl值变为-1，这个时候其他线程在If判断为true从而调用Thread.yield()让出CPU时间片。正在进行初始化的线程会调用U.compareAndSwapInt方法将sizeCtl改为-1即正在初始化的状态。另外还需要注意的事情是，在第四步中会进一步计算数组中可用的大小即为数组实际大小n乘以加载因子0.75，可以看看这里乘以0.75是怎么算的，0.75为四分之三，这里n - (n &gt;&gt;&gt; 2)是不是刚好是n-(1/4)n=(3/4)n，挺有意思的吧。如果选择是无参的构造器的话，这里在new Node数组的时候会使用默认大小为DEFAULT_CAPACITY（16），然后乘以加载因子0.75为12，也就是说数组的可用大小为12。 put方法使用ConcurrentHashMap最长用的也应该是put和get方法了吧，我们先来看看put方法是怎样实现的。调用put方法时实际具体实现是putVal方法，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); //1. 计算key的hash值 int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) { Node&lt;K,V&gt; f; int n, i, fh; //2. 如果当前table还没有初始化先调用initTable方法将tab进行初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); //3. tab中索引为i的位置的元素为null，则直接使用CAS将值插入即可 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin } //4. 当前正在扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; synchronized (f) { if (tabAt(tab, i) == f) { //5. 当前为链表，在链表中插入新的键值对 if (fh &gt;= 0) { binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) { pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; } } } // 6.当前为红黑树，将新的键值对插入到红黑树中 else if (f instanceof TreeBin) { Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } // 7.插入完键值对后再根据实际大小看是否需要转换成红黑树 if (binCount != 0) { if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } //8.对当前容量大小进行检查，如果超过了临界值（实际大小*加载因子）就需要扩容 addCount(1L, binCount); return null;} put方法的代码量有点长，我们按照上面的分解的步骤一步步来看。从整体而言，为了解决线程安全的问题，ConcurrentHashMap使用了synchronzied和CAS的方式。在之前了解过HashMap以及1.8版本之前的ConcurrenHashMap都应该知道ConcurrentHashMap结构图，为了方便下面的讲解这里先直接给出，如果对这有疑问的话，可以在网上随便搜搜即可。 如图（图片摘自网络），ConcurrentHashMap是一个哈希桶数组，如果不出现哈希冲突的时候，每个元素均匀的分布在哈希桶数组中。当出现哈希冲突的时候，是标准的链地址的解决方式，将hash值相同的节点构成链表的形式，称为“拉链法”，另外，在1.8版本中为了防止拉链过长，当链表的长度大于8的时候会将链表转换成红黑树。table数组中的每个元素实际上是单链表的头结点或者红黑树的根节点。当插入键值对时首先应该定位到要插入的桶，即插入table数组的索引i处。那么，怎样计算得出索引i呢？当然是根据key的hashCode值。 spread()重哈希，以减小Hash冲突 我们知道对于一个hash表来说，hash值分散的不够均匀的话会大大增加哈希冲突的概率，从而影响到hash表的性能。因此通过spread方法进行了一次重hash从而大大减小哈希冲突的可能性。spread方法为： 123static final int spread(int h) { return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;} 该方法主要是将key的hashCode的低16位于高16位进行异或运算，这样不仅能够使得hash值能够分散能够均匀减小hash冲突的概率，另外只用到了异或运算，在性能开销上也能兼顾，做到平衡的trade-off。 2.初始化table 紧接着到第2步，会判断当前table数组是否初始化了，没有的话就调用initTable进行初始化，该方法在上面已经讲过了。 3.能否直接将新值插入到table数组中 从上面的结构示意图就可以看出存在这样一种情况，如果插入值待插入的位置刚好所在的table数组为null的话就可以直接将值插入即可。那么怎样根据hash确定在table中待插入的索引i呢？很显然可以通过hash值与数组的长度取模操作，从而确定新值插入到数组的哪个位置。而之前我们提过ConcurrentHashMap的大小总是2的幂次方，(n - 1) &amp; hash运算等价于对长度n取模，也就是hash%n，但是位运算比取模运算的效率要高很多，Doug lea大师在设计并发容器的时候也是将性能优化到了极致，令人钦佩。 确定好数组的索引i后，就可以可以tabAt()方法（该方法在上面已经说明了，有疑问可以回过头去看看）获取该位置上的元素，如果当前Node f为null的话，就可以直接用casTabAt方法将新值插入即可。 4.当前是否正在扩容 如果当前节点不为null，且该节点为特殊节点（forwardingNode）的话，就说明当前concurrentHashMap正在进行扩容操作，关于扩容操作，下面会作为一个具体的方法进行讲解。那么怎样确定当前的这个Node是不是特殊的节点呢？是通过判断该节点的hash值是不是等于-1（MOVED），代码为(fh = f.hash) == MOVED，对MOVED的解释在源码上也写的很清楚了： 1static final int MOVED = -1; // hash for forwarding nodes 5.当table[i]为链表的头结点，在链表中插入新值 在table[i]不为null并且不为forwardingNode时，并且当前Node f的hash值大于0（fh &gt;= 0）的话说明当前节点f为当前桶的所有的节点组成的链表的头结点。那么接下来，要想向ConcurrentHashMap插入新值的话就是向这个链表插入新值。通过synchronized (f)的方式进行加锁以实现线程安全性。往链表中插入节点的部分代码为： 12345678910111213141516171819202122if (fh &gt;= 0) { binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; // 找到hash值相同的key,覆盖旧值即可 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) { //如果到链表末尾仍未找到，则直接将新值插入到链表末尾即可 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; } }} 这部分代码很好理解，就是两种情况：1. 在链表中如果找到了与待插入的键值对的key相同的节点，就直接覆盖即可；2. 如果直到找到了链表的末尾都没有找到的话，就直接将待插入的键值对追加到链表的末尾即可 6.当table[i]为红黑树的根节点，在红黑树中插入新值 按照之前的数组+链表的设计方案，这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，甚至在极端情况下，查找一个节点会出现时间复杂度为O(n)的情况，则会严重影响ConcurrentHashMap的性能，于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高ConcurrentHashMap的性能，其中会用到红黑树的插入、删除、查找等算法。当table[i]为红黑树的树节点时的操作为： 12345678910if (f instanceof TreeBin) { Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; }} 首先在if中通过f instanceof TreeBin判断当前table[i]是否是树节点，这下也正好验证了我们在最上面介绍时说的TreeBin会对TreeNode做进一步封装，对红黑树进行操作的时候针对的是TreeBin而不是TreeNode。这段代码很简单，调用putTreeVal方法完成向红黑树插入新节点，同样的逻辑，如果在红黑树中存在于待插入键值对的Key相同（hash值相等并且equals方法判断为true）的节点的话，就覆盖旧值，否则就向红黑树追加新节点。 7.根据当前节点个数进行调整 当完成数据新节点插入之后，会进一步对当前链表大小进行调整，这部分代码为： 1234567if (binCount != 0) { if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break;} 很容易理解，如果当前链表节点个数大于等于8（TREEIFY_THRESHOLD）的时候，就会调用treeifyBin方法将tabel[i]（第i个散列桶）拉链转换成红黑树。 至此，关于Put方法的逻辑就基本说的差不多了，现在来做一些总结： 整体流程： 首先对于每一个放入的值，首先利用spread方法对key的hashcode进行一次hash计算，由此来确定这个值在 table中的位置； 如果当前table数组还未初始化，先将table数组进行初始化操作； 如果这个位置是null的，那么使用CAS操作直接放入； 如果这个位置存在结点，说明发生了hash碰撞，首先判断这个节点的类型。如果该节点fh==MOVED(代表forwardingNode，数组正在进行扩容)的话，说明正在进行扩容； 如果是链表节点（fh&gt;0），则得到的结点就是hash值相同的节点组成的链表的头节点。需要依次向后遍历确定这个新加入的值所在位置。如果遇到key相同的节点，则只需要覆盖该结点的value值即可。否则依次向后遍历，直到链表尾插入这个结点； 如果这个节点的类型是TreeBin的话，直接调用红黑树的插入方法进行插入新的节点； 插入完节点之后再次检查链表长度，如果长度大于8，就把这个链表转换成红黑树； 对当前容量大小进行检查，如果超过了临界值（实际大小*加载因子）就需要扩容。 get方法看完了put方法再来看get方法就很容易了，用逆向思维去看就好，这样存的话我反过来这么取就好了。get方法源码为： 1234567891011121314151617181920212223public V get(Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // 1. 重hash int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) { // 2. table[i]桶节点的key与查找的key相同，则直接返回 if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; } // 3. 当前节点hash小于0说明为树节点，在红黑树中查找即可 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) { //4. 从链表中查找，查找到则返回该节点的value，否则就返回null即可 if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; } } return null;} 代码的逻辑请看注释，首先先看当前的hash桶数组节点即table[i]是否为查找的节点，若是则直接返回；若不是，则继续再看当前是不是树节点？通过看节点的hash值是否为小于0，如果小于0则为树节点。如果是树节点在红黑树中查找节点；如果不是树节点，那就只剩下为链表的形式的一种可能性了，就向后遍历查找节点，若查找到则返回节点的value即可，若没有找到就返回null。 transfer方法当ConcurrentHashMap容量不足的时候，需要对table进行扩容。这个方法的基本思想跟HashMap是很像的，但是由于它是支持并发扩容的，所以要复杂的多。原因是它支持多线程进行扩容操作，而并没有加锁。我想这样做的目的不仅仅是为了满足concurrent的要求，而是希望利用并发处理去减少扩容带来的时间影响。transfer方法源码为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) { int n = tab.length, stride; if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range //1. 新建Node数组，容量为之前的两倍 if (nextTab == null) { // initiating try { @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; } catch (Throwable ex) { // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; } nextTable = nextTab; transferIndex = n; } int nextn = nextTab.length; //2. 新建forwardingNode引用，在之后会用到 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) { Node&lt;K,V&gt; f; int fh; // 3. 确定遍历中的索引i while (advance) { int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) { i = -1; advance = false; } else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) { bound = nextBound; i = nextIndex - 1; advance = false; } } //4.将原数组中的元素复制到新数组中去 //4.5 for循环退出，扩容结束修改sizeCtl属性 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) { int sc; if (finishing) { nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; } if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) { if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit } } //4.1 当前数组中第i个元素为null，用CAS设置成特殊节点forwardingNode(可以理解成占位符) else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); //4.2 如果遍历到ForwardingNode节点 说明这个点已经被处理过了 直接跳过 这里是控制并发扩容的核心 else if ((fh = f.hash) == MOVED) advance = true; // already processed else { synchronized (f) { if (tabAt(tab, i) == f) { Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) { //4.3 处理当前节点为链表的头结点的情况，构造两个链表，一个是原链表 另一个是原链表的反序排列 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) { int b = p.hash &amp; n; if (b != runBit) { runBit = b; lastRun = p; } } if (runBit == 0) { ln = lastRun; hn = null; } else { hn = lastRun; ln = null; } for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) { int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); } //在nextTable的i位置上插入一个链表 setTabAt(nextTab, i, ln); //在nextTable的i+n的位置上插入另一个链表 setTabAt(nextTab, i + n, hn); //在table的i位置上插入forwardNode节点 表示已经处理过该节点 setTabAt(tab, i, fwd); //设置advance为true 返回到上面的while循环中 就可以执行i--操作 advance = true; } //4.4 处理当前节点是TreeBin时的情况，操作和上面的类似 else if (f instanceof TreeBin) { TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) { int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) { if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; } else { if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; } } ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } } } } }} 代码逻辑请看注释,整个扩容操作分为两个部分： 第一部分是构建一个nextTable,它的容量是原来的两倍，这个操作是单线程完成的。新建table数组的代码为:Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1],在原容量大小的基础上右移一位。 第二个部分就是将原来table中的元素复制到nextTable中，主要是遍历复制的过程。根据运算得到当前遍历的数组的位置i，然后利用tabAt方法获得i位置的元素再进行判断： 如果这个位置为空，就在原table中的i位置放入forwardNode节点，这个也是触发并发扩容的关键点； 如果这个位置是Node节点（fh&gt;=0），如果它是一个链表的头节点，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上 如果这个位置是TreeBin节点（fh&lt;0），也做一个反序处理，并且判断是否需要untreefi，把处理的结果分别放在nextTable的i和i+n的位置上 遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。设置为新容量的0.75倍代码为 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1)，仔细体会下是不是很巧妙，n&lt;&lt;1相当于n右移一位表示n的两倍即2n，n&gt;&gt;&gt;1左右一位相当于n除以2即0.5n,然后两者相减为2n-0.5n=1.5n，是不是刚好等于新容量的0.75倍即2n*0.75=1.5n。最后用一个示意图来进行总结（图片摘自网络）： 与size相关的一些方法对于ConcurrentHashMap来说，这个table里到底装了多少东西其实是个不确定的数量，因为不可能在调用size()方法的时候像GC的“stop the world”一样让其他线程都停下来让你去统计，因此只能说这个数量是个估计值。对于这个估计值，ConcurrentHashMap也是大费周章才计算出来的。 为了统计元素个数，ConcurrentHashMap定义了一些变量和一个内部类 1234567891011121314151617181920212223242526/** * A padded cell for distributing counts. Adapted from LongAdder * and Striped64. See their internal docs for explanation. */@sun.misc.Contended static final class CounterCell { volatile long value; CounterCell(long x) { value = x; }}/******************************************/ /** * 实际上保存的是hashmap中的元素个数 利用CAS锁进行更新 但它并不用返回当前hashmap的元素个数 */private transient volatile long baseCount;/** * Spinlock (locked via CAS) used when resizing and/or creating CounterCells. */private transient volatile int cellsBusy;/** * Table of counter cells. When non-null, size is a power of 2. */private transient volatile CounterCell[] counterCells; mappingCount与size方法 mappingCount与size方法的类似从给出的注释来看，应该使用mappingCount代替size方法 两个方法都没有直接返回basecount 而是统计一次这个值，而这个值其实也是一个大概的数值，因此可能在统计的时候有其他线程正在执行插入或删除操作。 1234567891011121314151617181920212223242526272829303132public int size() { long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);} /** * Returns the number of mappings. This method should be used * instead of {@link #size} because a ConcurrentHashMap may * contain more mappings than can be represented as an int. The * value returned is an estimate; the actual count may differ if * there are concurrent insertions or removals. * * @return the number of mappings * @since 1.8 */public long mappingCount() { long n = sumCount(); return (n &lt; 0L) ? 0L : n; // ignore transient negative values} final long sumCount() { CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) { for (int i = 0; i &lt; as.length; ++i) { if ((a = as[i]) != null) sum += a.value;//所有counter的值求和 } } return sum;} addCount方法 在put方法结尾处调用了addCount方法，把当前ConcurrentHashMap的元素个数+1这个方法一共做了两件事，更新baseCount的值，检测是否进行扩容。 123456789101112131415161718192021222324252627282930313233343536373839404142private final void addCount(long x, int check) { CounterCell[] as; long b, s; //利用CAS方法更新baseCount的值 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) { CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) { fullAddCount(x, uncontended); return; } if (check &lt;= 1) return; s = sumCount(); } //如果check值大于等于0 则需要检验是否需要进行扩容操作 if (check &gt;= 0) { Node&lt;K,V&gt;[] tab, nt; int n, sc; while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) { int rs = resizeStamp(n); // if (sc &lt; 0) { if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //如果已经有其他线程在执行扩容操作 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); } //当前线程是唯一的或是第一个发起扩容的线程 此时nextTable=null else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); } }} 总结JDK6，7中的ConcurrentHashmap主要使用Segment来实现减小锁粒度，分割成若干个Segment，在put的时候需要锁住Segment，get时候不加锁，使用volatile来保证可见性，当要统计全局时（比如size），首先会尝试多次计算modcount来确定，这几次尝试中，是否有其他线程进行了修改操作，如果没有，则直接返回size。如果有，则需要依次锁住所有的Segment来计算。 1.8之前put定位节点时要先定位到具体的segment，然后再在segment中定位到具体的桶。而在1.8的时候摒弃了segment臃肿的设计，直接针对的是Node[] tale数组中的每一个桶，进一步减小了锁粒度。并且防止拉链过长导致性能下降，当链表长度大于8的时候采用红黑树的设计。 主要设计上的变化有以下几点: 不采用segment而采用node，锁住node来实现减小锁粒度。 设计了MOVED状态 当resize的中过程中 线程2还在put数据，线程2会帮助resize。 使用3个CAS操作来确保node的一些操作的原子性，这种方式代替了锁。 sizeCtl的不同值来代表不同含义，起到了控制的作用。 采用synchronized而不是ReentrantLock","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-ConcurrentHashMap-jdk1-8-%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-ConcurrentLinkedQueue介绍","text":"ConcurrentLinkedQueue简介在单线程编程中我们会经常用到一些集合类，比如ArrayList，HashMap等，但是这些类都不是线程安全的类。在面试中也经常会有一些考点，比如ArrayList不是线程安全的，Vector是线程安全。而保障Vector线程安全的方式，是非常粗暴的在方法上用synchronized独占锁，将多线程执行变成串行化。要想将ArrayList变成线程安全的也可以使用Collections.synchronizedList(List&lt;T&gt; list)方法ArrayList转换成线程安全的，但这种转换方式依然是通过synchronized修饰方法实现的，很显然这不是一种高效的方式，同时，队列也是我们常用的一种数据结构，为了解决线程安全的问题，Doug Lea大师为我们准备了ConcurrentLinkedQueue这个线程安全的队列。从类名就可以看的出来实现队列的数据结构是链式。 Node要想先学习ConcurrentLinkedQueue自然而然得先从它的节点类看起，明白它的底层数据结构。Node类的源码为： 12345private static class Node&lt;E&gt; { volatile E item; volatile Node&lt;E&gt; next; .......} Node节点主要包含了两个域：一个是数据域item，另一个是next指针，用于指向下一个节点从而构成链式队列。并且都是用volatile进行修饰的，以保证内存可见性（关于volatile可以看这篇文章）。另外ConcurrentLinkedQueue含有这样两个成员变量： 12private transient volatile Node&lt;E&gt; head;private transient volatile Node&lt;E&gt; tail; 说明ConcurrentLinkedQueue通过持有头尾指针进行管理队列。当我们调用无参构造器时，其源码为： 123public ConcurrentLinkedQueue() { head = tail = new Node&lt;E&gt;(null);} head和tail指针会指向一个item域为null的节点，此时ConcurrentLinkedQueue状态如下图所示： 如图，head和tail指向同一个节点Node0，该节点item域为null，next域为null。 操作Node的几个CAS操作在队列进行出队入队的时候免不了对节点需要进行操作，在多线程就很容易出现线程安全的问题。可以看出在处理器指令集能够支持CMPXCHG指令后，在java源码中涉及到并发处理都会使用CAS操作(关于CAS操作可以看这篇文章)，那么在ConcurrentLinkedQueue对Node的CAS操作有这样几个： 123456789101112//更改Node中的数据域item boolean casItem(E cmp, E val) { return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val);}//更改Node中的指针域nextvoid lazySetNext(Node&lt;E&gt; val) { UNSAFE.putOrderedObject(this, nextOffset, val);}//更改Node中的指针域nextboolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) { return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val);} 可以看出这些方法实际上是通过调用UNSAFE实例的方法，UNSAFE为sun.misc.Unsafe类，该类是hotspot底层方法，目前为止了解即可，知道CAS的操作归根结底是由该类提供就好。 offer方法对一个队列来说，插入满足FIFO特性，插入元素总是在队列最末尾的地方进行插入，而取（移除）元素总是从队列的队头。所有要想能够彻底弄懂ConcurrentLinkedQueue自然而然是从offer方法和poll方法开始。那么为了能够理解offer方法，采用debug的方式来一行一行的看代码走。另外，在看多线程的代码时，可采用这样的思维方式： 单个线程offer多个线程offer部分线程offer，部分线程poll offer的速度快于poll 队列长度会越来越长，由于offer节点总是在对队列队尾，而poll节点总是在队列对头，也就是说offer线程和poll线程两者并无“交集”，也就是说两类线程间并不会相互影响，这种情况站在相对速率的角度来看，也就是一个”单线程offer” offer的速度慢于poll poll的相对速率快于offer，也就是队头删的速度要快于队尾添加节点的速度，导致的结果就是队列长度会越来越短，而offer线程和poll线程就会出现“交集”，即那一时刻就可以称之为offer线程和poll线程同时操作的节点为 临界点 ，且在该节点offer线程和poll线程必定相互影响。根据在临界点时offer和poll发生的相对顺序又可从两个角度去思考： 1. 执行顺序为offer–&gt;poll–&gt;offer，即表现为当offer线程在Node1后插入Node2时，此时poll线程已经将Node1删除，这种情况很显然需要在offer方法中考虑； 2.执行顺序可能为：poll–&gt;offer–&gt;poll，即表现为当poll线程准备删除的节点为null时（队列为空队列），此时offer线程插入一个节点使得队列变为非空队列 先看这么一段代码： 123ConcurrentLinkedQueue&lt;Integer&gt; queue = new ConcurrentLinkedQueue&lt;&gt;();queue.offer(1);queue.offer(2); 创建一个ConcurrentLinkedQueue实例，先offer 1，然后再offer 2。offer的源码为： 1234567891011121314151617181920212223242526272829public boolean offer(E e) { checkNotNull(e); // 1 final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); // 2 // for (Node&lt;E&gt; t = tail, p = t;;) { // 3 Node&lt;E&gt; q = p.next; // 4 if (q == null) { // 5 // p is last node // 6 if (p.casNext(null, newNode)) { // 7 // Successful CAS is the linearization point // // for e to become an element of this queue, // // and for newNode to become &quot;live&quot;. // if (p != t) // hop two nodes at a time // 8 casTail(t, newNode); // Failure is OK. // 9 return true; // 10 } // // Lost CAS race to another thread; re-read next // } // else if (p == q) // 11 // We have fallen off list. If tail is unchanged, it // // will also be off-list, in which case we need to // // jump to head, from which all live nodes are always // // reachable. Else the new tail is a better bet. // p = (t != (t = tail)) ? t : head; // 12 else // // Check for tail updates after two hops. // p = (p != t &amp;&amp; t != (t = tail)) ? t : q; // 13 }} 单线程执行角度分析： 先从单线程执行的角度看起，分析offer 1的过程。第1行代码会对是否为null进行判断，为null的话就直接抛出空指针异常，第2行代码将e包装成一个Node类，第3行为for循环，只有初始化条件没有循环结束条件，这很符合CAS的“套路”，在循环体CAS操作成功会直接return返回，如果CAS操作失败的话就在for循环中不断重试直至成功。这里实例变量t被初始化为tail，p被初始化为t即tail。为了方便下面的理解，p被认为队列真正的尾节点，tail不一定指向对象真正的尾节点，因为在ConcurrentLinkedQueue中tail是被延迟更新的，具体原因我们慢慢来看。代码走到第3行的时候，t和p都分别指向初始化时创建的item域为null，next域为null的Node0。第4行变量q被赋值为null，第5行if判断为true，在第7行使用casNext将插入的Node设置成当前队列尾节点p的next节点，如果CAS操作失败，此次循环结束在下次循环中进行重试。CAS操作成功走到第8行，此时p==t，if判断为false，直接return true返回。如果成功插入1的话，此时ConcurrentLinkedQueue的状态如下图所示： 如图，此时队列的尾节点应该为Node1，而tail指向的节点依然还是Node0，因此可以说明tail是延迟更新的。那么我们继续来看offer 2的时候的情况，很显然此时第4行q指向的节点不为null了，而是指向Node1，第5行if判断为false，第11行if判断为false,代码会走到第13行。好了，再插入节点的时候我们会问自己这样一个问题？上面已经解释了tail并不是指向队列真正的尾节点，那么在插入节点的时候，我们是不是应该最开始做的就是找到队列当前的尾节点在哪里才能插入？那么第13行代码就是找出队列真正的尾节点。 定位队列真正的对尾节点 1p = (p != t &amp;&amp; t != (t = tail)) ? t : q; 我们来分析一下这行代码，如果这段代码在单线程环境执行时，很显然由于p==t，此时p会被赋值为q，而q等于Node&lt;E&gt; q = p.next，即Node1。在第一次循环中指针p指向了队列真正的队尾节点Node1，那么在下一次循环中第4行q指向的节点为null，那么在第5行中if判断为true,那么在第7行依然通过casNext方法设置p节点的next为当前新增的Node，接下来走到第8行，这个时候p!=t，第8行if判断为true，会通过casTail(t, newNode)将当前节点Node设置为队列的队尾节点,此时的队列状态示意图如下图所示： tail指向的节点由Node0改变为Node2，这里的casTail失败不需要重试的原因是，offer代码中主要是通过p的next节点q(Node&lt;E&gt; q = p.next)决定后面的逻辑走向的，当casTail失败时状态示意图如下： 如图，如果这里casTail设置tail失败即tail还是指向Node0节点的话，无非就是多循环几次通过13行代码定位到队尾节点。 通过对单线程执行角度进行分析，我们可以了解到poll的执行逻辑为： 如果tail指向的节点的下一个节点（next域）为null的话，说明tail指向的节点即为队列真正的队尾节点，因此可以通过casNext插入当前待插入的节点，但此时tail并未变化 如果tail指向的节点的下一个节点（next域）不为null的话，说明tail指向的节点不是队列的真正队尾节点。通过q（Node&lt;E&gt; q = p.next）指针往前递进去找到队尾节点，然后通过casNext插入当前待插入的节点，并通过casTail方式更改tail。 我们回过头再来看p = (p != t &amp;&amp; t != (t = tail)) ? t : q;这行代码在单线程中，这段代码永远不会将p赋值为t，那么这么写就不会有任何作用，那我们试着在多线程的情况下进行分析。 多线程执行角度分析 多个线程offer 很显然这么写另有深意，其实在多线程环境下这行代码很有意思的。 t != (t = tail)这个操作并非一个原子操作，有这样一种情况： 如图，假设线程A此时读取了变量t，线程B刚好在这个时候offer一个Node后，此时会修改tail指针，那么这个时候线程A再次执行t=tail时t会指向另外一个节点，很显然线程A前后两次读取的变量t指向的节点不相同，即t != (t = tail)为true，并且由于t指向节点的变化p != t也为true，此时该行代码的执行结果为p和t最新的t指针指向了同一个节点，并且此时t也是队列真正的对尾节点。那么，现在已经定位到队列真正的队尾节点，就可以执行offer操作了。 offer-&gt;poll-&gt;offer 那么还剩下第11行的代码我们没有分析，大致可以猜想到应该就是回答一部分线程offer，一部分poll的这种情况。当if (p == q)为true时，说明p指向的节点的next也指向它自己，这种节点称之为哨兵节点，这种节点在队列中存在的价值不大，一般表示为要删除的节点或者是空节点。为了能够很好的理解这种情况，我们先看看poll方法的执行过程后，再回过头来看，总之这是一个很有意思的事情。 poll方法poll方法源码如下： 123456789101112131415161718192021222324public E poll() { restartFromHead: for (; ; ) { // 1. for (Node&lt;E&gt; h = head, p = h, q; ; ) { // 2. E item = p.item; // 3. // if (item != null &amp;&amp; p.casItem(item, null)) { // 4. // Successful CAS is the linearization point // // for item to be removed from this queue. // if (p != h) // hop two nodes at a time // 5. updateHead(h, ((q = p.next) != null) ? q : p); // 6. return item; // 7. } // else if ((q = p.next) == null) { // 8. updateHead(h, p); // 9. return null; // 10. } // else if (p == q) // 11. continue restartFromHead; // 12. else // p = q; // 13. } }} 我们还是先站在单线程的角度去理清该方法的基本逻辑。假设ConcurrentLinkedQueue初始状态如下图所示： 参数offer时的定义，我们还是先将变量p作为队列要删除真正的队头节点，h（head）指向的节点并不一定是队列的队头节点。先来看poll出Node1时的情况，由于p=h=head，参照上图，很显然此时p指向的Node1的数据域不为null,在第4行代码中item!=null判断为true后接下来通过casItem将Node1的数据域设置为null。如果CAS设置失败则此次循环结束等待下一次循环进行重试。若第4行执行成功进入到第5行代码，此时p和h都指向Node1,第5行if判断为false，然后直接到第7行return回Node1的数据域1，方法运行结束，此时的队列状态如下图。 下面继续从队列中poll，很显然当前h和p指向的Node1的数据域为null，那么第一件事就是要**定位准备删除的队头节点(找到数据域不为null的节点)**。 定位删除的队头节点 继续看，第三行代码item为null，第4行代码if判断为false,走到第8行代码（q = p.next）if也为false，由于q指向了Node2，在第11行的if判断也为false，因此代码走到了第13行，这个时候p和q共同指向了Node2,也就找到了要删除的真正的队头节点。可以总结出，定位待删除的队头节点的过程为：如果当前节点的数据域为null，很显然该节点不是待删除的节点，就用当前节点的下一个节点去试探。在经过第一次循环后，此时状态图为下图： 进行下一次循环，第4行的操作同上述，当前假设第4行中casItem设置成功，由于p已经指向了Node2，而h还依旧指向Node1，此时第5行的if判断为true，然后执行updateHead(h, ((q = p.next) != null) ? q : p)，此时q指向的Node3，所有传入updateHead方法的分别是指向Node1的h引用和指向Node3的q引用。updateHead方法的源码为： 1234final void updateHead(Node&lt;E&gt; h, Node&lt;E&gt; p) { if (h != p &amp;&amp; casHead(h, p)) h.lazySetNext(h);} 该方法主要是通过casHead将队列的head指向Node3，并且通过 h.lazySetNext将Node1的next域指向它自己。最后在第7行代码中返回Node2的值。此时队列的状态如下图所示： Node1的next域指向它自己，head指向了Node3。如果队列为空队列的话，就会执行到代码的第8行(q = p.next) == null，if判断为true,因此在第10行中直接返回null。以上的分析是从单线程执行的角度去看，也可以让我们了解poll的整体思路，现在来做一个总结： 如果当前head,h和p指向的节点的Item不为null的话，说明该节点即为真正的队头节点（待删除节点），只需要通过casItem方法将item域设置为null,然后将原来的item直接返回即可。 如果当前head,h和p指向的节点的item为null的话，则说明该节点不是真正的待删除节点，那么应该做的就是寻找item不为null的节点。通过让q指向p的下一个节点（q = p.next）进行试探，若找到则通过updateHead方法更新head指向的节点以及构造哨兵节点（通过updateHead方法的h.lazySetNext(h)）。 接下来，按照上面分析offer的思维方式，下面来分析一下多线程的情况，第一种情况是； 多线程执行情况分析： 多个线程poll 现在回过头来看poll方法的源码，有这样一部分： 12else if (p == q) continue restartFromHead; 这一部分就是处理多个线程poll的情况，q = p.next也就是说q永远指向的是p的下一个节点，那么什么情况下会使得p,q指向同一个节点呢？根据上面我们的分析，只有p指向的节点在poll的时候转变成了哨兵节点（通过updateHead方法中的h.lazySetNext）。当线程A在判断p==q时，线程B已经将执行完poll方法将p指向的节点转换为哨兵节点并且head指向的节点已经发生了改变，所以就需要从restartFromHead处执行，保证用到的是最新的head。 poll-&gt;offer-&gt;poll 试想，还有这样一种情况，如果当前队列为空队列，线程A进行poll操作，同时线程B执行offer，然后线程A在执行poll，那么此时线程A返回的是null还是线程B刚插入的最新的那个节点呢？我们来写一代demo： 123456789101112public static void main(String[] args) { Thread thread1 = new Thread(() -&gt; { Integer value = queue.poll(); System.out.println(Thread.currentThread().getName() + &quot; poll 的值为：&quot; + value); System.out.println(&quot;queue当前是否为空队列：&quot; + queue.isEmpty()); }); thread1.start(); Thread thread2 = new Thread(() -&gt; { queue.offer(1); }); thread2.start();} 输出结果为： Thread-0 poll 的值为：nullqueue当前是否为空队列：false 通过debug控制线程thread1和线程thread2的执行顺序，thread1先执行到第8行代码if ((q = p.next) == null)，由于此时队列为空队列if判断为true，进入if块，此时先让thread1暂停，然后thread2进行offer插入值为1的节点后，thread2执行结束。再让thread1执行，这时thread1并没有进行重试，而是代码继续往下走，返回null，尽管此时队列由于thread2已经插入了值为1的新的节点。所以输出结果为thread0 poll的为null，然队列不为空队列。因此，在判断队列是否为空队列的时候是不能通过线程在poll的时候返回为null进行判断的，可以通过isEmpty方法进行判断。 offer方法中部分线程offer部分线程poll在分析offer方法的时候我们还留下了一个问题，即对offer方法中第11行代码的理解。 offer-&gt;poll-&gt;offer 在offer方法的第11行代码if (p == q)，能够让if判断为true的情况为p指向的节点为哨兵节点，而什么时候会构造哨兵节点呢？在对poll方法的讨论中，我们已经找到了答案，即当head指向的节点的item域为null时会寻找真正的队头节点，等到待插入的节点插入之后，会更新head，并且将原来head指向的节点设置为哨兵节点。假设队列初始状态如下图所示：因此在线程A执行offer时，线程B执行poll就会存在如下一种情况： 如图，线程A的tail节点存在next节点Node1，因此会通过引用q往前寻找队列真正的队尾节点，当执行到判断if (p == q)时，此时线程B执行poll操作，在对线程B来说，head和p指向Node0，由于Node0的item域为null,同样会往前递进找到队列真正的队头节点Node1，在线程B执行完poll之后，Node0就会转换为哨兵节点，也就意味着队列的head发生了改变，此时队列状态为下图。 此时线程A在执行判断if (p == q)时就为true,会继续执行p = (t != (t = tail)) ? t : head;，由于tail指针没有发生改变所以p被赋值为head,重新从head开始完成插入操作。 HOPS的设计通过上面对offer和poll方法的分析，我们发现tail和head是延迟更新的，两者更新触发时机为： tail更新触发时机：当tail指向的节点的下一个节点不为null的时候，会执行定位队列真正的队尾节点的操作，找到队尾节点后完成插入之后才会通过casTail进行tail更新；当tail指向的节点的下一个节点为null的时候，只插入节点不更新tail。 head更新触发时机：当head指向的节点的item域为null的时候，会执行定位队列真正的队头节点的操作，找到队头节点后完成删除之后才会通过updateHead进行head更新；当head指向的节点的item域不为null的时候，只删除节点不更新head。 并且在更新操作时，源码中会有注释为：hop two nodes at a time。所以这种延迟更新的策略就被叫做HOPS的大概原因是这个（猜的 😃），从上面更新时的状态图可以看出，head和tail的更新是“跳着的”即中间总是间隔了一个。那么这样设计的意图是什么呢？ 如果让tail永远作为队列的队尾节点，实现的代码量会更少，而且逻辑更易懂。但是，这样做有一个缺点，如果大量的入队操作，每次都要执行CAS进行tail的更新，汇总起来对性能也会是大大的损耗。如果能减少CAS更新的操作，无疑可以大大提升入队的操作效率，所以doug lea大师每间隔1次（tail和队尾节点的距离为1）进行才利用CAS更新tail。对head的更新也是同样的道理，虽然，这样设计会多出在循环中定位队尾节点，但总体来说读的操作效率要远远高于写的性能，因此，多出来的在循环中定位尾节点的操作的性能损耗相对而言是很小的。 参考资料 《java并发编程的艺术》 《Java高并发程序设计》 ConcurrentLinkedQueue","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-ConcurrentLinkedQueue%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-Condition介绍及其等待通知机制","text":"Condition简介任何一个java对象都天然继承于Object类，在线程间实现通信的往往会应用到Object的几个方法，比如wait(),wait(long timeout),wait(long timeout, int nanos)与notify(),notifyAll()几个方法实现等待/通知机制，同样的， 在java Lock体系下依然会有同样的方法实现等待/通知机制。 从整体上来看Object的wait和notify/notifyAll是与对象监视器配合完成线程间的等待/通知机制，而Condition与Lock配合完成等待/通知机制，前者是java底层级别的，后者是语言级别的，具有更高的可控制性和扩展性。两者除了在使用方式上不同外，在功能特性上还是有很多的不同： Condition能够支持多个等待队列（new 多个Condition对象），而Object方式只能支持一个； Condition能够支持不响应中断，而通过使用Object方式不支持； Condition能够支持超时时间的设置，而Object不支持 参照Object的wait和notify/notifyAll方法，Condition也提供了同样的方法： 针对Object的wait方法 void await() throws InterruptedException:当前线程进入等待状态，如果其他线程调用condition的signal或者signalAll方法并且当前线程获取Lock从await方法返回，如果在等待状态中被中断会抛出被中断异常； long awaitNanos(long nanosTimeout)：当前线程进入等待状态直到被通知，中断或者超时； boolean await(long time, TimeUnit unit)throws InterruptedException：同第二种，支持自定义时间单位 boolean awaitUntil(Date deadline) throws InterruptedException：当前线程进入等待状态直到被通知，中断或者到了某个时间 针对Object的notify/notifyAll方法 void signal()：唤醒一个等待在condition上的线程，将该线程从等待队列中转移到同步队列中，如果在同步队列中能够竞争到Lock则可以从等待方法中返回。 void signalAll()：与1的区别在于能够唤醒所有等待在condition上的线程 Condition实现原理分析等待队列要想能够深入的掌握condition还是应该知道它的实现原理，现在我们一起来看看condiiton的源码。创建一个condition对象是通过lock.newCondition()，而这个方法实际上是会new出一个ConditionObject对象，该类是AQS（AQS的实现原理的文章）的一个内部类，有兴趣可以去看看。前面我们说过，condition是要和lock配合使用的，也就是condition和Lock是绑定在一起的，而lock的实现原理又依赖于AQS，自然而然ConditionObject作为AQS的一个内部类无可厚非。我们知道在锁机制的实现上，AQS内部维护了一个同步队列，如果是独占式锁的话，所有获取锁失败的线程将会尾插入到同步队列，同样的，condition内部也是使用同样的方式，内部维护了一个 等待队列，所有调用condition.await方法的线程会加入到等待队列中，并且线程状态转换为等待状态。另外注意到ConditionObject中有两个成员变量： 1234/** First node of condition queue. */private transient Node firstWaiter;/** Last node of condition queue. */private transient Node lastWaiter; 这样我们就可以看出来ConditionObject通过持有等待队列的头尾指针来管理等待队列。主要注意的是Node类复用了在AQS中的Node类，其节点状态和相关属性可以去看AQS的实现原理的文章，如果您仔细看完这篇文章对condition的理解易如反掌，对lock体系的实现也会有一个质的提升。Node类有这样一个属性： 12//后继节点Node nextWaiter; 进一步说明，等待队列是一个单向队列，而在之前说AQS时知道同步队列是一个双向队列。接下来我们用一个demo，通过debug进去看是不是符合我们的猜想： 123456789101112131415public static void main(String[] args) { for (int i = 0; i &lt; 10; i++) { Thread thread = new Thread(() -&gt; { lock.lock(); try { condition.await(); } catch (InterruptedException e) { e.printStackTrace(); }finally { lock.unlock(); } }); thread.start(); }} 这段代码没有任何实际意义，甚至很臭，只是想说明下我们刚才所想的。新建了10个线程，没有线程先获取锁，然后调用condition.await方法释放锁将当前线程加入到等待队列中，通过debug控制当走到第10个线程的时候查看firstWaiter即等待队列中的头结点，debug模式下情景图如下： 从这个图我们可以很清楚的看到这样几点：1. 调用condition.await方法后线程依次尾插入到等待队列中，如图队列中的线程引用依次为Thread-0,Thread-1,Thread-2…Thread-8；2. 等待队列是一个单向队列。通过我们的猜想然后进行实验验证，我们可以得出等待队列的示意图如下图所示： 同时还有一点需要注意的是：我们可以多次调用lock.newCondition()方法创建多个condition对象，也就是一个lock可以持有多个等待队列。而在之前利用Object的方式实际上是指在对象Object对象监视器上只能拥有一个同步队列和一个等待队列，而并发包中的Lock拥有一个同步队列和多个等待队列。示意图如下： 如图所示，ConditionObject是AQS的内部类，因此每个ConditionObject能够访问到AQS提供的方法，相当于每个Condition都拥有所属同步器的引用。 await实现原理当调用condition.await()方法后会使得当前获取lock的线程进入到等待队列，如果该线程能够从await()方法返回的话一定是该线程获取了与condition相关联的lock。接下来，我们还是从源码的角度去看，只有熟悉了源码的逻辑我们的理解才是最深的。await()方法源码为： 1234567891011121314151617181920212223public final void await() throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); // 1. 将当前线程包装成Node，尾插入到等待队列中 Node node = addConditionWaiter(); // 2. 释放当前线程所占用的lock，在释放的过程中会唤醒同步队列中的下一个节点 int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) {//当前线程是否是处于同步队列中，是：跳出循环 // 3. 当前线程进入到等待状态 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 4. 自旋等待获取到同步状态（即获取到lock） if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // 5. 处理被中断的情况 if (interruptMode != 0) reportInterruptAfterWait(interruptMode);} 代码的主要逻辑请看注释，我们都知道当前线程调用condition.await()方法后，会使得当前线程释放lock然后加入到等待队列中，直至被signal/signalAll后会使得当前线程从等待队列中移至到同步队列中去，直到获得了lock后才会从await方法返回，或者在等待时被中断会做中断处理。那么关于这个实现过程我们会有这样几个问题：1. 是怎样将当前线程添加到等待队列中去的？2.释放锁的过程？3.怎样才能从await方法退出？而这段代码的逻辑就是告诉我们这三个问题的答案。具体请看注释，在第1步中调用addConditionWaiter将当前线程添加到等待队列中，该方法源码为： 123456789101112131415161718private Node addConditionWaiter() { Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) { unlinkCancelledWaiters(); t = lastWaiter; } //将当前线程包装成Node Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else //尾插入 t.nextWaiter = node; //更新lastWaiter lastWaiter = node; return node;} 这段代码就很容易理解了，将当前节点包装成Node，如果等待队列的firstWaiter为null的话（等待队列为空队列），则将firstWaiter指向当前的Node，否则，更新lastWaiter(尾节点)即可。就是通过尾插入的方式将当前线程封装的Node插入到等待队列中即可，同时可以看出等待队列是一个不带头结点的链式队列，之前我们学习AQS时知道同步队列是一个带头结点的链式队列，这是两者的一个区别。将当前节点插入到等待对列之后，会使当前线程释放lock，由fullyRelease方法实现，fullyRelease源码为： 1234567891011121314151617final int fullyRelease(Node node) { boolean failed = true; try { int savedState = getState(); if (release(savedState)) { //成功释放同步状态 failed = false; return savedState; } else { //不成功释放同步状态抛出异常 throw new IllegalMonitorStateException(); } } finally { if (failed) node.waitStatus = Node.CANCELLED; }} 这段代码就很容易理解了，调用AQS的模板方法release方法释放AQS的同步状态并且唤醒在同步队列中头结点的后继节点引用的线程，如果释放成功则正常返回，若失败的话就抛出异常。到目前为止，这两段代码已经解决了前面的两个问题的答案了，还剩下第三个问题，怎样从await方法退出？现在回过头再来看await方法有这样一段逻辑： 123456while (!isOnSyncQueue(node)) { // 3. 当前线程进入到等待状态 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break;} 很显然，当线程第一次调用condition.await()方法时，会进入到这个while()循环中，然后通过LockSupport.park(this)方法使得当前线程进入等待状态，那么要想退出这个await方法第一个前提条件自然而然的是要先退出这个while循环，出口就只剩下两个地方：1. 逻辑走到break退出while循环；2. while循环中的逻辑判断为false。再看代码出现第1种情况的条件是当前等待的线程被中断后代码会走到break退出，第二种情况是当前节点被移动到了同步队列中（即另外线程调用的condition的signal或者signalAll方法），while中逻辑判断为false后结束while循环。总结下，就是当前线程被中断或者调用condition.signal/condition.signalAll方法，当前节点移动到了同步队列后 ，这是当前线程退出await方法的前提条件。当退出while循环后就会调用acquireQueued(node, savedState)，这个方法在介绍AQS的底层实现时说过了，若感兴趣的话可以去看这篇文章，该方法的作用是在自旋过程中线程不断尝试获取同步状态，直至成功（线程获取到lock）。这样也说明了退出await方法必须是已经获得了condition引用（关联）的lock。到目前为止，开头的三个问题我们通过阅读源码的方式已经完全找到了答案，也对await方法的理解加深。await方法示意图如下图： 如图，调用condition.await方法的线程必须是已经获得了lock，也就是当前线程是同步队列中的头结点。调用该方法后会使得当前线程所封装的Node尾插入到等待队列中。 超时机制的支持condition还额外支持了超时机制，使用者可调用方法awaitNanos,awaitUtil。这两个方法的实现原理，基本上与AQS中的tryAcquire方法如出一辙，关于tryAcquire可以仔细阅读这篇文章。 不响应中断的支持要想不响应中断可以调用condition.awaitUninterruptibly()方法，该方法的源码为： 123456789101112public final void awaitUninterruptibly() { Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean interrupted = false; while (!isOnSyncQueue(node)) { LockSupport.park(this); if (Thread.interrupted()) interrupted = true; } if (acquireQueued(node, savedState) || interrupted) selfInterrupt();} 这段方法与上面的await方法基本一致，只不过减少了对中断的处理，并省略了reportInterruptAfterWait方法抛被中断的异常。 signal/signalAll实现原理signal调用condition的signal或者signalAll方法可以将等待队列中等待时间最长的节点移动到同步队列中，使得该节点能够有机会获得lock。按照等待队列是先进先出（FIFO）的，所以等待队列的头节点必然会是等待时间最长的节点，也就是每次调用condition的signal方法是将头节点移动到同步队列中。我们来通过看源码的方式来看这样的猜想是不是对的，signal方法源码为： 123456789public final void signal() { //1. 先检测当前线程是否已经获取lock if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //2. 获取等待队列中第一个节点，之后的操作都是针对这个节点 Node first = firstWaiter; if (first != null) doSignal(first);} signal方法首先会检测当前线程是否已经获取lock，如果没有获取lock会直接抛出异常，如果获取的话再得到等待队列的头指针引用的节点，之后的操作的doSignal方法也是基于该节点。下面我们来看看doSignal方法做了些什么事情，doSignal方法源码为： 12345678910private void doSignal(Node first) { do { if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; //1. 将头结点从等待队列中移除 first.nextWaiter = null; //2. while中transferForSignal方法对头结点做真正的处理 } while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);} 具体逻辑请看注释，真正对头节点做处理的逻辑在transferForSignal放，该方法源码为： 123456789101112131415161718192021final boolean transferForSignal(Node node) { /* * If cannot change waitStatus, the node has been cancelled. */ //1. 更新状态为0 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ //2.将该节点移入到同步队列中去 Node p = enq(node); int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;} 关键逻辑请看注释，这段代码主要做了两件事情1.将头结点的状态更改为CONDITION；2.调用enq方法，将该节点尾插入到同步队列中，关于enq方法请看AQS的底层实现这篇文章。现在我们可以得出结论：调用condition的signal的前提条件是当前线程已经获取了lock，该方法会使得等待队列中的头节点即等待时间最长的那个节点移入到同步队列，而移入到同步队列后才有机会使得等待线程被唤醒，即从await方法中的LockSupport.park(this)方法中返回，从而才有机会使得调用await方法的线程成功退出。signal执行示意图如下图： signalAllsigllAll与sigal方法的区别体现在doSignalAll方法上，前面我们已经知道doSignal方法只会对等待队列的头节点进行操作，而doSignalAll的源码为： 123456789private void doSignalAll(Node first) { lastWaiter = firstWaiter = null; do { Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; } while (first != null);} 该方法只不过时间等待队列中的每一个节点都移入到同步队列中，即“通知”当前调用condition.await()方法的每一个线程。 await与signal/signalAll的结合思考文章开篇提到等待/通知机制，通过使用condition提供的await和signal/signalAll方法就可以实现这种机制，而这种机制能够解决最经典的问题就是“生产者与消费者问题”，关于“生产者消费者问题”之后会用单独的一篇文章进行讲解，这也是面试的高频考点。await和signal和signalAll方法就像一个开关控制着线程A（等待方）和线程B（通知方）。它们之间的关系可以用下面一个图来表现得更加贴切： 如图，线程awaitThread先通过lock.lock()方法获取锁成功后调用了condition.await方法进入等待队列，而另一个线程signalThread通过lock.lock()方法获取锁成功后调用了condition.signal或者signalAll方法，使得线程awaitThread能够有机会移入到同步队列中，当其他线程释放lock后使得线程awaitThread能够有机会获取lock，从而使得线程awaitThread能够从await方法中退出执行后续操作。如果awaitThread获取lock失败会直接进入到同步队列。 一个例子我们用一个很简单的例子说说condition的用法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class AwaitSignal { private static ReentrantLock lock = new ReentrantLock(); private static Condition condition = lock.newCondition(); private static volatile boolean flag = false; public static void main(String[] args) { Thread waiter = new Thread(new waiter()); waiter.start(); Thread signaler = new Thread(new signaler()); signaler.start(); } static class waiter implements Runnable { @Override public void run() { lock.lock(); try { while (!flag) { System.out.println(Thread.currentThread().getName() + &quot;当前条件不满足等待&quot;); try { condition.await(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(Thread.currentThread().getName() + &quot;接收到通知条件满足&quot;); } finally { lock.unlock(); } } } static class signaler implements Runnable { @Override public void run() { lock.lock(); try { flag = true; condition.signalAll(); } finally { lock.unlock(); } } }} 输出结果为： 12Thread-0当前条件不满足等待Thread-0接收到通知，条件满足 开启了两个线程waiter和signaler，waiter线程开始执行的时候由于条件不满足，执行condition.await方法使该线程进入等待状态同时释放锁，signaler线程获取到锁之后更改条件，并通知所有的等待线程后释放锁。这时，waiter线程获取到锁，并由于signaler线程更改了条件此时相对于waiter来说条件满足，继续执行。 参考文献 《Java并发编程的艺术》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-Condition%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E7%AD%89%E5%BE%85%E9%80%9A%E7%9F%A5%E6%9C%BA%E5%88%B6/"},{"title":"并发编程-CopyOnWriteArrayList介绍","text":"CopyOnWriteArrayList的简介java学习者都清楚ArrayList并不是线程安全的，在多线程在读取ArrayList的时候如果有写线程在写数据的时候，基于fast-fail机制，会抛出ConcurrentModificationException异常，也就是说ArrayList并不是一个线程安全的容器，当然您可以用Vector,或者使用Collections的静态方法将ArrayList包装成一个线程安全的类，但是这些方式都是采用java关键字synchronzied对方法进行修饰，利用独占式锁来保证线程安全的。但是，由于独占式锁在同一时刻只有一个线程能够获取到对象监视器，很显然这种方式效率并不是太高。 回到业务场景中，有很多业务往往是读多写少的，比如系统配置的信息，除了在初始进行系统配置的时候需要写入数据，其他大部分时刻其他模块之后对系统信息只需要进行读取，又比如白名单，黑名单等配置，只需要读取名单配置然后检测当前用户是否在该配置范围以内。类似的还有很多业务场景，它们都是属于读多写少的场景。如果在这种情况用到上述的方法，使用Vector,Collections转换的这些方式是不合理的，因为尽管多个读线程从同一个数据容器中读取数据，但是读线程对数据容器的数据并不会发生发生修改。很自然而然的我们会联想到ReenTrantReadWriteLock（关于读写锁可以看这篇文章），通过读写分离的思想，使得读读之间不会阻塞，无疑如果一个list能够做到被多个读线程读取的话，性能会大大提升不少。但是，如果仅仅是将list通过读写锁（ReentrantReadWriteLock）进行再一次封装的话，由于读写锁的特性，当写锁被写线程获取后，读写线程都会被阻塞。如果仅仅使用读写锁对list进行封装的话，这里仍然存在读线程在读数据的时候被阻塞的情况，如果想list的读效率更高的话，这里就是我们的突破口，如果我们保证读线程无论什么时候都不被阻塞，效率岂不是会更高？ Doug Lea大师就为我们提供CopyOnWriteArrayList容器可以保证线程安全，保证读读之间在任何时候都不会被阻塞，CopyOnWriteArrayList也被广泛应用于很多业务场景之中，CopyOnWriteArrayList值得被我们好好认识一番。 COW的设计思想回到上面所说的，如果简单的使用读写锁的话，在写锁被获取之后，读写线程被阻塞，只有当写锁被释放后读线程才有机会获取到锁从而读到最新的数据，站在读线程的角度来看，即读线程任何时候都是获取到最新的数据，满足数据实时性。既然我们说到要进行优化，必然有trade-off,我们就可以牺牲数据实时性满足数据的最终一致性即可。而CopyOnWriteArrayList就是通过Copy-On-Write(COW)，即写时复制的思想来通过延时更新的策略来实现数据的最终一致性，并且能够保证读线程间不阻塞。 COW通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。对CopyOnWrite容器进行并发的读的时候，不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，延时更新的策略是通过在写的时候针对的是不同的数据容器来实现的，放弃数据实时性达到数据的最终一致性。 CopyOnWriteArrayList的实现原理现在我们来通过看源码的方式来理解CopyOnWriteArrayList，实际上CopyOnWriteArrayList内部维护的就是一个数组 12/** The array, accessed only via getArray/setArray. */private transient volatile Object[] array; 并且该数组引用是被volatile修饰，注意这里仅仅是修饰的是数组引用，其中另有玄机，稍后揭晓。关于volatile很重要的一条性质是它能够够保证可见性，关于volatile的详细讲解可以看这篇文章。对list来说，我们自然而然最关心的就是读写的时候，分别为get和add方法的实现。 get方法实现原理get方法的源码为： 12345678910111213public E get(int index) { return get(getArray(), index);}/** * Gets the array. Non-private so as to also be accessible * from CopyOnWriteArraySet class. */final Object[] getArray() { return array;}private E get(Object[] a, int index) { return (E) a[index];} 可以看出来get方法实现非常简单，几乎就是一个“单线程”程序，没有对多线程添加任何的线程安全控制，也没有加锁也没有CAS操作等等，原因是，所有的读线程只是会读取数据容器中的数据，并不会进行修改。 add方法实现原理再来看下如何进行添加数据的？add方法的源码为： 12345678910111213141516171819public boolean add(E e) { final ReentrantLock lock = this.lock; //1. 使用Lock,保证写线程在同一时刻只有一个 lock.lock(); try { //2. 获取旧数组引用 Object[] elements = getArray(); int len = elements.length; //3. 创建新的数组，并将旧数组的数据复制到新数组中 Object[] newElements = Arrays.copyOf(elements, len + 1); //4. 往新数组中添加新的数据 newElements[len] = e; //5. 将旧数组引用指向新的数组 setArray(newElements); return true; } finally { lock.unlock(); }} add方法的逻辑也比较容易理解，请看上面的注释。需要注意这么几点： 采用ReentrantLock，保证同一时刻只有一个写线程正在进行数组的复制，否则的话内存中会有多份被复制的数据； 前面说过数组引用是volatile修饰的，因此将旧的数组引用指向新的数组，根据volatile的happens-before规则，写线程对数组引用的修改对读线程是可见的。 由于在写数据的时候，是在新的数组中插入数据的，从而保证读写实在两个不同的数据容器中进行操作。 总结我们知道COW和读写锁都是通过读写分离的思想实现的，但两者还是有些不同，可以进行比较： COW vs 读写锁相同点：1. 两者都是通过读写分离的思想实现；2.读线程间是互不阻塞的 不同点：对读线程而言，为了实现数据实时性，在写锁被获取后，读线程会等待或者当读锁被获取后，写线程会等待，从而解决“脏读”等问题。也就是说如果使用读写锁依然会出现读线程阻塞等待的情况。而COW则完全放开了牺牲数据实时性而保证数据最终一致性，即读线程对数据的更新是延时感知的，因此读线程不会存在等待的情况。 对这一点从文字上还是很难理解，我们来通过debug看一下，add方法核心代码为： 12345Object[] elements = getArray();int len = elements.length;Object[] newElements = Arrays.copyOf(elements, len + 1);newElements[len] = e;setArray(newElements); 假设COW的变化如下图所示： 数组中已有数据1,2,3，现在写线程想往数组中添加数据4，我们在第5行处打上断点，让写线程暂停。读线程依然会“不受影响”的能从数组中读取数据，可是还是只能读到1,2,3。如果读线程能够立即读到新添加的数据的话就叫做能保证数据实时性。当对第5行的断点放开后，读线程才能感知到数据变化，读到完整的数据1,2,3,4，而保证数据最终一致性，尽管有可能中间间隔了好几秒才感知到。 这里还有这样一个问题： 为什么需要复制呢？ 如果将array 数组设定为volitile的， 对volatile变量写happens-before读，读线程不是能够感知到volatile变量的变化。 原因是，这里volatile的修饰的仅仅只是数组引用，数组中的元素的修改是不能保证可见性的。因此COW采用的是新旧两个数据容器，通过第5行代码将数组引用指向新的数组。 这也是为什么concurrentHashMap只具有弱一致性的原因，关于concurrentHashMap的弱一致性可以看这篇文章。 COW的缺点CopyOnWrite容器有很多优点，但是同时也存在两个问题，即内存占用问题和数据一致性问题。所以在开发的时候需要注意一下。 内存占用问题：因为CopyOnWrite的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对 象的内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对 象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存）。如果这些对象占用的内存比较大，比 如说200M左右，那么再写入100M数据进去，内存就会占用300M，那么这个时候很有可能造成频繁的minor GC和major GC。 数据一致性问题：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。 参考资料 《java并发编程的艺术》COW讲解","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-CopyOnWriteArrayList%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-CountDownLatch与CyclicBarrier介绍","text":"倒计时器CountDownLatch在多线程协作完成业务功能时，有时候需要等待其他多个线程完成任务之后，主线程才能继续往下执行业务功能，在这种的业务场景下，通常可以使用Thread类的join方法，让主线程等待被join的线程执行完之后，主线程才能继续往下执行。当然，使用线程间消息通信机制也可以完成。其实，Java并发工具类中为我们提供了类似“倒计时”这样的工具类，可以十分方便的完成所说的这种业务场景。 为了能够理解CountDownLatch，举一个很通俗的例子，运动员进行跑步比赛时，假设有6个运动员参与比赛，裁判员在终点会为这6个运动员分别计时，可以想象每当一个运动员到达终点的时候，对于裁判员来说就少了一个计时任务。直到所有运动员都到达终点了，裁判员的任务也才完成。这6个运动员可以类比成6个线程，当线程调用CountDownLatch.countDown方法时就会对计数器的值减一，直到计数器的值为0的时候，裁判员（调用await方法的线程）才能继续往下执行。 下面来看些CountDownLatch的一些重要方法。 先从CountDownLatch的构造方法看起： 1public CountDownLatch(int count) 构造方法会传入一个整型数N，之后调用CountDownLatch的countDown方法会对N减一，直到N减到0的时候，当前调用await方法的线程继续执行。 CountDownLatch的方法不是很多，将它们一个个列举出来： await() throws InterruptedException：调用该方法的线程等到构造方法传入的N减到0的时候，才能继续往下执行； await(long timeout, TimeUnit unit)：与上面的await方法功能一致，只不过这里有了时间限制，调用该方法的线程等到指定的timeout时间后，不管N是否减至为0，都会继续往下执行； countDown()：使CountDownLatch初始值N减1； long getCount()：获取当前CountDownLatch维护的值； 一个例子下面用一个具体的例子来说明CountDownLatch的具体用法: 1234567891011121314151617181920212223242526272829303132333435363738394041public class CountDownLatchDemo { private static CountDownLatch startSignal = new CountDownLatch(1); //用来表示裁判员需要维护的是6个运动员 private static CountDownLatch endSignal = new CountDownLatch(6); public static void main(String[] args) throws InterruptedException { ExecutorService executorService = Executors.newFixedThreadPool(6); System.out.println(&quot;各位运动员准备啦！！！&quot;); for (int i = 0; i &lt; 6; i++) { executorService.execute(() -&gt; { try { System.out.println(Thread.currentThread().getName() + &quot; 运动员等待裁判员响哨！！！&quot;); // 确保所有运动员准备完毕 Thread.sleep(1000); startSignal.await(); System.out.println(Thread.currentThread().getName() + &quot; 正在全力冲刺&quot;); endSignal.countDown(); System.out.println(Thread.currentThread().getName() + &quot; 到达终点&quot;); } catch (InterruptedException e) { e.printStackTrace(); } }); } //将executorService转换为ThreadPoolExecutor,ThreadPoolExecutor有方法 getActiveCount()可以得到当前活动线程数 int threadCount = ((ThreadPoolExecutor)executorService).getActiveCount(); if (threadCount == 6) { System.out.println(&quot;裁判员响哨...&quot;); startSignal.countDown(); endSignal.await(); System.out.println(&quot;所有运动员到达终点，比赛结束！&quot;); } executorService.shutdown(); }} 输出结果 123456789101112131415161718192021各位运动员准备啦！！！pool-1-thread-1 运动员等待裁判员响哨！！！pool-1-thread-3 运动员等待裁判员响哨！！！pool-1-thread-2 运动员等待裁判员响哨！！！pool-1-thread-5 运动员等待裁判员响哨！！！pool-1-thread-4 运动员等待裁判员响哨！！！pool-1-thread-6 运动员等待裁判员响哨！！！裁判员响哨...pool-1-thread-5 正在全力冲刺pool-1-thread-5 到达终点pool-1-thread-6 正在全力冲刺pool-1-thread-2 正在全力冲刺pool-1-thread-2 到达终点pool-1-thread-1 正在全力冲刺pool-1-thread-1 到达终点pool-1-thread-3 正在全力冲刺pool-1-thread-3 到达终点pool-1-thread-4 正在全力冲刺pool-1-thread-6 到达终点pool-1-thread-4 到达终点所有运动员到达终点，比赛结束！ 该示例代码中设置了两个CountDownLatch，第一个endSignal用于控制让main线程（裁判员）必须等到其他线程（运动员）让CountDownLatch维护的数值N减到0为止。另一个startSignal用于让main线程对其他线程进行“发号施令”，startSignal引用的CountDownLatch初始值为1，而其他线程执行的run方法中都会先通过 startSignal.await()让这些线程都被阻塞，直到main线程通过调用startSignal.countDown();，将值N减1，CountDownLatch维护的数值N为0后，其他线程才能往下执行，并且，每个线程执行的run方法中都会通过endSignal.countDown();对endSignal维护的数值进行减一，由于往线程池提交了6个任务，会被减6次，所以endSignal维护的值最终会变为0，因此main线程在latch.await();阻塞结束，才能继续往下执行。 另外，需要注意的是，当调用CountDownLatch的countDown方法时，当前线程是不会被阻塞，会继续往下执行，比如在该例中会继续输出pool-1-thread-4 到达终点。 循环栅栏CyclicBarrierCyclicBarrier也是一种多线程并发控制的实用工具，和CountDownLatch一样具有等待计数的功能，但是相比于CountDownLatch功能更加强大。 为了理解CyclicBarrier，这里举一个通俗的例子。开运动会时，会有跑步这一项运动，我们来模拟下运动员入场时的情况，假设有6条跑道，在比赛开始时，就需要6个运动员在比赛开始的时候都站在起点了，裁判员吹哨后才能开始跑步。跑道起点就相当于“barrier”，是临界点，而这6个运动员就类比成线程的话，就是这6个线程都必须到达指定点了，意味着凑齐了一波，然后才能继续执行，否则每个线程都得阻塞等待，直至凑齐一波即可。cyclic是循环的意思，也就是说CyclicBarrier当多个线程凑齐了一波之后，仍然有效，可以继续凑齐下一波。CyclicBarrier的执行示意图如下： 当多个线程都达到了指定点后，才能继续往下继续执行。这就有点像报数的感觉，假设6个线程就相当于6个运动员，到赛道起点时会报数进行统计，如果刚好是6的话，这一波就凑齐了，才能往下执行。CyclicBarrier在使用一次后，下面依然有效，可以继续当做计数器使用，这是与CountDownLatch的区别之一。这里的6个线程，也就是计数器的初始值6，是通过CyclicBarrier的构造方法传入的。 下面来看下CyclicBarrier的主要方法： 1234567891011121314//等到所有的线程都到达指定的临界点await() throws InterruptedException, BrokenBarrierException //与上面的await方法功能基本一致，只不过这里有超时限制，阻塞等待直至到达超时时间为止await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException //获取当前有多少个线程阻塞等待在临界点上int getNumberWaiting()//用于查询阻塞等待的线程是否被中断boolean isBroken()//将屏障重置为初始状态。如果当前有线程正在临界点等待的话，将抛出BrokenBarrierException。void reset() 另外需要注意的是，CyclicBarrier提供了这样的构造方法： 1public CyclicBarrier(int parties, Runnable barrierAction) 可以用来，当指定的线程都到达了指定的临界点的时，接下来执行的操作可以由barrierAction传入即可。 一个例子下面用一个简单的例子，来看下CyclicBarrier的用法，我们来模拟下上面的运动员的例子。 123456789101112131415161718192021222324252627public class CyclicBarrierDemo { //指定必须有6个运动员到达才行 private static CyclicBarrier barrier = new CyclicBarrier(6, () -&gt; System.out.println(&quot;所有运动员入场，裁判员一声令下！！！！！&quot;) ); public static void main(String[] args) { System.out.println(&quot;运动员准备进场，全场欢呼............&quot;); ExecutorService service = Executors.newFixedThreadPool(6); for (int i = 0; i &lt; 6; i++) { service.execute(() -&gt; { try { System.out.println(Thread.currentThread().getName() + &quot; 运动员，进场&quot;); barrier.await(); System.out.println(Thread.currentThread().getName() + &quot; 运动员出发&quot;); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }); } }} 输出结果 1234567891011121314运动员准备进场，全场欢呼............pool-1-thread-1 运动员，进场pool-1-thread-4 运动员，进场pool-1-thread-3 运动员，进场pool-1-thread-2 运动员，进场pool-1-thread-6 运动员，进场pool-1-thread-5 运动员，进场所有运动员入场，裁判员一声令下！！！！！pool-1-thread-5 运动员出发pool-1-thread-1 运动员出发pool-1-thread-6 运动员出发pool-1-thread-3 运动员出发pool-1-thread-2 运动员出发pool-1-thread-4 运动员出发 从输出结果可以看出，当6个运动员（线程）都到达了指定的临界点（barrier）时候，才能继续往下执行，否则，则会阻塞等待在调用await()处 CountDownLatch与CyclicBarrier的比较CountDownLatch与CyclicBarrier都是用于控制并发的工具类，都可以理解成维护的就是一个计数器，但是这两者还是各有不同侧重点的： CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；CountDownLatch强调一个线程等多个线程完成某件事情。CyclicBarrier是多个线程互等，等大家都完成，再携手共进。 调用CountDownLatch的countDown方法后，当前线程并不会阻塞，会继续往下执行；而调用CyclicBarrier的await方法，会阻塞当前线程，直到CyclicBarrier指定的线程全部都到达了指定点的时候，才能继续往下执行； CountDownLatch方法比较少，操作比较简单，而CyclicBarrier提供的方法更多，比如能够通过getNumberWaiting()，isBroken()这些方法获取当前多个线程的状态，并且CyclicBarrier的构造方法可以传入barrierAction，指定当所有线程都到达时执行的业务功能； CountDownLatch是不能复用的，而CyclicLatch是可以复用的。","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-CountDownLatch%E4%B8%8ECyclicBarrier%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-Executors类创建四种常见线程池","text":"Java里面线程池的顶级接口是Executor，Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。 线程池架构 比较重要的几个类： 类/接口 描述 ExecutorService 真正的线程池接口 ScheduledExecutorService 和Timer/TimerTask类似，解决那些需要任务重复执行的问题 ThreadPoolExecutor ExecutorService的默认实现 ScheduledThreadPoolExecutor 继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现 要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。 Java通过Executors工厂类提供四种线程池，分别为： newCachedThreadPool ：创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，否则新建线程。（线程最大并发数不可控制） newFixedThreadPool：创建一个固定大小的线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool ： 创建一个定时线程池，支持定时及周期性任务执行。 newSingleThreadExecutor ：创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 我们先创建一个统一的线程任务，方便测试四种线程池 12345678public class MyRunnable implements Runnable { @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot; is running...&quot;); }} newSingleThreadExecutor1234567891011121314public class SingleThreadExecutorTest { public static void main(String[] args) { ExecutorService executorService = Executors.newSingleThreadExecutor(); MyRunnable myRunnable = new MyRunnable(); for (int i = 0; i &lt; 5; i++) { executorService.execute(myRunnable); } System.out.println(&quot;线程任务开始执行&quot;); executorService.shutdown(); }} 输出结果 123456线程任务开始执行pool-1-thread-1 is running...pool-1-thread-1 is running...pool-1-thread-1 is running...pool-1-thread-1 is running...pool-1-thread-1 is running... 底层实现 123456789101112/** * 核心线程池大小=1 * 最大线程池大小为1 * 线程过期时间为0ms * LinkedBlockingQueue作为工作队列 */public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));} 从参数可以看出来，SingleThreadExecutor 相当于特殊的 FixedThreadPool，它的执行流程如下： 线程池中没有线程时，新建一个线程执行任务 有一个线程以后，将任务加入阻塞队列，不停的加 唯一的这一个线程不停地去队列里取任务执行 SingleThreadExecutor 用于串行执行任务的场景，每个任务必须按顺序执行，不需要并发执行。 newFixedThreadPool1234567891011121314public class FixedThreadPoolTest { public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(2); MyRunnable myRunnable = new MyRunnable(); for (int i = 0; i &lt; 5; i++) { executorService.execute(myRunnable); } System.out.println(&quot;线程任务开始执行&quot;); executorService.shutdown(); }} 输出结果 123456线程任务开始执行pool-1-thread-1 is running...pool-1-thread-1 is running...pool-1-thread-2 is running...pool-1-thread-1 is running...pool-1-thread-2 is running... 底层实现 1234567891011/** * 核心线程池大小=传入参数 * 最大线程池大小为传入参数 * 线程过期时间为0ms * LinkedBlockingQueue作为工作队列 */public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());} 可以看到，FixedThreadPool 的核心线程数和最大线程数都是指定值，也就是说当线程池中的线程数超过核心线程数后，任务都会被放到阻塞队列中。 此外 keepAliveTime 为 0，也就是多余的空余线程会被立即终止（由于这里没有多余线程，这个参数也没什么意义了）。 而这里选用的阻塞队列是 LinkedBlockingQueue，使用的是默认容量 Integer.MAX_VALUE，相当于没有上限。 因此这个线程池执行任务的流程如下： 线程数少于核心线程数，也就是设置的线程数时，新建线程执行任务 线程数等于核心线程数后，将任务加入阻塞队列 由于队列容量非常大，可以一直加 执行完任务的线程反复去队列中取任务执行 FixedThreadPool 用于负载比较重的服务器，为了资源的合理利用，需要限制当前线程数量。 newCachedThreadPool1234567891011121314public class CachedThreadPoolTest { public static void main(String[] args) { ExecutorService executorService = Executors.newCachedThreadPool(); MyRunnable myRunnable = new MyRunnable(); for (int i = 0; i &lt; 5; i++) { executorService.execute(myRunnable); } System.out.println(&quot;线程任务开始执行&quot;); executorService.shutdown(); }} 输出结果 123456线程任务开始执行pool-1-thread-1 is running...pool-1-thread-4 is running...pool-1-thread-2 is running...pool-1-thread-5 is running...pool-1-thread-3 is running... 底层实现 1234567891011/** * 核心线程池大小=0 * 最大线程池大小为Integer.MAX_VALUE * 线程过期时间为60s * 使用SynchronousQueue作为工作队列 */public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());} 可以看到，CachedThreadPool 没有核心线程，非核心线程数无上限，也就是全部使用外包，但是每个外包空闲的时间只有 60 秒，超过后就会被回收。 CachedThreadPool 使用的队列是 SynchronousQueue，这个队列的作用就是传递任务，并不会保存。 因此当提交任务的速度大于处理任务的速度时，每次提交一个任务，就会创建一个线程。极端情况下会创建过多的线程，耗尽 CPU 和内存资源。 它的执行流程如下： 没有核心线程，直接向 SynchronousQueue 中提交任务 如果有空闲线程，就去取出任务执行；如果没有空闲线程，就新建一个 执行完任务的线程有 60 秒生存时间，如果在这个时间内可以接到新任务，就可以继续活下去，否则就拜拜 由于空闲 60 秒的线程会被终止，长时间保持空闲的 CachedThreadPool 不会占用任何资源。 CachedThreadPool 用于并发执行大量短期的小任务，或者是负载较轻的服务器。 newScheduledThreadPool1234567891011121314public class ScheduledThreadPoolTest { public static void main(String[] args) { ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(3); MyRunnable myRunnable = new MyRunnable(); for (int i = 0; i &lt; 5; i++) { // 参数1:目标对象,参数2:隔多长时间开始执行线程,参数3:执行周期,参数4:时间单位 scheduledExecutorService.scheduleAtFixedRate(myRunnable, 1, 2, TimeUnit.SECONDS); } System.out.println(&quot;线程任务开始执行&quot;); }} 输出结果 12345678910111213线程任务开始执行// 打印【线程任务开始执行】后1秒输出pool-1-thread-1 is running...pool-1-thread-2 is running...pool-1-thread-1 is running...pool-1-thread-3 is running...pool-1-thread-2 is running...// 2秒后输出pool-1-thread-1 is running...pool-1-thread-3 is running...pool-1-thread-2 is running...pool-1-thread-1 is running...pool-1-thread-3 is running... 底层实现 12345678910/** * 核心线程池大小=传入参数 * 最大线程池大小为Integer.MAX_VALUE * 线程过期时间为0ms * DelayedWorkQueue作为工作队列 */public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());} ScheduledThreadPoolExecutor 的执行流程如下： 添加一个任务 线程池中的线程从 DelayQueue 中取任务 然后执行任务 具体执行任务的步骤也比较复杂： 线程从 DelayQueue 中获取 time 大于等于当前时间的 ScheduledFutureTask 执行完后修改这个 task 的 time 为下次被执行的时间 然后再把这个 task 放回队列中 ScheduledThreadPoolExecutor 用于需要多个后台线程执行周期任务，同时需要限制线程数量的场景。 Executors和ThreaPoolExecutor创建线程池的区别Executors 各个方法的弊端： newFixedThreadPool 和 newSingleThreadExecutor:主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至 OOM。 newCachedThreadPool 和 newScheduledThreadPool:主要问题是线程数最大数是 Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至 OOM。 ThreaPoolExecutor 创建线程池方式只有一种，就是走它的构造函数，参数自己指定 两种提交任务的方法ExecutorService 提供了两种提交任务的方法： execute()：提交不需要返回值的任务 submit()：提交需要返回值的任务 execute1void execute(Runnable command); execute() 的参数是一个 Runnable，也没有返回值。因此提交后无法判断该任务是否被线程池执行成功。 1234567ExecutorService executor = Executors.newCachedThreadPool();executor.execute(new Runnable() { @Override public void run() { //do something }}); submit123&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task); submit() 有三种重载，参数可以是 Callable 也可以是 Runnable。 同时它会返回一个 Future 对象，通过它我们可以判断任务是否执行成功。 获得执行结果调用 Future.get() 方法，这个方法会阻塞当前线程直到任务完成。 提交一个 Callable 任务时，需要使用 FutureTask 包一层： 123456789101112131415FutureTask futureTask = new FutureTask(new Callable&lt;String&gt;() { //创建 Callable 任务 @Override public String call() throws Exception { String result = &quot;&quot;; //do something return result; }});Future&lt;?&gt; submit = executor.submit(futureTask); //提交到线程池try { Object result = submit.get(); //获取结果} catch (InterruptedException e) { e.printStackTrace();} catch (ExecutionException e) { e.printStackTrace();","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-Executors%E7%B1%BB%E5%88%9B%E5%BB%BA%E5%9B%9B%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"title":"并发编程-FutureTask介绍","text":"FutureTask简介在Executors框架体系中，FutureTask用来表示可获取结果的异步任务。FutureTask实现了Future接口，FutureTask提供了启动和取消异步任务，查询异步任务是否计算结束以及获取最终的异步任务的结果的一些常用的方法。通过get()方法来获取异步任务的结果，但是会阻塞当前线程直至异步任务执行结束。一旦任务执行结束，任务不能重新启动或取消，除非调用runAndReset()方法。 在FutureTask的源码中为其定义了这些状态： 1234567private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; 另外，在《Java并发编程的艺术》一书，作者根据FutureTask.run()方法的执行的时机，FutureTask分为了3种状态： 未启动。FutureTask.run()方法还没有被执行之前，FutureTask处于未启动状态。当创建一个FutureTask，还没有执行FutureTask.run()方法之前，FutureTask处于未启动状态。 已启动。FutureTask.run()方法被执行的过程中，FutureTask处于已启动状态。 已完成。FutureTask.run()方法执行结束，或者调用FutureTask.cancel(…)方法取消任务，或者在执行任务期间抛出异常，这些情况都称之为FutureTask的已完成状态。 由于FutureTask具有这三种状态，因此执行FutureTask的get方法和cancel方法，当前处于不同的状态对应的结果也是大不相同。这里对get方法和cancel方法做个总结： get方法当FutureTask处于未启动或已启动状态时，执行FutureTask.get()方法将导致调用线程阻塞; 当FutureTask处于已完成状态时，调用FutureTask.get()方法将导致调用线程立即返回结果或者抛出异常 cancel方法当FutureTask处于未启动状态时，执行FutureTask.cancel()方法将此任务永远不会执行； 当FutureTask处于已启动状态时，执行FutureTask.cancel(true)方法将以中断线程的方式来阻止任务继续进行，如果执行FutureTask.cancel(false)将不会对正在执行任务的线程有任何影响； 当FutureTask处于已完成状态时，执行FutureTask.cancel(…)方法将返回false。 对Future的get()方法和cancel()方法用下图进行总结 FutureTask的基本使用FutureTask除了实现Future接口外，还实现了Runnable接口。因此，FutureTask可以交给Executor执行，也可以由调用的线程直接执行（FutureTask.run()）。另外，FutureTask的获取也可以通过ExecutorService.submit()方法返回一个FutureTask对象，然后在通过FutureTask.get()或者FutureTask.cancel方法。 应用场景：当一个线程需要等待另一个线程把某个任务执行完后它才能继续执行，此时可以使用FutureTask。假设有多个线程执行若干任务，每个任务最多只能被执行一次。当多个线程试图执行同一个任务时，只允许一个线程执行任务，其他线程需要等待这个任务执行完后才能继续执行。 参考文献《Java并发编程的艺术》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-FutureTask%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-Java中atomic包中的原子操作类总结","text":"原子操作类简介在并发编程中很容易出现并发安全的问题，有一个很简单的例子就是多线程更新变量i=1,比如多个线程执行i++操作，就有可能获取不到正确的值，而这个问题，最常用的方法是通过Synchronized进行控制来达到线程安全的目的（关于synchronized可以看这篇文章）。但是由于synchronized是采用的是悲观锁策略，并不是特别高效的一种解决方案。实际上，在J.U.C下的atomic包提供了一系列的操作简单，性能高效，并能保证线程安全的类去更新基本类型变量，数组元素，引用类型以及更新对象中的字段类型。atomic包下的这些类都是采用的是乐观锁策略去原子更新数据，在java中则是使用CAS操作具体实现。 预备知识-CAS操作能够弄懂atomic包下这些原子操作类的实现原理，就要先明白什么是CAS操作。 什么是CAS?使用锁时，线程获取锁是一种悲观锁策略，即假设每一次执行临界区代码都会产生冲突，所以当前线程获取到锁的时候同时也会阻塞其他线程获取该锁。而CAS操作（又称为无锁操作）是一种乐观锁策略，它假设所有线程访问共享资源的时候不会出现冲突，既然不会出现冲突自然而然就不会阻塞其他线程的操作。因此，线程就不会出现阻塞停顿的状态。那么，如果出现冲突了怎么办？无锁操作是使用CAS(compare and swap)又叫做比较交换来鉴别线程是否出现冲突，出现冲突就重试当前操作直到没有冲突为止。 CAS的操作过程CAS比较交换的过程可以通俗的理解为CAS(V,O,N)，包含三个值分别为：V 内存地址存放的实际值；O 预期的值（旧值）；N 更新的新值。当V和O相同时，也就是说旧值和内存中实际的值相同表明该值没有被其他线程更改过，即该旧值O就是目前来说最新的值了，自然而然可以将新值N赋值给V。反之，V和O不相同，表明该值已经被其他线程改过了，则该旧值O不是最新版本的值了，所以不能将新值N赋给V，返回V即可。当多个线程使用CAS操作一个变量时，只有一个线程会成功，并成功更新，其余会失败。失败的线程会重新尝试，当然也可以选择挂起线程。 CAS的实现需要硬件指令集的支撑，在JDK1.5后虚拟机才可以使用处理器提供的CMPXCHG指令实现。 Synchronized VS CAS 元老级的Synchronized(未优化前)最主要的问题是：在存在线程竞争的情况下会出现线程阻塞和唤醒锁带来的性能问题，因为这是一种互斥同步（阻塞同步）。而CAS并不是武断的将线程挂起，当CAS操作失败后会进行一定的尝试，而非进行耗时的挂起唤醒的操作，因此也叫做非阻塞同步。这是两者主要的区别。 CAS的问题 ABA问题因为CAS会检查旧值有没有变化，这里存在这样一个有意思的问题。比如一个旧值A变为了成B，然后再变成A，刚好在做CAS时检查发现旧值并没有变化依然为A，但是实际上的确发生了变化。解决方案可以沿袭数据库中常用的乐观锁方式，添加一个版本号可以解决。原来的变化路径A-&gt;B-&gt;A就变成了1A-&gt;2B-&gt;3C。 自旋时间过长 使用CAS时非阻塞同步，也就是说不会将线程挂起，会自旋（无非就是一个死循环）进行下一次尝试，如果这里自旋时间过长对性能是很大的消耗。如果JVM能支持处理器提供的pause指令，那么在效率上会有一定的提升。 原子更新基本类型atomic包提高原子更新基本类型的工具类，主要有这些： AtomicBoolean：以原子更新的方式更新boolean； AtomicInteger：以原子更新的方式更新Integer; AtomicLong：以原子更新的方式更新Long； 这几个类的用法基本一致，这里以AtomicInteger为例总结常用的方法 addAndGet(int delta) ：以原子方式将输入的数值与实例中原本的值相加，并返回最后的结果； incrementAndGet() ：以原子的方式将实例中的原值进行加1操作，并返回最终相加后的结果； getAndSet(int newValue)：将实例中的值更新为新值，并返回旧值； getAndIncrement()：以原子的方式将实例中的原值加1，返回的是自增前的旧值； 还有一些方法，可以查看API，不再赘述。为了能够弄懂AtomicInteger的实现原理，以getAndIncrement方法为例，来看下源码： 123public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1);} 可以看出，该方法实际上是调用了unsafe实例的getAndAddInt方法，unsafe实例的获取时通过UnSafe类的静态方法getUnsafe获取： 1private static final Unsafe unsafe = Unsafe.getUnsafe(); Unsafe类在sun.misc包下，Unsafer类提供了一些底层操作，atomic包下的原子操作类的也主要是通过Unsafe类提供的compareAndSwapInt，compareAndSwapLong等一系列提供CAS操作的方法来进行实现。下面用一个简单的例子来说明AtomicInteger的用法： 12345678public class AtomicDemo { private static AtomicInteger atomicInteger = new AtomicInteger(1); public static void main(String[] args) { System.out.println(atomicInteger.getAndIncrement()); System.out.println(atomicInteger.get()); }} 输出结果 1212 例子很简单，就是新建了一个atomicInteger对象，而atomicInteger的构造方法也就是传入一个基本类型数据即可，对其进行了封装。对基本变量的操作比如自增，自减，相加，更新等操作，atomicInteger也提供了相应的方法进行这些操作。但是，因为atomicInteger借助了UnSafe提供的CAS操作能够保证数据更新的时候是线程安全的，并且由于CAS是采用乐观锁策略，因此，这种数据更新的方法也具有高效性。 AtomicLong的实现原理和AtomicInteger一致，只不过一个针对的是long变量，一个针对的是int变量。而boolean变量的更新类AtomicBoolean类是怎样实现更新的呢？核心方法是compareAndSett方法，其源码如下： 12345public final boolean compareAndSet(boolean expect, boolean update) { int e = expect ? 1 : 0; int u = update ? 1 : 0; return unsafe.compareAndSwapInt(this, valueOffset, e, u);} 可以看出，compareAndSet方法的实际上也是先转换成0,1的整型变量，然后是通过针对int型变量的原子更新方法compareAndSwapInt来实现的。可以看出atomic包中只提供了对boolean,int ,long这三种基本类型的原子更新的方法，参考对boolean更新的方式，原子更新char,doule,float也可以采用类似的思路进行实现。 原子更新数组类型atomic包下提供能原子更新数组中元素的类有： AtomicIntegerArray：原子更新整型数组中的元素； AtomicLongArray：原子更新长整型数组中的元素； AtomicReferenceArray：原子更新引用类型数组中的元素 这几个类的用法一致，就以AtomicIntegerArray来总结下常用的方法： addAndGet(int i, int delta)：以原子更新的方式将数组中索引为i的元素与输入值相加，返回值是相加后的结果； getAndAdd(int i, int delta)：将数组中索引为i的元素以原子更新的方式与输入值相加，返回值是相加前的结果； getAndIncrement(int i)：以原子更新的方式将数组中索引为i的元素自增加1； compareAndSet(int i, int expect, int update)：将数组中索引为i的位置的元素进行更新 可以看出，AtomicIntegerArray与AtomicInteger的方法基本一致，只不过在AtomicIntegerArray的方法中会多一个指定数组索引位i。下面举一个简单的例子： 123456789101112131415public class AtomicIntegerArrayDemo { private static int[] value = new int[]{1, 2, 3}; private static AtomicIntegerArray integerArray = new AtomicIntegerArray(value); public static void main(String[] args) { //对数组中索引为1的位置的元素加5 int result = integerArray.getAndAdd(1, 5); System.out.println(result); System.out.println(integerArray.get(1)); int result2 = integerArray.addAndGet(1, 5); System.out.println(result2); System.out.println(integerArray.get(1)); }} 输出结果 1234271212 通过getAndAdd方法将位置为1的元素加5，从结果可以看出索引为1的元素变成了7，该方法返回的也是相加之前的数为2； 通过addAndGet方法将位置为1的元素加5，从结果可以看出索引为1的元素变成了12，该方法返回的也是相加之后的数为12。 原子更新引用类型如果需要原子更新引用类型变量的话，为了保证线程安全，atomic也提供了相关的类： AtomicReference：原子更新引用类型； AtomicReferenceFieldUpdater：原子更新引用类型里的字段； AtomicMarkableReference：原子更新带有标记位的引用类型； 这几个类的使用方法也是基本一样的，以AtomicReference为例，来说明这些类的基本用法。下面是一个demo 12345678910111213141516171819202122232425262728293031public class AtomicReferenceDemo { private static AtomicReference&lt;User&gt; reference = new AtomicReference&lt;&gt;(); public static void main(String[] args) { User user1 = new User(&quot;a&quot;, 1); reference.set(user1); User user2 = new User(&quot;b&quot;,2); User user = reference.getAndSet(user2); System.out.println(user); System.out.println(reference.get()); } static class User { private String userName; private int age; public User(String userName, int age) { this.userName = userName; this.age = age; } @Override public String toString() { return &quot;User{&quot; + &quot;userName='&quot; + userName + '\\'' + &quot;, age=&quot; + age + '}'; } }} 输出结果 12User{userName='a', age=1}User{userName='b', age=2} 首先将对象User1用AtomicReference进行封装，然后调用getAndSet方法，从结果可以看出，该方法会原子更新引用的user对象，变为User{userName='b', age=2}，返回的是原来的user对象User{userName='a', age=1}。 原子更新字段类型如果需要更新对象的某个字段，并在多线程的情况下，能够保证线程安全，atomic同样也提供了相应的原子操作类： AtomicIntegeFieldUpdater：原子更新整型字段类； AtomicLongFieldUpdater：原子更新长整型字段类； AtomicStampedReference：原子更新引用类型，这种更新方式会带有版本号。而为什么在更新的时候会带有版本号，是为了解决CAS的ABA问题； 要想使用原子更新字段需要两步操作： 原子更新字段类都是抽象类，只能通过静态方法newUpdater来创建一个更新器，并且需要设置想要更新的类和属性； 更新类的属性必须使用public volatile进行修饰； 这几个类提供的方法基本一致，以AtomicIntegerFieldUpdater为例来看看具体的使用： 12345678910111213141516171819202122232425262728public class AtomicDemo { private static AtomicIntegerFieldUpdater updater = AtomicIntegerFieldUpdater.newUpdater(User.class,&quot;age&quot;); public static void main(String[] args) { User user = new User(&quot;a&quot;, 1); int oldValue = updater.getAndAdd(user, 5); System.out.println(oldValue); System.out.println(updater.get(user)); } static class User { private String userName; public volatile int age; public User(String userName, int age) { this.userName = userName; this.age = age; } @Override public String toString() { return &quot;User{&quot; + &quot;userName='&quot; + userName + '\\'' + &quot;, age=&quot; + age + '}'; } }} 输出结果 1216 从示例中可以看出，创建AtomicIntegerFieldUpdater是通过它提供的静态方法进行创建，getAndAdd方法会将指定的字段加上输入的值，并且返回相加之前的值。user对象中age字段原值为1，加5之后，可以看出user对象中的age字段的值已经变成了6。","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-Java%E4%B8%ADatomic%E5%8C%85%E4%B8%AD%E7%9A%84%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%B1%BB%E6%80%BB%E7%BB%93/"},{"title":"并发编程-Java内存模型以及happens-before","text":"在上一篇文章中总结了*线程的状态转换和一些基本操作*，对多线程已经有一点基本的认识了，如果多线程编程只有这么简单，那我们就不必费劲周折的去学习它了。在多线程中稍微不注意就会出现线程安全问题，那么什么是线程安全问题？ Java内存模型（JMM）的介绍我的认识是，在多线程下代码执行的结果与预期正确的结果不一致，该代码就是线程不安全的，否则则是线程安全的。虽然这种回答似乎不能获取什么内容，可以google下。 在&lt;&lt;深入理解Java虚拟机&gt;&gt;中看到的定义。原文如下： 当多个线程访问同一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替运行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获取正确的结果，那这个对象是线程安全的。 关于定义的理解是一个仁者见仁智者见智的事情。出现线程安全的问题一般是因为主内存和工作内存数据不一致性和重排序导致的，而解决线程安全的问题最重要的就是理解这两种问题是怎么来的，那么，理解它们的核心在于理解Java内存模型（JMM）。 在多线程条件下，多个线程肯定会相互协作完成一件事情，一般来说就会涉及到多个线程间相互通信告知彼此的状态以及当前的执行结果等，另外，为了性能优化，还会涉及到编译器指令重排序和处理器指令重排序。下面会一一来聊聊这些知识。 内存模型抽象结构线程间协作通信可以类比人与人之间的协作的方式，在现实生活中，之前网上有个流行语“你妈喊你回家吃饭了”，就以这个生活场景为例，小明在外面玩耍，小明妈妈在家里做饭，做完饭后准备叫小明回家吃饭，那么就存在两种方式： 小明妈妈要去上班了十分紧急这个时候手机又没有电了，于是就在桌子上贴了一张纸条“饭做好了，放在…”小明回家后看到纸条如愿吃到妈妈做的饭菜，那么，如果将小明妈妈和小明作为两个线程，那么这张纸条就是这两个线程间通信的共享变量，通过读写共享变量实现两个线程间协作； 还有一种方式就是，妈妈的手机还有电，妈妈在赶去坐公交的路上给小明打了个电话，这种方式就是通知机制来完成协作。同样，可以引申到线程间通信机制。 通过上面这个例子，应该有些认识。在并发编程中主要需要解决两个问题：1. 线程之间如何通信；2.线程之间如何完成同步（这里的线程指的是并发执行的活动实体）。通信是指线程之间以何种机制来交换信息，主要有两种：共享内存和消息传递。这里，可以分别类比上面的两个举例。Java内存模型是共享内存的并发模型，线程之间主要通过读-写共享变量来完成隐式通信。如果程序员不能理解Java的共享内存模型在编写并发程序时一定会遇到各种各样关于内存可见性的问题。 哪些是共享变量在Java程序中所有实例域，静态域和数组元素都是放在堆内存中（所有线程均可访问到，是可以共享的），而局部变量，方法定义参数和异常处理器参数不会在线程间共享。共享数据会出现线程安全的问题，而非共享数据不会出现线程安全的问题。关于JVM运行时内存区域在后面的文章会讲到。 JMM抽象结构模型我们知道CPU的处理速度和主存的读写速度不是一个量级的（CPU的处理速度快很多），为了平衡这种巨大的差距，每个CPU都会有缓存。因此，共享变量会先放在主存中，每个线程都有属于自己的工作内存，并且会把位于主存中的共享变量拷贝到自己的工作内存，之后的读写操作均使用位于工作内存的变量副本，并在某个时刻将工作内存的变量副本写回到主存中去。JMM就从抽象层次定义了这种方式，并且JMM决定了一个线程对共享变量的写入何时对其他线程是可见的。 如图为JMM抽象示意图，线程A和线程B之间要完成通信的话，要经历如下两步： 线程A从主内存中将共享变量读入线程A的工作内存后并进行操作，之后将数据重新写回到主内存中； 线程B从主存中读取最新的共享变量 从横向去看看，线程A和线程B就好像通过共享变量在进行隐式通信。这其中有个意思的问题，如果线程A更新后数据并没有及时写回到主存，而此时线程B读到的是过期的数据，这就出现了“脏读”现象。可以通过同步机制（控制不同线程间操作发生的相对顺序）来解决或者通过volatile关键字使得每次volatile变量都能够强制刷新到主存，从而对每个线程都是可见的。 重排序一个好的内存模型实际上会放宽对处理器和编译器规则的束缚，也就是说软件技术和硬件技术都为同一个目标而进行奋斗：在不改变程序执行结果的前提下，尽可能提高并行度。Java内存模型（JMM）对底层尽量减少约束，使其能够发挥自身优势。因此，在执行程序时，为了提高性能，编译器和处理器常常会对指令进行重排序。一般重排序可以分为如下三种： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序； 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序； 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行的。 如图，1属于编译器重排序，而2和3统称为处理器重排序。这些重排序会导致线程安全的问题，一个很经典的例子就是DCL（双重检验锁）问题，这个在以后的文章中会具体去聊。针对编译器重排序，Java内存模型（JMM）的编译器重排序规则会禁止一些特定类型的编译器重排序；针对处理器重排序，编译器在生成指令序列的时候会通过插入内存屏障指令来禁止某些特殊的处理器重排序。 那么什么情况下，不能进行重排序了？下面就来说说数据依赖性。有如下代码： 123double pi = 3.14 //Adouble r = 1.0 //Bdouble area = pi * r * r //C 这是一个计算圆面积的代码，由于A，B之间没有任何关系，对最终结果也不会存在影响，它们之间执行顺序可以重排序。因此执行顺序可以是A-&gt;B-&gt;C或者B-&gt;A-&gt;C执行最终结果都是3.14，即A和B之间没有数据依赖性。具体的定义为：如果两个操作访问同一个变量，且这两个操作有一个为写操作，此时这两个操作就存在数据依赖性，这里就存在三种情况：1. 读后写；2.写后写；3. 写后读，或者三种操作都是存在数据依赖性的，如果重排序会对最终执行结果产生影响，编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖性关系的两个操作的执行顺序 另外，还有一个比较有意思的就是as-if-serial语义。 as-if-serial as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提供并行度），（单线程）程序的执行结果不能被改变。编译器，runtime和处理器都必须遵守as-if-serial语义。as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器，runtime和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。比如上面计算圆面积的代码，在单线程中，会让人感觉代码是一行一行顺序执行上，实际上A,B两行不存在数据依赖性可能会进行重排序，即A，B不是顺序执行的。as-if-serial语义使程序员不必担心单线程中重排序的问题干扰他们，也无需担心内存可见性问题。 happens-before规则上面的内容讲述了重排序原则，一会是编译器重排序一会是处理器重排序，如果让程序员再去了解这些底层的实现以及具体规则，那么程序员的负担就太重了，严重影响了并发编程的效率。因此，JMM为程序员在上层提供了六条规则，这样我们就可以根据规则去推论跨线程的内存可见性问题，而不用再去理解底层重排序的规则。下面以两个方面来说。 happens-before定义happens-before的概念最初由Leslie Lamport在其一篇影响深远的论文（《Time，Clocks and the Ordering of Events in a Distributed System》）中提出，有兴趣的可以google一下。JSR-133使用happens-before的概念来指定两个操作之间的执行顺序。由于这两个操作可以在一个线程之内，也可以是在不同线程之间。因此，JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证（如果A线程的写操作a与B线程的读操作b之间存在happens-before关系，尽管a操作和b操作在不同的线程中执行，但JMM向程序员保证a操作将对b操作可见）。具体的定义为： 1）如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 2）两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。 上面的1）是JMM对程序员的承诺。从程序员的角度来说，可以这样理解happens-before关系：如果A happens-before B，那么Java内存模型将向程序员保证——A操作的结果将对B可见，且A的执行顺序排在B之前。注意，这只是Java内存模型向程序员做出的保证！ 上面的2）是JMM对编译器和处理器重排序的约束原则。正如前面所言，JMM其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。JMM这么做的原因是：程序员对于这两个操作是否真的被重排序并不关心，程序员关心的是程序执行时的语义不能被改变（即执行结果不能被改变）。因此，happens-before关系本质上和as-if-serial语义是一回事。 下面来比较一下as-if-serial和happens-before: as-if-serial VS happens-before as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。 as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。 as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。 具体规则具体的一共有六项规则： 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。 start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。 join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 程序中断规则：对线程interrupted()方法的调用先行于被中断线程的代码检测到中断时间的发生。 对象finalize规则：一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始。 下面以一个具体的例子来讲下如何使用这些规则进行推论： 依旧以上面计算圆面积的进行描述。利用程序顺序规则（规则1）存在三个happens-before关系：1. A happens-before B；2. B happens-before C;3. A happens-before C。这里的第三个关系是利用传递性进行推论的。A happens-before B,定义1要求A执行结果对B可见，并且A操作的执行顺序在B操作之前，但与此同时利用定义中的第二条，A,B操作彼此不存在数据依赖性，两个操作的执行顺序对最终结果都不会产生影响，在不改变最终结果的前提下，允许A，B两个操作重排序，即happens-before关系并不代表了最终的执行顺序。 总结上面已经聊了关于JMM的两个方面： JMM的抽象结构（主内存和线程工作内存）； 重排序以及happens-before规则。 接下来，我们来做一个总结。从两个方面进行考虑： 如果让我们设计JMM应该从哪些方面考虑，也就是说JMM承担哪些功能； happens-before与JMM的关系； 由于JMM，多线程情况下可能会出现哪些问题？ JMM的设计 JMM是语言级的内存模型，在我的理解中JMM处于中间层，包含了两个方面：（1）内存模型；（2）重排序以及happens-before规则。同时，为了禁止特定类型的重排序会对编译器和处理器指令序列加以控制。而上层会有基于JMM的关键字和J.U.C包下的一些具体类用来方便程序员能够迅速高效率的进行并发编程。站在JMM设计者的角度，在设计JMM时需要考虑两个关键因素: 程序员对内存模型的使用 程序员希望内存模型易于理解、易于编程。程序员希望基于一个强内存模型来编写代码。 编译器和处理器对内存模型的实现 编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。编译器和处理器希望实现一个弱内存模型。 另外还要一个特别有意思的事情就是关于重排序问题，更简单的说，重排序可以分为两类： 会改变程序执行结果的重排序。 不会改变程序执行结果的重排序。 JMM对这两种不同性质的重排序，采取了不同的策略，如下。 对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序。 对于不会改变程序执行结果的重排序，JMM对编译器和处理器不做要求（JMM允许这种 重排序） JMM的设计图为： 可以看出： JMM向程序员提供的happens-before规则能满足程序员的需求。JMM的happens-before规则不但简单易懂，而且也向程序员提供了足够强的内存可见性保证（有些内存可见性保证其实并不一定真实存在，比如上面的A happens-before B）。 JMM对编译器和处理器的束缚已经尽可能少。从上面的分析可以看出，JMM其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。例如，如果编译器经过细致的分析后，认定一个锁只会被单个线程访问，那么这个锁可以被消除。再如，如果编译器经过细致的分析后，认定一个volatile变量只会被单个线程访问，那么编译器可以把这个volatile变量当作一个普通变量来对待。这些优化既不会改变程序的执行结果，又能提高程序的执行效率。 happens-before与JMM的关系 一个happens-before规则对应于一个或多个编译器和处理器重排序规则。对于Java程序员来说，happens-before规则简单易懂，它避免Java程序员为了理解JMM提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现方法。 今后可能需要关注的问题从上面内存抽象结构来说，可能出在数据“脏读”的现象，这就是数据可见性的问题，另外，重排序在多线程中不注意的话也容易存在一些问题，比如一个很经典的问题就是DCL（双重检验锁），这就是需要禁止重排序，另外，在多线程下原子操作例如i++不加以注意的也容易出现线程安全的问题。但总的来说，在多线程开发时需要从原子性，有序性，可见性三个方面进行考虑。J.U.C包下的并发工具类和并发容器也是需要花时间去掌握的，这些东西在以后得文章中多会一一进行讨论。 参考文献：《java并发编程的艺术》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%BB%A5%E5%8F%8Ahappens-before/"},{"title":"并发编程-LockSupport介绍","text":"LockSupport简介在之前介绍AQS的底层实现、java中的Lock（比如ReentrantLock，ReentReadWriteLocks）、以及在介绍线程间等待/通知机制使用的Condition时，都会调用LockSupport.park()方法和LockSupport.unpark()方法。而这个在同步组件的实现中被频繁使用的LockSupport到底是何方神圣，现在就来看看。 LockSupport位于java.util.concurrent.locks包下，有兴趣的可以直接去看源码，该类的方法并不是很多。LockSupprot是线程的阻塞工具，用来阻塞线程和唤醒线程。每个使用LockSupport的线程都会与一个许可关联，如果该许可可用，并且可在线程中使用，则调用park()将会立即返回，否则可能阻塞。如果许可尚不可用，则可以调用 unpark 使其可用。但是注意许可不可重入，也就是说只能调用一次park()方法，否则会一直阻塞。 LockSupport方法介绍LockSupport中的方法不多，这里将这些方法做一个总结： 阻塞线程 void park()：阻塞当前线程，如果调用unpark方法或者当前线程被中断，就能从park()方法中返回 void park(Object blocker)：功能同方法1，入参增加一个Object对象，用来记录导致线程阻塞的阻塞对象，方便进行问题排查； void parkNanos(long nanos)：阻塞当前线程，最长不超过nanos纳秒，增加了超时返回的特性； void parkNanos(Object blocker, long nanos)：功能同方法3，入参增加一个Object对象，用来记录导致线程阻塞的阻塞对象，方便进行问题排查； void parkUntil(long deadline)：阻塞当前线程，直到deadline； void parkUntil(Object blocker, long deadline)：功能同方法5，入参增加一个Object对象，用来记录导致线程阻塞的阻塞对象，方便进行问题排查； 唤醒线程 void unpark(Thread thread)：唤醒处于阻塞状态的指定线程 总结实际上LockSupport阻塞和唤醒线程的功能是依赖于sun.misc.Unsafe，这是一个很底层的类，有兴趣的可以去查阅资料，比如park()方法的功能实现则是靠unsafe.park()方法。另外在阻塞线程这一系列方法中还有一个很有意思的现象就是，每个方法都会新增一个带有Object的阻塞对象的重载方法。那么增加了一个Object对象的入参会有什么不同的地方了？示例代码很简单就不说了，直接看dump线程的信息。 调用park()方法dump线程： 12345&quot;main&quot; #1 prio=5 os_prio=0 tid=0x02cdcc00 nid=0x2b48 waiting on condition [0x00d6f000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304) at learn.LockSupportDemo.main(LockSupportDemo.java:7) 调用park(Object blocker)方法dump线程 123456&quot;main&quot; #1 prio=5 os_prio=0 tid=0x0069cc00 nid=0x6c0 waiting on condition [0x00dcf000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x048c2d18&gt; (a java.lang.String) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at learn.LockSupportDemo.main(LockSupportDemo.java:7) 通过分别调用这两个方法然后dump线程信息可以看出，带Object的park方法相较于无参的park方法会增加 parking to wait for &lt;0x048c2d18&gt; (a java.lang.String）的信息，这种信息就类似于记录“案发现场”，有助于工程人员能够迅速发现问题解决问题。有个有意思的事情是，我们都知道如果使用synchronzed阻塞了线程dump线程时都会有阻塞对象的描述，在java 5推出LockSupport时遗漏了这一点，在java 6时进行了补充。还有一点需要补充的是：synchronzed致使线程阻塞，线程会进入到BLOCKED状态，而调用LockSupprt方法阻塞线程会致使线程进入到WAITING状态 一个例子用一个很简单的例子说说这些方法怎么用。 123456789101112131415public class LockSupportDemo { public static void main(String[] args) { Thread thread = new Thread(() -&gt; { LockSupport.park(); System.out.println(Thread.currentThread().getName() + &quot;被唤醒&quot;); }); thread.start(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } LockSupport.unpark(thread); }} thread线程调用LockSupport.park()致使thread阻塞，当main线程睡眠3秒结束后通过LockSupport.unpark(thread)方法唤醒thread线程，thread线程被唤醒执行后续操作。另外，还有一点值得关注的是，LockSupport.unpark(thread)可以指定线程对象唤醒指定的线程。","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-LockSupport%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-ReentrantLock(重入锁)介绍","text":"ReentrantLock的介绍ReentrantLock重入锁，是实现Lock接口的一个类，也是在实际编程中使用频率很高的一个锁，支持重入性，表示能够对共享资源能够重复加锁，即当前线程获取该锁再次获取不会被阻塞。在java关键字synchronized隐式支持重入性（关于synchronized可以看这篇文章），synchronized通过获取自增，释放自减的方式实现重入。与此同时，ReentrantLock还支持公平锁和非公平锁两种方式。那么，要想完完全全的弄懂ReentrantLock的话，主要也就是ReentrantLock同步语义的学习：1. 重入性的实现原理；2. 公平锁和非公平锁。 重入性的实现原理要想支持重入性，就要解决两个问题：1. 在线程获取锁的时候，如果已经获取锁的线程是当前线程的话则直接再次获取成功；2. 由于锁会被获取n次，那么只有锁在被释放同样的n次之后，该锁才算是完全释放成功。通过这篇文章，我们知道，同步组件主要是通过重写AQS的几个protected方法来表达自己的同步语义。针对第一个问题，我们来看看ReentrantLock是怎样实现的，以非公平锁为例，判断当前线程能否获得锁为例，核心方法为nonfairTryAcquire： 123456789101112131415161718192021final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); //1. 如果该锁未被任何线程占有，该锁能被当前线程获取 if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //2.若被占有，检查占有线程是否是当前线程 else if (current == getExclusiveOwnerThread()) { // 3. 再次获取，计数加一 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false;} 这段代码的逻辑也很简单，具体请看注释。为了支持重入性，在第二步增加了处理逻辑，如果该锁已经被线程所占有了，会继续检查占有线程是否为当前线程，如果是的话，同步状态加1返回true，表示可以再次获取成功。每次重新获取都会对同步状态进行加一的操作，那么释放的时候处理思路是怎样的了？（依然还是以非公平锁为例）核心方法为tryRelease： 123456789101112131415protected final boolean tryRelease(int releases) { //1. 同步状态减1 int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { //2. 只有当同步状态为0时，锁成功被释放，返回true free = true; setExclusiveOwnerThread(null); } // 3. 锁未被完全释放，返回false setState(c); return free;} 代码的逻辑请看注释，需要注意的是，重入锁的释放必须得等到同步状态为0时锁才算成功释放，否则锁仍未释放。如果锁被获取n次，释放了n-1次，该锁未完全释放返回false，只有被释放n次才算成功释放，返回true。到现在我们可以理清ReentrantLock重入性的实现了，也就是理解了同步语义的第一条。 公平锁与非公平锁ReentrantLock支持两种锁：公平锁和非公平锁。何谓公平性，是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求上的绝对时间顺序，满足FIFO。ReentrantLock的构造方法无参时是构造非公平锁，源码为： 123public ReentrantLock() { sync = new NonfairSync();} 另外还提供了另外一种方式，可传入一个boolean值，true时为公平锁，false时为非公平锁，源码为： 123public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync();} 在上面非公平锁获取时（nonfairTryAcquire方法）只是简单的获取了一下当前状态做了一些逻辑处理，并没有考虑到当前同步队列中线程等待的情况。我们来看看公平锁的处理逻辑是怎样的，核心方法为： 1234567891011121314151617181920protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; }} 这段代码的逻辑与nonfairTryAcquire基本上一致，唯一的不同在于增加了hasQueuedPredecessors的逻辑判断，方法名就可知道该方法用来判断当前节点在同步队列中是否有前驱节点的判断，如果有前驱节点说明有线程比当前线程更早的请求资源，根据公平性，当前线程请求资源失败。如果当前节点没有前驱节点的话，再才有做后面的逻辑判断的必要性。公平锁每次都是从同步队列中的第一个节点获取到锁，而非公平性锁则不一定，有可能刚释放锁的线程能再次获取到锁。 公平锁 VS 非公平锁 公平锁每次获取到锁为同步队列中的第一个节点，保证请求资源时间上的绝对顺序，而非公平锁有可能刚释放锁的线程下次继续获取该锁，则有可能导致其他线程永远无法获取到锁，造成“饥饿”现象。 公平锁为了保证时间上的绝对顺序，需要频繁的上下文切换，而非公平锁会降低一定的上下文切换，降低性能开销。因此，ReentrantLock默认选择的是非公平锁，则是为了减少一部分上下文切换，保证了系统更大的吞吐量。 参考文献 《Java并发编程的艺术》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-ReentrantLock-%E9%87%8D%E5%85%A5%E9%94%81-%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-ReentrantReadWriteLock(读写锁)介绍","text":"读写锁的介绍在并发场景中用于解决线程安全的问题，我们几乎会高频率的使用到独占式锁，通常使用java提供的关键字synchronized（关于synchronized可以看这篇文章）或者concurrents包中实现了Lock接口的ReentrantLock。它们都是独占式获取锁，也就是在同一时刻只有一个线程能够获取锁。 而在一些业务场景中，大部分只是读数据，写数据很少，如果仅仅是读数据的话并不会影响数据正确性（出现脏读），而如果在这种业务场景下，依然使用独占锁的话，很显然这将是出现性能瓶颈的地方。针对这种读多写少的情况，java还提供了另外一个实现Lock接口的ReentrantReadWriteLock(读写锁)。读写锁允许同一时刻被多个读线程访问，但是在写线程访问时，所有的读线程和其他的写线程都会被阻塞。在分析WirteLock和ReadLock的互斥性时可以按照WriteLock与WriteLock之间，WriteLock与ReadLock之间以及ReadLock与ReadLock之间进行分析。更多关于读写锁特性介绍大家可以看源码上的介绍（阅读源码是最好的一种学习方式，我也正在学习中，与大家共勉），这里做一个归纳总结： 公平性选择：支持非公平性（默认）和公平的锁获取方式，吞吐量还是非公平优于公平； 重入性：支持重入，读锁获取后能再次获取，写锁获取之后能够再次获取写锁，同时也能够获取读锁； 锁降级：遵循获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁 要想能够彻底的理解读写锁必须能够理解这样几个问题：1. 读写锁是怎样实现分别记录读写状态的？2. 写锁是怎样获取和释放的？3.读锁是怎样获取和释放的？我们带着这样的三个问题，再去了解下读写锁。 写锁详解写锁的获取同步组件的实现聚合了同步器（AQS），并通过重写同步器（AQS）中的方法实现同步组件的同步语义（关于同步组件的实现层级结构可以看这篇文章，AQS的底层实现分析可以看这篇文章）。因此，写锁的实现依然也是采用这种方式。在同一时刻写锁是不能被多个线程所获取，很显然写锁是独占式锁，而实现写锁的同步语义是通过重写AQS中的tryAcquire方法实现的。源码为: 12345678910111213141516171819202122232425262728293031323334353637protected final boolean tryAcquire(int acquires) { /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); // 1. 获取写锁当前的同步状态 int c = getState(); // 2. 获取写锁获取的次数（独占式获取的次数） int w = exclusiveCount(c); if (c != 0) { // (Note: if c != 0 and w == 0 then shared count != 0) // 3.1 当读锁已被读线程获取或者当前线程不是已经获取写锁的线程的话 // 当前线程获取写锁失败 if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire // 3.2 当前线程获取写锁，支持可重复加锁 setState(c + acquires); return true; } // 3.3 写锁未被任何线程获取，当前线程可获取写锁 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true;} 这段代码的逻辑请看注释，这里有一个地方需要重点关注，exclusiveCount©方法，该方法源码为： 1static int exclusiveCount(int c) { return c &amp; EXCLUSIVE_MASK; } 其中EXCLUSIVE_MASK为: static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1; EXCLUSIVE _MASK为1左移16位然后减1，即为0x0000FFFF。而exclusiveCount方法是将同步状态（state为int类型）与0x0000FFFF相与，即取同步状态的低16位。那么低16位代表什么呢？根据exclusiveCount方法的注释为独占式获取的次数即写锁被获取的次数，现在就可以得出来一个结论同步状态的低16位用来表示写锁的获取次数。同时还有一个方法值得我们注意： 1static int sharedCount(int c) { return c &gt;&gt;&gt; SHARED_SHIFT; } 该方法是获取读锁被获取的次数，是将同步状态（int c）右移16次，即取同步状态的高16位，现在我们可以得出另外一个结论同步状态的高16位用来表示读锁被获取的次数。现在还记得我们开篇说的需要弄懂的第一个问题吗？读写锁是怎样实现分别记录读锁和写锁的状态的，现在这个问题的答案就已经被我们弄清楚了，其示意图如下图所示： 现在我们回过头来看写锁获取方法tryAcquire，其主要逻辑为：当读锁已经被读线程获取或者写锁已经被其他写线程获取，则写锁获取失败；否则，获取成功并支持重入，增加写状态。 写锁的释放写锁释放通过重写AQS的tryRelease方法，源码为： 12345678910111213protected final boolean tryRelease(int releases) { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //1. 同步状态减去写状态 int nextc = getState() - releases; //2. 当前写状态是否为0，为0则释放写锁 boolean free = exclusiveCount(nextc) == 0; if (free) setExclusiveOwnerThread(null); //3. 不为0则更新同步状态 setState(nextc); return free;} 源码的实现逻辑请看注释，不难理解与ReentrantLock基本一致，这里需要注意的是，减少写状态int nextc = getState() - releases;只需要用当前同步状态直接减去写状态的原因正是我们刚才所说的写状态是由同步状态的低16位表示的。 读锁详解读锁的获取看完了写锁，现在来看看读锁，读锁不是独占式锁，即同一时刻该锁可以被多个读线程获取也就是一种共享式锁。按照之前对AQS介绍，实现共享式同步组件的同步语义需要通过重写AQS的tryAcquireShared方法和tryReleaseShared方法。读锁的获取实现方法为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748protected final int tryAcquireShared(int unused) { /* * Walkthrough: * 1. If write lock held by another thread, fail. * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ Thread current = Thread.currentThread(); int c = getState(); //1. 如果写锁已经被获取并且获取写锁的线程不是当前线程的话，当前 // 线程获取读锁失败返回-1 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; //2. 当前线程获取读锁 compareAndSetState(c, c + SHARED_UNIT)) { //3. 下面的代码主要是新增的一些功能，比如getReadHoldCount()方法 //返回当前获取读锁的次数 if (r == 0) { firstReader = current; firstReaderHoldCount = 1; } else if (firstReader == current) { firstReaderHoldCount++; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; } return 1; } //4. 处理在第二步中CAS操作失败的自旋已经实现重入性 return fullTryAcquireShared(current);} 代码的逻辑请看注释，需要注意的是 当写锁被其他线程获取后，读锁获取失败，否则获取成功利用CAS更新同步状态。另外，当前同步状态需要加上SHARED_UNIT（(1 &lt;&lt; SHARED_SHIFT)即0x00010000）的原因这是我们在上面所说的同步状态的高16位用来表示读锁被获取的次数。如果CAS失败或者已经获取读锁的线程再次获取读锁时，是靠fullTryAcquireShared方法实现的，这段代码就不展开说了，有兴趣可以看看。 读锁的释放读锁释放的实现主要通过方法tryReleaseShared，源码如下，主要逻辑请看注释： 1234567891011121314151617181920212223242526272829303132protected final boolean tryReleaseShared(int unused) { Thread current = Thread.currentThread(); // 前面还是为了实现getReadHoldCount等新功能 if (firstReader == current) { // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count &lt;= 1) { readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); } --rh.count; } for (;;) { int c = getState(); // 读锁释放 将同步状态减去读状态即可 int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; }} 锁降级读写锁支持锁降级，遵循按照获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁，不支持锁升级，关于锁降级下面的示例代码摘自ReentrantWriteReadLock源码中： 123456789101112131415161718192021222324252627void processCachedData() { rwl.readLock().lock(); if (!cacheValid) { // Must release read lock before acquiring write lock rwl.readLock().unlock(); rwl.writeLock().lock(); try { // Recheck state because another thread might have // acquired write lock and changed state before we did. if (!cacheValid) { data = ... cacheValid = true; } // Downgrade by acquiring read lock before releasing write lock rwl.readLock().lock(); } finally { rwl.writeLock().unlock(); // Unlock write, still hold read } } try { use(data); } finally { rwl.readLock().unlock(); } }}","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-ReentrantReadWriteLock-%E8%AF%BB%E5%86%99%E9%94%81-%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-ScheduledThreadPoolExecutor介绍","text":"ScheduledThreadPoolExecutor简介ScheduledThreadPoolExecutor可以用来在给定延时后执行异步任务或者周期性执行任务，相对于任务调度的Timer来说，其功能更加强大，Timer只能使用一个后台线程执行任务，而ScheduledThreadPoolExecutor则可以通过构造函数来指定后台线程的个数。 ScheduledThreadPoolExecutor类的UML图如下： 从UML图可以看出，ScheduledThreadPoolExecutor继承了ThreadPoolExecutor，也就是说ScheduledThreadPoolExecutor拥有execute()和submit()提交异步任务的基础功能，关于ThreadPoolExecutor可以看这篇文章。但是，ScheduledThreadPoolExecutor类实现了ScheduledExecutorService，该接口定义了ScheduledThreadPoolExecutor能够延时执行任务和周期执行任务的功能； ScheduledThreadPoolExecutor也两个重要的内部类：DelayedWorkQueue和ScheduledFutureTask。可以看出DelayedWorkQueue实现了BlockingQueue接口，也就是一个阻塞队列，ScheduledFutureTask则是继承了FutureTask类，也表示该类用于返回异步任务的结果。这两个关键类，下面会具体详细来看。 构造方法ScheduledThreadPoolExecutor有如下几个构造方法： 1234567891011121314151617181920212223public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());}public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);}public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler);}public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);} 可以看出由于ScheduledThreadPoolExecutor继承了ThreadPoolExecutor，它的构造方法实际上是调用了ThreadPoolExecutor，对ThreadPoolExecutor的介绍可以可以看这篇文章，理解ThreadPoolExecutor构造方法的几个参数的意义后，理解这就很容易了。可以看出，ScheduledThreadPoolExecutor的核心线程池的线程个数为指定的corePoolSize，当核心线程池的线程个数达到corePoolSize后，就会将任务提交给有界阻塞队列DelayedWorkQueue，对DelayedWorkQueue在下面进行详细介绍，线程池允许最大的线程个数为Integer.MAX_VALUE，也就是说理论上这是一个大小无界的线程池。 特有方法ScheduledThreadPoolExecutor实现了ScheduledExecutorService接口，该接口定义了可延时执行异步任务和可周期执行异步任务的特有功能，相应的方法分别为： 123456789101112131415161718192021222324//达到给定的延时时间后，执行任务。这里传入的是实现Runnable接口的任务，//因此通过ScheduledFuture.get()获取结果为nullpublic ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit);//达到给定的延时时间后，执行任务。这里传入的是实现Callable接口的任务，//因此，返回的是任务的最终计算结果public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit);//是以上一个任务开始的时间计时，period时间过去后，//检测上一个任务是否执行完毕，如果上一个任务执行完毕，//则当前任务立即执行，如果上一个任务没有执行完毕，则需要等上一个任务执行完毕后立即执行public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit);//当达到延时时间initialDelay后，任务开始执行。上一个任务执行结束后到下一次//任务执行，中间延时时间间隔为delay。以这种方式，周期性执行任务。public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit); 可周期性执行的任务-ScheduledFutureTaskScheduledThreadPoolExecutor最大的特色是能够周期性执行异步任务，当调用schedule,scheduleAtFixedRate和scheduleWithFixedDelay方法时，实际上是将提交的任务转换成的ScheduledFutureTask类，从源码就可以看出。以schedule方法为例： 1234567891011public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(delay, unit))); delayedExecute(t); return t;} 可以看出，通过decorateTask会将传入的Runnable转换成ScheduledFutureTask类。线程池最大作用是将任务和线程进行解耦，线程主要是任务的执行者，而任务也就是现在所说的ScheduledFutureTask。紧接着，会想到任何线程执行任务，总会调用run()方法。为了保证ScheduledThreadPoolExecutor能够延时执行任务以及能够周期性执行任务，ScheduledFutureTask重写了run方法： 12345678910111213public void run() { boolean periodic = isPeriodic(); if (!canRunInCurrentRunState(periodic)) cancel(false); else if (!periodic) //如果不是周期性执行任务，则直接调用run方法 ScheduledFutureTask.super.run(); //如果是周期性执行任务的话，需要重设下一次执行任务的时间 else if (ScheduledFutureTask.super.runAndReset()) { setNextRunTime(); reExecutePeriodic(outerTask); }} 从源码可以很明显的看出，在重写的run方法中会先if (!periodic)判断当前任务是否是周期性任务，如果不是的话就直接调用run()方法；否则的话执行setNextRunTime()方法重设下一次任务执行的时间，并通过reExecutePeriodic(outerTask)方法将下一次待执行的任务放置到DelayedWorkQueue中。 因此，可以得出结论：**ScheduledFutureTask最主要的功能是根据当前任务是否具有周期性，对异步任务进行进一步封装。如果不是周期性任务（调用schedule方法）则直接通过run()执行，若是周期性任务，则需要在每一次执行完后，重设下一次执行的时间，然后将下一次任务继续放入到阻塞队列中。** DelayedWorkQueue在ScheduledThreadPoolExecutor中还有另外的一个重要的类就是DelayedWorkQueue。为了实现其ScheduledThreadPoolExecutor能够延时执行异步任务以及能够周期执行任务，DelayedWorkQueue进行相应的封装。DelayedWorkQueue是一个基于堆的数据结构，类似于DelayQueue和PriorityQueue。在执行定时任务的时候，每个任务的执行时间都不同，所以DelayedWorkQueue的工作就是按照执行时间的升序来排列，执行时间距离当前时间越近的任务在队列的前面。 为什么要使用DelayedWorkQueue呢？定时任务执行时需要取出最近要执行的任务，所以任务在队列中每次出队时一定要是当前队列中执行时间最靠前的，所以自然要使用优先级队列。 DelayedWorkQueue是一个优先级队列，它可以保证每次出队的任务都是当前队列中执行时间最靠前的，由于它是基于堆结构的队列，堆结构在执行插入和删除操作时的最坏时间复杂度是 O(logN)。 DelayedWorkQueue的数据结构12345678//初始大小private static final int INITIAL_CAPACITY = 16;//DelayedWorkQueue是由一个大小为16的数组组成，数组元素为实现RunnableScheduleFuture接口的类//实际上为ScheduledFutureTaskprivate RunnableScheduledFuture&lt;?&gt;[] queue = new RunnableScheduledFuture&lt;?&gt;[INITIAL_CAPACITY];private final ReentrantLock lock = new ReentrantLock();private int size = 0; 可以看出DelayedWorkQueue底层是采用数组构成的，关于DelayedWorkQueue可以看这篇博主的文章，很详细。 关于DelayedWorkQueue我们可以得出这样的结论：DelayedWorkQueue是基于堆的数据结构，按照时间顺序将每个任务进行排序，将待执行时间越近的任务放在在队列的队头位置，以便于最先进行执行。 ScheduledThreadPoolExecutor执行过程现在我们对ScheduledThreadPoolExecutor的两个内部类ScheduledFutueTask和DelayedWorkQueue进行了了解，实际上这也是线程池工作流程中最重要的两个关键因素：任务以及阻塞队列。现在我们来看下ScheduledThreadPoolExecutor提交一个任务后，整体的执行过程。以ScheduledThreadPoolExecutor的schedule方法为例，具体源码为： 12345678910111213public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); //将提交的任务转换成ScheduledFutureTask RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(delay, unit))); //延时执行任务ScheduledFutureTask delayedExecute(t); return t;} 方法很容易理解，为了满足ScheduledThreadPoolExecutor能够延时执行任务和能周期执行任务的特性，会先将实现Runnable接口的类转换成ScheduledFutureTask。然后会调用delayedExecute方法进行执行任务，这个方法也是关键方法，来看下源码： 12345678910111213141516private void delayedExecute(RunnableScheduledFuture&lt;?&gt; task) { if (isShutdown()) //如果当前线程池已经关闭，则拒绝任务 reject(task); else { //将任务放入阻塞队列中 super.getQueue().add(task); if (isShutdown() &amp;&amp; !canRunInCurrentRunState(task.isPeriodic()) &amp;&amp; remove(task)) task.cancel(false); else //保证至少有一个线程启动，即使corePoolSize=0 ensurePrestart(); }} delayedExecute方法的主要逻辑请看注释，可以看出该方法的重要逻辑会是在ensurePrestart()方法中，它的源码为： 1234567void ensurePrestart() { int wc = workerCountOf(ctl.get()); if (wc &lt; corePoolSize) addWorker(null, true); else if (wc == 0) addWorker(null, false);} 可以看出该方法逻辑很简单，关键在于它所调用的addWorker方法，该方法主要功能：新建Worker类，当执行任务时，就会调用被Worker所重写的run方法，进而会继续执行runWorker方法。在runWorker方法中会调用getTask方法从阻塞队列中不断的去获取任务进行执行，直到从阻塞队列中获取的任务为null的话，线程结束终止。addWorker方法是ThreadPoolExecutor类中的方法，对ThreadPoolExecutor的源码分析可以看这篇文章，很详细。 总结 ScheduledThreadPoolExecutor继承了ThreadPoolExecutor类，因此，整体上功能一致，线程池主要负责创建线程（Worker类），线程从阻塞队列中不断获取新的异步任务，直到阻塞队列中已经没有了异步任务为止。但是相较于ThreadPoolExecutor来说，ScheduledThreadPoolExecutor具有延时执行任务和可周期性执行任务的特性，ScheduledThreadPoolExecutor重新设计了任务类ScheduleFutureTask，ScheduleFutureTask重写了run方法使其具有可延时执行和可周期性执行任务的特性。另外，阻塞队列DelayedWorkQueue是可根据优先级排序的队列，采用了堆的底层数据结构，使得与当前时间相比，待执行时间越靠近的任务放置队头，以便线程能够获取到任务进行执行； 线程池无论是ThreadPoolExecutor还是ScheduledThreadPoolExecutor，在设计时的三个关键要素是：任务，执行者以及任务结果。它们的设计思想也是完全将这三个关键要素进行了解耦。 执行者任务的执行机制，完全交由Worker类，也就是进一步了封装了Thread。向线程池提交任务，无论为ThreadPoolExecutor的execute方法和submit方法，还是ScheduledThreadPoolExecutor的schedule方法，都是先将任务移入到阻塞队列中，然后通过addWork方法新建了Work类，并通过runWorker方法启动线程，并不断的从阻塞对列中获取异步任务执行交给Worker执行，直至阻塞队列中无法取到任务为止。 任务在ThreadPoolExecutor和ScheduledThreadPoolExecutor中任务是指实现了Runnable接口和Callable接口的实现类。ThreadPoolExecutor中会将任务转换成FutureTask类，而在ScheduledThreadPoolExecutor中为了实现可延时执行任务和周期性执行任务的特性，任务会被转换成ScheduledFutureTask类，该类继承了FutureTask，并重写了run方法。 任务结果在ThreadPoolExecutor中提交任务后，获取任务结果可以通过Future接口的类，在ThreadPoolExecutor中实际上为FutureTask类，而在ScheduledThreadPoolExecutor中则是ScheduledFutureTask类","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-ScheduledThreadPoolExecutor%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-Semaphore与Exchanger介绍","text":"控制资源并发访问SemaphoreSemaphore可以理解为信号量，用于控制资源能够被并发访问的线程数量，以保证多个线程能够合理的使用特定资源。Semaphore就相当于一个许可证，线程需要先通过acquire方法获取该许可证，该线程才能继续往下执行，否则只能在该方法处阻塞等待。当执行完业务功能后，需要通过release()方法将许可证归还，以便其他线程能够获得许可证继续执行。 Semaphore可以用于做流量控制，特别是公共资源有限的应用场景，比如数据库连接。假如有多个线程读取数据后，需要将数据保存在数据库中，而可用的最大数据库连接只有10个，这时候就需要使用Semaphore来控制能够并发访问到数据库连接资源的线程个数最多只有10个。在限制资源使用的应用场景下，Semaphore是特别合适的。 下面来看下Semaphore的主要方法： 1234567891011121314151617181920212223242526272829303132333435//获取许可，如果无法获取到，则阻塞等待直至能够获取为止void acquire() throws InterruptedException //同acquire方法功能基本一样，只不过该方法可以一次获取多个许可void acquire(int permits) throws InterruptedException//释放许可void release()//释放指定个数的许可void release(int permits)//尝试获取许可，如果能够获取成功则立即返回true，否则，则返回falseboolean tryAcquire()//与tryAcquire方法一致，只不过这里可以指定获取多个许可boolean tryAcquire(int permits)//尝试获取许可，如果能够立即获取到或者在指定时间内能够获取到，则返回true，否则返回falseboolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException//与上一个方法一致，只不过这里能够获取多个许可boolean tryAcquire(int permits, long timeout, TimeUnit unit)//返回当前可用的许可证个数int availablePermits()//返回正在等待获取许可证的线程数int getQueueLength()//是否有线程正在等待获取许可证boolean hasQueuedThreads()//获取所有正在等待许可的线程集合Collection&lt;Thread&gt; getQueuedThreads() 另外，在Semaphore的构造方法中还支持指定是否具有公平性，默认的是非公平性，这样也是为了保证吞吐量。 一个例子下面用一个简单的例子来说明Semaphore的具体使用。我们来模拟这样一样场景。有一天，班主任需要班上10个同学到讲台上来填写一个表格，但是老师只准备了5支笔，因此，只能保证同时只有5个同学能够拿到笔并填写表格，没有获取到笔的同学只能够等前面的同学用完之后，才能拿到笔去填写表格。该示例代码如下： 12345678910111213141516171819202122232425262728public class SemaphoreDemo { //表示老师只有5支笔 private static Semaphore semaphore = new Semaphore(5); public static void main(String[] args) { //表示10个学生 ExecutorService service = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { service.execute(() -&gt; { try { System.out.println(Thread.currentThread().getName() + &quot; 同学准备获取笔......&quot;); semaphore.acquire(); System.out.println(Thread.currentThread().getName() + &quot; 同学获取到笔&quot;); System.out.println(Thread.currentThread().getName() + &quot; 填写表格ing.....&quot;); TimeUnit.SECONDS.sleep(3); semaphore.release(); System.out.println(Thread.currentThread().getName() + &quot; 填写完表格，归还了笔！！！！！！&quot;); } catch (InterruptedException e) { e.printStackTrace(); } }); } service.shutdown(); }} 输出结果 12345678910111213141516171819202122232425262728293031323334353637383940pool-1-thread-2 同学准备获取笔......pool-1-thread-4 同学准备获取笔......pool-1-thread-5 同学准备获取笔......pool-1-thread-3 同学准备获取笔......pool-1-thread-3 同学获取到笔pool-1-thread-1 同学准备获取笔......pool-1-thread-3 填写表格ing.....pool-1-thread-9 同学准备获取笔......pool-1-thread-8 同学准备获取笔......pool-1-thread-5 同学获取到笔pool-1-thread-5 填写表格ing.....pool-1-thread-4 同学获取到笔pool-1-thread-4 填写表格ing.....pool-1-thread-6 同学准备获取笔......pool-1-thread-2 同学获取到笔pool-1-thread-2 填写表格ing.....pool-1-thread-10 同学准备获取笔......pool-1-thread-7 同学准备获取笔......pool-1-thread-1 同学获取到笔pool-1-thread-1 填写表格ing.....pool-1-thread-4 填写完表格，归还了笔！！！！！！pool-1-thread-10 同学获取到笔pool-1-thread-10 填写表格ing.....pool-1-thread-7 同学获取到笔pool-1-thread-7 填写表格ing.....pool-1-thread-6 同学获取到笔pool-1-thread-6 填写表格ing.....pool-1-thread-9 同学获取到笔pool-1-thread-9 填写表格ing.....pool-1-thread-5 填写完表格，归还了笔！！！！！！pool-1-thread-8 同学获取到笔pool-1-thread-3 填写完表格，归还了笔！！！！！！pool-1-thread-1 填写完表格，归还了笔！！！！！！pool-1-thread-2 填写完表格，归还了笔！！！！！！pool-1-thread-8 填写表格ing.....pool-1-thread-7 填写完表格，归还了笔！！！！！！pool-1-thread-6 填写完表格，归还了笔！！！！！！pool-1-thread-10 填写完表格，归还了笔！！！！！！pool-1-thread-8 填写完表格，归还了笔！！！！！！pool-1-thread-9 填写完表格，归还了笔！！！！！！ 根据输出结果进行分析，Semaphore允许的最大许可数为5，也就是允许的最大并发执行的线程个数为5，可以看出，前5个线程（前5个学生）先获取到笔，然后填写表格，而6-10这5个线程，由于获取不到许可，只能阻塞等待。当线程pool-1-thread-4释放了许可之后，pool-1-thread-10就可以获取到许可，继续往下执行。对其他线程的执行过程，也是同样的道理。从这个例子就可以看出，Semaphore用来做特殊资源的并发访问控制是相当合适的，如果有业务场景需要进行流量控制，可以优先考虑Semaphore。 线程间交换数据的工具ExchangerExchanger是一个用于线程间协作的工具类，用于两个线程间交换数据。它提供了一个交换的同步点，在这个同步点两个线程能够交换数据。交换数据是通过exchange方法来实现的，如果一个线程先执行exchange方法，那么它会同步等待另一个线程也执行exchange方法，这个时候两个线程就都达到了同步点，两个线程就可以交换数据。 Exchanger除了一个无参的构造方法外，主要方法也很简单： 1234567//当一个线程执行该方法的时候，会等待另一个线程也执行该方法，因此两个线程就都达到了同步点//将数据交换给另一个线程，同时返回获取的数据V exchange(V x) throws InterruptedException//同上一个方法功能基本一样，只不过这个方法同步等待的时候，增加了超时时间V exchange(V x, long timeout, TimeUnit unit) throws InterruptedException, TimeoutException 一个例子Exchanger理解起来很容易，这里用一个简单的例子来看下它的具体使用。我们来模拟这样一个情景，在青春洋溢的中学时代，下课期间，男生经常会给走廊里为自己喜欢的女孩子送情书，相信大家都做过这样的事情吧。男孩会先到女孩教室门口，然后等女孩出来，教室那里就是一个同步点，然后彼此交换信物，也就是彼此交换了数据。现在，就来模拟这个情景。 12345678910111213141516171819202122232425262728293031public class ExchangerDemo { private static Exchanger&lt;String&gt; exchanger = new Exchanger(); public static void main(String[] args) { //代表男生和女生 ExecutorService service = Executors.newFixedThreadPool(2); service.execute(() -&gt; { try { //男生对女生说的话 String girl = exchanger.exchange(&quot;我其实暗恋你很久了......&quot;); System.out.println(&quot;女孩儿说：&quot; + girl); } catch (InterruptedException e) { e.printStackTrace(); } }); service.execute(() -&gt; { try { System.out.println(&quot;女生慢慢的从教室你走出来......&quot;); TimeUnit.SECONDS.sleep(3); //男生对女生说的话 String boy = exchanger.exchange(&quot;我也很喜欢你......&quot;); System.out.println(&quot;男孩儿说：&quot; + boy); } catch (InterruptedException e) { e.printStackTrace(); } }); }} 输出结果 123女生慢慢的从教室你走出来......男孩儿说：我其实暗恋你很久了......女孩儿说：我也很喜欢你...... 这个例子很简单，也很能说明Exchanger的基本使用。当两个线程都到达调用exchange方法的同步点的时候，两个线程就能交换彼此的数据。","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-Semaphore%E4%B8%8EExchanger%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-ThreadLocal介绍","text":"ThreadLocal的简介在多线程编程中通常解决线程安全的问题我们会利用synchronzed或者lock控制线程对临界区资源的同步顺序从而解决线程安全的问题，但是这种加锁的方式会让未获取到锁的线程进行阻塞等待，很显然这种方式的时间效率并不是很好。线程安全问题的核心在于多个线程会对同一个临界区共享资源进行操作，那么，如果每个线程都使用自己的“共享资源”，各自使用各自的，又互相不影响到彼此即让多个线程间达到隔离的状态，这样就不会出现线程安全的问题。事实上，这就是一种“空间换时间”的方案，每个线程都会都拥有自己的“共享资源”无疑内存会大很多，但是由于不需要同步也就减少了线程可能存在的阻塞等待的情况从而提高的时间效率。 虽然ThreadLocal并不在java.util.concurrent包中而在java.lang包中，但我更倾向于把它当作是一种并发容器（虽然真正存放数据的是ThreadLoclMap）进行归类。从ThreadLocal这个类名可以顾名思义的进行理解，表示线程的“本地变量”，即每个线程都拥有该变量副本，达到人手一份的效果，各用各的这样就可以避免共享资源的竞争。 ThreadLocal的实现原理要想学习到ThreadLocal的实现原理，就必须了解它的几个核心方法，包括怎样存怎样取等等，下面我们一个个来看。 void set(T value)set方法设置在当前线程中threadLocal变量的值，该方法的源码为： 123456789101112public void set(T value) { //1. 获取当前线程实例对象 Thread t = Thread.currentThread(); //2. 通过当前线程实例获取到ThreadLocalMap对象 ThreadLocalMap map = getMap(t); if (map != null) //3. 如果Map不为null,则以当前threadLocl实例为key,值为value进行存入 map.set(this, value); else //4.map为null,则新建ThreadLocalMap并存入value createMap(t, value);} 方法的逻辑很清晰，具体请看上面的注释。通过源码我们知道value是存放在了ThreadLocalMap里了，当前先把它理解为一个普普通通的map即可，也就是说，数据value是真正的存放在了ThreadLocalMap这个容器中了，并且是以当前threadLocal实例为key。先简单的看下ThreadLocalMap是什么，有个简单的认识就好，下面会具体说的。 首先ThreadLocalMap是怎样来的？源码很清楚，是通过getMap(t)进行获取： 123ThreadLocalMap getMap(Thread t) { return t.threadLocals;} 该方法直接返回的就是当前线程对象t的一个成员变量threadLocals： 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 也就是说ThreadLocalMap的引用是作为Thread的一个成员变量，被Thread进行维护的。回过头再来看看set方法，当map为Null的时候会通过createMap(t，value)方法： 123void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue);} 该方法就是new一个ThreadLocalMap实例对象，然后同样以当前threadLocal实例作为key,值为value存放到threadLocalMap中，然后将当前线程对象的threadLocals赋值为threadLocalMap。 现在来对set方法进行总结一下：通过当前线程对象thread获取该thread所维护的threadLocalMap,若threadLocalMap不为null,则以threadLocal实例为key,值为value的键值对存入threadLocalMap,若threadLocalMap为null的话，就新建threadLocalMap然后在以threadLocal为键，值为value的键值对存入即可 T get()get方法是获取当前线程中threadLocal变量的值，同样的还是来看看源码： 123456789101112131415161718public T get() { //1. 获取当前线程的实例对象 Thread t = Thread.currentThread(); //2. 获取当前线程的threadLocalMap ThreadLocalMap map = getMap(t); if (map != null) { //3. 获取map中当前threadLocal实例为key的值的entry ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(&quot;unchecked&quot;) //4. 当前entitiy不为null的话，就返回相应的值value T result = (T)e.value; return result; } } //5. 若map为null或者entry为null的话通过该方法初始化，并返回该方法返回的value return setInitialValue();} 弄懂了set方法的逻辑，看get方法只需要带着逆向思维去看就好，如果是那样存的，反过来去拿就好。代码逻辑请看注释，另外，看下setInitialValue主要做了些什么事情？ 12345678910private T setInitialValue() { T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;} 这段方法的逻辑和set方法几乎一致，另外值得关注的是initialValue方法: 123protected T initialValue() { return null;} 这个方法是protected修饰的也就是说继承ThreadLocal的子类可重写该方法，实现赋值为其他的初始值。关于get方法来总结一下： 通过当前线程thread实例获取到它所维护的threadLocalMap，然后以当前threadLocal实例为key获取该map中的键值对（Entry），若Entry不为null则返回Entry的value。如果获取threadLocalMap为null或者Entry为null的话，就以当前threadLocal为Key，value为null存入map后，并返回null void remove()1234567public void remove() { //1. 获取当前线程的threadLocalMap ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) //2. 从map中删除以当前threadLocal实例为key的键值对 m.remove(this);} get,set方法实现了存数据和读数据，我们当然还得学会如何删数据。删除数据当然是从map中删除数据，先获取与当前线程相关联的threadLocalMap然后从map中删除该threadLocal实例为key的键值对即可。 ThreadLocalMap详解从上面的分析我们已经知道，数据其实都放在了threadLocalMap中，threadLocal的get，set和remove方法实际上具体是通过threadLocalMap的getEntry，set和remove方法实现的。如果想真正全方位的弄懂threadLocal，势必得在对threadLocalMap做一番理解。 Entry数据结构ThreadLocalMap是threadLocal一个静态内部类，和大多数容器一样内部维护了一个数组，同样的threadLocalMap内部维护了一个Entry类型的table数组。 12345/** * The table, resized as necessary. * table.length MUST always be a power of two. */private Entry[] table; 通过注释可以看出，table数组的长度为2的幂次方。接下来看下Entry是什么： 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; }} Entry是一个以ThreadLocal为key，Object为value的键值对，另外需要注意的是这里的threadLocal是弱引用，因为Entry继承了WeakReference，在Entry的构造方法中，调用了super(k)方法就会将threadLocal实例包装成一个WeakReferenece。到这里我们可以用一个图来理解下thread，threadLocal，threadLocalMap，Entry之间的关系： 注意上图中的实线表示强引用，虚线表示弱引用。如图所示，每个线程实例中可以通过threadLocals获取到threadLocalMap，而threadLocalMap实际上就是一个以threadLocal实例为key，任意对象为value的Entry数组。当我们为threadLocal变量赋值，实际上就是以当前threadLocal实例为key，值为value的Entry往这个threadLocalMap中存放。需要注意的是Entry中的key是弱引用，当threadLocal外部强引用被置为null(threadLocalInstance=null),那么系统 GC 的时候，根据可达性分析，这个threadLocal实例就没有任何一条链路能够引用到它，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。当然，如果当前thread运行结束，threadLocal，threadLocalMap,Entry没有引用链可达，在垃圾回收的时候都会被系统进行回收。在实际开发中，会使用线程池去维护线程的创建和复用，比如固定大小的线程池，线程为了复用是不会主动结束的，所以，threadLocal的内存泄漏问题，是应该值得我们思考和注意的问题，关于这个问题可以看这篇文章—-详解threadLocal内存泄漏问题 set方法与concurrentHashMap，hashMap等容器一样，threadLocalMap也是采用散列表进行实现的。在了解set方法前，我们先来回顾下关于散列表相关的知识（摘自这篇的threadLocalMap的讲解部分以及这篇文章的hash）。 散列表 理想状态下，散列表就是一个包含关键字的固定大小的数组，通过使用散列函数，将关键字映射到数组的不同位置。下面是 在理想状态下，哈希函数可以将关键字均匀的分散到数组的不同位置，不会出现两个关键字散列值相同（假设关键字数量小于数组的大小）的情况。但是在实际使用中，经常会出现多个关键字散列值相同的情况（被映射到数组的同一个位置），我们将这种情况称为散列冲突。为了解决散列冲突，主要采用下面两种方式： 分离链表法（separate chaining）和开放定址法（open addressing） 分离链表法（拉链法） 分散链表法使用链表解决冲突，将散列值相同的元素都保存到一个链表中。当查询的时候，首先找到元素所在的链表，然后遍历链表查找对应的元素，典型实现为hashMap，concurrentHashMap的拉链法。下面是一个示意图： 开放定址法 开放定址法不会创建链表，当关键字散列到的数组单元已经被另外一个关键字占用的时候，就会尝试在数组中寻找其他的单元，直到找到一个空的单元。探测数组空单元的方式有很多，这里介绍一种最简单的 – 线性探测法。线性探测法就是从冲突的数组单元开始，依次往后搜索空单元，如果到数组尾部，再从头开始搜索（环形查找）。如下图所示： 拉链法与开放定址法比较（可以参考 这篇文章） 与开放定址法相比，拉链法有如下几个优点： 拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短； 由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况； 开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而拉链法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间； 在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。而对开放地址法构造的散列表，删除结点不能简单地将被删结 点的空间置为空，否则将截断在它之后填人散列表的同义词结点的查找路径。这是因为各种开放地址法中，空地址单元（即开放地址）都是查找失败的条件。因此在用开放地址法处理冲突的散列表上执行删除操作，只能在被删结点上做删除标记，而不能真正删除结点。 拉链法的缺点：指针需要额外的空间，故当结点规模较小时，开放定址法较为节省空间，而若将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放定址法中的冲突，从而提高平均查找速度。 ThreadLocalMap 中使用开放地址法来处理散列冲突，而 HashMap 中使用的分离链表法。之所以采用不同的方式主要是因为：在 ThreadLocalMap 中的散列值分散的十分均匀，很少会出现冲突。并且 ThreadLocalMap 经常需要清除无用的对象，使用纯数组更加方便。 在了解这些相关知识后我们再回过头来看一下set方法。set方法的源码为： 12345678910111213141516171819202122232425262728293031323334353637private void set(ThreadLocal&lt;?&gt; key, Object value) { // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; //根据threadLocal的hashCode确定Entry应该存放的位置 int i = key.threadLocalHashCode &amp; (len-1); //采用开放地址法，hash冲突的时候使用线性探测 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal&lt;?&gt; k = e.get(); //覆盖旧Entry if (k == key) { e.value = value; return; } //当key为null时，说明threadLocal强引用已经被释放掉，那么就无法 //再通过这个key获取threadLocalMap中对应的entry，这里就存在内存泄漏的可能性 if (k == null) { //用当前插入的值替换掉这个key为null的“脏”entry replaceStaleEntry(key, value, i); return; } } //新建entry并插入table中i处 tab[i] = new Entry(key, value); int sz = ++size; //插入后再次清除一些key为null的“脏”entry,如果大于阈值就需要扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();} set方法的关键部分请看上面的注释，主要有这样几点需要注意： threadLocal的hashcode? 123456789private final int threadLocalHashCode = nextHashCode();private static final int HASH_INCREMENT = 0x61c88647;private static AtomicInteger nextHashCode =new AtomicInteger();/** * Returns the next hash code. */private static int nextHashCode() { return nextHashCode.getAndAdd(HASH_INCREMENT);} 从源码中我们可以清楚的看到threadLocal实例的hashCode是通过nextHashCode()方法实现的，该方法实际上总是用一个AtomicInteger加上0x61c88647来实现的。0x61c88647这个数是有特殊意义的，它能够保证hash表的每个散列桶能够均匀的分布，这是Fibonacci Hashing，关于更多介绍可以看这篇文章的threadLocal散列值部分。也正是能够均匀分布，所以threadLocal选择使用开放地址法来解决hash冲突的问题。 怎样确定新值插入到哈希表中的位置？ 该操作源码为：key.threadLocalHashCode &amp; (len-1)，同hashMap和ConcurrentHashMap等容器的方式一样，利用当前key(即threadLocal实例)的hashcode与哈希表大小相与，因为哈希表大小总是为2的幂次方，所以相与等同于一个取模的过程，这样就可以通过Key分配到具体的哈希桶中去。而至于为什么取模要通过位与运算的原因就是位运算的执行效率远远高于了取模运算。 怎样解决hash冲突？ 源码中通过nextIndex(i, len)方法解决hash冲突的问题，该方法为((i + 1 &lt; len) ? i + 1 : 0);，也就是不断往后线性探测，当到哈希表末尾的时候再从0开始，成环形。 怎样解决“脏”Entry？ 在分析threadLocal,threadLocalMap以及Entry的关系的时候，我们已经知道使用threadLocal有可能存在内存泄漏（对象创建出来后，在之后的逻辑一直没有使用该对象，但是垃圾回收器无法回收这个部分的内存），在源码中针对这种key为null的Entry称之为“stale entry”，直译为不新鲜的entry，我把它理解为“脏entry”，自然而然，Josh Bloch and Doug Lea大师考虑到了这种情况,在set方法的for循环中寻找和当前Key相同的可覆盖entry的过程中通过replaceStaleEntry方法解决脏entry的问题。如果当前table[i]为null的话，直接插入新entry后也会通过cleanSomeSlots来解决脏entry的问题，关于cleanSomeSlots和replaceStaleEntry方法，会在详解threadLocal内存泄漏中讲到，具体可看那篇文章 如何进行扩容？ threshold的确定 也几乎和大多数容器一样，threadLocalMap会有扩容机制，那么它的threshold又是怎样确定的了？ 1234567891011121314151617181920private int threshold; // Default to 0/** * The initial capacity -- MUST be a power of two. */private static final int INITIAL_CAPACITY = 16;ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) { table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY);}/** * Set the resize threshold to maintain at worst a 2/3 load factor. */private void setThreshold(int len) { threshold = len * 2 / 3;} 根据源码可知，在第一次为threadLocal进行赋值的时候会创建初始大小为16的threadLocalMap,并且通过setThreshold方法设置threshold，其值为当前哈希数组长度乘以（2/3），也就是说加载因子为2/3(加载因子是衡量哈希表密集程度的一个参数，如果加载因子越大的话，说明哈希表被装载的越多，出现hash冲突的可能性越大，反之，则被装载的越少，出现hash冲突的可能性越小。同时如果过小，很显然内存使用率不高，该值取值应该考虑到内存使用率和hash冲突概率的一个平衡，如hashMap,concurrentHashMap的加载因子都为0.75)。这里threadLocalMap初始大小为16，加载因子为2/3，所以哈希表可用大小为：16*2/3=10，即哈希表可用容量为10。 扩容resize 从set方法中可以看出当hash表的size大于threshold的时候，会通过resize方法进行扩容。 123456789101112131415161718192021222324252627282930313233/** * Double the capacity of the table. */private void resize() { Entry[] oldTab = table; int oldLen = oldTab.length; //新数组为原数组的2倍 int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) { Entry e = oldTab[j]; if (e != null) { ThreadLocal&lt;?&gt; k = e.get(); //遍历过程中如果遇到脏entry的话直接另value为null,有助于value能够被回收 if (k == null) { e.value = null; // Help the GC } else { //重新确定entry在新数组的位置，然后进行插入 int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; } } } //设置新哈希表的threshHold和size属性 setThreshold(newLen); size = count; table = newTab;} 方法逻辑请看注释，新建一个大小为原来数组长度的两倍的数组，然后遍历旧数组中的entry并将其插入到新的hash数组中，主要注意的是，在扩容的过程中针对脏entry的话会令value为null，以便能够被垃圾回收器能够回收，解决隐藏的内存泄漏的问题。 getEntry方法getEntry方法源码为： 12345678910111213private Entry getEntry(ThreadLocal&lt;?&gt; key) { //1. 确定在散列数组中的位置 int i = key.threadLocalHashCode &amp; (table.length - 1); //2. 根据索引i获取entry Entry e = table[i]; //3. 满足条件则返回该entry if (e != null &amp;&amp; e.get() == key) return e; else //4. 未查找到满足条件的entry，额外在做的处理 return getEntryAfterMiss(key, i, e);}123456789101112 方法逻辑很简单，若能当前定位的entry的key和查找的key相同的话就直接返回这个entry，否则的话就是在set的时候存在hash冲突的情况，需要通过getEntryAfterMiss做进一步处理。getEntryAfterMiss方法为： 1234567891011121314151617181920private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) { Entry[] tab = table; int len = tab.length; while (e != null) { ThreadLocal&lt;?&gt; k = e.get(); if (k == key) //找到和查询的key相同的entry则返回 return e; if (k == null) //解决脏entry的问题 expungeStaleEntry(i); else //继续向后环形查找 i = nextIndex(i, len); e = tab[i]; } return null;}12345678910111213141516171819 这个方法同样很好理解，通过nextIndex往后环形查找，如果找到和查询的key相同的entry的话就直接返回，如果在查找过程中遇到脏entry的话使用expungeStaleEntry方法进行处理。到目前为止，为了解决潜在的内存泄漏的问题，在set，resize,getEntry这些地方都会对这些脏entry进行处理，可见为了尽可能解决这个问题几乎无时无刻都在做出努力。 remove方法12345678910111213141516171819/** * Remove the entry for key. */private void remove(ThreadLocal&lt;?&gt; key) { Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { if (e.get() == key) { //将entry的key置为null e.clear(); //将该entry的value也置为null expungeStaleEntry(i); return; } }} 该方法逻辑很简单，通过往后环形查找到与指定key相同的entry后，先通过clear方法将key置为null后，使其转换为一个脏entry，然后调用expungeStaleEntry方法将其value置为null，以便垃圾回收时能够清理，同时将table[i]置为null。 ThreadLocal的使用场景ThreadLocal 不是用来解决共享对象的多线程访问问题的，数据实质上是放在每个thread实例引用的threadLocalMap，也就是说每个不同的线程都拥有专属于自己的数据容器（threadLocalMap），彼此不影响。因此threadLocal只适用于 共享对象会造成线程安全 的业务场景。比如hibernate中通过threadLocal管理Session就是一个典型的案例，不同的请求线程（用户）拥有自己的session，若将session共享出去被多线程访问，必然会带来线程安全问题。下面，我们自己来写一个例子，SimpleDateFormat.parse方法会有线程安全的问题，我们可以尝试使用threadLocal包装SimpleDateFormat，将该实例不被多线程共享即可。 1234567891011121314151617181920212223242526272829303132public class ThreadLocalDemo { private static ThreadLocal&lt;SimpleDateFormat&gt; sdf = new ThreadLocal&lt;&gt;(); public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 100; i++) { executorService.submit(new DateUtil(&quot;2019-11-25 09:00:&quot; + i % 60)); } } static class DateUtil implements Runnable { private String date; public DateUtil(String date) { this.date = date; } @Override public void run() { if (sdf.get() == null) { sdf.set(new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;)); } else { try { Date date = sdf.get().parse(this.date); System.out.println(date); } catch (ParseException e) { e.printStackTrace(); } } } }} 如果当前线程不持有SimpleDateformat对象实例，那么就新建一个并把它设置到当前线程中，如果已经持有，就直接使用。另外，从if (sdf.get() == null){....}else{.....}可以看出为每一个线程分配一个SimpleDateformat对象实例是从应用层面（业务代码逻辑）去保证的。 在上面我们说过threadLocal有可能存在内存泄漏，在使用完之后，最好使用remove方法将这个变量移除，就像在使用数据库连接一样，及时关闭连接。 参考资料 《java高并发程序设计》 这篇文章的threadLocalMap讲解和threadLocal的hashCode讲解不错 这篇文章讲解了hash，不错 解决hash冲突 链地址法和开放地址法的比较","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-ThreadLocal%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-三大性质总结","text":"三大性质简介在并发编程中分析线程安全的问题时往往需要切入点，那就是两大核心：JMM抽象内存模型以及happens-before规则（在之前文章中已经讲过了），三条性质：原子性，有序性和可见性。关于synchronized和volatile也已经讨论过了，就想着将并发编程中这两大神器在 原子性，有序性和可见性上做一个比较，当然这也是面试中的高频考点，值得注意。 原子性原子性是指一个操作是不可中断的，要么全部执行成功要么全部执行失败，有着“同生共死”的感觉。即使在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程所干扰。我们先来看看哪些是原子操作，哪些不是原子操作，有一个直观的印象： 1234int a = 10; //1 a++; //2 int b=a; //3 a = a+1; //4 上面这四个语句中只有第1个语句是原子操作，将10赋值给线程工作内存的变量a,而语句2（a++），实际上包含了三个操作：1. 读取变量a的值；2：对a进行加一的操作；3.将计算后的值再赋值给变量a，而这三个操作无法构成原子操作。对语句3,4的分析同理可得这两条语句不具备原子性。当然，*java内存模型*中定义了8中操作都是原子的，不可再分的。 lock(锁定)：作用于主内存中的变量，它把一个变量标识为一个线程独占的状态； unlock(解锁):作用于主内存中的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便后面的load动作使用； load（载入）：作用于工作内存中的变量，它把read操作从主内存中得到的变量值放入工作内存中的变量副本 use（使用）：作用于工作内存中的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作； assign（赋值）：作用于工作内存中的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作； store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送给主内存中以便随后的write操作使用； write（操作）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。 上面的这些指令操作是相当底层的，可以作为扩展知识面掌握下。那么如何理解这些指令了?比如，把一个变量从主内存中复制到工作内存中就需要执行read,load操作，将工作内存同步到主内存中就需要执行store,write操作。注意的是：java内存模型只是要求上述两个操作是顺序执行的并不是连续执行的。也就是说read和load之间可以插入其他指令，store和writer可以插入其他指令。比如对主内存中的a,b进行访问就可以出现这样的操作顺序：read a,read b, load b,load a。 由原子性变量操作read,load,use,assign,store,write，可以大致认为基本数据类型的访问读写具备原子性（例外就是long和double的非原子性协定） synchronized上面一共有八条原子操作，其中六条可以满足基本数据类型的访问读写具备原子性，还剩下lock和unlock两条原子操作。如果我们需要更大范围的原子性操作就可以使用lock和unlock原子操作。尽管jvm没有把lock和unlock开放给我们使用，但jvm以更高层次的指令monitorenter和monitorexit指令开放给我们使用，反应到java代码中就是—synchronized关键字，也就是说synchronized满足原子性。 volatile我们先来看这样一个例子： 12345678910111213141516171819202122public class VolatileExample { private static volatile int counter = 0; public static void main(String[] args) { for (int i = 0; i &lt; 10; i++) { Thread thread = new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 10000; i++) counter++; } }); thread.start(); } try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(counter); }} 开启10个线程，每个线程都自加10000次，如果不出现线程安全的问题最终的结果应该就是：10*10000 = 100000;可是运行多次都是小于100000的结果，问题在于 volatile并不能保证原子性，在前面说过counter++这并不是一个原子操作，包含了三个步骤：1.读取变量counter的值；2.对counter加一；3.将新值赋值给变量counter。如果线程A读取counter到工作内存后，其他线程对这个值已经做了自增操作后，那么线程A的这个值自然而然就是一个过期的值，因此，总结果必然会是小于100000的。 如果让volatile保证原子性，必须符合以下两条规则： 运算结果并不依赖于变量的当前值，或者能够确保只有一个线程修改变量的值； 变量不需要与其他的状态变量共同参与不变约束 有序性synchronizedsynchronized语义表示锁在同一时刻只能由一个线程进行获取，当锁被占用后，其他线程只能等待。因此，synchronized语义就要求线程在访问读写共享变量时只能“串行”执行，因此synchronized具有有序性。 volatile在java内存模型中说过，为了性能优化，编译器和处理器会进行指令重排序；也就是说java程序天然的有序性可以总结为：如果在本线程内观察，所有的操作都是有序的；如果在一个线程观察另一个线程，所有的操作都是无序的。在单例模式的实现上有一种双重检验锁定的方式（Double-checked Locking）。代码如下： 1234567891011121314public class Singleton { private Singleton() { } private volatile static Singleton instance; public Singleton getInstance(){ if(instance==null){ synchronized (Singleton.class){ if(instance==null){ instance = new Singleton(); } } } return instance; }} 这里为什么要加volatile了？我们先来分析一下不加volatile的情况，有问题的语句是这条： 1instance = new Singleton(); 这条语句实际上包含了三个操作：1.分配对象的内存空间；2.初始化对象；3.设置instance指向刚分配的内存地址。但由于存在重排序的问题，可能有以下的执行顺序： 如果2和3进行了重排序的话，线程B进行判断if(instance==null)时就会为true，而实际上这个instance并没有初始化成功，显而易见对线程B来说之后的操作就会是错得。而用volatile修饰的话就可以禁止2和3操作重排序，从而避免这种情况。volatile包含禁止指令重排序的语义，其具有有序性。 可见性可见性是指当一个线程修改了共享变量后，其他线程能够立即得知这个修改。通过之前对*synchronzed内存语义进行了分析，当线程获取锁时会从主内存中获取共享变量的最新值，释放锁的时候会将共享变量同步到主内存中。从而，synchronized具有可见性。同样的在volatile分析中*，会通过在指令中添加lock指令，以实现内存可见性。因此, volatile具有可见性 总结通过这篇文章，主要是比较了synchronized和volatile在三条性质：原子性，可见性，以及有序性的情况，归纳如下： synchronized: 具有原子性，有序性和可见性； volatile：具有有序性和可见性； final：具有可见性 参考文献 《java并发编程的艺术》 《深入理解java虚拟机》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E4%B8%89%E5%A4%A7%E6%80%A7%E8%B4%A8%E6%80%BB%E7%BB%93/"},{"title":"并发编程-优缺点","text":"Java并发编程是整个Java开发体系中最难以理解，但也是最重要的知识点之一，因此学习起来比较费劲，从而导致很多人望而却步，但是无论是职场面试还是高并发高流量的系统的实现都离不开并发编程，能够真正掌握并发编程的人才在市场上供不应求。 为什么要使用并发编程（优点）充分利用多核CPU的计算能力摩尔定律：当价格不变时，集成电路上可容纳的元器件的数目，约每隔18-24个月便会增加一倍，性能也将提升一倍。换言之，每一美元所能买到的电脑性能，将每隔18-24个月翻一倍以上。这一定律揭示了信息技术进步的速度。 一直以来，硬件的发展极其迅速，也有一个很著名的”摩尔定律”，你可能会奇怪明明讨论的是并发编程为什么会扯到了硬件的发展，这其中的关系应该是多核CPU的发展为并发编程提供的硬件基础。摩尔定律并不是一种自然法则或者是物理定律，它只是基于观测数据，对未来的一种预测。按照所预测的速度，我们的计算能力会按照指数级别的速度增长，不久以后会拥有超强的计算能力，正是在畅想未来的时候，2004年，Intel宣布4GHz芯片的计划推迟到2005年，然后在2004年秋季，Intel宣布彻底取消4GHz的计划，也就是说摩尔定律的有效性超过了半个世纪戛然而止。但是，聪明的硬件工程师并没有停止研发的脚步，他们为了进一步提升计算速度，不是再追求单独的计算单元，而是将多个计算单元整合到了一起，也就是形成了多核CPU。短短十几年的时间，家用型CPU，比如Intel i7就可以达到4核心甚至8核心。而专业服务器则通常可以达到几个独立的CPU，每一个CPU甚至拥有多达8个以上的内核。因此，摩尔定律似乎在CPU核心扩展上继续得到体验。因此，多核的CPU的背景下，催生了并发编程的趋势，通过并发编程的形式可以将多核CPU的计算能力发挥到极致，性能得到提升。 顶级计算机科学家Donald Ervin Knuth如此评价这种情况：在我看来，这种现象（并发）或多或少是由于硬件设计者无计可施导致的，他们将摩尔定律的责任推给了软件开发者。 方便进行业务拆分，提升系统并发能力和性能在特殊的业务场景下先天的就适合于并发编程。现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。比如在图像处理领域，一张1024X768像素的图片，包含78万6千多个像素。将所有的像素遍历一边都需要很长的时间，面对如此复杂的计算量就需要充分利用多核CPU的计算能力。又比如当我们在网上购物时，为了提升响应速度，减库存、生成订单等等这些操作就可以进行拆分，利用多线程的技术完成。面对复杂业务模型，并行程序会比串行程序更适应业务需求，而并发编程更能吻合这种业务拆分 。 并发编程的缺点并发编程的目的就是为了能提高程序的执行效率，提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、上下文切换、线程安全、死锁等问题。 频繁的上下文切换任务从保存到再加载就是一次上下文切换。 时间片是CPU分配给各个线程的时间，因为时间非常短，所以CPU不断通过切换线程，让我们觉得多个线程是同时执行的，时间片一般是几十毫秒。而每次切换时，需要保存当前的状态，以便能够进行恢复先前的状态，而这个切换时非常损耗性能，过于频繁反而无法发挥出多线程编程的优势。 减少上下文切换的解决方案 无锁并发编程：可以参照concurrentHashMap锁分段的思想，不同的线程处理不同段的数据，这样在多线程竞争的条件下，可以减少上下文切换的时间。 CAS算法：利用Atomic下使用CAS算法来更新数据，使用了乐观锁，可以有效的减少一部分不必要的锁竞争带来的上下文切换。 使用最少线程：避免创建不需要的线程，比如任务很少，但是创建了很多的线程，这样会造成大量的线程都处于等待状态。 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。 由于上下文切换也是个相对比较耗时的操作，所以在”java并发编程的艺术”一书中有过一个实验，并发累加未必会比串行累加速度要快。 可以使用Lmbench3测量上下文切换的时长 vmstat测量上下文切换次数 线程安全多线程编程中最难以把握的就是临界区线程安全问题，稍微不注意就会出现死锁的情况，一旦产生死锁就会造成系统功能不可用。 1234567891011121314151617181920212223242526272829303132333435363738394041public class DeadLockDemo { private static String resource_a = &quot;A&quot;; private static String resource_b = &quot;B&quot;; public static void main(String[] args) { deadLock(); } public static void deadLock() { Thread threadA = new Thread(new Runnable() { @Override public void run() { synchronized (resource_a) { System.out.println(&quot;get resource a&quot;); try { Thread.sleep(3000); synchronized (resource_b) { System.out.println(&quot;get resource b&quot;); } } catch (InterruptedException e) { e.printStackTrace(); } } } }); Thread threadB = new Thread(new Runnable() { @Override public void run() { synchronized (resource_b) { System.out.println(&quot;get resource b&quot;); synchronized (resource_a) { System.out.println(&quot;get resource a&quot;); } } } }); threadA.start(); threadB.start(); }} 在上面的这个demo中，开启了两个线程threadA， threadB，其中threadA占用了resource_a， 并等待被threadB占用的resource _b。threadB占用了resource _b正在等待被threadA占用的resource _a。因此threadA，threadB出现线程安全的问题，形成死锁。同样可以通过jps，jstack证明这种推论： 123456789101112131415161718192021&quot;Thread-1&quot;: waiting to lock monitor 0x000000000b695360 (object 0x00000007d5ff53a8, a java.lang.String), which is held by &quot;Thread-0&quot;&quot;Thread-0&quot;: waiting to lock monitor 0x000000000b697c10 (object 0x00000007d5ff53d8, a java.lang.String), which is held by &quot;Thread-1&quot;Java stack information for the threads listed above:===================================================&quot;Thread-1&quot;: at learn.DeadLockDemo$2.run(DeadLockDemo.java:34) - waiting to lock &lt;0x00000007d5ff53a8(a java.lang.String) - locked &lt;0x00000007d5ff53d8(a java.lang.String) at java.lang.Thread.run(Thread.java:722)&quot;Thread-0&quot;: at learn.DeadLockDemo$1.run(DeadLockDemo.java:20) - waiting to lock &lt;0x00000007d5ff53d8(a java.lang.String) - locked &lt;0x00000007d5ff53a8(a java.lang.String) at java.lang.Thread.run(Thread.java:722)Found 1 deadlock. 如上所述，完全可以看出当前死锁的情况。 那么，通常可以用如下方式避免死锁的情况： 避免一个线程同时获得多个锁； 避免一个线程在锁内部占有多个资源，尽量保证每个锁只占用一个资源； 尝试使用定时锁，使用lock.tryLock(timeOut)，当超时等待时当前线程不会阻塞； 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。 所以，如何正确的使用多线程编程技术有很大的学问，比如如何保证线程安全，如何正确理解由于JVM内存模型在原子性，有序性，可见性带来的问题，比如数据脏读，DCL等问题。而在学习多线程编程技术的过程中也会让你收获颇丰。 易混淆的概念阻塞与非阻塞阻塞与非阻塞的重点在于进/线程等待消息时候的行为，也就是在等待消息的时候，当前进/线程是挂起状态，还是非挂起状态。 阻塞：调用在发出去后，在消息返回之前，当前进/线程会被挂起，直到有消息返回，当前进/线程才会被激活； 非阻塞：调用在发出去后，不会阻塞当前进/线程，而会立即返回。 同步与异步同步：当一个同步调用发出去后，调用者要一直等待调用结果的返回后，才能进行后续的操作。 异步：当一个异步调用发出去后，调用者不用管被调用方法是否完成，都会继续执行后面的代码。 异步调用，要想获得结果，一般有两种方式： 主动轮询异步调用的结果； 被调用方通过callback来通知调用方调用结果； 比如，在超市购物，如果一件物品没了，你得等仓库人员跟你调货，直到仓库人员跟你把货物送过来，你才能继续去收银台付款，这就类似同步调用。而异步调用了，就像网购，你在网上付款下单后，什么事就不用管了，该干嘛就干嘛去了，当货物到达后你收到通知去取就好。 临界区临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用。但是每个线程使用时，一旦临界区资源被一个线程占有，那么其他线程必须等待。 并发与并行 并发： 同一时间段，多个任务交替执行 (单位时间内不一定同时执行)； 并行：单位时间内，多个任务同时执行。真正意义上的“同时进行”，真正的并行只能出现在拥有多个CPU的系统中； 串行：线程串行的情况下，有n个任务或者你可以理解n个方法，由一个线程顺序执行。由于任务、方法都在一个线程执行所以不存在线程不安全情况，也就不存在临界区的问题。 上下文切换多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。 概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。 Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。 参考： 并发编程的优缺点","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E4%BC%98%E7%BC%BA%E7%82%B9/"},{"title":"并发编程-关键字-final","text":"final的简介final可以修饰变量，方法和类，用于表示所修饰的内容一旦赋值之后就不会再被改变，比如String类就是一个final类型的类。即使能够知道final具体的使用方法，final在多线程中存在的重排序问题很容易忽略，希望能够一起做下探讨。 final的具体使用场景final能够修饰变量，方法和类，也就是final使用范围基本涵盖了Java每个地方，下面就分别以锁修饰的位置：变量，方法和类分别来说一说。 变量在Java中变量，可以分为成员变量以及方法局部变量。因此也是按照这种方式依次来说，以避免漏掉任何一个死角。 final成员变量通常每个类中的成员变量可以分为类变量（static修饰的变量）以及实例变量。针对这两种类型的变量赋初值的时机是不同的，类变量可以在声明变量的时候直接赋初值或者在静态代码块中给类变量赋初值。而实例变量可以在声明变量的时候给实例变量赋初值，在非静态初始化块中以及构造器中赋初值。类变量有两个时机赋初值，而实例变量则可以有三个时机赋初值。当final变量未初始化时系统不会进行隐式初始化，会出现报错。这样说起来还是比较抽象，下面用具体的代码来演示。（代码涵盖了final修饰变量所有的可能情况，耐心看下去会有收获的） 看上面的图片已经将每种情况整理出来了，这里用截图的方式也是觉得在IDE出现红色出错的标记更能清晰的说明情况。现在我们来将这几种情况归纳整理一下： 类变量：必须要在静态初始化块中指定初始值或者声明该类变量时指定初始值，而且只能在这两个地方之一进行指定； 实例变量：必要要在非静态初始化块，声明该实例变量或者在构造器中指定初始值，而且只能在这三个地方进行指定。 final局部变量final局部变量由程序员进行显式初始化，如果final局部变量已经进行了初始化则后面就不能再次进行更改，如果final变量未进行初始化，可以进行赋值，当且仅有一次赋值，一旦赋值之后再次赋值就会出错。下面用具体的代码演示final局部变量的情况： 现在我们来换一个角度进行考虑，final修饰的是基本数据类型和引用类型有区别吗？ final基本数据类型 VS final引用数据类型通过上面的例子我们已经看出来，如果final修饰的是一个基本数据类型的数据，一旦赋值后就不能再次更改，那么，如果final是引用数据类型了？这个引用的对象能够改变吗？我们同样来看一段代码。 123456789101112131415161718192021222324252627public class FinalExample { //在声明final实例成员变量时进行赋值 private final static Person person = new Person(24, 170); public static void main(String[] args) { //对final引用数据类型person进行更改 person.age = 22; System.out.println(person.toString()); } static class Person { private int age; private int height; public Person(int age, int height) { this.age = age; this.height = height; } @Override public String toString() { return &quot;Person{&quot; + &quot;age=&quot; + age + &quot;, height=&quot; + height + '}'; } }} 当我们对final修饰的引用数据类型变量person的属性改成22，是可以成功操作的。通过这个实验我们就可以看出来当final修饰基本数据类型变量时，不能对基本数据类型变量重新赋值，因此基本数据类型变量不能被改变。而对于引用类型变量而言，它仅仅保存的是一个引用，final只保证这个引用类型变量所引用的地址不会发生改变，即一直引用这个对象，但这个对象属性是可以改变的。 宏变量利用final变量的不可更改性，在满足以下三个条件时，该变量就会成为一个“宏变量”，即是一个常量。 使用final修饰符修饰； 在定义该final变量时就指定了初始值； 该初始值在编译时就能够唯一指定。 注意：当程序中其他地方使用该宏变量的地方，编译器会直接替换成该变量的值 方法重写当父类的方法被final修饰的时候，子类不能重写父类的该方法，比如在Object中，getClass()方法就是final的，我们就不能重写该方法，但是hashCode()方法就不是被final所修饰的，我们就可以重写hashCode()方法。我们还是来写一个例子来加深一下理解：先定义一个父类，里面有final修饰的方法test(); 1234public class FinalExampleParent { public final void test() { }} 然后FinalExample继承该父类FinalExampleParent，当重写test()方法时出现报错 通过这个现象我们就可以看出来被final修饰的方法不能够被子类所重写。 重载1234567public class FinalExampleParent { public final void test() { } public final void test(String str) { }} 可以看出被final修饰的方法是可以重载的。经过我们的分析可以得出如下结论： 1. 父类的final方法是不能够被子类重写的 2. final方法是可以被重载的 类当一个类被final修饰时，表名该类是不能被子类继承的。子类继承往往可以重写父类的方法和改变父类属性，会带来一定的安全隐患，因此，当一个类不希望被继承时就可以使用final修饰。还是来写一个小例子： 1234public final class FinalExampleParent { public final void test() { }} 父类会被final修饰，当子类继承该父类的时候，就会报错，如下图： final关键字举例final经常会被用作不变类上，利用final的不可更改性。我们先来看看什么是不变类。 不变类不变类的意思是创建该类的实例后，该实例的实例变量是不可改变的。满足以下条件则可以成为不可变类： 使用private和final修饰符来修饰该类的成员变量； 提供带参的构造器用于初始化类的成员变量； 仅为该类的成员变量提供getter方法，不提供setter方法，因为普通方法无法修改fina修饰的成员变量； 如果有必要就重写Object类 的hashCode()和equals()方法，应该保证用equals()判断相同的两个对象其Hashcode值也是相等的。 JDK中提供的八个包装类和String类都是不可变类，我们来看看String的实现。 12/** The value is used for character storage. */ private final char value[]; 可以看出String的value就是final修饰的，上述其他几条性质也是吻合的。 多线程中你真的了解final吗上面我们聊的final使用，应该属于Java基础层面的，当理解这些后我们就真的算是掌握了final吗？有考虑过final在多线程并发的情况吗？在*Java内存模型*中我们知道Java内存模型为了能让处理器和编译器底层发挥他们的最大优势，对底层的约束就很少，也就是说针对底层来说Java内存模型就是一弱内存数据模型。同时，处理器和编译为了性能优化会对指令序列有编译器和处理器重排序。那么，在多线程情况下，final会进行怎样的重排序？会导致线程安全的问题吗？下面，就来看看final的重排序。 final域重排序规则final域为基本类型先看一段示例性的代码： 1234567891011121314151617181920public class FinalDemo { private int a; //普通域 private final int b; //final域 private static FinalDemo finalDemo; public FinalDemo() { a = 1; // 1. 写普通域 b = 2; // 2. 写final域 } public static void writer() { finalDemo = new FinalDemo(); } public static void reader() { FinalDemo demo = finalDemo; // 3.读对象引用 int a = demo.a; //4.读普通域 int b = demo.b; //5.读final域 }} 假设线程A在执行writer()方法，线程B执行reader()方法。 写final域重排序规则写final域的重排序规则禁止对final域的写重排序到构造函数之外，这个规则的实现主要包含了两个方面： JMM禁止编译器把final域的写重排序到构造函数之外； 编译器会在final域写之后，构造函数return之前，插入一个storestore屏障。这个屏障可以禁止处理器把final域的写重排序到构造函数之外。 我们再来分析writer方法，虽然只有一行代码，但实际上做了两件事情： 构造了一个FinalDemo对象； 把这个对象赋值给成员变量finalDemo。 我们来画下存在的一种可能执行时序图，如下： 由于a,b之间没有数据依赖性，普通域（普通变量）a可能会被重排序到构造函数之外，线程B就有可能读到的是普通变量a初始化之前的值（零值），这样就可能出现错误。而final域变量b，根据重排序规则，会禁止final修饰的变量b重排序到构造函数之外，从而b能够正确赋值，线程B就能够读到final变量初始化后的值。 因此，写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，而普通域就不具有这个保障。比如在上例，线程B有可能就是一个未正确初始化的对象finalDemo。 读final域重排序规则读final域重排序规则为：在一个线程中，初次读对象引用和初次读该对象包含的final域，JMM会禁止这两个操作的重排序。（注意，这个规则仅仅是针对处理器），处理器会在读final域操作的前面插入一个LoadLoad屏障。实际上，读对象的引用和读该对象的final域存在间接依赖性，一般处理器不会重排序这两个操作。但是有一些处理器会重排序，因此，这条禁止重排序规则就是针对这些处理器而设定的。 read()方法主要包含了三个操作： 初次读引用变量finalDemo; 初次读引用变量finalDemo的普通域a; 初次读引用变量finalDemo的final域b; 假设线程A写过程没有重排序，那么线程A和线程B有一种的可能执行时序为下图： 读对象的普通域被重排序到了读对象引用的前面就会出现线程B还未读到对象引用就在读取该对象的普通域变量，这显然是错误的操作。而final域的读操作就“限定”了在读final域变量前已经读到了该对象的引用，从而就可以避免这种情况。 读final域的重排序规则可以确保：在读一个对象的final域之前，一定会先读这个包含这个final域的对象的引用。 final域为引用类型我们已经知道了final域是基本数据类型的时候重排序规则是怎么的了？如果是引用数据类型了？我们接着继续来探讨。 对final修饰的对象的成员域写操作针对引用数据类型，final域写针对编译器和处理器重排序增加了这样的约束：在构造函数内对一个final修饰的对象的成员域的写入，与随后在构造函数之外把这个被构造的对象的引用赋给一个引用变量，这两个操作是不能被重排序的。注意这里的是“增加”也就说前面对final基本数据类型的重排序规则在这里还是使用。这句话是比较拗口的，下面结合实例来看。 1234567891011121314151617181920212223public class FinalReferenceDemo { final int[] arrays; private FinalReferenceDemo finalReferenceDemo; public FinalReferenceDemo() { arrays = new int[1]; //1 arrays[0] = 1; //2 } public void writerOne() { finalReferenceDemo = new FinalReferenceDemo(); //3 } public void writerTwo() { arrays[0] = 2; //4 } public void reader() { if (finalReferenceDemo != null) { //5 int temp = finalReferenceDemo.arrays[0]; //6 } }} 针对上面的实例程序，线程线程A执行wirterOne方法，执行完后线程B执行writerTwo方法，然后线程C执行reader方法。下图就以这种执行时序出现的一种情况来讨论（耐心看完才有收获）。 由于对final域的写禁止重排序到构造方法外，因此1和3不能被重排序。由于一个final域的引用对象的成员域写入不能与随后将这个被构造出来的对象赋给引用变量重排序，因此2和3不能重排序。 对final修饰的对象的成员域读操作JMM可以确保线程C至少能看到写线程A对final引用的对象的成员域的写入，即能看下arrays[0] = 1，而写线程B对数组元素的写入可能看到可能看不到。JMM不保证线程B的写入对线程C可见，线程B和线程C之间存在数据竞争，此时的结果是不可预知的。如果可见的，可使用锁或者volatile。 关于final重排序的总结按照final修饰的数据类型分类： 基本数据类型: final域写：禁止final域写与构造方法重排序，即禁止final域写重排序到构造方法之外，从而保证该对象对所有线程可见时，该对象的final域全部已经初始化过。 final域读：禁止初次读对象的引用与读该对象包含的final域的重排序。 引用数据类型： 额外增加约束：禁止在构造函数对一个final修饰的对象的成员域的写入与随后将这个被构造的对象的引用赋值给引用变量 重排序 final的实现原理上面我们提到过，写final域会要求编译器在final域写之后，构造函数返回前插入一个StoreStore屏障。读final域的重排序规则会要求编译器在读final域的操作前插入一个LoadLoad屏障。 很有意思的是，如果以X86处理为例，X86不会对写-写重排序，所以StoreStore屏障可以省略。由于不会对有间接依赖性的操作重排序，所以在X86处理器中，读final域需要的LoadLoad屏障也会被省略掉。也就是说，以X86为例的话，对final域的读/写的内存屏障都会被省略！具体是否插入还是得看是什么处理器 为什么final引用不能从构造函数中“溢出”这里还有一个比较有意思的问题：上面对final域写重排序规则可以确保我们在使用一个对象引用的时候该对象的final域已经在构造函数被初始化过了。但是这里其实是有一个前提条件的，也就是：在构造函数，不能让这个被构造的对象被其他线程可见，也就是说该对象引用不能在构造函数中“溢出”。以下面的例子来说： 12345678910111213141516171819public class FinalReferenceEscapeDemo { private final int a; private FinalReferenceEscapeDemo referenceDemo; public FinalReferenceEscapeDemo() { a = 1; //1 referenceDemo = this; //2 } public void writer() { new FinalReferenceEscapeDemo(); } public void reader() { if (referenceDemo != null) { //3 int temp = referenceDemo.a; //4 } }} 可能的执行时序如图所示： 假设一个线程A执行writer方法另一个线程执行reader方法。因为构造函数中操作1和2之间没有数据依赖性，1和2可以重排序，先执行了2，这个时候引用对象referenceDemo是个没有完全初始化的对象，而当线程B去读取该对象时就会出错。尽管依然满足了final域写重排序规则：在引用对象对所有线程可见时，其final域已经完全初始化成功。但是，引用对象“this”溢出，该代码依然存在线程安全的问题。 参看文献 《Java并发编程的艺术》 《疯狂Java讲义》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%85%B3%E9%94%AE%E5%AD%97-final/"},{"title":"并发编程-关键字-synchronized","text":"synchronized简介在学习知识前，我们先来看一个现象： 12345678910111213141516171819202122public class SynchronizedDemo implements Runnable { private static int count = 0; public static void main(String[] args) { for (int i = 0; i &lt; 10; i++) { Thread thread = new Thread(new SynchronizedDemo()); thread.start(); } try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;result: &quot; + count); } @Override public void run() { for (int i = 0; i &lt; 1000000; i++) count++; }} 开启了10个线程，每个线程都累加了1000000次，如果结果正确的话自然而然总数就应该是10 * 1000000 = 10000000。可就运行多次结果都不是这个数，而且每次运行结果都不一样。这是为什么了？有什么解决方案了？这就是我们今天要聊的事情。 在上一篇博文中我们已经了解了***Java内存模型的一些知识，并且已经知道出现线程安全的主要来源于JMM的设计，主要集中在主内存和线程的工作内存而导致的内存可见性问题*，以及重排序导致的问题，进一步知道了happens-before规则。线程运行时拥有自己的栈空间，会在自己的栈空间运行，如果多线程间没有共享的数据也就是说多线程间并没有协作完成一件事情，那么，多线程就不能发挥优势，不能带来巨大的价值。那么共享数据的线程安全问题怎样处理？很自然而然的想法就是每一个线程依次去读写这个共享变量，这样就不会有任何数据安全的问题，因为每个线程所操作的都是当前最新的版本数据。那么，在Java关键字synchronized就具有使每个线程依次排队操作共享变量的功能。很显然，这种同步机制效率很低，但synchronized是其他并发容器实现的基础，对它的理解也会大大提升对并发编程的感觉，从功利的角度来说，这也是面试高频的考点。好了，下面，就来具体说说这个关键字。 synchronized实现原理在Java代码中，synchronized可使用在代码块和方法中，根据synchronized用的位置可以有这些使用场景： 如图，synchronized可以用在方法上也可以使用在代码块中，其中方法是实例方法和静态方法分别锁的是该类的实例对象和该类的对象。而使用在代码块中也可以分为三种，具体的可以看上面的表格。这里的需要注意的是：如果锁的是类对象的话，尽管new多个实例对象，但他们仍然是属于同一个类依然会被锁住，即线程之间保证同步关系。 现在我们已经初步了解了synchronized，看起来很简单，拥有了这个关键字就真的可以在并发编程中得心应手了吗？爱学的你，就真的不想知道synchronized底层是怎样实现了吗？ 对象锁（monitor）机制现在我们来看看synchronized的具体底层实现。先写一个简单的demo: 12345678910public class SynchronizedDemo { public static void main(String[] args) { synchronized (SynchronizedDemo.class) { } method(); } private static void method() { }} 上面的代码中有一个同步代码块，锁住的是类对象，并且还有一个同步静态方法，锁住的依然是该类的类对象。编译之后，切换到SynchronizedDemo.class的同级目录之后，然后用javap -v SynchronizedDemo.class查看字节码文件： 如图，上面用黄色高亮的部分就是需要注意的部分了，这也是添synchronized关键字之后独有的。执行同步代码块后首先要先执行monitorenter指令，退出的时候monitorexit指令。通过分析之后可以看出，使用synchronized进行同步，其关键就是必须要对对象的监视器monitor进行获取，当线程获取monitor后才能继续往下执行，否则就只能等待。而这个获取的过程是互斥的，即同一时刻只有一个线程能够获取到monitor。上面的demo中在执行完同步代码块之后紧接着再会去执行一个静态同步方法，而这个方法锁的对象依然就这个类对象，那么这个正在执行的线程还需要获取该锁吗？答案是不必的，从上图中就可以看出来，执行静态同步方法的时候就只有一条monitorexit指令，并没有monitorenter获取锁的指令。这就是锁的重入性，即在同一锁程中，线程不需要再次获取同一把锁。synchronized先天具有重入性。每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一。 任意一个对象都拥有自己的监视器，当这个对象由同步块或者这个对象的同步方法调用时，执行方法的线程必须先获取该对象的监视器才能进入同步块和同步方法，如果没有获取到监视器的线程将会被阻塞在同步块和同步方法的入口处，进入到BLOCKED状态（关于线程的状态可以看***线程的状态和基本操作***) 下图表现了对象，对象监视器，同步队列以及执行线程状态之间的关系： 该图可以看出，任意线程对Object的访问，首先要获得Object的监视器，如果获取失败，该线程就进入同步状态，线程状态变为BLOCKED，当Object的监视器占有者释放后，在同步队列中得线程就会有机会重新获取该监视器。 synchronized的happens-before关系在上一篇文章中讨论过*happens-before*规则，抱着学以致用的原则我们现在来看一看synchronized的happens-before规则，即监视器锁规则：对同一个监视器的解锁，happens-before对该监视器的加锁。继续来看代码： 1234567891011public class MonitorDemo { private int a = 0; public synchronized void writer() { // 1 a++; // 2 } // 3 public synchronized void reader() { // 4 int i = a; // 5 } // 6} 该代码的happens-before关系如图所示： 在图中每一个箭头连接的两个节点就代表之间的happens-before关系，黑色的是通过程序顺序规则推导出来，红色的为监视器锁规则推导而出：线程A释放锁happens-before线程B加锁，蓝色的则是通过程序顺序规则和监视器锁规则推测出来happens-befor关系，通过传递性规则进一步推导的happens-before关系。现在我们来重点关注2 happens-before 5，通过这个关系我们可以得出什么？ 根据happens-before的定义中的一条：如果A happens-before B，则A的执行结果对B可见，并且A的执行顺序先于B。线程A先对共享变量A进行加一，由2 happens-before 5关系可知线程A的执行结果对线程B可见即线程B所读取到的a的值为1。 锁获取和锁释放的内存语义在上一篇文章提到过JMM核心为两个部分：happens-before规则以及内存抽象模型。我们分析完synchronized的happens-before关系后，还是不太完整的，我们接下来看看基于Java内存抽象模型的synchronized的内存语义。 废话不多说依旧先上图。 从上图可以看出，线程A会首先先从主内存中读取共享变量a=0的值然后将该变量拷贝到自己的本地内存，进行加一操作后，再将该值刷新到主内存，整个过程即为线程A 加锁–&gt;执行临界区代码–&gt;释放锁相对应的内存语义。 线程B获取锁的时候同样会获取主内存中共享变量a的值，这个时候就是最新的值1，然后将该值拷贝到线程B的工作内存中去，释放锁的时候同样会重写到主内存中。 从整体上来看，线程A的执行结果（a=1）对线程B是可见的，实现原理为：释放锁的时候会将值刷新到主内存中，其他线程获取锁时会强制从主内存中获取最新的值。另外也验证了2 happens-before 5，2的执行结果对5是可见的。 从横向来看，这就像线程A通过主内存中的共享变量和线程B进行通信，A 告诉 B 我们俩的共享数据现在为1啦，这种线程间的通信机制正好吻合Java的内存模型，正好是共享内存的并发模型结构。 synchronized优化通过上面的讨论现在我们对synchronized应该有所印象了，它最大的特征就是在同一时刻只有一个线程能够获得对象的监视器（monitor），从而进入到同步代码块或者同步方法之中，即表现为互斥性（排它性）。这种方式肯定效率低下，每次只能通过一个线程，既然每次只能通过一个，这种形式不能改变的话，那么我们能不能让每次通过的速度变快一点了。打个比方，去收银台付款，之前的方式是，大家都去排队，然后去纸币付款收银员找零，有在付款的时候从包里拿出钱包再去拿出钱，这个过程是比较耗时的，然后，支付宝解放了大家去钱包找钱的过程，现在只需要扫描下就可以完成付款了，也省去了收银员跟你找零的时间的了。同样是需要排队，但整个付款的时间大大缩短，是不是整体的效率变高速率变快了？这种优化方式同样可以引申到锁优化上，缩短获取锁的时间，伟大的科学家们也是这样做的，令人钦佩，毕竟Java是这么优秀的语言（微笑脸）。 在聊到锁的优化也就是锁的几种状态前，有两个知识点需要先关注：（1）CAS操作 （2）Java对象头，这是理解下面知识的前提条件。 CAS操作什么是CAS?使用锁时，线程获取锁是一种悲观锁策略，即假设每一次执行临界区代码都会产生冲突，所以当前线程获取到锁的时候同时也会阻塞其他线程获取该锁。而CAS操作（又称为无锁操作）是一种乐观锁策略，它假设所有线程访问共享资源的时候不会出现冲突，既然不会出现冲突自然而然就不会阻塞其他线程的操作。因此，线程就不会出现阻塞停顿的状态。那么，如果出现冲突了怎么办？无锁操作是使用CAS(compare and swap)又叫做比较交换来鉴别线程是否出现冲突，出现冲突就重试当前操作直到没有冲突为止。 CAS的操作过程CAS比较交换的过程可以通俗的理解为CAS(V,O,N)，包含三个值分别为：V 内存地址存放的实际值；O 预期的值（旧值）；N 更新的新值。当V和O相同时，也就是说旧值和内存中实际的值相同表明该值没有被其他线程更改过，即该旧值O就是目前来说最新的值了，自然而然可以将新值N赋值给V。反之，V和O不相同，表明该值已经被其他线程改过了则该旧值O不是最新版本的值了，所以不能将新值N赋给V，返回V即可。当多个线程使用CAS操作一个变量时，只有一个线程会成功，并成功更新，其余会失败。失败的线程会重新尝试，当然也可以选择挂起线程 CAS的实现需要硬件指令集的支撑，在JDK1.5后虚拟机才可以使用处理器提供的CMPXCHG指令实现。 synchronized VS CAS 元老级的synchronized(未优化前)最主要的问题是：在存在线程竞争的情况下会出现线程阻塞和唤醒锁带来的性能问题，因为这是一种互斥同步（阻塞同步）。而CAS并不是武断的将线程挂起，当CAS操作失败后会进行一定的尝试，而非进行耗时的挂起唤醒的操作，因此也叫做非阻塞同步。这是两者主要的区别。 CAS的应用场景在J.U.C包中利用CAS实现类有很多，可以说是支撑起整个concurrency包的实现，在Lock实现中会有CAS改变state变量，在atomic包中的实现类也几乎都是用CAS实现，关于这些具体的实现场景在之后会详细聊聊，现在有个印象就好了（微笑脸）。 CAS的问题1. ABA问题因为CAS会检查旧值有没有变化，这里存在这样一个有意思的问题。比如一个旧值A变为了成B，然后再变成A，刚好在做CAS时检查发现旧值并没有变化依然为A，但是实际上的确发生了变化。解决方案可以沿袭数据库中常用的乐观锁方式，添加一个版本号可以解决。原来的变化路径A-&gt;B-&gt;A就变成了1A-&gt;2B-&gt;3C。Java这么优秀的语言，当然在Java 1.5后的atomic包中提供了AtomicStampedReference来解决ABA问题，解决思路就是这样的。 2. 自旋时间过长 使用CAS时非阻塞同步，也就是说不会将线程挂起，会自旋（无非就是一个死循环）进行下一次尝试，如果这里自旋时间过长对性能是很大的消耗。如果JVM能支持处理器提供的pause指令，那么在效率上会有一定的提升。 3. 只能保证一个共享变量的原子操作 当对一个共享变量执行操作时CAS能保证其原子性，如果对多个共享变量进行操作，CAS就不能保证其原子性。有一个解决方案是利用对象整合多个共享变量，即一个类中的成员变量就是这几个共享变量。然后将这个对象做CAS操作就可以保证其原子性。atomic中提供了AtomicReference来保证引用对象之间的原子性。 Java对象头在同步的时候是获取对象的monitor，即获取到对象的锁。那么对象的锁怎么理解？无非就是类似对对象的一个标志，那么这个标志就是存放在Java对象的对象头。Java对象头里的Mark Word里默认的存放的对象的hashcode、对象分代年龄和锁标记位。32位JVM Mark Word默认存储结构为（注：Java对象头以及下面的锁状态变化摘自《Java并发编程的艺术》一书，该书我认为写的足够好，就没在自己组织语言班门弄斧了）： 如图在Mark Word会默认存放hasdcode，年龄值以及锁标志位等信息。 Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。对象的MarkWord变化为下图： 偏向锁HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。 偏向锁的获取当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁的撤销偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。 如图，偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。 下图线程1展示了偏向锁获取的过程，线程2展示了偏向锁撤销的过程。 如何关闭偏向锁偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：**-XX:BiasedLockingStartupDelay=0。如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false**，那么程序默认会进入轻量级锁状态。 轻量级锁加锁线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 解锁轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 各种锁的比较 一个例子经过上面的理解，我们现在应该知道了该怎样解决了。更正后的代码为： 123456789101112131415161718192021222324public class SynchronizedDemo implements Runnable { private static int count = 0; public static void main(String[] args) { for (int i = 0; i &lt; 10; i++) { Thread thread = new Thread(new SynchronizedDemo()); thread.start(); } try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;result: &quot; + count); } @Override public void run() { synchronized (SynchronizedDemo.class) { for (int i = 0; i &lt; 1000000; i++) count++; } }} 开启十个线程，每个线程在原值上累加1000000次，最终正确的结果为10X1000000=10000000，这里能够计算出正确的结果是因为在做累加操作时使用了同步代码块，这样就能保证每个线程所获得共享变量的值都是当前最新的值，如果不使用同步的话，就可能会出现A线程累加后，而B线程做累加操作有可能是使用原来的就值，即“脏值”。这样，就导致最终的计算结果不是正确的。而使用synchronized就可能保证内存可见性，保证每个线程都是操作的最新值。这里只是一个示例性的demo，聪明的你，还有其他办法吗？ 参考文献 《Java并发编程的艺术》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%85%B3%E9%94%AE%E5%AD%97-synchronized/"},{"title":"并发编程-关键字-volatile","text":"volatile简介在上一篇文章中我们深入理解了Java关键字-synchronized，我们知道在java中还有一大神器就是关键volatile，可以说是和synchronized各领风骚，其中奥妙，我们来共同探讨下。 通过上一篇的文章我们了解到synchronized是阻塞式同步，在线程竞争激烈的情况下会升级为重量级锁。而volatile就可以说是Java虚拟机提供的最轻量级的同步机制。但它同时不容易被正确理解，也至于在并发编程中很多程序员遇到线程安全的问题就会使用synchronized。*Java内存模型*告诉我们，各个线程会将共享变量从主内存中拷贝到工作内存，然后执行引擎会基于工作内存中的数据进行操作处理。线程在工作内存进行操作后何时会写到主内存中？这个时机对普通变量是没有规定的，而针对volatile修饰的变量给Java虚拟机特殊的约定，线程对volatile变量的修改会立刻被其他线程所感知，即不会出现数据脏读的现象，从而保证数据的“可见性”。 现在我们有了一个大概的印象就是：被volatile修饰的变量能够保证每个线程能够获取该变量的最新值，从而避免出现数据脏读的现象 volatile实现原理volatile是怎样实现了？比如一个很简单的Java代码： 1instance = new Instancce() //instance是volatile变量 在生成汇编代码时会在volatile修饰的共享变量进行写操作的时候会多出Lock前缀的指令（具体的大家可以使用一些工具去看一下，这里我就只把结果说出来）。我们想这个Lock指令肯定有神奇的地方，那么Lock前缀的指令在多核处理器下会发现什么事情了？主要有这两个方面的影响： 将当前处理器缓存行的数据写回系统内存； 这个写回内存的操作会使得其他CPU里缓存了该内存地址的数据无效 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。因此，经过分析我们可以得出如下结论： Lock前缀的指令会引起处理器缓存写回内存； 一个处理器的缓存回写到内存会导致其他处理器的缓存失效； 当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。 这样针对volatile变量通过这样的机制就使得每个线程都能获得该变量的最新值。 volatile的happens-before关系经过上面的分析，我们已经知道了volatile变量可以通过缓存一致性协议保证每个线程都能获得最新值，即满足数据的“可见性”。我们继续延续上一篇博客分析问题的方式（我一直认为思考问题的方式是属于自己，也才是最重要的，也在不断培养这方面的能力），我一直将并发分析的切入点分为两个核心，三大性质。两大核心：JMM内存模型（主内存和工作内存）以及happens-before；三条性质：原子性，可见性，有序性（关于三大性质的总结在以后得文章会和大家共同探讨）。废话不多说，先来看两个核心之一：volatile的happens-before关系。 在六条*happens-before规则*中有一条是：volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。下面我们结合具体的代码，我们利用这条规则推导下： 12345678910111213public class VolatileExample { private int a = 0; private volatile boolean flag = false; public void writer(){ a = 1; //1 flag = true; //2 } public void reader(){ if(flag){ //3 int i = a; //4 } }} 上面的实例代码对应的happens-before关系如下图所示： 加锁线程A先执行writer方法，然后线程B执行reader方法，图中每一个箭头两个节点就代码一个happens-before关系，黑色的代表根据程序顺序规则推导出来，红色的是根据volatile变量的写happens-before 于任意后续对volatile变量的读，而蓝色的就是根据传递性规则推导出来的。这里的2 happen-before 3，同样根据happens-before规则定义：如果A happens-before B，则A的执行结果对B可见，并且A的执行顺序先于B的执行顺序，我们可以知道操作2执行结果对操作3来说是可见的，也就是说当线程A将volatile变量 flag更改为true后线程B就能够迅速感知。 volatile的内存语义还是按照两个核心的分析方式，分析完happens-before关系后我们现在就来进一步分析volatile的内存语义（按照这种方式去学习，会不会让大家对知识能够把握的更深，而不至于不知所措）。还是以上面的代码为例，假设线程A先执行writer方法，线程B随后执行reader方法，初始时线程的本地内存中flag和a都是初始状态，下图是线程A执行volatile写后的状态图。 当volatile变量写后，线程中本地内存中共享变量就会置为失效的状态，因此线程B再需要读取从主内存中去读取该变量的最新值。下图就展示了线程B读取同一个volatile变量的内存变化示意图。 从横向来看，线程A和线程B之间进行了一次通信，线程A在写volatile变量时，实际上就像是给B发送了一个消息告诉线程B你现在的值都是旧的了，然后线程B读这个volatile变量时就像是接收了线程A刚刚发送的消息。既然是旧的了，那线程B该怎么办了？自然而然就只能去主内存去取啦。 好的，我们现在两个核心：happens-before以及内存语义现在已经都了解清楚了。是不是还不过瘾，突然发现原来自己会这么爱学习（微笑脸），那我们下面就再来一点干货—-volatile内存语义的实现。 volatile的内存语义实现我们都知道，为了性能优化，JMM在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序，那如果想阻止重排序要怎么办了？答案是可以添加内存屏障。 内存屏障JMM内存屏障分为四类见下图， Java编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。为了实现volatile的内存语义，JMM会限制特定类型的编译器和处理器重排序，JMM会针对编译器制定volatile重排序规则表： “NO”表示禁止重排序。为了实现volatile内存语义时，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎是不可能的，为此，JMM采取了保守策略： 在每个volatile写操作的前面插入一个StoreStore屏障； 在每个volatile写操作的后面插入一个StoreLoad屏障； 在每个volatile读操作的后面插入一个LoadLoad屏障； 在每个volatile读操作的后面插入一个LoadStore屏障。 需要注意的是：volatile写是在前面和后面分别插入内存屏障，而volatile读操作是在后面插入两个内存屏障 StoreStore屏障：禁止上面的普通写和下面的volatile写重排序； StoreLoad屏障：防止上面的volatile写与下面可能有的volatile读/写重排序 LoadLoad屏障：禁止下面所有的普通读操作和上面的volatile读重排序 LoadStore屏障：禁止下面所有的普通写操作和上面的volatile读重排序 下面以两个示意图进行理解，图片摘自相当好的一本书《Java并发编程的艺术》。 一个示例我们现在已经理解volatile的精华了，文章开头的那个问题我想现在我们都能给出答案了。更正后的代码为： 12345678910111213141516171819public class VolatileDemo { private static volatile boolean isOver = false; public static void main(String[] args) { Thread thread = new Thread(new Runnable() { @Override public void run() { while (!isOver) ; } }); thread.start(); try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } isOver = true; }} 注意不同点，现在已经将isOver设置成了volatile变量，这样在main线程中将isOver改为了true后，thread的工作内存该变量值就会失效，从而需要再次从主内存中读取该值，现在能够读出isOver最新值为true从而能够结束在thread里的死循环，从而能够顺利停止掉thread线程。现在问题也解决了，知识也学到了。 参考文献 《Java并发编程的艺术》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%85%B3%E9%94%AE%E5%AD%97-volatile/"},{"title":"并发编程-初识Lock与AQS","text":"concurrent包的结构层次在针对并发编程中，Doug Lea大师为我们提供了大量实用，高性能的工具类，针对这些代码进行研究会让我们对并发编程的掌握更加透彻也会大大提升我们对并发编程技术的热爱。这些代码在java.util.concurrent包下。如下图，即为concurrent包的目录结构图。 其中包含了两个子包：atomic以及locks，另外在concurrent下的阻塞队列以及executors,这些就是concurrent包中的精华，之后会一一进行学习。而这些类的实现主要是依赖于volatile以及CAS，从整体上来看concurrent包的整体实现图如下图所示： lock简介我们先来看concurrent包下的locks子包。锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源。在Lock接口出现之前，java程序主要是靠synchronized关键字实现锁功能的，而java SE5之后，并发包中增加了lock接口，它提供了与synchronized一样的锁功能。虽然它失去了像synchronize关键字隐式加锁解锁的便捷性，但是却拥有了锁获取和释放的可操作性，可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。通常使用显式使用lock的形式如下： 1234567Lock lock = new ReentrantLock();lock.lock();try{ .......}finally{ lock.unlock();} 需要注意的是synchronized同步块执行完成或者遇到异常时锁会自动释放，而lock必须调用unlock()方法释放锁，因此在finally块中释放锁。 Lock接口API我们现在就来看看lock接口定义了哪些方法： 123456789101112//获取锁void lock(); //获取锁的过程能够响应中断void lockInterruptibly() throws InterruptedException;//非阻塞式响应中断能立即返回，获取锁放回true反之返回fasleboolean tryLock();//超时获取锁，在超时内或者未中断的情况下能够获取锁boolean tryLock(long time, TimeUnit unit) throws InterruptedException;//获取与lock绑定的等待通知组件，当前线程必须获得了锁才能进行等待，进行等待时会先释放锁，当再次获取锁时才能从等待中返回Condition newCondition();// 释放锁。unlock(); 上面是lock接口下的六个方法，也只是从源码中英译中翻译了一遍，感兴趣的可以自己的去看看。那么在locks包下有哪些类实现了该接口了？先从最熟悉的ReentrantLock说起。 1public class ReentrantLock implements Lock, java.io.Serializable 很显然ReentrantLock实现了lock接口，接下来我们来仔细研究一下它是怎样实现的。当你查看源码时你会惊讶的发现ReentrantLock并没有多少代码，另外有一个很明显的特点是：**基本上所有的方法的实现实际上都是调用了其静态内存类Sync中的方法，而Sync类继承了AbstractQueuedSynchronizer（AQS）**。可以看出要想理解ReentrantLock关键核心在于对队列同步器AbstractQueuedSynchronizer（简称同步器）的理解。 初识AQS关于AQS在源码中有十分具体的解释： 12345678910111213141516171819202122Provides a framework for implementing blocking locks and relatedsynchronizers (semaphores, events, etc) that rely onfirst-in-first-out (FIFO) wait queues. This class is designed tobe a useful basis for most kinds of synchronizers that rely on asingle atomic {@code int} value to represent state. Subclassesmust define the protected methods that change this state, and whichdefine what that state means in terms of this object being acquiredor released. Given these, the other methods in this class carryout all queuing and blocking mechanics. Subclasses can maintainother state fields, but only the atomically updated {@code int}value manipulated using methods {@link #getState}, {@link#setState} and {@link #compareAndSetState} is tracked with respectto synchronization.&lt;p&gt;Subclasses should be defined as non-public internal helperclasses that are used to implement the synchronization propertiesof their enclosing class. Class{@code AbstractQueuedSynchronizer} does not implement anysynchronization interface. Instead it defines methods such as{@link #acquireInterruptibly} that can be invoked asappropriate by concrete locks and related synchronizers toimplement their public methods. 同步器是用来构建锁和其他同步组件的基础框架，它的实现主要依赖一个int成员变量来表示同步状态以及通过一个FIFO队列构成等待队列。它的子类必须重写AQS的几个protected修饰的用来改变同步状态的方法，其他方法主要是实现了排队和阻塞机制。状态的更新使用getState，setState以及compareAndSetState这三个方法。 子类被推荐定义为自定义同步组件的静态内部类，同步器自身没有实现任何同步接口，它仅仅是定义了若干同步状态的获取和释放方法来供自定义同步组件的使用，同步器既支持独占式获取同步状态，也可以支持共享式获取同步状态，这样就可以方便的实现不同类型的同步组件。 同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器，利用同步器实现锁的语义。可以这样理解二者的关系：锁是面向使用者，它定义了使用者与锁交互的接口，隐藏了实现细节；同步器是面向锁的实现者，它简化了锁的实现方式，屏蔽了同步状态的管理，线程的排队，等待和唤醒等底层操作。锁和同步器很好的隔离了使用者和实现者所需关注的领域。 AQS的模板方法设计模式AQS的设计是使用模板方法设计模式，它将一些方法开放给子类进行重写，而同步器给同步组件所提供模板方法又会重新调用被子类所重写的方法。举个例子，AQS中需要重写的方法tryAcquire： AQS中的tryAcquire()方法： 123protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException();} ReentrantLock中NonfairSync（继承AQS）会重写该方法为： 123protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires);} 而AQS中的模板方法acquire()： 12345public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 会调用tryAcquire方法，而此时当继承AQS的NonfairSync调用模板方法acquire时就会调用已经被NonfairSync重写的tryAcquire方法。这就是使用AQS的方式，在弄懂这点后对lock的实现理解有很大的提升。可以归纳总结为这么几点： 同步组件（这里不仅仅指锁，还包括CountDownLatch等）的实现依赖于同步器AQS，在同步组件实现中，使用AQS的方式被推荐定义继承AQS的静态内存类； AQS采用模板方法进行设计，AQS的protected修饰的方法需要由继承AQS的子类进行重写实现，当调用AQS的子类的方法时就会调用被重写的方法； AQS负责同步状态的管理，线程的排队，等待和唤醒这些底层操作，而Lock等同步组件主要专注于实现同步语义； 在重写AQS的方式时，使用AQS提供的getState(),setState(),compareAndSetState()方法进行修改同步状态 AQS可重写的方法如下图（摘自《Java并发编程的艺术》一书）： 在实现同步组件时AQS提供的模板方法如下图： AQS提供的模板方法可以分为3类： 独占式获取与释放同步状态； 共享式获取与释放同步状态； 查询同步队列中等待线程情况； 同步组件通过AQS提供的模板方法实现自己的同步语义。 一个例子下面使用一个例子来进一步理解下AQS的使用。这个例子也是来源于AQS源码中的example。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class Mutex implements Lock, java.io.Serializable { // Our internal helper class // 继承AQS的静态内存类 // 重写方法 private static class Sync extends AbstractQueuedSynchronizer { // Reports whether in locked state protected boolean isHeldExclusively() { return getState() == 1; } // Acquires the lock if state is zero public boolean tryAcquire(int acquires) { assert acquires == 1; // Otherwise unused if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } // Releases the lock by setting state to zero protected boolean tryRelease(int releases) { assert releases == 1; // Otherwise unused if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; } // Provides a Condition Condition newCondition() { return new ConditionObject(); } // Deserializes properly private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException { s.defaultReadObject(); setState(0); // reset to unlocked state } } // The sync object does all the hard work. We just forward to it. private final Sync sync = new Sync(); //使用同步器的模板方法实现自己的同步语义 public void lock() { sync.acquire(1); } public boolean tryLock() { return sync.tryAcquire(1); } public void unlock() { sync.release(1); } public Condition newCondition() { return sync.newCondition(); } public boolean isLocked() { return sync.isHeldExclusively(); } public boolean hasQueuedThreads() { return sync.hasQueuedThreads(); } public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(timeout)); } } MutexDemo： 12345678910111213141516171819public class MutextDemo { private static Mutex mutex = new Mutex(); public static void main(String[] args) { for (int i = 0; i &lt; 10; i++) { Thread thread = new Thread(() -&gt; { mutex.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } finally { mutex.unlock(); } }); thread.start(); } }} 执行情况： 上面的这个例子实现了独占锁的语义，在同一个时刻只允许一个线程占有锁。MutexDemo新建了10个线程，分别睡眠3s。从执行情况也可以看出来当前Thread-6正在执行占有锁而其他Thread-7，Thread-8等线程处于WAIT状态。按照推荐的方式，Mutex定义了一个继承AQS的静态内部类Sync，并且重写了AQS的tryAcquire等等方法，而对state的更新也是利用了setState()，getState()，compareAndSetState()这三个方法。在实现实现lock接口中的方法也只是调用了AQS提供的模板方法（因为Sync继承AQS）。从这个例子就可以很清楚的看出来，在同步组件的实现上主要是利用了AQS，而AQS“屏蔽”了同步状态的修改，线程排队等底层实现，通过AQS的模板方法可以很方便的给同步组件的实现者进行调用。而针对用户来说，只需要调用同步组件提供的方法来实现并发编程即可。同时在新建一个同步组件时需要把握的两个关键点是： 实现同步组件时推荐定义继承AQS的静态内存类，并重写需要的protected修饰的方法； 同步组件语义的实现依赖于AQS的模板方法，而AQS模板方法又依赖于被AQS的子类所重写的方法。 通俗点说，因为AQS整体设计思路采用模板方法设计模式，同步组件以及AQS的功能实际上分别切分成各自的两部分： 同步组件实现者的角度： 通过可重写的方法：独占式： tryAcquire()(独占式获取同步状态），tryRelease()（独占式释放同步状态）；共享式 ：tryAcquireShared()(共享式获取同步状态)，tryReleaseShared()(共享式释放同步状态)；告诉AQS怎样判断当前同步状态是否成功获取或者是否成功释放。同步组件专注于对当前同步状态的逻辑判断，从而实现自己的同步语义。这句话比较抽象，举例来说，上面的Mutex例子中通过tryAcquire方法实现自己的同步语义，在该方法中如果当前同步状态为0（即该同步组件没被任何线程获取），当前线程可以获取同时将状态更改为1返回true，否则，该组件已经被线程占用返回false。很显然，该同步组件只能在同一时刻被线程占用，Mutex专注于获取释放的逻辑来实现自己想要表达的同步语义。 AQS的角度 而对AQS来说，只需要同步组件返回的true和false即可，因为AQS会对true和false会有不同的操作，true会认为当前线程获取同步组件成功直接返回，而false的话就AQS也会将当前线程插入同步队列等一系列的方法。 总的来说，同步组件通过重写AQS的方法实现自己想要表达的同步语义，而AQS只需要同步组件表达的true和false即可，AQS会针对true和false不同的情况做不同的处理，至于底层实现，可以看这篇文章。 参考文献 《Java并发编程的艺术》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%88%9D%E8%AF%86Lock%E4%B8%8EAQS/"},{"title":"并发编程-前言","text":"整个系列文章为Java并发专题，一是自己的兴趣，二是，这部分在实际理解上很有难度，另外在面试过程中也是经常被问到。所以在学习过程中，记录了Java并发相关的基础知识，一是自己对知识能够建立体系，同时也希望有幸能够对其他人有用。 基础知识1.1 并发编程的优缺点 知识点：（1）为什么要用到并发？（优点）；（2）并发编程的缺点；（3）易混淆的概念 1.2 线程的状态和基本操作 知识点：（1）如何新建线程；（2）线程状态的转换；（3）线程的基本操作；（4）线程的优先级； （5）线程和进程的区别；（6）守护线程Daemon；（7）线程的死锁 并发理论（JMM）2.1 java内存模型以及happens-before规则 知识点：（1）JMM内存结构；（2）重排序；（3）happens-before规则 并发关键字3.1 让你彻底理解Synchronized 知识点：（1）如何使用synchronized；（2）monitor机制；（3）synchronized的happens-before关系；（4）synchronized的内存语义；（5）锁优化；（6）锁升级策略 3.2 让你彻底理解volatile 知识点：（1）实现原理；（2）happens-before的关系推导；（3）内存语义；（4）内存语义的实现 3.3 你以为你真的了解final吗？ 知识点：（1）如何使用；（2）final的重排序规则；（3）final实现原理；（4）final引用不能从构造函数中“溢出”（this逃逸） 3.4 三大性质总结：原子性，有序性，可见性 知识点：（1）原子性：synchronized；（2）可见性：synchronized，volatile；（3）有序性：synchronized，volatile Lock体系4.1 初识Lock与AbstractQueuedSynchronizer(AQS) 知识点：（1）Lock和synchronized的比较；（2）AQS设计意图；（3）如何使用AQS实现自定义同步组件；（4）可重写的方法；（5）AQS提供的模板方法； 4.2 深入理解AbstractQueuedSynchronizer(AQS) 知识点：（1）AQS同步队列的数据结构；（2）独占式锁；（3）共享式锁； 4.3 再一次理解ReentrantLock 知识点：（1）重入锁的实现原理；（2）公平锁的实现原理；（3）非公平锁的实现原理；（4）公平锁和非公平锁的比较 4.4 深入理解读写锁ReentrantReadWriteLock 知识点：（1）如何表示读写状态；（2）WriteLock的获取和释放；（3）ReadLock的获取和释放；（4）锁降级策略；（5）生成Condition等待队列；（6）应用场景 4.5 详解Condition的await和signal等待/通知机制 知识点：（1）与Object的wait/notify机制相比具有的特性；（2）与Object的wait/notify相对应的方法；（3）底层数据结构；（4）await实现原理；（5）signal/signalAll实现原理；（6）await和signal/signalAll的结合使用； 4.6 LockSupport工具 知识点：（1）主要功能；（2）与synchronized阻塞唤醒相比具有的特色； 并发容器5.1 并发容器之ConcurrentHashMap(JDK 1.8版本) 知识点：（1）关键属性；（2）重要内部类；（3）涉及到的CAS操作；（4）构造方法；（5）put执行流程；（6）get执行流程；（7）扩容机制；（8）用于统计size的方法的执行流程；（9）1.8版本的ConcurrentHashMap与之前版本的比较 5.2 并发容器之CopyOnWriteArrayList 知识点：（1）实现原理；（2）COW和ReentrantReadWriteLock的区别；（3）应用场景；（4）为什么具有弱一致性；（5）COW的缺点； 5.3 并发容器之ConcurrentLinkedQueue 知识点：（1）实现原理；（2）数据结构；（3）核心方法；（4）HOPS延迟更新的设计意图 5.4 并发容器之ThreadLocal 知识点：（1）实现原理；（2）set方法原理；（3）get方法原理；（4）remove方法原理；（5）ThreadLocalMap 5.5 一篇文章，从源码深入详解ThreadLocal内存泄漏问题 知识点：（1）ThreadLocal内存泄漏原理；（2）ThreadLocal的最佳实践；（3）应用场景 5.6 并发容器之BlockingQueue 知识点：（1）BlockingQueue的基本操作；（2）常用的BlockingQueue； 5.7 并发容器之ArrayBlockingQueue和LinkedBlockingQueue实现原理详解 线程池（Executor体系）6.1 线程池实现原理 知识点：（1）为什么要用到线程池？（2）执行流程；（3）构造器各个参数的意义；（4）如何关闭线程池；（5）如何配置线程池； 6.2 Executors类创建四种常见线程池 知识点：（1）newSingleThreadExecutor；（2）newFixedThreadPool；（3）newCachedThreadPool；（4）newScheduledThreadPool； 6.3 线程池之ScheduledThreadPoolExecutor 知识点：（1）类结构；（2）常用方法；（3）ScheduledFutureTask；（3）DelayedWorkQueue; 6.4 FutureTask基本操作总结 知识点：（1）FutureTask的几种状态；（2）get方法；（3）cancel方法；（4）应用场景；（5）实现 Runnable接口 原子操作类7.1 Java中atomic包中的原子操作类总结 知识点：（1）实现原理；（2）原子更新基本类型；（3）原子更新数组类型；（4）原子更新引用类型；（5）原子更新字段类型 并发工具8.1 并发编程-CountDownLatch与CyclicBarrier介绍 知识点：（1）倒计时器CountDownLatch；（2）循环栅栏CyclicBarrier；（3）CountDownLatch与CyclicBarrier的比较 8.2 并发编程-Semaphore与Exchanger介绍 知识点：（1）资源访问控制Semaphore；（2）数据交换Exchanger 并发实践9.1 并发编程-弄懂生产者和消费者问题 参考：https://www.codercc.com/backend/basic/juc","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%89%8D%E8%A8%80/"},{"title":"并发编程-深入理解AbstractQueuedSynchronizer(AQS)","text":"AQS简介在上一篇文章中我们对lock和AbstractQueuedSynchronizer(AQS)有了初步的认识。在同步组件的实现中，AQS是核心部分，同步组件的实现者通过使用AQS提供的模板方法实现同步组件语义，AQS则实现了对同步状态的管理，以及对阻塞线程进行排队，等待通知等等一些底层的实现处理。AQS的核心也包括了这些方面：同步队列，独占式锁的获取和释放，共享锁的获取和释放以及可中断锁，超时等待锁获取这些特性的实现，而这些实际上则是AQS提供出来的模板方法，归纳整理如下： 独占式锁： 1234void acquire(int arg);// 独占式获取同步状态，如果获取失败则插入同步队列进行等待；void acquireInterruptibly(int arg);// 与acquire方法相同，但在同步队列中进行等待的时候可以检测中断；boolean tryAcquireNanos(int arg, long nanosTimeout);// 在acquireInterruptibly基础上增加了超时等待功能，在超时时间内没有获得同步状态返回false;boolean release(int arg);// 释放同步状态，该方法会唤醒在同步队列中的下一个节点 共享式锁： 1234void acquireShared(int arg);// 共享式获取同步状态，与独占式的区别在于同一时刻有多个线程获取同步状态；void acquireSharedInterruptibly(int arg);// 在acquireShared方法基础上增加了能响应中断的功能；boolean tryAcquireSharedNanos(int arg, long nanosTimeout);// 在acquireSharedInterruptibly基础上增加了超时等待的功能；boolean releaseShared(int arg);// 共享式释放同步状态 要想掌握AQS的底层实现，其实也就是对这些模板方法的逻辑进行学习。在学习这些模板方法之前，我们得首先了解下AQS中的同步队列是一种什么样的数据结构，因为同步队列是AQS对同步状态的管理的基石。 同步队列当共享资源被某个线程占有，其他请求该资源的线程将会阻塞，从而进入同步队列。就数据结构而言，队列的实现方式无外乎两者一是通过数组的形式，另外一种则是链表的形式。AQS中的同步队列则是通过链表方式进行实现。接下来，很显然我们至少会抱有这样的疑问：1. 节点的数据结构是什么样的？2. 是单向还是双向？3. 是带头结点的还是不带头节点的？我们依旧先是通过看源码的方式。 在AQS有一个静态内部类Node，其中有这样一些属性： 1234567static final Node SHARED = new Node();//指示节点正在共享模式下等待的标记static final Node EXCLUSIVE = null;//指示节点正在独占模式下等待的标记volatile int waitStatus; //节点状态volatile Node prev; //当前节点/线程的前驱节点volatile Node next; //当前节点/线程的后继节点volatile Thread thread;//加入同步队列的线程引用Node nextWaiter;//等待队列中的下一个节点 节点的状态有以下这些： 12345static final int CANCELLED = 1//节点从同步队列中取消static final int SIGNAL = -1//后继节点的线程处于等待状态，如果当前节点释放同步状态会通知后继节点，使得后继节点的线程能够运行；static final int CONDITION = -2//当前节点进入等待队列中static final int PROPAGATE = -3//表示下一次共享式同步状态获取将会无条件传播下去static final int INITIAL = 0;//初始状态 现在我们知道了节点的数据结构类型，并且每个节点拥有其前驱和后继节点，很显然这是一个双向队列。同样的我们可以用一段demo看一下。 12345678910111213141516171819public class LockDemo { private static ReentrantLock lock = new ReentrantLock(); public static void main(String[] args) { for (int i = 0; i &lt; 5; i++) { Thread thread = new Thread(() -&gt; { lock.lock(); try { Thread.sleep(10000); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }); thread.start(); } }} 实例代码中开启了5个线程，先获取锁之后再睡眠10S中，实际上这里让线程睡眠是想模拟出当线程无法获取锁时进入同步队列的情况。通过debug，当Thread-4（在本例中最后一个线程）获取锁失败后进入同步时，AQS时现在的同步队列如图所示： Thread-0先获得锁后进行睡眠，其他线程（Thread-1,Thread-2,Thread-3,Thread-4）获取锁失败进入同步队列，同时也可以很清楚的看出来每个节点有两个域：prev(前驱)和next(后继)，并且每个节点用来保存获取同步状态失败的线程引用以及等待状态等信息。另外AQS中有两个重要的成员变量： 12private transient volatile Node head;private transient volatile Node tail; 也就是说AQS实际上通过头尾指针来管理同步队列，同时实现包括获取锁失败的线程进行入队，释放锁时对同步队列中的线程进行通知等核心方法。其示意图如下： 通过对源码的理解以及做实验的方式，现在我们可以清楚的知道这样几点： 节点的数据结构，即AQS的静态内部类Node,节点的等待状态等信息； 同步队列是一个双向队列，AQS通过持有头尾指针管理同步队列； 那么，节点如何进行入队和出队是怎样做的了？实际上这对应着锁的获取和释放两个操作：获取锁失败进行入队操作，获取锁成功进行出队操作。 独占锁独占锁的获取（acquire方法）我们继续通过看源码和debug的方式来看，还是以上面的demo为例，调用lock()方法是获取独占式锁，获取失败就将当前线程加入同步队列，成功则线程执行。而lock()方法实际上会调用AQS的acquire()方法，源码如下 1234567public final void acquire(int arg) { //先看同步状态是否获取成功，如果成功则方法结束返回 //若失败则先调用addWaiter()方法再调用acquireQueued()方法 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 关键信息请看注释，acquire根据当前获得同步状态成功与否做了两件事情：1. 成功，则方法结束返回，2. 失败，则先调用addWaiter()然后在调用acquireQueued()方法。 获取同步状态失败，入队操作当线程获取独占式锁失败后就会将当前线程加入同步队列，那么加入队列的方式是怎样的了？我们接下来就应该去研究一下addWaiter()和acquireQueued()。addWaiter()源码如下： 123456789101112131415161718private Node addWaiter(Node mode) { // 1. 将当前线程构建成Node类型 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 2. 当前尾节点是否为null Node pred = tail; if (pred != null) { // 2.2 将当前节点尾插入的方式插入同步队列中 node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } // 2.1. 当前同步队列尾节点为null，说明当前线程是第一个加入同步队列进行等待的线程 enq(node); return node;} 分析可以看上面的注释。程序的逻辑主要分为两个部分：1. 当前同步队列的尾节点为null，调用方法enq()插入;2. 当前队列的尾节点不为null，则采用尾插入（compareAndSetTail（）方法）的方式入队。另外还会有另外一个问题：如果 if (compareAndSetTail(pred, node))为false怎么办？会继续执行到enq()方法，同时很明显compareAndSetTail是一个CAS操作，通常来说如果CAS操作失败会继续自旋（死循环）进行重试。因此，经过我们这样的分析，enq()方法可能承担两个任务：1. 处理当前同步队列尾节点为null时进行入队操作；2. 如果CAS尾插入节点失败后负责自旋进行尝试。那么是不是真的就像我们分析的一样了？只有源码会告诉我们答案，enq()源码如下： 1234567891011121314151617private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize //1. 构造头结点 if (compareAndSetHead(new Node())) tail = head; } else { // 2. 尾插入，CAS操作失败自旋尝试 node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } }} 在上面的分析中我们可以看出在第1步中会先创建头结点，说明同步队列是带头结点的链式存储结构。带头结点与不带头结点相比，会在入队和出队的操作中获得更大的便捷性，因此同步队列选择了带头结点的链式存储结构。那么带头节点的队列初始化时机是什么？自然而然是在tail为null时，即当前线程是第一次插入同步队列。compareAndSetTail(t, node)方法会利用CAS操作设置尾节点，如果CAS操作失败会在for (;;)for死循环中不断尝试，直至成功return返回为止。因此，对enq()方法可以做这样的总结： 在当前线程是第一个加入同步队列时，调用compareAndSetHead(new Node())方法，完成链式队列的头结点的初始化； 自旋不断尝试CAS尾插入节点直至成功为止。 现在我们已经很清楚获取独占式锁失败的线程包装成Node然后插入同步队列的过程了？那么紧接着会有下一个问题？在同步队列中的节点（线程）会做什么事情来保证自己能够有机会获得独占式锁了？带着这样的问题我们就来看看acquireQueued()方法，从方法名就可以很清楚，这个方法的作用就是排队获取锁的过程，源码如下： 123456789101112131415161718192021222324252627final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { // 1. 获得当前节点的先驱节点 final Node p = node.predecessor(); // 2. 当前节点能否获取独占式锁 // 2.1 如果当前节点的先驱节点是头结点并且成功获取同步状态，即可以获得独占式锁 if (p == head &amp;&amp; tryAcquire(arg)) { //队列头指针用指向当前节点 setHead(node); //释放前驱节点 p.next = null; // help GC failed = false; return interrupted; } // 2.2 获取锁失败，线程进入等待状态等待获取独占式锁 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }} 程序逻辑通过注释已经标出，整体来看这又是一个自旋的过程（for (;;)for循环），代码首先获取当前节点的先驱节点，如果先驱节点是头结点的并且成功获得同步状态的时候（if (p == head &amp;&amp; tryAcquire(arg))），当前节点所指向的线程能够获取锁。反之，获取锁失败进入等待状态。整体示意图为下图： 获取锁成功，出队操作获取锁的节点出队的逻辑是： 123456//队列头结点引用指向当前节点setHead(node);//释放前驱节点p.next = null; // help GCfailed = false;return interrupted; setHead()方法为： 12345private void setHead(Node node) { head = node; node.thread = null; node.prev = null;} 将当前节点通过setHead()方法设置为队列的头结点，然后将之前的头结点的next域设置为null并且pre域也为null，即与队列断开，无任何引用方便GC时能够将内存进行回收。示意图如下： 那么当获取锁失败的时候会调用shouldParkAfterFailedAcquire()方法和parkAndCheckInterrupt()方法，看看他们做了什么事情。shouldParkAfterFailedAcquire()方法源码为： 123456789101112131415161718192021222324252627private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false;} shouldParkAfterFailedAcquire()方法主要逻辑是使用compareAndSetWaitStatus(pred, ws, Node.SIGNAL)使用CAS将节点状态由INITIAL设置成SIGNAL，表示当前线程阻塞。当compareAndSetWaitStatus设置失败则说明shouldParkAfterFailedAcquire方法返回false，然后会在acquireQueued()方法中for (;;)死循环中会继续重试，直至compareAndSetWaitStatus设置节点状态位为SIGNAL时shouldParkAfterFailedAcquire返回true时才会执行方法parkAndCheckInterrupt()方法，该方法的源码为： 12345private final boolean parkAndCheckInterrupt() { //使得该线程阻塞 LockSupport.park(this); return Thread.interrupted();} 该方法的关键是会调用LookSupport.park()方法（关于LookSupport会在以后的文章进行讨论），该方法是用来阻塞当前线程的。因此到这里就应该清楚了，acquireQueued()在自旋过程中主要完成了两件事情： 如果当前节点的前驱节点是头节点，并且能够获得同步状态的话，当前线程能够获得锁该方法执行结束退出； 获取锁失败的话，先将节点状态设置成SIGNAL，然后调用LookSupport.park方法使得当前线程阻塞。 经过上面的分析，独占式锁的获取过程也就是acquire()方法的执行流程如下图所示： 独占锁的释放（release()方法）独占锁的释放就相对来说比较容易理解了，废话不多说先来看下源码： 123456789public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;} 这段代码逻辑就比较容易理解了，如果同步状态释放成功（tryRelease返回true）则会执行if块中的代码，当head指向的头结点不为null，并且该节点的状态值不为0的话才会执行unparkSuccessor()方法。unparkSuccessor方法源码： 1234567891011121314151617181920212223242526272829private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ //头节点的后继节点 Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) //后继节点不为null时唤醒该线程 LockSupport.unpark(s.thread);} 源码的关键信息请看注释，首先获取头节点的后继节点，当后继节点的时候会调用LookSupport.unpark()方法，该方法会唤醒该节点的后继节点所包装的线程。因此，每一次锁释放后就会唤醒队列中该节点的后继节点所引用的线程，从而进一步可以佐证获得锁的过程是一个FIFO（先进先出）的过程。 到现在我们终于啃下了一块硬骨头了，通过学习源码的方式非常深刻的学习到了独占式锁的获取和释放的过程以及同步队列。可以做一下总结： 线程获取锁失败，线程被封装成Node进行入队操作，核心方法在于addWaiter()和enq()，同时enq()完成对同步队列的头结点初始化工作以及CAS操作失败的重试; 线程获取锁是一个自旋的过程，当且仅当 当前节点的前驱节点是头结点并且成功获得同步状态时，节点出队即该节点引用的线程获得锁，否则，当不满足条件时就会调用LookSupport.park()方法使得线程阻塞； 释放锁的时候会唤醒后继节点； 总体来说：在获取同步状态时，AQS维护一个同步队列，获取同步状态失败的线程会加入到队列中进行自旋；移除队列（或停止自旋）的条件是前驱节点是头结点并且成功获得了同步状态。在释放同步状态时，同步器会调用unparkSuccessor()方法唤醒后继节点。 独占锁特性学习可中断式获取锁（acquireInterruptibly方法）我们知道lock相较于synchronized有一些更方便的特性，比如能响应中断以及超时等待等特性，现在我们依旧采用通过学习源码的方式来看看能够响应中断是怎么实现的。可响应中断式锁可调用方法lock.lockInterruptibly()；而该方法其底层会调用AQS的acquireInterruptibly方法，源码为： 12345678public final void acquireInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) //线程获取锁失败 doAcquireInterruptibly(arg);} 在获取同步状态失败后就会调用doAcquireInterruptibly方法： 12345678910111213141516171819202122232425private void doAcquireInterruptibly(int arg) throws InterruptedException { //将节点插入到同步队列中 final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); //获取锁出队 if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) //线程中断抛异常 throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); }} 关键信息请看注释，现在看这段代码就很轻松了吧，与acquire方法逻辑几乎一致，唯一的区别是当parkAndCheckInterrupt返回true时，即线程阻塞时该线程被中断，代码抛出被中断异常。 超时等待式获取锁（tryAcquireNanos()方法）通过调用lock.tryLock(timeout,TimeUnit)方式达到超时等待获取锁的效果，该方法会在三种情况下才会返回： 在超时时间内，当前线程成功获取了锁； 当前线程在超时时间内被中断； 超时时间结束，仍未获得锁返回false。 我们仍然通过采取阅读源码的方式来学习底层具体是怎么实现的，该方法会调用AQS的方法tryAcquireNanos()，源码为： 12345678public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || //实现超时等待的效果 doAcquireNanos(arg, nanosTimeout);} 很显然这段源码最终是靠doAcquireNanos方法实现超时等待的效果，该方法源码如下： 123456789101112131415161718192021222324252627282930313233343536private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (nanosTimeout &lt;= 0L) return false; //1. 根据超时时间和当前时间计算出截止时间 final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); //2. 当前线程获得锁出队列 if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return true; } // 3.1 重新计算超时时间 nanosTimeout = deadline - System.nanoTime(); // 3.2 已经超时返回false if (nanosTimeout &lt;= 0L) return false; // 3.3 线程阻塞等待 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); // 3.4 线程被中断抛出被中断异常 if (Thread.interrupted()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); }} 程序逻辑如图所示： 程序逻辑同独占锁可响应中断式获取基本一致，唯一的不同在于获取锁失败后，对超时时间的处理上，在第1步会先计算出按照现在时间和超时时间计算出理论上的截止时间，比如当前时间是8h10min，超时时间是10min，那么根据deadline = System.nanoTime() + nanosTimeout计算出刚好达到超时时间时的系统时间就是8h 10min+10min = 8h 20min。然后根据deadline - System.nanoTime()就可以判断是否已经超时了，比如，当前系统时间是8h 30min很明显已经超过了理论上的系统时间8h 20min，deadline - System.nanoTime()计算出来就是一个负数，自然而然会在3.2步中的If判断之间返回false。如果还没有超时即3.2步中的if判断为true时就会继续执行3.3步通过LockSupport.parkNanos使得当前线程阻塞，同时在3.4步增加了对中断的检测，若检测出被中断直接抛出被中断异常。 共享锁共享锁的获取（acquireShared()方法）在聊完AQS对独占锁的实现后，我们继续一鼓作气的来看看共享锁是怎样实现的？共享锁的获取方法为acquireShared，源码为： 1234public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);} 这段源码的逻辑很容易理解，在该方法中会首先调用tryAcquireShared方法，tryAcquireShared返回值是一个int类型，当返回值为大于等于0的时候方法结束说明获得成功获取锁，否则，表明获取同步状态失败即所引用的线程获取锁失败，会执行doAcquireShared方法，该方法的源码为： 12345678910111213141516171819202122232425262728private void doAcquireShared(int arg) { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); if (r &gt;= 0) { // 当该节点的前驱节点是头结点且成功获取同步状态 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }} 现在来看这段代码会不会很容易了？逻辑几乎和独占式锁的获取一模一样，这里的自旋过程中能够退出的条件是当前节点的前驱节点是头结点并且tryAcquireShared(arg)返回值大于等于0即能成功获得同步状态。 共享锁的释放（releaseShared()方法）共享锁的释放在AQS中会调用方法releaseShared： 1234567public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false;} 当成功释放同步状态之后即tryReleaseShared会继续执行doReleaseShared方法： 1234567891011121314151617181920212223242526272829private void doReleaseShared() { /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) { Node h = head; if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); } else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } if (h == head) // loop if head changed break; }} 这段方法跟独占式锁释放过程有点点不同，在共享式锁的释放过程中，对于能够支持多个线程同时访问的并发组件，必须保证多个线程能够安全的释放同步状态，这里采用的CAS保证，当CAS操作失败continue，在下一次循环中进行重试。 可中断（acquireSharedInterruptibly()方法），超时等待（tryAcquireSharedNanos()方法）关于可中断锁以及超时等待的特性其实现和独占式锁可中断获取锁以及超时等待的实现几乎一致，具体的就不再说了，如果理解了上面的内容对这部分的理解也是水到渠成的。 通过这篇，加深了对AQS的底层实现更加清楚了，也对了解并发组件的实现原理打下了基础，学无止境，继续加油。 参考文献 《Java并发编程的艺术》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3AbstractQueuedSynchronizer-AQS/"},{"title":"并发编程-弄懂生产者和消费者问题","text":"生产者-消费者模式是一个十分经典的多线程并发协作的模式，弄懂生产者-消费者问题能够让我们对并发编程的理解加深。所谓生产者-消费者问题，实际上主要是包含了两类线程，一种是生产者线程用于生产数据，另一种是消费者线程用于消费数据，为了解耦生产者和消费者的关系，通常会有一个共享的数据区域，就像是一个仓库，生产者生产数据之后直接放置在共享数据区中，并不需要关心消费者的行为；而消费者只需要从共享数据区中去获取数据，就不再需要关心生产者的行为。 但是，这个共享数据区域中应该具备这样的线程间并发协作的功能： 如果共享数据区已满的话，阻塞生产者继续生产数据放置入内； 如果共享数据区为空的话，阻塞消费者继续消费数据； 在实现生产者消费者问题时，可以采用三种方式： 使用Object的wait/notify的消息通知机制； 使用Lock的Condition的await/signal的消息通知机制； 使用BlockingQueue实现。 本文主要将这三种实现方式进行总结归纳。 wait/notify的消息通知机制预备知识Java 中，可以通过配合调用 Object 对象的 wait() 方法和 notify()方法或 notifyAll() 方法来实现线程间的通信。在线程中调用 wait() 方法，将阻塞当前线程，直至等到其他线程调用了 notify() 方法或 notifyAll() 方法进行通知之后，当前线程才能从wait()方法出返回，继续执行下面的操作。 wait 该方法用来将当前线程置入休眠状态，直到接到通知或被中断为止。在调用 wait()之前，线程必须要获得该对象的对象监视器锁，即只能在同步方法或同步块中调用 wait()方法。调用wait()方法之后，当前线程会释放锁。如果调用wait()方法时，线程并未获取到锁的话，则会抛出IllegalMonitorStateException异常，这是以个RuntimeException。如果再次获取到锁的话，当前线程才能从wait()方法处成功返回。 notify 该方法也要在同步方法或同步块中调用，即在调用前，线程也必须要获得该对象的对象级别锁，如果调用 notify()时没有持有适当的锁，也会抛出 IllegalMonitorStateException。该方法任意从WAITTING状态的线程中挑选一个进行通知，使得调用wait()方法的线程从等待队列移入到同步队列中，等待有机会再一次获取到锁，从而使得调用wait()方法的线程能够从wait()方法处退出。调用notify后，当前线程不会马上释放该对象锁，要等到程序退出同步块后，当前线程才会释放锁。 notifyAll该方法与 notify ()方法的工作方式相同，重要的一点差异是：notifyAll 使所有原来在该对象上 wait 的线程统统退出WAITTING状态，使得他们全部从等待队列中移入到同步队列中去，等待下一次能够有机会获取到对象监视器锁。 wait/notify消息通知潜在的一些问题notify过早通知notify 通知的遗漏很容易理解，即 threadA 还没开始 wait 的时候，threadB 已经 notify 了，这样，threadB 通知是没有任何响应的，当 threadB 退出 synchronized 代码块后，threadA 再开始 wait，便会一直阻塞等待，直到被别的线程打断。比如在下面的示例代码中，就模拟出notify早期通知带来的问题： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class EarlyNotifyDemo1 { private static String lockObject = &quot;&quot;; public static void main(String[] args) { WaitThread waitThread = new WaitThread(lockObject); NotifyThread notifyThread = new NotifyThread(lockObject); notifyThread.start(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } waitThread.start(); } static class WaitThread extends Thread { private String lock; public WaitThread(String lock) { this.lock = lock; } @Override public void run() { synchronized (lock) { try { System.out.println(Thread.currentThread().getName() + &quot; 进去代码块&quot;); System.out.println(Thread.currentThread().getName() + &quot; 开始wait&quot;); lock.wait(); System.out.println(Thread.currentThread().getName() + &quot; 结束wait&quot;); } catch (InterruptedException e) { e.printStackTrace(); } } } } static class NotifyThread extends Thread { private String lock; public NotifyThread(String lock) { this.lock = lock; } @Override public void run() { synchronized (lock) { System.out.println(Thread.currentThread().getName() + &quot; 进去代码块&quot;); System.out.println(Thread.currentThread().getName() + &quot; 开始notify&quot;); lock.notify(); System.out.println(Thread.currentThread().getName() + &quot; 结束开始notify&quot;); } } }} 输出结果 12345Thread-1 进去代码块Thread-1 开始notifyThread-1 结束开始notifyThread-0 进去代码块Thread-0 开始wait 示例中开启了两个线程，一个是WaitThread，另一个是NotifyThread。NotifyThread会先启动，先调用notify方法。然后WaitThread线程才启动，调用wait方法，但是由于通知过了，wait方法就无法再获取到相应的通知，因此WaitThread会一直在wait方法出阻塞，这种现象就是通知过早的现象。针对这种现象，解决方法，一般是添加一个状态标志，让waitThread调用wait方法前先判断状态是否已经改变了没，如果通知早已发出的话，WaitThread就不再去wait。对上面的代码进行更正： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class EarlyNotifyDemo2 { private static String lockObject = &quot;&quot;; private static boolean isWait = true; public static void main(String[] args) { WaitThread waitThread = new WaitThread(lockObject); NotifyThread notifyThread = new NotifyThread(lockObject); notifyThread.start(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } waitThread.start(); } static class WaitThread extends Thread { private String lock; public WaitThread(String lock) { this.lock = lock; } @Override public void run() { synchronized (lock) { try { while (isWait) { System.out.println(Thread.currentThread().getName() + &quot; 进去代码块&quot;); System.out.println(Thread.currentThread().getName() + &quot; 开始wait&quot;); lock.wait(); System.out.println(Thread.currentThread().getName() + &quot; 结束wait&quot;); } } catch (InterruptedException e) { e.printStackTrace(); } } } } static class NotifyThread extends Thread { private String lock; public NotifyThread(String lock) { this.lock = lock; } @Override public void run() { synchronized (lock) { System.out.println(Thread.currentThread().getName() + &quot; 进去代码块&quot;); System.out.println(Thread.currentThread().getName() + &quot; 开始notify&quot;); lock.notifyAll(); isWait = false; System.out.println(Thread.currentThread().getName() + &quot; 结束开始notify&quot;); } } }} 这段代码只是增加了一个isWait状态变量，NotifyThread调用notify方法后会对状态变量进行更新，在WaitThread中调用wait方法之前会先对状态变量进行判断，在该示例中，调用notify后将状态变量isWait改变为false，因此，在WaitThread中while对isWait判断后就不会执行wait方法，从而避免了Notify过早通知造成遗漏的情况。 总结：在使用线程的等待/通知机制时，一般都要配合一个 boolean 变量值（或者其他能够判断真假的条件），在 notify 之前改变该 boolean 变量的值，让 wait 返回后能够退出 while 循环（一般都要在 wait 方法外围加一层 while 循环，以防止早期通知），或在通知被遗漏后，不会被阻塞在 wait 方法处。这样便保证了程序的正确性 等待wait的条件发生变化如果线程在等待时接受到了通知，但是之后等待的条件发生了变化，并没有再次对等待条件进行判断，也会导致程序出现错误。 下面用一个例子来说明这种情况 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ConditionChangeDemo1 { private static List&lt;String&gt; lockObject = new ArrayList(); public static void main(String[] args) { Consumer consumer1 = new Consumer(lockObject); Consumer consumer2 = new Consumer(lockObject); Productor productor = new Productor(lockObject); consumer1.start(); consumer2.start(); productor.start(); } static class Consumer extends Thread { private List&lt;String&gt; lock; public Consumer(List lock) { this.lock = lock; } @Override public void run() { synchronized (lock) { try { //这里使用if的话，就会存在wait条件变化造成程序错误的问题 if (lock.isEmpty()) { System.out.println(Thread.currentThread().getName() + &quot; list为空&quot;); System.out.println(Thread.currentThread().getName() + &quot; 调用wait方法&quot;); lock.wait(); System.out.println(Thread.currentThread().getName() + &quot; wait方法结束&quot;); } String element = lock.remove(0); System.out.println(Thread.currentThread().getName() + &quot; 取出第一个元素为：&quot; + element); } catch (InterruptedException e) { e.printStackTrace(); } } } } static class Productor extends Thread { private List&lt;String&gt; lock; public Productor(List lock) { this.lock = lock; } @Override public void run() { synchronized (lock) { System.out.println(Thread.currentThread().getName() + &quot; 开始添加元素&quot;); lock.add(Thread.currentThread().getName()); lock.notifyAll(); } } }} 输出结果 123456Thread-0 list为空Thread-0 调用wait方法Thread-2 开始添加元素Thread-1 取出第一个元素为：Thread-2Thread-0 wait方法结束Exception in thread &quot;Thread-0&quot; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 异常原因分析：在这个例子中一共开启了3个线程，Consumer1,Consumer2以及Productor。首先Consumer1调用了wait方法后，线程处于了WAITTING状态，并且将对象锁释放出来。因此，Consumer2能够获取对象锁，从而进入到同步代块中，当执行到wait方法时，同样的也会释放对象锁。因此，productor能够获取到对象锁，进入到同步代码块中，向list中插入数据后，通过notifyAll方法通知处于WAITING状态的Consumer1和Consumer2线程。consumer1得到对象锁后，从wait方法出退出，删除了一个元素让List为空，方法执行结束，退出同步块，释放掉对象锁。这个时候Consumer2获取到对象锁后，从wait方法退出，继续往下执行，这个时候Consumer2再执行lock.remove(0);就会出错，因为List由于Consumer1删除一个元素之后已经为空了。 解决方案：通过上面的分析，可以看出Consumer2报异常是因为线程从wait方法退出之后没有再次对wait条件进行判断，因此，此时的wait条件已经发生了变化。解决办法就是，在wait退出之后再对条件进行判断即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class ConditionChangeDemo2 { private static List&lt;String&gt; lockObject = new ArrayList(); public static void main(String[] args) { Consumer consumer1 = new Consumer(lockObject); Consumer consumer2 = new Consumer(lockObject); Productor productor = new Productor(lockObject); consumer1.start(); consumer2.start(); productor.start(); } static class Consumer extends Thread { private List&lt;String&gt; lock; public Consumer(List lock) { this.lock = lock; } @Override public void run() { synchronized (lock) { try { //这里使用if的话，就会存在wait条件变化造成程序错误的问题 while (lock.isEmpty()) { System.out.println(Thread.currentThread().getName() + &quot; list为空&quot;); System.out.println(Thread.currentThread().getName() + &quot; 调用wait方法&quot;); lock.wait(); System.out.println(Thread.currentThread().getName() + &quot; wait方法结束&quot;); } String element = lock.remove(0); System.out.println(Thread.currentThread().getName() + &quot; 取出第一个元素为：&quot; + element); } catch (InterruptedException e) { e.printStackTrace(); } } } } static class Productor extends Thread { private List&lt;String&gt; lock; public Productor(List lock) { this.lock = lock; } @Override public void run() { synchronized (lock) { System.out.println(Thread.currentThread().getName() + &quot; 开始添加元素&quot;); lock.add(Thread.currentThread().getName()); lock.notifyAll(); } } }} 输出结果 1234567Thread-0 list为空Thread-0 调用wait方法Thread-2 开始添加元素Thread-1 取出第一个元素为：Thread-2Thread-0 wait方法结束Thread-0 list为空Thread-0 调用wait方法 上面的代码与之前的代码仅仅只是将 wait 外围的 if 语句改为 while 循环即可，这样当 list 为空时，线程便会继续等待，而不会继续去执行删除 list 中元素的代码。 总结：在使用线程的等待/通知机制时，一般都要在 while 循环中调用 wait()方法，因此配合使用一个 boolean 变量（或其他能判断真假的条件，如本文中的 list.isEmpty()），满足 while 循环的条件时，进入 while 循环，执行 wait()方法，不满足 while 循环的条件时，跳出循环，执行后面的代码。 假死状态现象：如果是多消费者和多生产者情况，如果使用notify方法可能会出现“假死”的情况，即唤醒的是同类线程。 原因分析：假设当前多个生产者线程会调用wait方法阻塞等待，当其中的生产者线程获取到对象锁之后使用notify通知处于WAITTING状态的线程，如果唤醒的仍然是生产者线程，就会造成所有的生产者线程都处于等待状态。 解决办法：将notify方法替换成notifyAll方法，如果使用的是lock的话，就将signal方法替换成signalAll方法。 总结在Object提供的消息通知机制应该遵循如下这些条件： 永远在while循环中对条件进行判断而不是if语句中进行wait条件的判断； 使用NotifyAll而不是使用notify。 基本的使用范式如下： 12345678// The standard idiom for calling the wait method in Java synchronized (sharedObject) { while (condition) { sharedObject.wait(); // (Releases lock, and reacquires on wakeup) } // do action based upon condition e.g. take or put into queue } wait/notifyAll实现生产者-消费者利用wait/notifyAll实现生产者和消费者代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class ProductorConsumerDemo1 { public static void main(String[] args) { LinkedList linkedList = new LinkedList(); ExecutorService service = Executors.newFixedThreadPool(15); for (int i = 0; i &lt; 5; i++) { service.submit(new Productor(linkedList, 8)); } for (int i = 0; i &lt; 10; i++) { service.submit(new Consumer(linkedList)); } } static class Productor implements Runnable { private List&lt;Integer&gt; list; private int maxLength; public Productor(List list, int maxLength) { this.list = list; this.maxLength = maxLength; } @Override public void run() { while (true) { synchronized (list) { try { while (list.size() == maxLength) { System.out.println(&quot;生产者&quot; + Thread.currentThread().getName() + &quot; list以达到最大容量，进行wait&quot;); list.wait(); System.out.println(&quot;生产者&quot; + Thread.currentThread().getName() + &quot; 退出wait&quot;); } Random random = new Random(); int i = random.nextInt(); System.out.println(&quot;生产者&quot; + Thread.currentThread().getName() + &quot; 生产数据&quot; + i); list.add(i); list.notifyAll(); Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } } } } } static class Consumer implements Runnable { private List&lt;Integer&gt; list; public Consumer(List list) { this.list = list; } @Override public void run() { while (true) { synchronized (list) { try { while (list.isEmpty()) { System.out.println(&quot;消费者&quot; + Thread.currentThread().getName() + &quot; list为空，进行wait&quot;); list.wait(); System.out.println(&quot;消费者&quot; + Thread.currentThread().getName() + &quot; 退出wait&quot;); } Integer element = list.remove(0); System.out.println(&quot;消费者&quot; + Thread.currentThread().getName() + &quot; 消费数据：&quot; + element); list.notifyAll(); Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } } } } }}12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182 输出结果 1234567891011121314151617181920212223242526272829生产者pool-1-thread-2 生产数据-703210513生产者pool-1-thread-2 生产数据-1025434820生产者pool-1-thread-2 生产数据70070412生产者pool-1-thread-2 生产数据-598504371生产者pool-1-thread-2 生产数据-716978999生产者pool-1-thread-2 生产数据-1175198461生产者pool-1-thread-2 生产数据-1212912406生产者pool-1-thread-2 生产数据-332467186生产者pool-1-thread-2 list以达到最大容量，进行wait消费者pool-1-thread-15 消费数据：-703210513消费者pool-1-thread-15 消费数据：-1025434820消费者pool-1-thread-15 消费数据：70070412消费者pool-1-thread-15 消费数据：-598504371消费者pool-1-thread-15 消费数据：-716978999消费者pool-1-thread-15 消费数据：-1175198461消费者pool-1-thread-15 消费数据：-1212912406消费者pool-1-thread-15 消费数据：-332467186消费者pool-1-thread-15 list为空，进行wait消费者pool-1-thread-14 list为空，进行wait消费者pool-1-thread-13 list为空，进行wait消费者pool-1-thread-11 list为空，进行wait消费者pool-1-thread-12 list为空，进行wait消费者pool-1-thread-10 list为空，进行wait消费者pool-1-thread-9 list为空，进行wait消费者pool-1-thread-8 list为空，进行wait消费者pool-1-thread-7 list为空，进行wait消费者pool-1-thread-6 list为空，进行wait生产者pool-1-thread-5 生产数据84590545生产者pool-1-thread-5 生产数据-1631754695 使用Lock中Condition的await/signalAll实现生产者-消费者参照Object的wait和notify/notifyAll方法，Condition也提供了同样的方法： 针对wait方法void await() throws InterruptedException：当前线程进入等待状态，如果其他线程调用condition的signal或者signalAll方法并且当前线程获取Lock从await方法返回，如果在等待状态中被中断会抛出被中断异常； long awaitNanos(long nanosTimeout)：当前线程进入等待状态直到被通知，中断或者超时； boolean await(long time, TimeUnit unit)throws InterruptedException：同第二种，支持自定义时间单位 boolean awaitUntil(Date deadline) throws InterruptedException：当前线程进入等待状态直到被通知，中断或者到了某个时间 针对notify方法void signal()：唤醒一个等待在condition上的线程，将该线程从等待队列中转移到同步队列中，如果在同步队列中能够竞争到Lock则可以从等待方法中返回。 void signalAll()：与signal的区别在于能够唤醒所有等待在condition上的线程 也就是说wait—&gt;await，notify—-&gt;Signal。另外，关于lock中condition消息通知的原理解析可以看这篇文章。 如果采用lock中Conditon的消息通知原理来实现生产者-消费者问题，原理同使用wait/notifyAll一样。直接上代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class ProductorConsumerDemo2 { private static ReentrantLock lock = new ReentrantLock(); private static Condition full = lock.newCondition(); private static Condition empty = lock.newCondition(); public static void main(String[] args) { LinkedList linkedList = new LinkedList(); ExecutorService service = Executors.newFixedThreadPool(15); for (int i = 0; i &lt; 5; i++) { service.submit(new Productor(linkedList, 8, lock)); } for (int i = 0; i &lt; 10; i++) { service.submit(new Consumer(linkedList, lock)); } } static class Productor implements Runnable { private List&lt;Integer&gt; list; private int maxLength; private Lock lock; public Productor(List list, int maxLength, Lock lock) { this.list = list; this.maxLength = maxLength; this.lock = lock; } @Override public void run() { while (true) { lock.lock(); try { while (list.size() == maxLength) { System.out.println(&quot;生产者&quot; + Thread.currentThread().getName() + &quot; list以达到最大容量，进行wait&quot;); full.await(); System.out.println(&quot;生产者&quot; + Thread.currentThread().getName() + &quot; 退出wait&quot;); } Random random = new Random(); int i = random.nextInt(); System.out.println(&quot;生产者&quot; + Thread.currentThread().getName() + &quot; 生产数据&quot; + i); list.add(i); empty.signalAll(); Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } } } static class Consumer implements Runnable { private List&lt;Integer&gt; list; private Lock lock; public Consumer(List list, Lock lock) { this.list = list; this.lock = lock; } @Override public void run() { while (true) { lock.lock(); try { while (list.isEmpty()) { System.out.println(&quot;消费者&quot; + Thread.currentThread().getName() + &quot; list为空，进行wait&quot;); empty.await(); System.out.println(&quot;消费者&quot; + Thread.currentThread().getName() + &quot; 退出wait&quot;); } Integer element = list.remove(0); System.out.println(&quot;消费者&quot; + Thread.currentThread().getName() + &quot; 消费数据：&quot; + element); full.signalAll(); Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } } }} 输出结果 12345678910111213141516171819202122232425262728293031323334生产者pool-1-thread-1 生产数据-1633842993生产者pool-1-thread-1 生产数据1337251950生产者pool-1-thread-1 生产数据1310879631生产者pool-1-thread-1 生产数据-214297115生产者pool-1-thread-1 生产数据738937512生产者pool-1-thread-1 生产数据13060041生产者pool-1-thread-1 生产数据-957049554生产者pool-1-thread-1 生产数据-1062017880生产者pool-1-thread-1 list以达到最大容量，进行wait生产者pool-1-thread-2 list以达到最大容量，进行wait生产者pool-1-thread-3 list以达到最大容量，进行wait生产者pool-1-thread-4 list以达到最大容量，进行wait生产者pool-1-thread-5 list以达到最大容量，进行wait消费者pool-1-thread-6 消费数据：-1633842993消费者pool-1-thread-6 消费数据：1337251950消费者pool-1-thread-6 消费数据：1310879631消费者pool-1-thread-6 消费数据：-214297115消费者pool-1-thread-6 消费数据：738937512消费者pool-1-thread-6 消费数据：13060041消费者pool-1-thread-6 消费数据：-957049554消费者pool-1-thread-6 消费数据：-1062017880消费者pool-1-thread-6 list为空，进行wait消费者pool-1-thread-7 list为空，进行wait消费者pool-1-thread-8 list为空，进行wait消费者pool-1-thread-9 list为空，进行wait消费者pool-1-thread-10 list为空，进行wait消费者pool-1-thread-11 list为空，进行wait消费者pool-1-thread-12 list为空，进行wait消费者pool-1-thread-13 list为空，进行wait消费者pool-1-thread-14 list为空，进行wait消费者pool-1-thread-15 list为空，进行wait生产者pool-1-thread-1 退出wait生产者pool-1-thread-1 生产数据1949864858生产者pool-1-thread-1 生产数据-1693880970 使用BlockingQueue实现生产者-消费者由于BlockingQueue内部实现就附加了两个阻塞操作。即当队列已满时，阻塞向队列中插入数据的线程，直至队列中未满；当队列为空时，阻塞从队列中获取数据的线程，直至队列非空时为止。关于BlockingQueue更多细节可以看这篇文章。可以利用BlockingQueue实现生产者-消费者为题，阻塞队列完全可以充当共享数据区域，就可以很好的完成生产者和消费者线程之间的协作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class ProductorConsumerDmoe3 { private static LinkedBlockingQueue&lt;Integer&gt; queue = new LinkedBlockingQueue&lt;&gt;(); public static void main(String[] args) { ExecutorService service = Executors.newFixedThreadPool(15); for (int i = 0; i &lt; 5; i++) { service.submit(new Productor(queue)); } for (int i = 0; i &lt; 10; i++) { service.submit(new Consumer(queue)); } } static class Productor implements Runnable { private BlockingQueue queue; public Productor(BlockingQueue queue) { this.queue = queue; } @Override public void run() { try { while (true) { Random random = new Random(); int i = random.nextInt(); System.out.println(&quot;生产者&quot; + Thread.currentThread().getName() + &quot;生产数据&quot; + i); queue.put(i); Thread.sleep(1000); } } catch (InterruptedException e) { e.printStackTrace(); } } } static class Consumer implements Runnable { private BlockingQueue queue; public Consumer(BlockingQueue queue) { this.queue = queue; } @Override public void run() { try { while (true) { Integer element = (Integer) queue.take(); System.out.println(&quot;消费者&quot; + Thread.currentThread().getName() + &quot;正在消费数据&quot; + element); Thread.sleep(1000); } } catch (InterruptedException e) { e.printStackTrace(); } } }} 输出结果 1234567891011121314151617181920生产者pool-1-thread-2生产数据-1056722868生产者pool-1-thread-1生产数据-1217947426生产者pool-1-thread-3生产数据590686437生产者pool-1-thread-4生产数据1782376429生产者pool-1-thread-5生产数据1558897279消费者pool-1-thread-6正在消费数据-1056722868消费者pool-1-thread-7正在消费数据-1217947426消费者pool-1-thread-8正在消费数据590686437消费者pool-1-thread-9正在消费数据1782376429消费者pool-1-thread-10正在消费数据1558897279生产者pool-1-thread-4生产数据1977644261生产者pool-1-thread-3生产数据182370155消费者pool-1-thread-11正在消费数据1977644261生产者pool-1-thread-2生产数据949821636生产者pool-1-thread-5生产数据1931032717消费者pool-1-thread-13正在消费数据949821636生产者pool-1-thread-1生产数据873417555消费者pool-1-thread-14正在消费数据1931032717消费者pool-1-thread-12正在消费数据182370155消费者pool-1-thread-15正在消费数据873417555 可以看出，使用BlockingQueue来实现生产者-消费者很简洁，这正是利用了BlockingQueue插入和获取数据附加阻塞操作的特性。","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%BC%84%E6%87%82%E7%94%9F%E4%BA%A7%E8%80%85%E5%92%8C%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"title":"并发编程-线程池ThreadPoolExecutor实现原理介绍","text":"为什么要使用线程池在实际使用中，线程是很占用系统资源的，如果对线程管理不善很容易导致系统问题。因此，在大多数并发框架中都会使用线程池来管理线程，使用线程池管理线程主要有如下好处： 降低资源消耗。通过复用已存在的线程和降低线程关闭的次数来尽可能降低系统性能损耗； 提升系统响应速度。通过复用线程，省去创建线程的过程，因此整体上提升了系统的响应速度； 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，因此，需要使用线程池来管理线程。 线程池的工作原理当一个并发任务提交给线程池，线程池分配线程去执行任务的过程如下图所示： 从图可以看出，线程池执行所提交的任务过程主要有这样几个阶段： 先判断线程池中核心线程池所有的线程是否都在执行任务。如果不是，则新创建一个线程执行刚提交的任务，否则，核心线程池中所有的线程都在执行任务，则进入第2步； 判断当前阻塞队列是否已满，如果未满，则将提交的任务放置在阻塞队列中；否则，则进入第3步； 判断线程池中所有的线程是否都在执行任务，如果没有，则创建一个新的线程来执行任务，否则，则交给饱和策略进行处理 线程池的创建创建线程池主要是ThreadPoolExecutor类来完成，ThreadPoolExecutor的有许多重载的构造方法，通过参数最多的构造方法来理解创建线程池有哪些需要配置的参数。ThreadPoolExecutor的构造方法为： 1234567ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 下面对参数进行说明： corePoolSize：表示核心线程池的大小。当提交一个任务时，如果当前核心线程池的线程个数没有达到corePoolSize，即使当前核心线程池有空闲的线程，也会创建新的线程来执行所提交的任务。如果当前核心线程池的线程个数已经达到了corePoolSize，则不再重新创建线程。如果调用了prestartCoreThread()或者 prestartAllCoreThreads()，线程池创建的时候所有的核心线程都会被创建并且启动。 maximumPoolSize：表示线程池能创建线程的最大个数。如果当阻塞队列已满时，并且当前线程池线程个数没有超过maximumPoolSize的话，就会创建新的线程来执行任务。 keepAliveTime：空闲线程存活时间。如果当前线程池的线程个数已经超过了corePoolSize，并且线程空闲时间超过了keepAliveTime的话，就会将这些空闲线程销毁，这样可以尽可能降低系统资源消耗。 unit：时间单位。为keepAliveTime指定时间单位。 workQueue：阻塞队列。用于保存任务的阻塞队列，关于阻塞队列可以看这篇文章。可以使用ArrayBlockingQueue, LinkedBlockingQueue, SynchronousQueue, PriorityBlockingQueue。 ArrayBlockingQueue：一个用数组实现的有界阻塞队列，按照先入先出(FIFO)的原则对元素进行排序。不保证线程公平访问队列，使用较少 LinkedBlockingQueue：一个用链表实现的有界阻塞队列，队列默认和最长长度为Integer.MAX_VALUE。队列按照先入先出的原则对元素进行排序，使用较多 吞吐量通常要高于 ArrayBlockingQueue Executors.newFixedThreadPool() 使用了这个队列 SynchronousQueue：不储存元素(无容量)的阻塞队列，每个put操作必须等待一个take操作，否则不能继续添加元素。支持公平访问队列，常用于生产者，消费者模型，吞吐量较高，使用较多 每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态 吞吐量通常要高于 LinkedBlockingQueue Executors.newCachedThreadPool使用了这个队列 PriorityBlockingQueue：支持优先级的无界阻塞队列，使用较少 threadFactory：创建线程的工厂类。可以通过指定线程工厂为每个创建出来的线程设置更有意义的名字，如果出现并发问题，也方便查找问题原因。 handler：饱和策略。当线程池的阻塞队列已满和指定的线程都已经开启，说明当前线程池已经处于饱和状态了，那么就需要采用一种策略来处理这种情况。采用的策略有这几种： AbortPolicy： 直接拒绝所提交的任务，并抛出RejectedExecutionException异常； CallerRunsPolicy：只用调用者所在的线程来执行任务； DiscardPolicy：不处理直接丢弃掉任务； DiscardOldestPolicy：丢弃掉阻塞队列中存放时间最久的任务，执行当前任务 自定义策略 线程池执行逻辑通过ThreadPoolExecutor创建线程池后，提交任务后执行过程是怎样的，下面来通过源码来看一看。execute方法源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); //如果线程池的线程个数少于corePoolSize则创建新线程执行当前任务 if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } //如果线程个数大于corePoolSize或者创建线程失败，则将任务存放在阻塞队列workQueue中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } //如果当前任务无法放进阻塞队列中，则创建新的线程来执行任务 else if (!addWorker(command, false)) reject(command);} ThreadPoolExecutor的execute方法执行逻辑请见注释。下图为ThreadPoolExecutor的execute方法的执行示意图： execute方法执行逻辑有这样几种情况： 如果当前运行的线程少于corePoolSize，则会创建新的线程来执行新的任务； 如果运行的线程个数等于或者大于corePoolSize，则会将提交的任务存放到阻塞队列workQueue中； 如果当前workQueue队列已满的话，则会创建新的线程来执行任务； 如果线程个数已经超过了maximumPoolSize，则会使用饱和策略RejectedExecutionHandler来进行处理。 需要注意的是，线程池的设计思想就是使用了核心线程池corePoolSize，阻塞队列workQueue和线程池线程最大个数maximumPoolSize，这样的缓存策略来处理任务，实际上这样的设计思想在需要框架中都会使用。 线程池的关闭关闭线程池，可以通过shutdown和shutdownNow这两个方法。它们的原理都是遍历线程池中所有的线程，然后依次中断线程。shutdown和shutdownNow还是有不一样的地方： shutdownNow首先将线程池的状态设置为STOP，然后尝试停止所有的正在执行和未执行任务的线程，并返回等待执行任务的列表； shutdown只是将线程池的状态设置为SHUTDOWN状态，然后中断所有没有正在执行任务的线程 可以看出shutdown方法会将正在执行的任务继续执行完，而shutdownNow会直接中断正在执行的任务。调用了这两个方法的任意一个，isShutdown方法都会返回true，当所有的线程都关闭成功，才表示线程池成功关闭，这时调用isTerminated方法才会返回true。 如何合理配置线程池参数？要想合理的配置线程池，就必须首先分析任务特性，可以从以下几个角度来进行分析： 任务的性质：CPU密集型任务，IO密集型任务和混合型任务。 任务的优先级：高，中和低。 任务的执行时间：长，中和短。 任务的依赖性：是否依赖其他系统资源，如数据库连接。 任务性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务配置尽可能少的线程数量，如配置CPU个数+1的线程数的线程池。IO密集型任务则由于需要等待IO操作，线程并不是一直在执行任务，则配置尽可能多的线程，如配置两倍CPU个数+1。混合型的任务，如果可以拆分，则将其拆分成一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐率要高于串行执行的吞吐率，如果这两个任务执行时间相差太大，则没必要进行分解。我们可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。 优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先得到执行，需要注意的是如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。 执行时间不同的任务可以交给不同规模的线程池来处理，或者也可以使用优先级队列，让执行时间短的任务先执行。 依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，如果等待的时间越长CPU空闲时间就越长，那么线程数应该设置越大，这样才能更好的利用CPU。 并且，阻塞队列最好是使用有界队列，如果采用无界队列的话，一旦任务积压在阻塞队列中的话就会占用过多的内存资源，甚至会使得系统崩溃。 当然具体合理线程池值大小，需要结合系统实际情况，在大量的尝试下比较才能得出，以上只是前人总结的规律。 最佳线程数目 = （（线程等待时间+线程CPU运行时间）/线程CPU运行时间 ）* CPU数目 比如平均每个线程CPU运行时间为0.5s，而线程等待时间（非CPU运行时间，比如IO）为1.5s，CPU核心数为8，那么根据上面这个公式估算得到：((1.5+0.5)/0.5)*8=32。这个公式进一步转化为： 最佳线程数目 = （线程等待时间与线程CPU运行时间之比 + 1）* CPU数目 可以得出一个结论：线程等待时间所占比例越高，需要越多线程。线程CPU运行时间所占比例越高，需要越少线程。以上公式与之前的CPU和IO密集型任务设置线程数基本吻合。 参考文献 《Java并发编程的艺术》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E7%BA%BF%E7%A8%8B%E6%B1%A0ThreadPoolExecutor%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/"},{"title":"并发编程-线程的状态和基本操作","text":"在上一篇文章中为什么要学习并发编程谈到了为什么花功夫去学习并发编程的技术，也就是说我们必须了解到并发编程的优缺点，我们在什么情况下可以去考虑开启多个线程去实现我们的业务，当然使用多线程我们应该着重注意一些什么，在上一篇文章中会有一些讨论。那么，说了这么多，无论是针对面试还是实际工作中作为一名软件开发人员都应该具备这样的技能。万事开头难，接下来就应该了解如何新建一个线程？线程状态是怎样转换的？关于线程状态的操作是怎样的？这篇文章就主要围绕这三个方面来聊一聊 新建线程一个java程序从main()方法开始执行，然后按照既定的代码逻辑执行，看似没有其他线程参与，但实际上java程序天生就是一个多线程程序，包含了：（1）分发处理发送给给JVM信号的线程；（2）调用对象的finalize方法的线程；（3）清除Reference的线程；（4）main线程，用户程序的入口。那么，如何在用户程序中新建一个线程呢？ 主要有三种方式创建线程和Executor框架创建线程池 创建线程方式继承Thread类步骤 定义一个Thread类的子类，重写run方法，将相关逻辑实现，run()方法就是线程要执行的业务逻辑方法 创建自定义的线程子类对象 调用子类实例的star()方法来启动线程 12345678910111213141516171819public class MyThread extends Thread { @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot; run()方法正在执行...&quot;); }}public class TheadTest { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); System.out.println(Thread.currentThread().getName() + &quot; main()方法执行结束&quot;); }} 运行结果 12main main()方法执行结束Thread-0 run()方法正在执行... 实现Runnable接口步骤 定义Runnable接口实现类MyRunnable，并重写run()方法 创建MyRunnable实例myRunnable，以myRunnable作为target创建Thead对象，该Thread对象才是真正的线程对象 调用线程对象的start()方法 1234567891011121314151617181920public class MyRunnable implements Runnable { @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot; run()方法执行中...&quot;); }}public class RunnableTest { public static void main(String[] args) { MyRunnable myRunnable = new MyRunnable(); Thread thread = new Thread(myRunnable); thread.start(); System.out.println(Thread.currentThread().getName() + &quot; main()方法执行完成&quot;); }} 执行结果 12main main()方法执行完成Thread-0 run()方法执行中... 实现Callable接口步骤 创建实现Callable接口的类myCallable 以myCallable为参数创建FutureTask对象 将FutureTask作为参数创建Thread对象 调用线程对象的start()方法 123456789101112131415161718192021222324252627282930public class MyCallable implements Callable&lt;Integer&gt; { @Override public Integer call() { System.out.println(Thread.currentThread().getName() + &quot; call()方法执行中...&quot;); return 1; }}public class CallableTest { public static void main(String[] args) { FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new MyCallable()); Thread thread = new Thread(futureTask); thread.start(); try { Thread.sleep(1000); System.out.println(&quot;返回结果 &quot; + futureTask.get()); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + &quot; main()方法执行完成&quot;); }} 执行结果 123Thread-0 call()方法执行中...返回结果 1main main()方法执行完成 使用Executor框架创建线程池Executors提供了一系列工厂方法用于创先线程池，返回的线程池都实现了ExecutorService接口。 主要有newFixedThreadPool，newCachedThreadPool，newSingleThreadExecutor，newScheduledThreadPool，后续详细介绍这四种线程池 123456789101112131415161718192021222324public class MyRunnable implements Runnable { @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot; run()方法执行中...&quot;); }}public class SingleThreadExecutorTest { public static void main(String[] args) { ExecutorService executorService = Executors.newSingleThreadExecutor(); MyRunnable runnableTest = new MyRunnable(); for (int i = 0; i &lt; 5; i++) { executorService.execute(runnableTest); } System.out.println(&quot;线程任务开始执行&quot;); executorService.shutdown(); }} 执行结果 123456线程任务开始执行pool-1-thread-1 is running...pool-1-thread-1 is running...pool-1-thread-1 is running...pool-1-thread-1 is running...pool-1-thread-1 is running... 三种标准方式合在一起如下： 12345678910111213141516171819202122232425262728293031323334353637public class CreateThreadDemo { public static void main(String[] args) { //1.继承Thread Thread thread = new Thread() { @Override public void run() { System.out.println(&quot;继承Thread&quot;); super.run(); } }; thread.start(); //2.实现runable接口 Thread thread1 = new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;实现runable接口&quot;); } }); thread1.start(); //3.实现callable接口 ExecutorService service = Executors.newSingleThreadExecutor(); Future&lt;String&gt; future = service.submit(new Callable() { @Override public String call() throws Exception { return &quot;通过实现Callable接口&quot;; } }); try { String result = future.get(); System.out.println(result); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } }} 四种新建线程的方式具体看以上注释，需要注意的是： 由于java不能多继承可以实现多个接口，因此，在创建线程的时候尽量多考虑采用实现接口的形式； 实现callable接口，提交给ExecutorService返回的是异步执行的结果，另外，通常也可以利用FutureTask(Callable&lt;V&gt; callable)将callable进行包装然后FeatureTask提交给ExecutorsService。如图， 另外由于FeatureTask也实现了Runable接口也可以利用上面第二种方式（实现Runable接口）来新建线程； 可以通过Executors将Runable转换成Callable，具体方法是：Callable callable(Runnable task, T result)， Callable&lt;Object&gt; callable(Runnable task)。 线程状态转换 此图来源于《JAVA并发编程的艺术》一书中，线程是会在不同的状态间进行转换的，java线程线程转换图如上图所示。线程创建之后它将处于 NEW（新建） 状态，之后调用start()方法开始运行，当调用wait(),join(),LockSupport.lock()方法线程会进入到WAITING(等待)状态，而同样的wait(long timeout)，sleep(long),join(long),LockSupport.parkNanos(),LockSupport.parkUtil()增加了超时等待的功能，也就是调用这些方法后线程会进入TIMED_WAITING(超时等待)状态，当超时等待时间到达后，线程会切换到Runable的状态，另外当WAITING和TIMED _WAITING状态时可以通过Object.notify(),Object.notifyAll()方法使线程转换到Runable状态。当线程出现资源竞争时，即等待获取锁的时候，线程会进入到BLOCKED阻塞状态，当线程获取锁时，线程进入到Runable状态。线程运行结束后，线程进入到TERMINATED状态，状态转换可以说是线程的生命周期。另外需要注意的是： 当线程进入到synchronized方法或者synchronized代码块时，线程切换到的是BLOCKED状态，而使用java.util.concurrent.locks下lock进行加锁的时候线程切换的是WAITING或者TIMED_WAITING状态，因为lock会调用LockSupport的方法。 用一个表格将上面六种状态进行一个总结归纳。 线程状态的基本操作除了新建一个线程外，线程在生命周期内还有需要进行一些基本操作，而这些操作会成为线程间一种通信方式，比如使用中断（interrupted）方式通知实现线程间的交互等等，下面就将具体说说这些操作。 interrupted中断可以理解为线程的一个标志位，它表示了一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了一个招呼。其他线程可以调用该线程的interrupt()方法对其进行中断操作，同时该线程可以调用isInterrupted()来感知其他线程对其自身的中断操作，从而做出响应。另外，同样可以调用Thread的静态方法interrupted()对当前线程进行中断操作，该方法会清除中断标志位。需要注意的是，当抛出InterruptedException时候，会清除中断标志位，也就是说在调用isInterrupted会返回false。 方法名 详细解释 备注 public void interrupt() 中断该线程对象 如果该线程被调用了Object wait/Object wait(long)，或者被调用sleep(long)，join()/join(long)方法时会抛出interruptedException并且中断标志位将会被清除 public boolean isinterrupted() 测试该线程对象是否被中断 中断标志位不会被清除 public static boolean interrupted() 测试当前线程是否被中断 中断标志位会被清除 下面结合具体的实例来看一看 123456789101112131415161718192021222324252627282930public class InterruptDemo { public static void main(String[] args) throws InterruptedException { //sleepThread睡眠1000ms final Thread sleepThread = new Thread() { @Override public void run() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } super.run(); } }; //busyThread一直执行死循环 Thread busyThread = new Thread() { @Override public void run() { while (true) ; } }; sleepThread.start(); busyThread.start(); sleepThread.interrupt(); busyThread.interrupt(); while (sleepThread.isInterrupted()) ; System.out.println(&quot;sleepThread isInterrupted: &quot; + sleepThread.isInterrupted()); System.out.println(&quot;busyThread isInterrupted: &quot; + busyThread.isInterrupted()); }} 输出结果 12345sleepThread isInterrupted: falsebusyThread isInterrupted: truejava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at com.jourwon.test.InterruptDemo$1.run(InterruptDemo.java:17) 开启了两个线程分别为sleepThread和BusyThread， sleepThread睡眠1s，BusyThread执行死循环。然后分别对着两个线程进行中断操作，可以看出sleepThread抛出InterruptedException后清除标志位，而busyThread就不会清除标志位。 另外，同样可以通过中断的方式实现线程间的简单交互， while (sleepThread.isInterrupted()) 表示在Main线程中会持续监测sleepThread线程，一旦sleepThread的中断标志位清零，即sleepThread.isInterrupted()返回为false时才会继续Main线程才会继续往下执行。因此，中断操作可以看做线程间一种简便的交互方式。一般在结束线程时通过中断标志位或者标志位的方式可以有机会去清理资源，相对于武断而直接的结束线程，这种方式要优雅和安全 joinjoin方法可以看做是线程间协作的一种方式，很多时候，一个线程的输入可能非常依赖于另一个线程的输出，这就像两个好基友，一个基友先走在前面突然看见另一个基友落在后面了，这个时候他就会在原处等一等这个基友，等基友赶上来后，就两人携手并进。其实线程间的这种协作方式也符合现实生活。在软件开发的过程中，从客户那里获取需求后，需要经过需求分析师进行需求分解后，这个时候产品，开发才会继续跟进。如果一个线程实例A执行了threadB.join()，其含义是：当前线程A会等待threadB线程终止后threadA才会继续执行。关于join方法一共提供如下这些方法: 方法名 详细注释 备注 public final void join() throws InterruptedException 等待这个线程死亡。 如果任何线程中断当前线程，如果抛出InterruptedException异常时，当前线程的中断状态将被清除 public final void join(long millis) throws InterruptedException 等待这个线程死亡的时间最多为millis毫秒。 0的超时意味着永远等待。 如果millis为负数，抛出IllegalArgumentException异常 public final void join(long millis, int nanos) throws InterruptedException 等待最多millis毫秒加上这个线程死亡的nanos纳秒。 如果millis为负数或者nanos不在0-999999范围抛出IllegalArgumentException异常 Thread类除了提供join()方法外，另外还提供了超时等待的方法，如果线程threadB在等待的时间内还没有结束的话，threadA会在超时之后继续执行。join方法源码关键是： 123while (isAlive()) { wait(0);} 可以看出来当前等待对象threadA会一直阻塞，直到被等待对象threadB结束后即isAlive()返回false的时候才会结束while循环，当threadB退出时会调用notifyAll()方法通知所有的等待线程。下面用一个具体的例子来说说join方法的使用： 12345678910111213141516171819202122232425262728public class JoinDemo { public static void main(String[] args) { Thread previousThread = Thread.currentThread(); for (int i = 1; i &lt;= 10; i++) { Thread curThread = new JoinThread(previousThread); curThread.start(); previousThread = curThread; } } static class JoinThread extends Thread { private Thread thread; public JoinThread(Thread thread) { this.thread = thread; } @Override public void run() { try { thread.join(); System.out.println(thread.getName() + &quot; terminated.&quot;); } catch (InterruptedException e) { e.printStackTrace(); } } }} 输出结果为： 12345678910main terminated.Thread-0 terminated.Thread-1 terminated.Thread-2 terminated.Thread-3 terminated.Thread-4 terminated.Thread-5 terminated.Thread-6 terminated.Thread-7 terminated.Thread-8 terminated. 在上面的例子中一个创建了10个线程，每个线程都会等待前一个线程结束才会继续运行。可以通俗的理解成接力，前一个线程将接力棒传给下一个线程，然后又传给下一个线程… sleeppublic static native void sleep(long millis)方法显然是Thread的静态方法，很显然它是让当前线程按照指定的时间休眠，其休眠时间的精度取决于处理器的计时器和调度器。需要注意的是如果当前线程获得了锁，sleep方法并不会失去锁。sleep方法经常拿来与Object.wait()方法进行比较，这也是面试经常被问的地方。 sleep() VS wait() 两者主要的区别： sleep()方法是Thread的静态方法，而wait是Object实例方法 wait()方法必须要在同步方法或者同步块中调用，也就是必须已经获得对象锁。而sleep()方法没有这个限制可以在任何地方使用。另外，wait()方法会释放占有的对象锁，使得该线程进入等待池中，等待下一次获取资源。而sleep()方法只是会让出CPU并不会释放掉对象锁； sleep()方法在休眠时间达到后，如果再次获得CPU时间片就会继续执行，而wait()方法必须等待Object.notift/Object.notifyAll通知后，才会离开等待池，并且再次获得CPU时间片才会继续执行。 yieldpublic static native void yield();这是一个静态方法，一旦执行，它会是当前线程让出CPU，但是，需要注意的是，让出的CPU并不是代表当前线程不再运行了，如果在下一次竞争中，又获得了CPU时间片当前线程依然会继续运行。另外，让出的时间片只会分配给当前线程相同优先级的线程。什么是线程优先级了？下面就来具体聊一聊。 现代操作系统基本采用时分的形式调度运行的线程，操作系统会分出一个个时间片，线程会分配到若干时间片，当前时间片用完后就会发生线程调度，并等待这下次分配。线程分配到的时间多少也就决定了线程使用处理器资源的多少，而线程优先级就是决定线程需要或多或少分配一些处理器资源的线程属性。 在Java程序中，通过一个整型成员变量Priority来控制优先级，优先级的范围从1~10.在构建线程的时候可以通过**setPriority(int)**方法进行设置，默认优先级为5，优先级高的线程相较于优先级低的线程优先获得处理器时间片。需要注意的是在不同JVM以及操作系统上，线程规划存在差异，有些操作系统甚至会忽略线程优先级的设定。 另外需要注意的是，sleep()和yield()方法，同样都是当前线程会交出处理器资源，而它们不同的是，sleep()交出来的时间片其他线程都可以去竞争，也就是说都有机会获得当前线程让出的时间片。而yield()方法只允许与当前线程具有相同优先级的线程能够获得释放出来的CPU时间片。 线程优先级理论上来说系统会根据优先级来决定首先使哪个线程进入运行状态。当 CPU 比较闲的时候，设置线程优先级几乎不会有任何作用，而且很多操作系统压根不会理会你设置的线程优先级，所以不要让业务过度依赖于线程的优先级。 另外，线程优先级具有继承特性比如 A 线程启动 B 线程，则 B 线程的优先级和 A 是一样的。线程优先级还具有随机性 也就是说线程优先级高的不一定每一次都先执行完。 Thread 类中包含的成员变量代表了线程的某些优先级。如Thread.MIN_PRIORITY（常数 1），Thread.NORM_PRIORITY（常数 5）,Thread.MAX_PRIORITY（常数 10）。其中每个线程的优先级都在1到10 之间，1的优先级为最低，10的优先级为最高，在默认情况下优先级都是Thread.NORM_PRIORITY（常数 5）。 一般情况下，不会对线程设定优先级别，更不会让某些业务严重地依赖线程的优先级别，比如权重，借助优先级设定某个任务的权重，这种方式是不可取的，一般定义线程的时候使用默认的优先级就好了。 相关方法： 12public final void setPriority(int newPriority) //为线程设定优先级public final int getPriority() //获取线程的优先级 设置线程优先级方法源码： 123456789101112131415public final void setPriority(int newPriority) { ThreadGroup g; checkAccess(); //线程游戏优先级不能小于 1 也不能大于 10，否则会抛出异常 if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) { throw new IllegalArgumentException(); } //如果指定的线程优先级大于该线程所在线程组的最大优先级，那么该线程的优先级将设为线程组的最大优先级 if((g = getThreadGroup()) != null) { if (newPriority &gt; g.getMaxPriority()) { newPriority = g.getMaxPriority(); } setPriority0(priority = newPriority); }} 进程和线程进程一个在内存中运行的应用程序。每个进程都有自己独立的一块内存空间，一个进程可以有多个线程，比如在Windows系统中，一个运行的xx.exe就是一个进程。 线程进程中的一个执行任务（控制单元），负责当前进程中程序的执行。一个进程至少有一个线程，一个进程可以运行多个线程，多个线程可共享数据。 与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 Java 程序天生就是多线程程序，我们可以通过 JMX 来看一下一个普通的 Java 程序有哪些线程，代码如下。 123456789101112public class MultiThread { public static void main(String[] args) { // 获取 Java 线程管理 MXBean ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean(); // 不需要获取同步的 monitor 和 synchronizer 信息，仅获取线程和线程堆栈信息 ThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false, false); // 遍历线程信息，仅打印线程 ID 和线程名称信息 for (ThreadInfo threadInfo : threadInfos) { System.out.println(&quot;[&quot; + threadInfo.getThreadId() + &quot;] &quot; + threadInfo.getThreadName()); } }} 上述程序输出如下（输出内容可能不同，不用太纠结下面每个线程的作用，只用知道 main 线程执行 main 方法即可）： 123456[6] Monitor Ctrl-Break //监听线程转储或“线程堆栈跟踪”的线程[5] Attach Listener //负责接收到外部的命令，而对该命令进行执行的并且把结果返回给发送者[4] Signal Dispatcher // 分发处理给 JVM 信号的线程[3] Finalizer //在垃圾收集前，调用对象 finalize 方法的线程[2] Reference Handler //用于处理引用对象本身（软引用、弱引用、虚引用）的垃圾回收的线程[1] main //main 线程,程序入口 从上面的输出内容可以看出：一个 Java 程序的运行是 main 线程和多个其他线程同时运行。 进程与线程的区别总结线程具有许多传统进程所具有的特征，故又称为轻型进程(Light—Weight Process)或进程元；而把传统的进程称为重型进程(Heavy—Weight Process)，它相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都有若干个线程，至少包含一个线程。 根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位 资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。 包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。 内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的 影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。 执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行 从 JVM 角度说进程和线程之间的关系（重要）图解进程和线程的关系下图是 Java 内存区域，通过下图我们从 JVM 的角度来说一下线程和进程之间的关系。 从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的堆和方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的程序计数器、虚拟机栈 和 本地方法栈。 程序计数器为什么是私有的?程序计数器主要有下面两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。 所以，程序计数器私有主要是为了线程切换后能恢复到正确的执行位置。 虚拟机栈和本地方法栈为什么是私有的? 虚拟机栈：每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。 本地方法栈：和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 所以，为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。 一句话简单了解堆和方法区堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 多进程和多线程区别多进程：操作系统中同时运行的多个程序 多线程：在同一个进程中同时运行的多个任务 举个例子，多线程下载软件，可以同时运行多个线程，但是通过程序运行的结果发现，每一次结果都不一致。 因为多线程存在一个特性：随机性。造成的原因：CPU在瞬间不断切换去处理各个线程而导致的，可以理解成多个线程在抢CPU资源。 多线程提高CPU使用率 多线程并不能提高运行速度，但可以提高运行效率，让CPU的使用率更高。但是如果多线程有安全问题或出现频繁的上下文切换时，运算速度可能反而更低。 Java中的多线程Java程序的进程里有几个线程：主线程，垃圾回收线程(后台线程)等 在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。 Java支持多线程，当Java程序执行main方法的时候，就是在执行一个名字叫做main的线程，可以在main方法执行时，开启多个线程A,B,C，多个线程 main,A,B,C同时执行，相互抢夺CPU，Thread类是java.lang包下的一个常用类,每一个Thread类的对象，就代表一个处于某种状态的线程 守护线程Daemon守护线程是一种特殊的线程，就和它的名字一样，它是系统的守护者，在后台默默地守护一些系统服务，比如垃圾回收线程，JIT线程就可以理解守护线程。与之对应的就是用户线程，用户线程就可以认为是系统的工作线程，它会完成整个系统的业务操作。用户线程完全结束后就意味着整个系统的业务任务全部结束了，因此系统就没有对象需要守护的了，守护线程自然而然就会退。当一个Java应用，只有守护线程的时候，虚拟机就会自然退出。下面以一个简单的例子来表述Daemon线程的使用。 123456789101112131415161718192021222324252627public class DaemonDemo { public static void main(String[] args) { Thread daemonThread = new Thread(new Runnable() { @Override public void run() { while (true) { try { System.out.println(&quot;i am alive&quot;); Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } finally { System.out.println(&quot;finally block&quot;); } } } }); daemonThread.setDaemon(true); daemonThread.start(); //确保main线程结束前能给daemonThread能够分到时间片 try { Thread.sleep(800); } catch (InterruptedException e) { e.printStackTrace(); } }} 输出结果为： 123i am alivefinally blocki am alive 上面的例子中daemodThread run方法中是一个while死循环，会一直打印,但是当main线程结束后daemonThread就会退出所以不会出现死循环的情况。main线程先睡眠800ms保证daemonThread能够拥有一次时间片的机会，也就是说可以正常执行一次打印“i am alive”操作和一次finally块中”finally block”操作。紧接着main 线程结束后，daemonThread退出，这个时候只打印了”i am alive”并没有打印finnal块中的。因此，这里需要注意的是守护线程在退出的时候并不会执行finnaly块中的代码，所以将释放资源等操作不要放在finnaly块中执行，这种操作是不安全的 线程可以通过setDaemon(true)的方法将线程设置为守护线程。并且需要注意的是设置守护线程要先于start()方法，否则会报这样的异常: 1Exception in thread &quot;main&quot; java.lang.IllegalThreadStateException at java.lang.Thread.setDaemon(Thread.java:1365) at learn.DaemonDemo.main(DaemonDemo.java:19) 但是该线程还是会执行，只不过会当做正常的用户线程执行。 线程死锁认识线程死锁百度百科：死锁是指两个或两个以上的进程（线程）在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程（线程）称为死锁进程（线程）。 多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。 如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。 下面通过一个例子来说明线程死锁，代码模拟了上图的死锁的情况 (代码来源于《并发编程之美》)： 123456789101112131415161718192021222324252627282930313233343536public class DeadLockDemo { private static Object resource1 = new Object();//资源 1 private static Object resource2 = new Object();//资源 2 public static void main(String[] args) { new Thread(() -&gt; { synchronized (resource1) { System.out.println(Thread.currentThread() + &quot;get resource1&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;); synchronized (resource2) { System.out.println(Thread.currentThread() + &quot;get resource2&quot;); } } }, &quot;线程 1&quot;).start(); new Thread(() -&gt; { synchronized (resource2) { System.out.println(Thread.currentThread() + &quot;get resource2&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread() + &quot;waiting get resource1&quot;); synchronized (resource1) { System.out.println(Thread.currentThread() + &quot;get resource1&quot;); } } }, &quot;线程 2&quot;).start(); }} 输出结果 1234Thread[线程 1,5,main]get resource1Thread[线程 2,5,main]get resource2Thread[线程 1,5,main]waiting get resource2Thread[线程 2,5,main]waiting get resource1 线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过Thread.sleep(1000)；让线程 A 休眠 1s 为的是让线程 B 得到CPU执行权，然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。 形成死锁的四个必要条件： 互斥条件：线程(进程)对于所分配到的资源具有排它性，即一个资源只能被一个线程(进程)占用，直到被该线程(进程)释放 请求与保持条件：一个线程(进程)因请求被占用资源而发生阻塞时，对已获得的资源保持不放。 不剥夺条件：线程(进程)已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 循环等待条件：当发生死锁时，所等待的线程(进程)必定会形成一个环路（类似于死循环），造成永久阻塞 如何避免线程死锁我们只要破坏产生死锁的四个条件中的其中一个就可以了。 破坏互斥条件 这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。 破坏请求与保持条件 一次性申请所有的资源。 破坏不剥夺条件 占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 破坏循环等待条件 靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。 我们对线程 2 的代码修改成下面这样就不会产生死锁了。 1234567891011121314new Thread(() -&gt; { synchronized (resource1) { System.out.println(Thread.currentThread() + &quot;get resource1&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;); synchronized (resource2) { System.out.println(Thread.currentThread() + &quot;get resource2&quot;); } }}, &quot;线程 2&quot;).start(); 输出结果 1234567Thread[线程 1,5,main]get resource1Thread[线程 1,5,main]waiting get resource2Thread[线程 1,5,main]get resource2Thread[线程 2,5,main]get resource1Thread[线程 2,5,main]waiting get resource2Thread[线程 2,5,main]get resource2123456 我们分析一下上面的代码为什么避免了死锁的发生? 线程 1 首先获得到 resource1 的监视器锁，这时候线程 2 就获取不到了。然后线程 1 再去获取 resource2 的监视器锁，可以获取到。然后线程 1 释放了对 resource1、resource2 的监视器锁的占用，线程 2 获取到就可以执行了。这样就破坏了破坏循环等待条件，因此避免了死锁。 参考： 线程状态及基本操作 线程的状态和基本操作","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"title":"并发编程-重排序与数据依赖性","text":"为什么需要重排序现在的CPU一般采用流水线来执行指令。一个指令的执行被分成：取指、译码、访存、执行、写回、等若干个阶段。然后，多条指令可以同时存在于流水线中，同时被执行。 指令流水线并不是串行的，并不会因为一个耗时很长的指令在“执行”阶段呆很长时间，而导致后续的指令都卡在“执行”之前的阶段上。我们编写的程序都要经过优化后（编译器和处理器会对我们的程序进行优化以提高运行效率）才会被运行，优化分为很多种，其中有一种优化叫做重排序，重排序需要遵守as-if-serial规则和happens-before规则，不能说你想怎么排就怎么排，如果那样岂不是乱了套。重排序的目的是为了性能。 Example: 1234过程A：cpu0—写入1—&gt; bank0；过程B：cpu0—写入2—&gt; bank1；如果bank0状态为busy, 则A过程需要等待如果进行重排序，则直接可以先执行B过程。 重排序分类一般重排序可以分为如下三种： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序； 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序； 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行的。 重排序过程一个好的内存模型实际上会放宽对处理器和编译器规则的束缚，也就是说软件技术和硬件技术都为同一个目标而进行奋斗：在不改变程序执行结果的前提下，尽可能提高并行度。Java内存模型（JMM）对底层尽量减少约束，使其能够发挥自身优势。因此，在执行程序时，为了提高性能，编译器和处理器常常会对指令进行重排序。 如图，1属于编译器重排序，而2和3统称为处理器重排序。这些重排序会导致线程安全的问题，一个很经典的例子就是DCL（双重检验锁）问题，这个在以后的文章中会具体去聊。针对编译器重排序，Java内存模型（JMM）的编译器重排序规则会禁止一些特定类型的编译器重排序；针对处理器重排序，编译器在生成指令序列的时候会通过插入内存屏障指令来禁止某些特殊的处理器重排序。 那么什么情况下，不能进行重排序了？下面就来说说数据依赖性。有如下代码： 123double pi = 3.14 //Adouble r = 1.0 //Bdouble area = pi * r * r //C 这是一个计算圆面积的代码，由于A，B之间没有任何关系，对最终结果也不会存在影响，它们之间执行顺序可以重排序。因此执行顺序可以是A-&gt;B-&gt;C或者B-&gt;A-&gt;C执行最终结果都是3.14，即A和B之间没有数据依赖性。具体的定义为：如果两个操作访问同一个变量，且这两个操作有一个为写操作，此时这两个操作就存在数据依赖性，这里就存在三种情况：1. 读后写；2.写后写；3. 写后读，或者三种操作都是存在数据依赖性的，如果重排序会对最终执行结果产生影响，编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖性关系的两个操作的执行顺序 重排序对多线程的影响12345678910111213141516class ReorderExample { int a = 0; boolean flag = false; public void writer() { a = 1; //1 flag = true; //2 } public void reader() { if (flag) { //3 int i = a * a; //4 …… } }} flag为标志位，表示a有没有被写入，当A线程执行 writer 方法，B线程执行 reader 方法，线程B在执行4操作的时候，能否看到线程A对a的写入操作？ 答案是：不一定！ 由于操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序。 如果操作1和操作2做了重排序，程序执行时，线程A首先写标记变量 flag，随后线程 B 读这个变量。由于条件判断为真，线程 B 将读取变量a。此时，变量 a 还根本没有被线程 A 写入，在这里多线程程序的语义被重排序破坏了！ 数据依赖性如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型： 名称 代码示例 说明 写后读 a = 1;b = a; 写一个变量之后，再读这个位置。 写后写 a = 1;a = 2; 写一个变量之后，再写这个变量。 读后写 a = b;b = 1; 读一个变量之后，再写这个变量。 上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。前面提到过，编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。所以有数据依赖性的语句不能进行重排序。 参考：https://blog.csdn.net/ThinkWon","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E9%87%8D%E6%8E%92%E5%BA%8F%E4%B8%8E%E6%95%B0%E6%8D%AE%E4%BE%9D%E8%B5%96%E6%80%A7/"},{"title":"并发编程-详解threadLocal内存泄漏问题","text":"造成内存泄漏的原因？threadLocal是为了解决对象不能被多线程共享访问的问题，通过threadLocal.set方法将对象实例保存在每个线程自己所拥有的threadLocalMap中，这样每个线程使用自己的对象实例，彼此不会影响达到隔离的作用，从而就解决了对象在被共享访问带来线程安全问题。如果将同步机制和threadLocal做一个横向比较的话，同步机制就是通过控制线程访问共享对象的顺序，而threadLocal就是为每一个线程分配一个该对象，各用各的互不影响。 打个比方说，现在有100个同学需要填写一张表格但是只有一支笔，同步就相当于A使用完这支笔后给B，B使用后给C用…老师就控制着这支笔的使用顺序，使得同学之间不会产生冲突。而threadLocal就相当于，老师直接准备了100支笔，这样每个同学都使用自己的，同学之间就不会产生冲突。很显然这就是两种不同的思路，同步机制以“时间换空间”，由于每个线程在同一时刻共享对象只能被一个线程访问造成整体上响应时间增加，但是对象只占有一份内存，牺牲了时间效率换来了空间效率即“时间换空间”。而threadLocal，为每个线程都分配了一份对象，自然而然内存使用率增加，每个线程各用各的，整体上时间效率要增加很多，牺牲了空间效率换来时间效率即“空间换时间”。 关于threadLocal，threadLocalMap更多的细节可以看这篇文章，给出了很详细的各个方面的知识（很多也是面试高频考点）。threadLocal，threadLocalMap，entry之间的关系如下图所示： 上图中，实线代表强引用，虚线代表的是弱引用，如果threadLocal外部强引用被置为null(threadLocalInstance=null)的话，threadLocal实例就没有一条引用链路可达，很显然在gc(垃圾回收)的时候势必会被回收，因此entry就存在key为null的情况，无法通过一个Key为null去访问到该entry的value。同时，就存在了这样一条引用链：threadRef-&gt;currentThread-&gt;threadLocalMap-&gt;entry-&gt;valueRef-&gt;valueMemory，导致在垃圾回收的时候进行可达性分析的时候,value可达从而不会被回收掉，但是该value永远不能被访问到，这样就存在了内存泄漏。当然，如果线程执行结束后，threadLocal，threadRef会断掉，因此threadLocal，threadLocalMap，entry都会被回收掉。可是，在实际使用中我们都是会用线程池去维护我们的线程，比如在Executors.newFixedThreadPool()时创建线程的时候，为了复用线程是不会结束的，所以threadLocal内存泄漏就值得我们关注。 已经做出了哪些改进？实际上，为了解决threadLocal潜在的内存泄漏的问题，Josh Bloch and Doug Lea大师已经做了一些改进。在threadLocal的set和get方法中都有相应的处理。下文为了叙述，针对key为null的entry，源码注释为stale entry，直译为不新鲜的entry，这里我就称之为“脏entry”。比如在ThreadLocalMap的set方法中： 1234567891011121314151617181920212223242526272829303132private void set(ThreadLocal&lt;?&gt; key, Object value) { // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal&lt;?&gt; k = e.get(); if (k == key) { e.value = value; return; } if (k == null) { replaceStaleEntry(key, value, i); return; } } tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();} 在该方法中针对脏entry做了这样的处理： 如果当前table[i]！=null的话说明hash冲突就需要向后环形查找，若在查找过程中遇到脏entry就通过replaceStaleEntry进行处理； 如果当前table[i]==null的话说明新的entry可以直接插入，但是插入后会调用cleanSomeSlots方法检测并清除脏entry cleanSomeSlots方法该方法的源码为： 123456789101112131415161718192021222324252627282930/* @param i a position known NOT to hold a stale entry. The * scan starts at the element after i. * * @param n scan control: {@code log2(n)} cells are scanned, * unless a stale entry is found, in which case * {@code log2(table.length)-1} additional cells are scanned. * When called from insertions, this parameter is the number * of elements, but when from replaceStaleEntry, it is the * table length. (Note: all this could be changed to be either * more or less aggressive by weighting n instead of just * using straight log n. But this version is simple, fast, and * seems to work well.) * * @return true if any stale entries have been removed. */private boolean cleanSomeSlots(int i, int n) { boolean removed = false; Entry[] tab = table; int len = tab.length; do { i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) { n = len; removed = true; i = expungeStaleEntry(i); } } while ( (n &gt;&gt;&gt;= 1) != 0); return removed;} 入参： i表示：插入entry的位置i，很显然在上述情况2（table[i]==null）中，entry刚插入后该位置i很显然不是脏entry; 参数n n的用途 主要用于扫描控制（scan control），从while中是通过n来进行条件判断的说明n就是用来控制扫描趟数（循环次数）的。在扫描过程中，如果没有遇到脏entry就整个扫描过程持续log2(n)次，log2(n)的得来是因为n &gt;&gt;&gt;= 1，每次n右移一位相当于n除以2。如果在扫描过程中遇到脏entry的话就会令n为当前hash表的长度（n=len），再扫描log2(n)趟，注意此时n增加无非就是多增加了循环次数从而通过nextIndex往后搜索的范围扩大，示意图如下 按照n的初始值，搜索范围为黑线，当遇到了脏entry，此时n变成了哈希数组的长度（n取值增大），搜索范围log2(n)增大，红线表示。如果在整个搜索过程没遇到脏entry的话，搜索结束，采用这种方式的主要是用于时间效率上的平衡。 n的取值 如果是在set方法插入新的entry后调用（上述情况2），n位当前已经插入的entry个数size；如果是在replaceSateleEntry方法中调用n为哈希表的长度len。 expungeStaleEntry方法如果对输入参数能够理解的话，那么cleanSomeSlots方法搜索基本上清除了，但是全部搞定还需要掌握expungeStaleEntry方法，当在搜索过程中遇到了脏entry的话就会调用该方法去清理掉脏entry。源码为： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Expunge a stale entry by rehashing any possibly colliding entries * lying between staleSlot and the next null slot. This also expunges * any other stale entries encountered before the trailing null. See * Knuth, Section 6.4 * * @param staleSlot index of slot known to have null key * @return the index of the next null slot after staleSlot * (all between staleSlot and this slot will have been checked * for expunging). */private int expungeStaleEntry(int staleSlot) { Entry[] tab = table; int len = tab.length; //1.清除当前脏entry // expunge entry at staleSlot tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; //2.往后环形继续查找,直到遇到table[i]==null时结束 for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal&lt;?&gt; k = e.get(); //3. 如果在向后搜索过程中再次遇到脏entry，同样将其清理掉 if (k == null) { e.value = null; tab[i] = null; size--; } else { //处理rehash的情况 int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) { tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; } } } return i;} 该方法逻辑请看注释（第1,2,3步），主要做了这么几件事情： 清理当前脏entry，即将其value引用置为null，并且将table[staleSlot]也置为null。value置为null后该value域变为不可达，在下一次gc的时候就会被回收掉，同时table[staleSlot]为null后以便于存放新的entry; 从当前staleSlot位置向后环形（nextIndex）继续搜索，直到遇到哈希桶（tab[i]）为null的时候退出； 若在搜索过程再次遇到脏entry，继续将其清除。 也就是说该方法，清理掉当前脏entry后，并没有闲下来继续向后搜索，若再次遇到脏entry继续将其清理，直到哈希桶（table[i]）为null时退出。因此方法执行完的结果为 从当前脏entry（staleSlot）位到返回的i位，这中间所有的entry不是脏entry。为什么是遇到null退出呢？原因是存在脏entry的前提条件是 当前哈希桶（table[i]）不为null,只是该entry的key域为null。如果遇到哈希桶为null,很显然它连成为脏entry的前提条件都不具备。 现在对cleanSomeSlot方法做一下总结，其方法执行示意图如下： 如图所示，cleanSomeSlot方法主要有这样几点： 从当前位置i处（位于i处的entry一定不是脏entry）为起点在初始小范围（log2(n)，n为哈希表已插入entry的个数size）开始向后搜索脏entry，若在整个搜索过程没有脏entry，方法结束退出 如果在搜索过程中遇到脏entryt通过expungeStaleEntry方法清理掉当前脏entry，并且该方法会返回下一个哈希桶(table[i])为null的索引位置为i。这时重新令搜索起点为索引位置i，n为哈希表的长度len，再次扩大搜索范围为log2(n’)继续搜索。 下面，以一个例子更清晰的来说一下，假设当前table数组的情况如下图。 如图当前n等于hash表的size即n=10，i=1,在第一趟搜索过程中通过nextIndex,i指向了索引为2的位置，此时table[2]为null，说明第一趟未发现脏entry,则第一趟结束进行第二趟的搜索。 第二趟所搜先通过nextIndex方法，索引由2的位置变成了i=3,当前table[3]!=null但是该entry的key为null，说明找到了一个脏entry，先将n置为哈希表的长度len,然后继续调用expungeStaleEntry方法，该方法会将当前索引为3的脏entry给清除掉（令value为null，并且table[3]也为null）,但是该方法可不想偷懒，它会继续往后环形搜索，往后会发现索引为4,5的位置的entry同样为脏entry，索引为6的位置的entry不是脏entry保持不变，直至i=7的时候此处table[7]位null，该方法就以i=7返回。至此，第二趟搜索结束； 由于在第二趟搜索中发现脏entry，n增大为数组的长度len，因此扩大搜索范围（增大循环次数）继续向后环形搜索； 直到在整个搜索范围里都未发现脏entry，cleanSomeSlot方法执行结束退出。 replaceStaleEntry方法先来看replaceStaleEntry 方法，该方法源码为： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/* * @param key the key * @param value the value to be associated with key * @param staleSlot index of the first stale entry encountered while * searching for key. */private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) { Entry[] tab = table; int len = tab.length; Entry e; // Back up to check for prior stale entry in current run. // We clean out whole runs at a time to avoid continual // incremental rehashing due to garbage collector freeing // up refs in bunches (i.e., whenever the collector runs). //向前找到第一个脏entry int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i;//1. // Find either the key or trailing null slot of run, whichever // occurs first for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal&lt;?&gt; k = e.get(); // If we find key, then we need to swap it // with the stale entry to maintain hash table order. // The newly stale slot, or any other stale slot // encountered above it, can then be sent to expungeStaleEntry // to remove or rehash all of the other entries in run. if (k == key) { //如果在向后环形查找过程中发现key相同的entry就覆盖并且和脏entry进行交换 e.value = value;//2. tab[i] = tab[staleSlot];//3. tab[staleSlot] = e;//4. // Start expunge at preceding stale entry if it exists //如果在查找过程中还未发现脏entry，那么就以当前位置作为cleanSomeSlots //的起点 if (slotToExpunge == staleSlot) slotToExpunge = i;//5. //搜索脏entry并进行清理 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);//6. return; } // If we didn't find stale entry on backward scan, the // first stale entry seen while scanning for key is the // first still present in the run. //如果向前未搜索到脏entry，则在查找过程遇到脏entry的话，后面就以此时这个位置 //作为起点执行cleanSomeSlots if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i;//7. } // If key not found, put new entry in stale slot //如果在查找过程中没有找到可以覆盖的entry，则将新的entry插入在脏entry tab[staleSlot].value = null;//8. tab[staleSlot] = new Entry(key, value);//9. // If there are any other stale entries in run, expunge them if (slotToExpunge != staleSlot)//10. //执行cleanSomeSlots cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);//11.} 该方法的逻辑请看注释，下面我结合各种情况详细说一下该方法的执行过程。首先先看这一部分的代码： 123456int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; 这部分代码通过PreIndex方法实现往前环形搜索脏entry的功能，初始时slotToExpunge和staleSlot相同，若在搜索过程中发现了脏entry，则更新slotToExpunge为当前索引i。另外，说明replaceStaleEntry并不仅仅局限于处理当前已知的脏entry，它认为在出现脏entry的相邻位置也有很大概率出现脏entry，所以为了一次处理到位，就需要向前环形搜索，找到前面的脏entry。那么根据在向前搜索中是否还有脏entry以及在for循环后向环形查找中是否找到可覆盖的entry，我们分这四种情况来充分理解这个方法： 1.前向有脏entry 1.1后向环形查找找到可覆盖的entry该情形如下图所示。 如图，slotToExpunge初始状态和staleSlot相同，当前向环形搜索遇到脏entry时，在第1行代码中slotToExpunge会更新为当前脏entry的索引i，直到遇到哈希桶（table[i]）为null的时候，前向搜索过程结束。在接下来的for循环中进行后向环形查找，若查找到了可覆盖的entry，第2,3,4行代码先覆盖当前位置的entry，然后再与staleSlot位置上的脏entry进行交换。交换之后脏entry就更换到了i处，最后使用cleanSomeSlots方法从slotToExpunge为起点开始进行清理脏entry的过程 1.2 后向环形查找未找到可覆盖的entry该情形如下图所示。如图，slotToExpunge初始状态和staleSlot相同，当前向环形搜索遇到脏entry时，在第1行代码中slotToExpunge会更新为当前脏entry的索引i，直到遇到哈希桶（table[i]）为null的时候，前向搜索过程结束。在接下来的for循环中进行后向环形查找，若没有查找到了可覆盖的entry，哈希桶（table[i]）为null的时候，后向环形查找过程结束。那么接下来在8,9行代码中，将插入的新entry直接放在staleSlot处即可，最后使用cleanSomeSlots方法从slotToExpunge为起点开始进行清理脏entry的过程 2.前向没有脏entry 2.1后向环形查找找到可覆盖的entry该情形如下图所示。 如图，slotToExpunge初始状态和staleSlot相同，当前向环形搜索直到遇到哈希桶（table[i]）为null的时候，前向搜索过程结束，若在整个过程未遇到脏entry，slotToExpunge初始状态依旧和staleSlot相同。在接下来的for循环中进行后向环形查找，若遇到了脏entry，在第7行代码中更新slotToExpunge为位置i。若查找到了可覆盖的entry，第2,3,4行代码先覆盖当前位置的entry，然后再与staleSlot位置上的脏entry进行交换，交换之后脏entry就更换到了i处。如果在整个查找过程中都还没有遇到脏entry的话，会通过第5行代码，将slotToExpunge更新当前i处，最后使用cleanSomeSlots方法从slotToExpunge为起点开始进行清理脏entry的过程。 2.2后向环形查找未找到可覆盖的entry该情形如下图所示。 如图，slotToExpunge初始状态和staleSlot相同，当前向环形搜索直到遇到哈希桶（table[i]）为null的时候，前向搜索过程结束，若在整个过程未遇到脏entry，slotToExpunge初始状态依旧和staleSlot相同。在接下来的for循环中进行后向环形查找，若遇到了脏entry，在第7行代码中更新slotToExpunge为位置i。若没有查找到了可覆盖的entry，哈希桶（table[i]）为null的时候，后向环形查找过程结束。那么接下来在8,9行代码中，将插入的新entry直接放在staleSlot处即可。另外，如果发现slotToExpunge被重置，则第10行代码if判断为true,就使用cleanSomeSlots方法从slotToExpunge为起点开始进行清理脏entry的过程。 下面用一个实例来有个直观的感受，示例代码就不给出了，代码debug时table状态如下图所示： 如图所示，当前的staleSolt为i=4，首先先进行前向搜索脏entry，当i=3的时候遇到脏entry，slotToExpung更新为3，当i=2的时候tabel[2]为null，因此前向搜索脏entry的过程结束。然后进行后向环形查找，知道i=7的时候遇到table[7]为null，结束后向查找过程，并且在该过程并没有找到可以覆盖的entry。最后只能在staleSlot（4）处插入新entry，然后从slotToExpunge（3）为起点进行cleanSomeSlots进行脏entry的清理。是不是上面的1.2的情况。 这些核心方法，通过源码又给出示例图，应该最终都能掌握了，也还挺有意思的。 当我们调用threadLocal的get方法时，当table[i]不是和所要找的key相同的话，会继续通过threadLocalMap的getEntryAfterMiss方法向后环形去找，该方法为： 12345678910111213141516private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) { Entry[] tab = table; int len = tab.length; while (e != null) { ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; } return null;} 当key==null的时候，即遇到脏entry也会调用expungeStleEntry对脏entry进行清理。 当我们调用threadLocal.remove方法时候，实际上会调用threadLocalMap的remove方法，该方法的源码为： 1234567891011121314private void remove(ThreadLocal&lt;?&gt; key) { Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { if (e.get() == key) { e.clear(); expungeStaleEntry(i); return; } }} 同样的可以看出，当遇到了key为null的脏entry的时候，也会调用expungeStaleEntry清理掉脏entry。 从以上set,getEntry,remove方法看出，在threadLocal的生命周期里，针对threadLocal存在的内存泄漏的问题，都会通过expungeStaleEntry，cleanSomeSlots,replaceStaleEntry这三个方法清理掉key为null的脏entry。 为什么使用弱引用？从文章开头通过threadLocal,threadLocalMap,entry的引用关系看起来threadLocal存在内存泄漏的问题似乎是因为threadLocal是被弱引用修饰的。那为什么要使用弱引用呢？ 如果使用强引用 假设threadLocal使用的是强引用，在业务代码中执行threadLocalInstance==null操作，以清理掉threadLocal实例的目的，但是因为threadLocalMap的Entry强引用threadLocal，因此在gc的时候进行可达性分析，threadLocal依然可达，对threadLocal并不会进行垃圾回收，这样就无法真正达到业务逻辑的目的，出现逻辑错误 如果使用弱引用 假设Entry弱引用threadLocal，尽管会出现内存泄漏的问题，但是在threadLocal的生命周期里（set,getEntry,remove）里，都会针对key为null的脏entry进行处理。 从以上的分析可以看出，使用弱引用的话在threadLocal生命周期里会尽可能的保证不出现内存泄漏的问题，达到安全的状态。 Thread.exit()当线程退出时会执行exit方法： 1234567891011121314private void exit() { if (group != null) { group.threadTerminated(this); group = null; } /* Aggressively null out all reference fields: see bug 4006245 */ target = null; /* Speed the release of some of these resources */ threadLocals = null; inheritableThreadLocals = null; inheritedAccessControlContext = null; blocker = null; uncaughtExceptionHandler = null;} 从源码可以看出当线程结束时，会令threadLocals=null，也就意味着GC的时候就可以将threadLocalMap进行垃圾回收，换句话说threadLocalMap生命周期实际上thread的生命周期相同。 ThreadLocal最佳实践通过这篇文章对threadLocal的内存泄漏做了很详细的分析，我们可以完全理解threadLocal内存泄漏的前因后果，那么实践中我们应该怎么做？ 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。 在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。 参考资料 《Java高并发程序设计》","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E8%AF%A6%E8%A7%A3threadLocal%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98/"},{"title":"微信小程序WXML教程","text":"介绍WXML（WeiXin Markup Language）是框架设计的一套标签语言，结合基础组件、事件系统，可以构建出页面的结构。 标签与属性常用基础标签：text view特征： text类似html的span标签，行内元素，不换行； view类似html的div标签，块级元素，换行； 1234&lt;text&gt;text 类似html span标签 行内元素&lt;/text&gt; &lt;text&gt;，不换行&lt;/text&gt;&lt;view&gt;view 类似html div标签 块级元素&lt;/view&gt; &lt;view&gt;view 类似html div标签 换行&lt;/view&gt; 公共属性所有组件都有以下属性： 属性名 类型 描述 注解 id String 组件的唯一标示 保持整个页面唯一 class String 组件的样式类 在对应的 WXSS 中定义的样式类 style String 组件的内联样式 可以动态设置的内联样式 hidden Boolean 组件是否显示 所有组件默认显示 data-* Any 自定义属性 组件上触发的事件时，会发送给事件处理函数 bind* / catch* EventHandler 组件的事件 详见事件 1234567&lt;!--pages/tag/tag.wxml--&gt;&lt;text&gt;text 类似html span标签 行内元素&lt;/text&gt; &lt;text&gt;，不换行&lt;/text&gt;&lt;view&gt;view 类似html div标签 块级元素&lt;/view&gt; &lt;view&gt;view 类似html div标签 换行&lt;/view&gt;&lt;view id=&quot;name&quot; class=&quot;namceClass&quot; style=&quot;font-style: italic;&quot; hidden=&quot;&quot;&gt;view 类似html div标签 块级元素&lt;/view&gt; 数据绑定数据绑定功能使得程序在运行过程中,具备动态改变渲染界面的能力,从而达到了更好的用户体验效果。在 WEB开发中,需要借助JavaScript并通过DOM接口来实现界面的动态更新,而在小程序中,则是使用WXML 语言提供的数据绑定功能来实现的。 WXML 中的动态数据均来自对应 Page 的 data。 简单的数据绑定数据绑定使用 Mustache 语法（双大括号）将变量包起来 1234567891011121314151617&lt;!--pages/dataBinding/dataBingding.wxml--&gt;&lt;view&gt;{{message}}&lt;/view&gt;&lt;view&gt;{{number}}&lt;/view&gt;&lt;view&gt;{{condition}}&lt;/view&gt;&lt;view&gt;{{isChecked}}&lt;/view&gt;&lt;view&gt;{{person}}&lt;/view&gt;&lt;view&gt;{{person.name}}&lt;/view&gt;&lt;view&gt;{{person.age}}&lt;/view&gt;&lt;view&gt;{{person.sex}}&lt;/view&gt;&lt;!-- 自定义属性 data --&gt;&lt;view data-number=&quot;{{number}}&quot;&gt;自定义属性&lt;/view&gt;&lt;!-- 组件属性（需要在双引号之内） --&gt;&lt;view id=&quot;item-{{id}}&quot;&gt;组件属性&lt;/view&gt;&lt;!-- 控制属性 --&gt;&lt;view wx:if=&quot;{{condition}}&quot;&gt;控制属性&lt;/view&gt;&lt;!-- 使用布尔类型充当属性 --&gt;&lt;checkbox checked=&quot;{{isChecked}}&quot;&gt;&lt;/checkbox&gt; 1234567891011121314151617// pages/dataBinding/dataBingding.jsPage({ /** * 页面的初始数据 */ data: { id: 1, message: 'Hello MINA!', number: 1234, condition: true, isChecked: true, person: { name: &quot;张三&quot;, age: 25, sex: &quot;男&quot; } }}) 运算可以在 {{}} 内进行简单的运算，支持的有如下几种方式： 1234567891011&lt;!--pages/operation/operation.wxml--&gt;&lt;!-- 三元运算 --&gt;&lt;view hidden=&quot;{{flag?true:false}}&quot;&gt;三元运算&lt;/view&gt;&lt;!-- 算数运算 --&gt;&lt;view&gt; {{a + b}} + {{c}} + d &lt;/view&gt;&lt;!-- 逻辑判断 --&gt;&lt;view wx:if=&quot;{{length &gt; 5}}&quot;&gt;逻辑判断&lt;/view&gt;&lt;!-- 字符串拼接 --&gt;&lt;view&gt;{{&quot;hello &quot; + name}}&lt;/view&gt;&lt;!-- 数据路径运算 --&gt;&lt;view&gt;{{object.key}} {{array[0]}}&lt;/view&gt; 12345678910111213141516171819// pages/operation/operation.jsPage({ /** * 页面的初始数据 */ data: { flag: false, a: 1, b: 2, c: 3, length: 6, name: &quot;MINA&quot;, object: { key: 'Hello' }, array: ['MINA'] }}) 列表渲染wx:for在组件上使用 wx:for 控制属性绑定一个数组，即可使用数组中各项的数据重复渲染该组件。 默认数组的当前项的下标变量名默认为 index，数组当前项的变量名默认为 item 使用 wx:for-item 可以指定数组当前元素的变量名， 使用 wx:for-index 可以指定数组当前下标的变量名： 12345678&lt;!--pages/listRender/listRender.wxml--&gt;&lt;!-- wx:for --&gt;&lt;view wx:for=&quot;{{array}}&quot; wx:for-item=&quot;item&quot; wx:for-index=&quot;index&quot;&gt; {{index}}-{{item.id}}-{{item.name}} &lt;/view&gt; 1234567891011121314151617181920212223// pages/listRender/listRender.jsPage({ /** * 页面的初始数据 */ data: { array: [ { id: 1, name: '张三' }, { id: 2, name: '李四' }, { id: 3, name: '王五' } ] }}) wx:key如果列表中项目的位置会动态改变或者有新的项目添加到列表中，并且希望列表中的项目保持自己的特征和状态（如 input 中的输入内容，switch 的选中状态），需要使用 wx:key 来指定列表中项目的唯一的标识符。 wx:key 的值以两种形式提供 字符串，代表在 for 循环的 array 中 item 的某个 property，该 property 的值需要是列表中唯一的字符串或数字，且不能动态改变。 保留关键字 *this 代表在 for 循环中的 item 本身，这种表示需要 item 本身是一个唯一的字符串或者数字。 当数据改变触发渲染层重新渲染的时候，会校正带有 key 的组件，框架会确保他们被重新排序，而不是重新创建，以确保使组件保持自身的状态，并且提高列表渲染时的效率。 如不提供 wx:key，会报一个 warning， 如果明确知道该列表是静态，或者不必关注其顺序，可以选择忽略。 123456789&lt;!--pages/listRender/listRender.wxml--&gt;&lt;!-- wx:for --&gt;&lt;view wx:for=&quot;{{array}}&quot; wx:for-item=&quot;item&quot; wx:for-index=&quot;index&quot; wx:key=&quot;id&quot;&gt; {{index}}-{{item.id}}-{{item.name}} &lt;/view&gt; block wx:for类似 block wx:if，也可以将 wx:for 用在&lt;block/&gt;标签上，以渲染一个包含多节点的结构块。例如： 1234567891011121314151617181920&lt;!--pages/listRender/listRender.wxml--&gt;&lt;!-- wx:for --&gt;&lt;view wx:for=&quot;{{array}}&quot; wx:for-item=&quot;item&quot; wx:for-index=&quot;index&quot; wx:key=&quot;id&quot;&gt; {{index}}-{{item.id}}-{{item.name}} &lt;/view&gt; &lt;!-- block wx:for --&gt; &lt;view&gt; &lt;block wx:for=&quot;{{array}}&quot; wx:for-item=&quot;item&quot; wx:for-index=&quot;index&quot; wx:key=&quot;id&quot;&gt; {{index}}-{{item.id}}-{{item.name}} &lt;/block&gt; &lt;/view&gt; 条件渲染wx:if在框架中，使用 wx:if=&quot;&quot; 来判断是否需要渲染该代码块： 1&lt;view wx:if=&quot;{{condition}}&quot;&gt; True &lt;/view&gt; 也可以用 wx:elif 和 wx:else 来添加一个 else 块： 123&lt;view wx:if=&quot;{{length &gt; 5}}&quot;&gt; 1 &lt;/view&gt;&lt;view wx:elif=&quot;{{length &gt; 2}}&quot;&gt; 2 &lt;/view&gt;&lt;view wx:else&gt; 3 &lt;/view&gt; block wx:if因为 wx:if 是一个控制属性，需要将它添加到一个标签上。如果要一次性判断多个组件标签，可以使用一个 &lt;block/&gt; 标签将多个组件包装起来，并在上边使用 wx:if 控制属性。 1234&lt;block wx:if=&quot;{{true}}&quot;&gt; &lt;view&gt; view1 &lt;/view&gt; &lt;view&gt; view2 &lt;/view&gt;&lt;/block&gt; 注意： &lt;block/&gt; 并不是一个组件，它仅仅是一个包装元素，不会在页面中做任何渲染，只接受控制属性。 hidden1&lt;view hidden=&quot;{{condition}}&quot;&gt; hidden &lt;/view&gt; 因为 wx:if 之中的模板也可能包含数据绑定，所以当 wx:if 的条件值切换时，框架有一个局部渲染的过程，因为它会确保条件块在切换时销毁或重新渲染。 同时 wx:if 也是惰性的，如果在初始渲染条件为 false，框架什么也不做，在条件第一次变成真的时候才开始局部渲染。 相比之下，hidden 就简单的多，组件始终会被渲染，只是简单的控制显示与隐藏。 一般来说，wx:if 有更高的切换消耗而 hidden 有更高的初始渲染消耗。因此，如果需要频繁切换的情景下，用 hidden 更好，如果在运行时条件不大可能改变则 wx:if 较好。 示例代码123456789101112131415161718&lt;!--pages/conditionRender/conditionRender.wxml--&gt;&lt;!-- wx:if wx:elif wx:else --&gt;&lt;view wx:if=&quot;{{condition}}&quot;&gt; True &lt;/view&gt;&lt;view wx:if=&quot;{{length &gt; 5}}&quot;&gt; 1 &lt;/view&gt;&lt;view wx:elif=&quot;{{length &gt; 2}}&quot;&gt; 2 &lt;/view&gt;&lt;view wx:else&gt; 3 &lt;/view&gt;&lt;!-- block wx:if --&gt;&lt;view&gt; &lt;block wx:if=&quot;{{true}}&quot;&gt; &lt;view&gt; view1 &lt;/view&gt; &lt;view&gt; view2 &lt;/view&gt; &lt;/block&gt;&lt;/view&gt;&lt;!-- hidden --&gt;&lt;view hidden=&quot;{{condition}}&quot;&gt; hidden &lt;/view&gt; 1234567891011// pages/conditionRender/conditionRender.jsPage({ /** * 页面的初始数据 */ data: { condition: false, length: 6 }}) 模版WXML提供模板（template），可以在模板中定义代码片段，然后在不同的地方调用。 定义模板使用 name 属性，作为模板的名字。然后在&lt;template/&gt;内定义代码片段，如： 1234567891011&lt;!-- index: int msg: string time: string--&gt;&lt;template name=&quot;msgItem&quot;&gt; &lt;view&gt; &lt;text&gt; {{index}}: {{msg}} &lt;/text&gt; &lt;text&gt; Time: {{time}} &lt;/text&gt; &lt;/view&gt;&lt;/template&gt; 使用模板使用 is 属性，声明需要的使用的模板，然后将模板所需要的 data 传入，如： 1&lt;template is=&quot;msgItem&quot; data=&quot;{{...item}}&quot;/&gt; 123456789Page({ data: { item: { index: 0, msg: 'this is a template', time: '2016-09-15' } }}) is 属性可以使用 Mustache 语法，来动态决定具体需要渲染哪个模板： 12345678910&lt;template name=&quot;odd&quot;&gt; &lt;view&gt; odd &lt;/view&gt;&lt;/template&gt;&lt;template name=&quot;even&quot;&gt; &lt;view&gt; even &lt;/view&gt;&lt;/template&gt;&lt;block wx:for=&quot;{{[1, 2, 3, 4, 5]}}&quot;&gt; &lt;template is=&quot;{{item % 2 == 0 ? 'even' : 'odd'}}&quot;/&gt;&lt;/block&gt; 模板的作用域模板拥有自己的作用域，只能使用 data 传入的数据以及模板定义文件中定义的 &lt;wxs /&gt; 模块。 示例代码123456789101112131415161718192021&lt;!--pages/templateTest/templateTest.wxml--&gt;&lt;template name=&quot;msgItem&quot;&gt; &lt;view&gt; &lt;text&gt; {{index}}: {{msg}}&lt;/text&gt; &lt;text&gt; Time: {{time}}&lt;/text&gt; &lt;/view&gt;&lt;/template&gt;&lt;template is=&quot;msgItem&quot; data=&quot;{{...item}}&quot;/&gt;&lt;template name=&quot;odd&quot;&gt; &lt;view&gt; odd &lt;/view&gt;&lt;/template&gt;&lt;template name=&quot;even&quot;&gt; &lt;view&gt; even &lt;/view&gt;&lt;/template&gt;&lt;block wx:for=&quot;{{[1, 2, 3, 4, 5]}}&quot;&gt; &lt;template is=&quot;{{item % 2 == 0 ? 'even' : 'odd'}}&quot;/&gt;&lt;/block&gt; 1234567891011121314// pages/templateTest/templateTest.jsPage({ /** * 页面的初始数据 */ data: { item: { index: 0, msg: 'this is a template', time: '2016-09-15' } }}) 引用WXML 提供两种文件引用方式import和include。 importimport可以在该文件中使用目标文件定义的template，如： 在 item.wxml 中定义了一个叫item的template： 1234&lt;!-- item.wxml --&gt;&lt;template name=&quot;item&quot;&gt; &lt;text&gt;{{text}}&lt;/text&gt;&lt;/template&gt; 在 index.wxml 中引用了 item.wxml，就可以使用item模板： 12&lt;import src=&quot;item.wxml&quot;/&gt;&lt;template is=&quot;item&quot; data=&quot;{{text: 'forbar'}}&quot;/&gt; import 的作用域import 有作用域的概念，即只会 import 目标文件中定义的 template，而不会 import 目标文件 import 的 template。 **如：C import B，B import A，在C中可以使用B定义的template，在B中可以使用A定义的template，但是C不能使用A定义的template**。 12345678910111213&lt;!-- A.wxml --&gt;&lt;template name=&quot;A&quot;&gt; &lt;text&gt; A template &lt;/text&gt;&lt;/template&gt;&lt;!-- B.wxml --&gt;&lt;import src=&quot;a.wxml&quot;/&gt;&lt;template name=&quot;B&quot;&gt; &lt;text&gt; B template &lt;/text&gt;&lt;/template&gt;&lt;!-- C.wxml --&gt;&lt;import src=&quot;b.wxml&quot;/&gt;&lt;template is=&quot;A&quot;/&gt; &lt;!-- Error! Can not use tempalte when not import A. --&gt;&lt;template is=&quot;B&quot;/&gt; includeinclude 可以将目标文件除了 &lt;template/&gt; &lt;wxs/&gt; 外的整个代码引入，相当于是拷贝到 include 位置，如： 12345678&lt;!-- index.wxml --&gt;&lt;include src=&quot;header.wxml&quot;/&gt;&lt;view&gt; body &lt;/view&gt;&lt;include src=&quot;footer.wxml&quot;/&gt;&lt;!-- header.wxml --&gt;&lt;view&gt; header &lt;/view&gt;&lt;!-- footer.wxml --&gt;&lt;view&gt; footer &lt;/view&gt; 事件什么是事件 事件是视图层到逻辑层的通讯方式。 事件可以将用户的行为反馈到逻辑层进行处理。 事件可以绑定在组件上，当达到触发事件，就会执行逻辑层中对应的事件处理函数。 事件对象可以携带额外信息，如 id, dataset, touches。 事件的使用方式 在组件中绑定一个事件处理函数。 如bindtap，当用户点击该组件的时候会在该页面对应的Page中找到相应的事件处理函数。 1&lt;view id=&quot;tapTest&quot; data-hi=&quot;Weixin&quot; bindtap=&quot;tapName&quot;&gt; Click me! &lt;/view&gt; 在相应的Page定义中写上相应的事件处理函数，参数是event。 12345Page({ tapName: function(event) { console.log(event) }}) 事件分类事件分为冒泡事件和非冒泡事件： 冒泡事件：当一个组件上的事件被触发后，该事件会向父节点传递。 非冒泡事件：当一个组件上的事件被触发后，该事件不会向父节点传递。 WXML的冒泡事件列表： 类型 触发条件 最低版本 touchstart 手指触摸动作开始 touchmove 手指触摸后移动 touchcancel 手指触摸动作被打断，如来电提醒，弹窗 touchend 手指触摸动作结束 tap 手指触摸后马上离开 longpress 手指触摸后，超过350ms再离开，如果指定了事件回调函数并触发了这个事件，tap事件将不被触发 1.5.0 longtap 手指触摸后，超过350ms再离开（推荐使用longpress事件代替） transitionend 会在 WXSS transition 或 wx.createAnimation 动画结束后触发 animationstart 会在一个 WXSS animation 动画开始时触发 animationiteration 会在一个 WXSS animation 一次迭代结束时触发 animationend 会在一个 WXSS animation 动画完成时触发 touchforcechange 在支持 3D Touch 的 iPhone 设备，重按时会触发 1.9.90 注：除上表之外的其他组件自定义事件如无特殊声明都是非冒泡事件，如 form 的submit事件，input 的input事件，scroll-view 的scroll事件，(详见各个组件) 绑定并阻止事件冒泡除 bind 外，也可以用 catch 来绑定事件。与 bind 不同， catch 会阻止事件向上冒泡。 例如在下边这个例子中，点击 inner view 会先后调用handleTap3和handleTap2(因为tap事件会冒泡到 middle view，而 middle view 阻止了 tap 事件冒泡，不再向父节点传递)，点击 middle view 会触发handleTap2，点击 outer view 会触发handleTap1。 123456789&lt;view id=&quot;outer&quot; bindtap=&quot;handleTap1&quot;&gt; outer view &lt;view id=&quot;middle&quot; catchtap=&quot;handleTap2&quot;&gt; middle view &lt;view id=&quot;inner&quot; bindtap=&quot;handleTap3&quot;&gt; inner view &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; 示例一实现文本输入框和文本框数据同步，思路： 通过bindinput绑定input事件，通过事件源参数e获取文本输入框数据，最后通过setData方法，设置 num值; 123&lt;!--pages/eventTest1/eventTest1.wxml--&gt;&lt;input type=&quot;text&quot; style=&quot;border: 1px solid; padding: 2px; margin: 2px;&quot; bindinput=&quot;handleInput&quot;/&gt;&lt;text&gt;文本框的值是：{{num}}&lt;/text&gt; 123456789101112131415161718192021// pages/eventTest1/eventTest1.jsPage({ /** * 页面的初始数据 */ data: { num: '' }, /** * input事件处理 * @param {*} e */ handleInput(e){ console.log(e.detail.value); this.setData({ num: e.detail.value }) }}) 示例二实现简单加计算器，思路： 这里我们要用bindtap绑定按钮点击事件;input双向绑定 model:value ; 事件代码里设置total数据; 1234567&lt;!--pages/eventTest2/eventTest2.wxml--&gt;&lt;input type=&quot;text&quot; class=&quot;inputNumber&quot; model:value=&quot;{{numA}}&quot;/&gt;&lt;button&gt;+&lt;/button&gt;&lt;input type=&quot;text&quot; class=&quot;inputNumber&quot; model:value=&quot;{{numB}}&quot;/&gt;&lt;button bindtap=&quot;handleTap&quot;&gt;=&lt;/button&gt;&lt;input type=&quot;text&quot; disabled class=&quot;inputNumber&quot; value=&quot;{{total}}&quot;/&gt; 12345678910111213141516171819202122232425// pages/eventTest2/eventTest2.jsPage({ /** * 页面的初始数据 */ data: { numA: '', numB: '', total: '' }, /** * 按钮点击事件处理 * @param {*}} e 事件源 */ handleTap(e){ console.log(e); console.log(this.data.numA); console.log(this.data.numB); this.setData({ total: parseInt(this.data.numA) + parseInt(this.data.numB) }) }}) 进阶：事件传参通过data- 带参数; 事件里通过e.currentTarget.dataset获取参数值; 1&lt;button bindtap=&quot;handleTap&quot; data-action=&quot;=&quot;&gt;=&lt;/button&gt; 1234567891011121314/** * 按钮点击事件处理 * @param {*}} e 事件源 */ handleTap(e){ console.log(e); let action = e.currentTarget.dataset.action; console.log(action); if(action == &quot;=&quot;){ this.setData({ total: parseInt(this.data.numA) + parseInt(this.data.numB) }) } },","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8FWXML%E6%95%99%E7%A8%8B/"},{"title":"微信小程序WXSS教程","text":"介绍WXSS (WeiXin Style Sheets)是一套样式语言，用于描述 WXML 的组件样式。 WXSS 用来决定 WXML 的组件应该怎么显示。 为了适应广大的前端开发者，WXSS 具有 CSS 大部分特性。同时为了更适合开发微信小程序，WXSS 对 CSS 进行了扩充以及修改。 与 CSS 相比，WXSS 扩展的特性有： 尺寸单位 样式导入 尺寸单位 rpx（responsive pixel）: 可以根据屏幕宽度进行自适应。规定屏幕宽为750rpx。如在 iPhone6 上，屏幕宽度为375px，共有750个物理像素，则750rpx = 375px = 750物理像素，1rpx = 0.5px = 1物理像素。 设备 rpx换算px (屏幕宽度/750) px换算rpx (750/屏幕宽度) iPhone5 1rpx = 0.42px 1px = 2.34rpx iPhone6 1rpx = 0.5px 1px = 2rpx iPhone6 Plus 1rpx = 0.552px 1px = 1.81rpx 建议： 开发微信小程序时设计师可以用 iPhone6 作为视觉稿的标准。 注意： 在较小的屏幕上不可避免的会有一些毛刺，请在开发时尽量避免这种情况。 123&lt;!--pages/rpxTest/rpxTest.wxml--&gt;&lt;text&gt;pages/rpxTest/rpxTest.wxml&lt;/text&gt;&lt;view style=&quot;width:375rpx;height:300rpx;border:1px solid black&quot;&gt;测试RPX&lt;/view&gt; &lt;view style=&quot;width:162px;height:300px;border:1px solid black&quot;&gt;测试PX&lt;/view&gt; 我们发现，用rpx各种机型是等比例缩放的，但是px的话 就是固定的宽度了。 样式导入使用@import语句可以导入外联样式表，@import后跟需要导入的外联样式表的相对路径，用;表示语句结束。 示例代码： 123456/* pages/rpxTest/rpxTest.wxss */@import &quot;../../styles/common.wxss&quot;;text{ font-weight: bolder;} 1234567&lt;!--pages/rpxTest/rpxTest.wxml--&gt;&lt;view style=&quot;width:375rpx;height:300rpx;border:1px solid black&quot;&gt;测试RPX&lt;/view&gt; &lt;view style=&quot;width:162px;height:300px;border:1px solid black&quot;&gt;测试PX&lt;/view&gt;&lt;text&gt;@import测试&lt;/text&gt; 内联样式框架组件上支持使用 style、class 属性来控制组件的样式。 style：静态的样式统一写到 class 中。style 接收动态的样式，在运行时会进行解析，请尽量避免将静态的样式写进 style 中，以免影响渲染速度。 1&lt;view style=&quot;color:{{color}};&quot; /&gt; class：用于指定样式规则，其属性值是样式规则中类选择器名(样式类名)的集合，样式类名不需要带上.，样式类名之间用空格分隔。 1&lt;view class=&quot;normal_view&quot; /&gt; 选择器目前支持的选择器有： 选择器 样例 样例描述 .class .intro 选择所有拥有 class=”intro” 的组件 #id #firstname 选择拥有 id=”firstname” 的组件 element view 选择所有 view 组件 element, element view, checkbox 选择所有文档的 view 组件和所有的 checkbox 组件 ::after view::after 在 view 组件后边插入内容 ::before view::before 在 view 组件前边插入内容 全局样式与局部样式定义在 app.wxss 中的样式为全局样式，作用于每一个页面。在 page 的 wxss 文件中定义的样式为局部样式，只作用在对应的页面，并会覆盖 app.wxss 中相同的选择器。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8FWXSS%E6%95%99%E7%A8%8B/"},{"title":"微信小程序WXS教程","text":"介绍WXS（WeiXin Script）是小程序的一套脚本语言，结合 WXML，可以构建出页面的结构。 WXS 与 JavaScript 是不同的语言，有自己的语法，并不和 JavaScript 一致。 WXS 代码可以编写在 wxml 文件中的 &lt;wxs&gt; 标签内，或以 .wxs 为后缀名的文件内。 模块每一个 .wxs 文件和 &lt;wxs&gt; 标签都是一个单独的模块。 每个模块都有自己独立的作用域。即在一个模块里面定义的变量与函数，默认为私有的，对其他模块不可见。 一个模块要想对外暴露其内部的私有变量与函数，只能通过 module.exports 实现。 &lt;wxs&gt; 标签 属性名 类型 默认值 说明 module String 当前 &lt;wxs&gt; 标签的模块名。必填字段。 src String 引用 .wxs 文件的相对路径。仅当本标签为单闭合标签或标签的内容为空时有效。 module 属性module 属性是当前 &lt;wxs&gt; 标签的模块名。在单个 wxml 文件内，建议其值唯一。有重复模块名则按照先后顺序覆盖（后者覆盖前者）。不同文件之间的 wxs 模块名不会相互覆盖。 module 属性值的命名必须符合下面两个规则： 首字符必须是：字母（a-zA-Z），下划线（_） 剩余字符可以是：字母（a-zA-Z），下划线（_）， 数字（0-9） 每个 wxs 模块均有一个内置的 module 对象。 属性 exports: 通过该属性，可以对外共享本模块的私有变量与函数。 示例： 12345678&lt;!--pages/moduleTest/moduleTest.wxml--&gt;&lt;wxs module=&quot;foo&quot;&gt;var some_msg = &quot;hello world&quot;; module.exports = { msg : some_msg, }&lt;/wxs&gt;&lt;view&gt; {{foo.msg}} &lt;/view&gt; 页面输出： 上面例子声明了一个名字为 foo 的模块，将 some_msg 变量暴露出来，供当前页面使用。 src 属性src 属性可以用来引用其他的 wxs 文件模块。 引用的时候，要注意如下几点： 只能引用 .wxs 文件模块，且必须使用相对路径。 wxs 模块均为单例，wxs 模块在第一次被引用时，会自动初始化为单例对象。多个页面，多个地方，多次引用，使用的都是同一个 wxs 模块对象。 如果一个 wxs 模块在定义之后，一直没有被引用，则该模块不会被解析与运行。 示例代码: 在微信开发者工具里面，右键可以直接创建 .wxs 文件，在其中直接编写 WXS 脚本。 12345678910// /pages/comm.wxsvar foo = &quot;'hello world' from comm.wxs&quot;;var bar = function(d) { return d;}module.exports = { foo: foo, bar: bar}; 上述例子在 /pages/comm.wxs 的文件里面编写了 WXS 代码。该 .wxs 文件可以被其他的 .wxs 文件 或 WXML 中的 &lt;wxs&gt; 标签引用。 wxs标签通过src引入: 12345&lt;!--pages/moduleTest/moduleTest.wxml--&gt;&lt;wxs src=&quot;../../pages/comm.wxs&quot; module=&quot;comm&quot;/&gt;&lt;view&gt;{{comm.msg}}&lt;/view&gt;&lt;view&gt;{{comm.bar(comm.foo)}}&lt;/view&gt; 运行结果： require函数在.wxs模块中引用其他 wxs 文件模块，可以使用 require 函数。 引用的时候，要注意如下几点： 只能引用 .wxs 文件模块，且必须使用相对路径。 wxs 模块均为单例，wxs 模块在第一次被引用时，会自动初始化为单例对象。多个页面，多个地方，多次引用，使用的都是同一个 wxs 模块对象。 如果一个 wxs 模块在定义之后，一直没有被引用，则该模块不会被解析与运行。 1234567891011// /pages/tools.wxsvar foo = &quot;'hello world' from tools.wxs&quot;;var bar = function (d) { return d;}module.exports = { FOO: foo, bar: bar,};module.exports.msg = &quot;some msg&quot;; 1234567// /pages/logic.wxsvar tools = require(&quot;./tools.wxs&quot;);console.log(tools.FOO);console.log(tools.bar(&quot;logic.wxs&quot;));console.log(tools.msg); 123&lt;!--pages/moduleTest/moduleTest.wxml--&gt;&lt;wxs src=&quot;./../logic.wxs&quot; module=&quot;logic&quot;/&gt; 控制台输出： 123'hello world' from tools.wxslogic.wxssome msg 注意事项 &lt;wxs&gt; 模块只能在定义模块的 WXML 文件中被访问到。使用 &lt;include&gt; 或 &lt;import&gt; 时，&lt;wxs&gt; 模块不会被引入到对应的 WXML 文件中。 &lt;template&gt; 标签中，只能使用定义该 &lt;template&gt; 的 WXML 文件中定义的 &lt;wxs&gt; 模块。 变量概念 WXS 中的变量均为值的引用。 没有声明的变量直接赋值使用，会被定义为全局变量。 如果只声明变量而不赋值，则默认值为 undefined。 var表现与javascript一致，会有变量提升。 123var foo = 1;var bar = &quot;hello world&quot;;var i; // i === undefined 上面代码，分别声明了 foo、 bar、 i 三个变量。然后，foo 赋值为数值 1 ，bar 赋值为字符串 &quot;hello world&quot;。 变量名变量命名必须符合下面两个规则： 首字符必须是：字母（a-zA-Z），下划线（_） 剩余字符可以是：字母（a-zA-Z），下划线（_）， 数字（0-9） 保留标识符以下标识符不能作为变量名： 12345678910111213141516171819202122232425262728293031deletevoidtypeofnullundefinedNaNInfinityvarifelsetruefalserequirethisfunctionargumentsreturnforwhiledobreakcontinueswitchcasedefault 注释WXS 主要有 3 种注释的方法。 示例代码： 12345678910111213141516&lt;!-- wxml --&gt;&lt;wxs module=&quot;sample&quot;&gt;// 方法一：单行注释/*方法二：多行注释*//*方法三：结尾注释。即从 /* 开始往后的所有 WXS 代码均被注释var a = 1;var b = 2;var c = &quot;fake&quot;;&lt;/wxs&gt; 上述例子中，所有 WXS 代码均被注释掉了。 方法三 和 方法二 的唯一区别是，没有 */ 结束符。 运算符基本运算符示例代码： 123456789101112var a = 10, b = 20;// 加法运算console.log(30 === a + b);// 减法运算console.log(-10 === a - b);// 乘法运算console.log(200 === a * b);// 除法运算console.log(0.5 === a / b);// 取余运算console.log(10 === a % b); 加法运算（+）也可以用作字符串的拼接。 1234var a = '.w' , b = 'xs';// 字符串拼接console.log('.wxs' === a + b); 一元运算符示例代码： 12345678910111213141516171819202122var a = 10, b = 20;// 自增运算console.log(10 === a++);console.log(12 === ++a);// 自减运算console.log(12 === a--);console.log(10 === --a);// 正值运算console.log(10 === +a);// 负值运算console.log(0-10 === -a);// 否运算console.log(-11 === ~a);// 取反运算console.log(false === !a);// delete 运算console.log(true === delete a.fake);// void 运算console.log(undefined === void a);// typeof 运算console.log(&quot;number&quot; === typeof a); 位运算符示例代码： 1234567891011121314var a = 10, b = 20;// 左移运算console.log(80 === (a &lt;&lt; 3));// 带符号右移运算console.log(2 === (a &gt;&gt; 2));// 无符号右移运算console.log(2 === (a &gt;&gt;&gt; 2));// 与运算console.log(2 === (a &amp; 3));// 异或运算console.log(9 === (a ^ 3));// 或运算console.log(11 === (a | 3)); 比较运算符示例代码： 12345678910var a = 10, b = 20;// 小于console.log(true === (a &lt; b));// 大于console.log(false === (a &gt; b));// 小于等于console.log(true === (a &lt;= b));// 大于等于console.log(false === (a &gt;= b)); 等值运算符示例代码： 12345678910var a = 10, b = 20;// 等号console.log(false === (a == b));// 非等号console.log(true === (a != b));// 全等号console.log(false === (a === b));// 非全等号console.log(true === (a !== b)); 赋值运算符示例代码： 123456789101112131415161718192021222324var a = 10;a = 10; a *= 10;console.log(100 === a);a = 10; a /= 5;console.log(2 === a);a = 10; a %= 7;console.log(3 === a);a = 10; a += 5;console.log(15 === a);a = 10; a -= 11;console.log(-1 === a);a = 10; a &lt;&lt;= 10;console.log(10240 === a);a = 10; a &gt;&gt;= 2;console.log(2 === a);a = 10; a &gt;&gt;&gt;= 2;console.log(2 === a);a = 10; a &amp;= 3;console.log(2 === a);a = 10; a ^= 3;console.log(9 === a);a = 10; a |= 3;console.log(11 === a); 二元逻辑运算符示例代码： 123456var a = 10, b = 20;// 逻辑与console.log(20 === (a &amp;&amp; b));// 逻辑或console.log(10 === (a || b)); 其他运算符示例代码： 123456var a = 10, b = 20;//条件运算符console.log(20 === (a &gt;= 10 ? a + 10 : b + 10));//逗号运算符console.log(20 === (a, b)); 运算符优先级 优先级 运算符 说明 结合性 20 ( … ) 括号 n/a 19 … . … 成员访问 从左到右 … [ … ] 成员访问 从左到右 … ( … ) 函数调用 从左到右 17 … ++ 后置递增 n/a … -- 后置递减 n/a 16 ! … 逻辑非 从右到左 ~ … 按位非 从右到左 + … 一元加法 从右到左 - … 一元减法 从右到左 ++ … 前置递增 从右到左 -- … 前置递减 从右到左 typeof … typeof 从右到左 void … void 从右到左 delete … delete 从右到左 14 … * … 乘法 从左到右 … / … 除法 从左到右 … % … 取模 从左到右 13 … + … 加法 从左到右 … - … 减法 从左到右 12 … &lt;&lt; … 按位左移 从左到右 … &gt;&gt; … 按位右移 从左到右 … &gt;&gt;&gt; … 无符号右移 从左到右 11 … &lt; … 小于 从左到右 … &lt;= … 小于等于 从左到右 … &gt; … 大于 从左到右 … &gt;= … 大于等于 从左到右 10 … == … 等号 从左到右 … != … 非等号 从左到右 … === … 全等号 从左到右 … !== … 非全等号 从左到右 9 … &amp; … 按位与 从左到右 8 … ^ … 按位异或 从左到右 7 … ｜ … 按位或 从左到右 6 … &amp;&amp; … 逻辑与 从左到右 5 … ｜｜ … 逻辑或 从左到右 4 … ? … : … 条件运算符 从右到左 3 … = … 赋值 从右到左 … += … 赋值 从右到左 … -= … 赋值 从右到左 … *= … 赋值 从右到左 … /= … 赋值 从右到左 … %= … 赋值 从右到左 … &lt;&lt;= … 赋值 从右到左 … &gt;&gt;= … 赋值 从右到左 … &gt;&gt;&gt;= … 赋值 从右到左 … &amp;= … 赋值 从右到左 … ^= … 赋值 从右到左 … ｜= … 赋值 从右到左 0 … , … 逗号 从左到右 语句if 语句在 WXS 中，可以使用以下格式的 if 语句 ： if (expression) statement ： 当 expression 为 truthy 时，执行 statement。 if (expression) statement1 else statement2 : 当 expression 为 truthy 时，执行 statement1。 否则，执行 statement2 if ... else if ... else statementN 通过该句型，可以在 statement1 ~ statementN 之间选其中一个执行。 示例语法： 123456789101112131415161718192021222324252627282930313233343536373839// if ...if (表达式) 语句;if (表达式) 语句;if (表达式) { 代码块;}// if ... elseif (表达式) 语句;else 语句;if (表达式) 语句;else 语句;if (表达式) { 代码块;} else { 代码块;}// if ... else if ... else ...if (表达式) { 代码块;} else if (表达式) { 代码块;} else if (表达式) { 代码块;} else { 代码块;} switch 语句示例语法： 1234567891011switch (表达式) { case 变量: 语句; case 数字: 语句; break; case 字符串: 语句; default: 语句;} default 分支可以省略不写。 case 关键词后面只能使用：变量，数字，字符串。 示例代码： 123456789101112131415var exp = 10;switch ( exp ) {case &quot;10&quot;: console.log(&quot;string 10&quot;); break;case 10: console.log(&quot;number 10&quot;); break;case exp: console.log(&quot;var exp&quot;); break;default: console.log(&quot;default&quot;);} 输出： 1number 10 for 语句示例语法： 123456for (语句; 语句; 语句) 语句;for (语句; 语句; 语句) { 代码块;} 支持使用 break，continue 关键词。 示例代码： 1234for (var i = 0; i &lt; 3; ++i) { console.log(i); if( i &gt;= 1) break;} 输出： 1201 while 语句示例语法： 12345678910while (表达式) 语句;while (表达式){ 代码块;}do { 代码块;} while (表达式) 当表达式为 true 时，循环执行语句或代码块。 支持使用 break，continue 关键词。 数据类型WXS 语言目前共有以下几种数据类型： number ： 数值 string ：字符串 boolean：布尔值 object：对象 function：函数 array : 数组 date：日期 regexp：正则 number语法number 包括两种数值：整数，小数。 12var a = 10;var PI = 3.141592653589793; 属性 constructor：返回字符串 &quot;Number&quot;。 方法 toString toLocaleString valueOf toFixed toExponential toPrecision 以上方法的具体使用请参考 ES5 标准。 string语法string 有两种写法： 12'hello world';&quot;hello world&quot;; 属性 constructor：返回字符串 &quot;String&quot;。 length 除constructor外属性的具体含义请参考 ES5 标准。 方法 toString valueOf charAt charCodeAt concat indexOf lastIndexOf localeCompare match replace search slice split substring toLowerCase toLocaleLowerCase toUpperCase toLocaleUpperCase trim 以上方法的具体使用请参考 ES5 标准。 boolean语法布尔值只有两个特定的值：true 和 false。 属性 constructor：返回字符串 &quot;Boolean&quot;。 方法 toString valueOf 以上方法的具体使用请参考 ES5 标准。 object语法object 是一种无序的键值对。使用方法如下所示： 12345678910111213141516171819202122var o = {} //生成一个新的空对象//生成一个新的非空对象o = { 'string' : 1, //object 的 key 可以是字符串 const_var : 2, //object 的 key 也可以是符合变量定义规则的标识符 func : {}, //object 的 value 可以是任何类型};//对象属性的读操作console.log(1 === o['string']);console.log(2 === o.const_var);//对象属性的写操作o['string']++;o['string'] += 10;o.const_var++;o.const_var += 10;//对象属性的读操作console.log(12 === o['string']);console.log(13 === o.const_var); 属性 constructor：返回字符串 &quot;Object&quot;。 1console.log(&quot;Object&quot; === {k:&quot;1&quot;,v:&quot;2&quot;}.constructor) 方法 toString：返回字符串 &quot;[object Object]&quot;。 function语法function 支持以下的定义方式： 123456789//方法 1function a (x) { return x;}//方法 2var b = function (x) { return x;} function 同时也支持以下的语法（匿名函数，闭包等）： 123456var a = function (x) { return function () { return x;}}var b = a(100);console.log( 100 === b() ); argumentsfunction 里面可以使用 arguments 关键词。该关键词目前只支持以下的属性： length: 传递给函数的参数个数。 [index]: 通过 index 下标可以遍历传递给函数的每个参数。 示例代码： 1234567var a = function(){ console.log(3 === arguments.length); console.log(100 === arguments[0]); console.log(200 === arguments[1]); console.log(300 === arguments[2]);};a(100,200,300); 属性 constructor：返回字符串 &quot;Function&quot;。 length：返回函数的形参个数。 方法 toString：返回字符串 &quot;[function Function]&quot;。 示例代码： 12345var func = function (a,b,c) { }console.log(&quot;Function&quot; === func.constructor);console.log(3 === func.length);console.log(&quot;[function Function]&quot; === func.toString()); array语法array 支持以下的定义方式： 123var a = []; //生成一个新的空数组a = [1,&quot;2&quot;,{},function(){}]; //生成一个新的非空数组，数组元素可以是任何类型 属性 constructor：返回字符串 &quot;Array&quot;。 length 除constructor外属性的具体含义请参考 ES5 标准。 方法 toString concat join pop push reverse shift slice sort splice unshift indexOf lastIndexOf every some forEach map filter reduce reduceRight 以上方法的具体使用请参考 ES5 标准。 date语法生成 date 对象需要使用 getDate函数, 返回一个当前时间的对象。 1234getDate()getDate(milliseconds)getDate(datestring)getDate(year, month[, date[, hours[, minutes[, seconds[, milliseconds]]]]]) 参数 milliseconds: 从1970年1月1日00:00:00 UTC开始计算的毫秒数 datestring: 日期字符串，其格式为：”month day, year hours:minutes:seconds” 示例代码： 12345678var date = getDate(); //返回当前时间对象date = getDate(1500000000000);// Fri Jul 14 2017 10:40:00 GMT+0800 (中国标准时间)date = getDate('2017-7-14');// Fri Jul 14 2017 00:00:00 GMT+0800 (中国标准时间)date = getDate(2017, 6, 14, 10, 40, 0, 0);// Fri Jul 14 2017 10:40:00 GMT+0800 (中国标准时间) 属性 constructor：返回字符串 “Date”。 方法 toString toDateString toTimeString toLocaleString toLocaleDateString toLocaleTimeString valueOf getTime getFullYear getUTCFullYear getMonth getUTCMonth getDate getUTCDate getDay getUTCDay getHours getUTCHours getMinutes getUTCMinutes getSeconds getUTCSeconds getMilliseconds getUTCMilliseconds getTimezoneOffset setTime setMilliseconds setUTCMilliseconds setSeconds setUTCSeconds setMinutes setUTCMinutes setHours setUTCHours setDate setUTCDate setMonth setUTCMonth setFullYear setUTCFullYear toUTCString toISOString toJSON 以上方法的具体使用请参考 ES5 标准。 regexp语法生成 regexp 对象需要使用 getRegExp函数。 1getRegExp(pattern[, flags]) 参数： pattern: 正则表达式的内容。 flags:修饰符。该字段只能包含以下字符: g: global i: ignoreCase m: multiline。 示例代码： 12345var a = getRegExp(&quot;x&quot;, &quot;img&quot;);console.log(&quot;x&quot; === a.source);console.log(true === a.global);console.log(true === a.ignoreCase);console.log(true === a.multiline); 属性 constructor：返回字符串 &quot;RegExp&quot;。 source global ignoreCase multiline lastIndex 除constructor外属性的具体含义请参考 ES5 标准。 方法 exec test toString 以上方法的具体使用请参考 ES5 标准。 数据类型判断constructor 属性数据类型的判断可以使用 constructor 属性。 示例代码： 1234567891011121314151617181920212223var number = 10;console.log( &quot;Number&quot; === number.constructor );var string = &quot;str&quot;;console.log( &quot;String&quot; === string.constructor );var boolean = true;console.log( &quot;Boolean&quot; === boolean.constructor );var object = {};console.log( &quot;Object&quot; === object.constructor );var func = function(){};console.log( &quot;Function&quot; === func.constructor );var array = [];console.log( &quot;Array&quot; === array.constructor );var date = getDate();console.log( &quot;Date&quot; === date.constructor );var regexp = getRegExp();console.log( &quot;RegExp&quot; === regexp.constructor ); typeof使用 typeof 也可以区分部分数据类型。 示例代码： 123456789101112131415161718var number = 10;var boolean = true;var object = {};var func = function(){};var array = [];var date = getDate();var regexp = getRegExp();console.log( 'number' === typeof number );console.log( 'boolean' === typeof boolean );console.log( 'object' === typeof object );console.log( 'function' === typeof func );console.log( 'object' === typeof array );console.log( 'object' === typeof date );console.log( 'object' === typeof regexp );console.log( 'undefined' === typeof undefined );console.log( 'object' === typeof null ); 基础类库consoleconsole.log 方法用于在 console 窗口输出信息。它可以接受多个参数，将它们的结果连接起来输出。 Math属性 E LN10 LN2 LOG2E LOG10E PI SQRT1_2 SQRT2 以上属性的具体使用请参考 ES5 标准。 方法 abs acos asin atan atan2 ceil cos exp floor log max min pow random round sin sqrt tan 以上方法的具体使用请参考 ES5 标准。 JSON方法 stringify(object): 将 object 对象转换为 JSON 字符串，并返回该字符串。 parse(string): 将 JSON 字符串转化成对象，并返回该对象。 示例代码： 12345678910111213141516171819console.log(undefined === JSON.stringify());console.log(undefined === JSON.stringify(undefined));console.log(&quot;null&quot;===JSON.stringify(null));console.log(&quot;111&quot;===JSON.stringify(111));console.log('&quot;111&quot;'===JSON.stringify(&quot;111&quot;));console.log(&quot;true&quot;===JSON.stringify(true));console.log(undefined===JSON.stringify(function(){}));console.log(undefined===JSON.parse(JSON.stringify()));console.log(undefined===JSON.parse(JSON.stringify(undefined)));console.log(null===JSON.parse(JSON.stringify(null)));console.log(111===JSON.parse(JSON.stringify(111)));console.log(&quot;111&quot;===JSON.parse(JSON.stringify(&quot;111&quot;)));console.log(true===JSON.parse(JSON.stringify(true)));console.log(undefined===JSON.parse(JSON.stringify(function(){}))); Number属性 MAX_VALUE MIN_VALUE NEGATIVE_INFINITY POSITIVE_INFINITY 以上属性的具体使用请参考 ES5 标准。 Date属性 parse UTC now 以上属性的具体使用请参考 ES5 标准。 Global属性 NaN Infinity undefined 以上属性的具体使用请参考 ES5 标准。 方法 parseInt parseFloat isNaN isFinite decodeURI decodeURIComponent encodeURI encodeURIComponent 以上方法的具体使用请参考 ES5 标准。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8FWXS%E6%95%99%E7%A8%8B/"},{"title":"并发编程-问题总结","text":"基础知识并发编程的优缺点为什么要使用并发编程（并发编程的优点） 充分利用多核CPU的计算能力：通过并发编程的形式可以将多核CPU的计算能力发挥到极致，性能得到提升 方便进行业务拆分，提升系统并发能力和性能：在特殊的业务场景下，先天的就适合于并发编程。现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。面对复杂业务模型，并行程序会比串行程序更适应业务需求，而并发编程更能吻合这种业务拆分 。 并发编程有什么缺点并发编程的目的就是为了能提高程序的执行效率，提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、上下文切换、线程安全、死锁等问题。 并发编程三要素是什么？在 Java 程序中怎么保证多线程的运行安全？并发编程三要素（线程的安全性问题体现在）： 原子性：原子，即一个不可再被分割的颗粒。原子性指的是一个或多个操作要么全部执行成功要么全部执行失败。 可见性：一个线程对共享变量的修改,另一个线程能够立刻看到。（synchronized,volatile） 有序性：程序执行的顺序按照代码的先后顺序执行。（处理器可能会对指令进行重排序） 出现线程安全问题的原因： 线程切换带来的原子性问题 缓存导致的可见性问题 编译优化带来的有序性问题 解决办法： JDK Atomic开头的原子类、synchronized、LOCK，可以解决原子性问题 synchronized、volatile、LOCK，可以解决可见性问题 Happens-Before 规则可以解决有序性问题 并行和并发有什么区别？ 并发：多个任务在同一个 CPU 核上，按细分的时间片轮流(交替)执行，从逻辑上来看那些任务是同时执行。 并行：单位时间内，多个处理器或多核处理器同时处理多个任务，是真正意义上的“同时进行”。 串行：有n个任务，由一个线程按顺序执行。由于任务、方法都在一个线程执行所以不存在线程不安全情况，也就不存在临界区的问题。 做一个形象的比喻： 并发 = 两个队列和一台咖啡机。 并行 = 两个队列和两台咖啡机。 串行 = 一个队列和一台咖啡机。 什么是多线程，多线程的优劣？多线程：多线程是指程序中包含多个执行流，即在一个程序中可以同时运行多个不同的线程来执行不同的任务。 多线程的好处： 可以提高 CPU 的利用率。在多线程程序中，一个线程必须等待的时候，CPU 可以运行其它的线程而不是等待，这样就大大提高了程序的效率。也就是说允许单个程序创建多个并行执行的线程来完成各自的任务。 多线程的劣势： 线程也是程序，所以线程需要占用内存，线程越多占用内存也越多； 多线程需要协调和管理，所以需要 CPU 时间跟踪线程； 线程之间对共享资源的访问会相互影响，必须解决竞用共享资源的问题。 线程和进程区别什么是线程和进程?进程 一个在内存中运行的应用程序。每个进程都有自己独立的一块内存空间，一个进程可以有多个线程，比如在Windows系统中，一个运行的xx.exe就是一个进程。 线程 进程中的一个执行任务（控制单元），负责当前进程中程序的执行。一个进程至少有一个线程，一个进程可以运行多个线程，多个线程可共享数据。 进程与线程的区别线程具有许多传统进程所具有的特征，故又称为轻型进程(Light—Weight Process)或进程元；而把传统的进程称为重型进程(Heavy—Weight Process)，它相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都有若干个线程，至少包含一个线程。 根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位 资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。 包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。 内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的 影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。 执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行 什么是上下文切换?多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。 概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。 Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。 守护线程和用户线程有什么区别呢？守护线程和用户线程 用户 (User) 线程：运行在前台，执行具体的任务，如程序的主线程、连接网络的子线程等都是用户线程 守护 (Daemon) 线程：运行在后台，为其他前台线程服务。也可以说守护线程是 JVM 中非守护线程的 “佣人”。一旦所有用户线程都结束运行，守护线程会随 JVM 一起结束工作 main 函数所在的线程就是一个用户线程啊，main 函数启动的同时在 JVM 内部同时还启动了好多守护线程，比如垃圾回收线程。 比较明显的区别之一是用户线程结束，JVM 退出，不管这个时候有没有守护线程运行。而守护线程不会影响 JVM 的退出。 注意事项： setDaemon(true)必须在start()方法前执行，否则会抛出 IllegalThreadStateException 异常 在守护线程中产生的新线程也是守护线程 不是所有的任务都可以分配给守护线程来执行，比如读写操作或者计算逻辑 守护 (Daemon) 线程中不能依靠 finally 块的内容来确保执行关闭或清理资源的逻辑。因为我们上面也说过了一旦所有用户线程都结束运行，守护线程会随 JVM 一起结束工作，所以守护 (Daemon) 线程中的 finally 语句块可能无法被执行。 守护线程详解守护线程是一种特殊的线程，就和它的名字一样，它是系统的守护者，在后台默默地守护一些系统服务，比如垃圾回收线程，JIT线程就可以理解为守护线程。与之对应的就是用户线程，用户线程就可以认为是系统的工作线程，它会完成整个系统的业务操作。用户线程完全结束后就意味着整个系统的业务任务全部结束了，因此系统就没有对象需要守护的了，守护线程自然而然就会退。当一个Java应用，只有守护线程的时候，虚拟机就会自然退出。下面以一个简单的例子来表述Daemon线程的使用。 123456789101112131415161718192021222324252627public class DaemonDemo { public static void main(String[] args) { Thread daemonThread = new Thread(new Runnable() { @Override public void run() { while (true) { try { System.out.println(&quot;i am alive&quot;); Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } finally { System.out.println(&quot;finally block&quot;); } } } }); daemonThread.setDaemon(true); daemonThread.start(); //确保main线程结束前能给daemonThread能够分到时间片 try { Thread.sleep(800); } catch (InterruptedException e) { e.printStackTrace(); } }} 输出结果为： 123i am alivefinally blocki am alive 上面的例子中daemodThread run()方法中是一个while死循环，会一直打印,但是当main线程结束后daemonThread就会退出所以不会出现死循环的情况。main线程先睡眠800ms保证daemonThread能够拥有一次时间片的机会，也就是说可以正常执行一次打印“i am alive”操作和一次finally块中”finally block”操作。紧接着main 线程结束后，daemonThread退出，这个时候只打印了”i am alive”并没有打印finnal块中的。因此，这里需要注意的是守护线程在退出的时候并不会执行finnaly块中的代码，所以守护 (Daemon) 线程中不能依靠 finally 块的内容来确保执行关闭或清理资源的逻辑 线程可以通过setDaemon(true)的方法将线程设置为守护线程。并且需要注意的是设置守护线程要先于start()方法，否则会报 1Exception in thread &quot;main&quot; java.lang.IllegalThreadStateException 但是该线程还是会执行，只不过会当做正常的用户线程执行。 如何在 Windows 和 Linux 上查找哪个线程cpu利用率最高？windows上面用任务管理器看，linux下可以用 top 这个工具看。 找出cpu耗用厉害的进程pid， 终端执行top命令，然后按下shift+p 查找出cpu利用最厉害的pid号 根据上面第一步拿到的pid号，top -H -p pid 。然后按下shift+p，查找出cpu利用率最厉害的线程号，比如top -H -p 1328 将获取到的线程号转换成16进制，去百度转换一下就行 使用jstack工具将进程信息打印输出，jstack pid号 &gt; /tmp/t.dat，比如jstack 31365 &gt; /tmp/t.dat 编辑/tmp/t.dat文件，查找线程号对应的信息 什么是线程死锁百度百科：死锁是指两个或两个以上的进程（线程）在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程（线程）称为死锁进程（线程）。 多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。 如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。 下面通过一个例子来说明线程死锁，代码模拟了上图的死锁的情况 (代码来源于《并发编程之美》)： 123456789101112131415161718192021222324252627282930313233343536public class DeadLockDemo { private static Object resource1 = new Object();//资源 1 private static Object resource2 = new Object();//资源 2 public static void main(String[] args) { new Thread(() -&gt; { synchronized (resource1) { System.out.println(Thread.currentThread() + &quot;get resource1&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;); synchronized (resource2) { System.out.println(Thread.currentThread() + &quot;get resource2&quot;); } } }, &quot;线程 1&quot;).start(); new Thread(() -&gt; { synchronized (resource2) { System.out.println(Thread.currentThread() + &quot;get resource2&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread() + &quot;waiting get resource1&quot;); synchronized (resource1) { System.out.println(Thread.currentThread() + &quot;get resource1&quot;); } } }, &quot;线程 2&quot;).start(); }} 输出结果 1234Thread[线程 1,5,main]get resource1Thread[线程 2,5,main]get resource2Thread[线程 1,5,main]waiting get resource2Thread[线程 2,5,main]waiting get resource1 线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过Thread.sleep(1000)；让线程 A 休眠 1s 为的是让线程 B 得到CPU执行权，然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。 形成死锁的四个必要条件是什么 互斥条件：线程(进程)对于所分配到的资源具有排它性，即一个资源只能被一个线程(进程)占用，直到被该线程(进程)释放 请求与保持条件：一个线程(进程)因请求被占用资源而发生阻塞时，对已获得的资源保持不放。 不剥夺条件：线程(进程)已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 循环等待条件：当发生死锁时，所等待的线程(进程)必定会形成一个环路（类似于死循环），造成永久阻塞 如何避免线程死锁我们只要破坏产生死锁的四个条件中的其中一个就可以了。 破坏互斥条件 这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。 破坏请求与保持条件 一次性申请所有的资源。 破坏不剥夺条件 占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 破坏循环等待条件 靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。 我们对线程 2 的代码修改成下面这样就不会产生死锁了。 1234567891011121314new Thread(() -&gt; { synchronized (resource1) { System.out.println(Thread.currentThread() + &quot;get resource1&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;); synchronized (resource2) { System.out.println(Thread.currentThread() + &quot;get resource2&quot;); } }}, &quot;线程 2&quot;).start(); 输出结果 123456Thread[线程 1,5,main]get resource1Thread[线程 1,5,main]waiting get resource2Thread[线程 1,5,main]get resource2Thread[线程 2,5,main]get resource1Thread[线程 2,5,main]waiting get resource2Thread[线程 2,5,main]get resource2 我们分析一下上面的代码为什么避免了死锁的发生? 线程 1 首先获得到 resource1 的监视器锁，这时候线程 2 就获取不到了。然后线程 1 再去获取 resource2 的监视器锁，可以获取到。然后线程 1 释放了对 resource1、resource2 的监视器锁的占用，线程 2 获取到就可以执行了。这样就破坏了破坏循环等待条件，因此避免了死锁。 创建线程的四种方式创建线程有哪几种方式？创建线程有四种方式： 继承 Thread 类； 实现 Runnable 接口； 实现 Callable 接口； 使用 Executors 工具类创建线程池 继承 Thread 类步骤 定义一个Thread类的子类，重写run方法，将相关逻辑实现，run()方法就是线程要执行的业务逻辑方法 创建自定义的线程子类对象 调用子类实例的star()方法来启动线程 123456789101112131415161718public class MyThread extends Thread { @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot; run()方法正在执行...&quot;); }}public class TheadTest { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); System.out.println(Thread.currentThread().getName() + &quot; main()方法执行结束&quot;); }} 运行结果 12main main()方法执行结束Thread-0 run()方法正在执行... 实现 Runnable 接口步骤 定义Runnable接口实现类MyRunnable，并重写run()方法 创建MyRunnable实例myRunnable，以myRunnable作为target创建Thead对象，该Thread对象才是真正的线程对象 调用线程对象的start()方法 1234567891011121314151617181920public class MyRunnable implements Runnable { @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot; run()方法执行中...&quot;); }}public class RunnableTest { public static void main(String[] args) { MyRunnable myRunnable = new MyRunnable(); Thread thread = new Thread(myRunnable); thread.start(); System.out.println(Thread.currentThread().getName() + &quot; main()方法执行完成&quot;); }} 执行结果 12main main()方法执行完成Thread-0 run()方法执行中... 实现 Callable 接口步骤 创建实现Callable接口的类myCallable，并重写call()方法 以myCallable实例为参数创建FutureTask对象 将FutureTask作为参数创建Thread对象 调用线程对象的start()方法 123456789101112131415161718192021222324252627282930public class MyCallable implements Callable&lt;Integer&gt; { @Override public Integer call() { System.out.println(Thread.currentThread().getName() + &quot; call()方法执行中...&quot;); return 1; }}public class CallableTest { public static void main(String[] args) { FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new MyCallable()); Thread thread = new Thread(futureTask); thread.start(); try { Thread.sleep(1000); System.out.println(&quot;返回结果 &quot; + futureTask.get()); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + &quot; main()方法执行完成&quot;); }} 执行结果 123Thread-0 call()方法执行中...返回结果 1main main()方法执行完成 使用 Executors 工具类创建线程池Executors提供了一系列工厂方法用于创先线程池，返回的线程池都实现了ExecutorService接口。 主要有newFixedThreadPool，newCachedThreadPool，newSingleThreadExecutor，newScheduledThreadPool 123456789101112131415161718192021222324public class MyRunnable implements Runnable { @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot; run()方法执行中...&quot;); }}public class SingleThreadExecutorTest { public static void main(String[] args) { ExecutorService executorService = Executors.newSingleThreadExecutor(); MyRunnable runnableTest = new MyRunnable(); for (int i = 0; i &lt; 5; i++) { executorService.execute(runnableTest); } System.out.println(&quot;线程任务开始执行&quot;); executorService.shutdown(); }} 执行结果 123456线程任务开始执行pool-1-thread-1 is running...pool-1-thread-1 is running...pool-1-thread-1 is running...pool-1-thread-1 is running...pool-1-thread-1 is running... 说一下 runnable 和 callable 有什么区别？相同点 都是接口 都可以编写多线程程序 都采用Thread.start()启动线程 主要区别 Runnable 接口 run 方法无返回值；Callable 接口 call 方法有返回值，是个泛型，和Future、FutureTask配合可以用来获取异步执行的结果 Runnable 接口 run 方法只能抛出运行时异常，且无法捕获处理；Callable 接口 call 方法允许抛出异常，可以获取异常信息 注：Callalbe接口支持返回执行结果，需要调用FutureTask.get()得到，此方法会阻塞主进程的继续往下执行，如果不调用不会阻塞。 什么是 Callable 和 Future?Callable 接口类似于 Runnable，从名字就可以看出来了，但是 Runnable 不会返回结果，并且无法抛出返回结果的异常，而 Callable 功能更强大一些，被线程执行后，可以返回值，这个返回值可以被 Future 拿到，也就是说，Future 可以拿到异步执行任务的返回值。 Future 接口表示异步任务，是一个可能还没有完成的异步任务的结果。所以说 Callable用于产生结果，Future 用于获取结果。 什么是 FutureTaskFutureTask 表示一个异步运算的任务。FutureTask 里面可以传入一个 Callable 的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。只有当运算完成的时候结果才能取回，如果运算尚未完成 get 方法将会阻塞。一个 FutureTask 对象可以对调用了 Callable 和 Runnable 的对象进行包装，由于 FutureTask 也是Runnable 接口的实现类，所以 FutureTask 也可以放入线程池中。 线程的状态和基本操作说说线程的生命周期及五种基本状态？ **新建(new)**：新创建了一个线程对象。 **可运行(runnable)**：线程对象创建后，当调用线程对象的 start()方法，该线程处于就绪状态，等待被线程调度选中，获取cpu的使用权。 **运行(running)**：可运行状态(runnable)的线程获得了cpu时间片（timeslice），执行程序代码。注：就绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中； **阻塞(block)**：处于运行状态中的线程由于某种原因，暂时放弃对 CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才 有机会再次被 CPU 调用以进入到运行状态。 阻塞的情况分三种：(一). 等待阻塞：运行状态中的线程执行 wait()方法，JVM会把该线程放入等待队列(waitting queue)中，使本线程进入到等待阻塞状态；(二). 同步阻塞：线程在获取 synchronized 同步锁失败(因为锁被其它线程所占用)，则JVM会把该线程放入锁池(lock pool)中，线程会进入同步阻塞状态；(三). 其他阻塞: 通过调用线程的 sleep()或 join()或发出了 I/O 请求时，线程会进入到阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O 处理完毕时，线程重新转入就绪状态。 **死亡(dead)**：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。 Java 中用到的线程调度算法是什么？计算机通常只有一个 CPU，在任意时刻只能执行一条机器指令，每个线程只有获得CPU 的使用权才能执行指令。所谓多线程的并发运行，其实是指从宏观上看，各个线程轮流获得 CPU 的使用权，分别执行各自的任务。在运行池中，会有多个处于就绪状态的线程在等待 CPU，JAVA 虚拟机的一项任务就是负责线程的调度，线程调度是指按照特定机制为多个线程分配 CPU 的使用权。 有两种调度模型：分时调度模型和抢占式调度模型。 分时调度模型是指让所有的线程轮流获得 cpu 的使用权，并且平均分配每个线程占用的 CPU 的时间片这个也比较好理解。 Java虚拟机采用抢占式调度模型，是指优先让可运行池中优先级高的线程占用CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用CPU。处于运行状态的线程会一直运行，直至它不得不放弃 CPU。 什么是线程调度器(Thread Scheduler)和时间分片(Time Slicing )？线程调度器是一个操作系统服务，它负责为 Runnable 状态的线程分配 CPU 时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。 时间分片是指将可用的 CPU 时间分配给可用的 Runnable 线程的过程。分配 CPU 时间可以基于线程优先级或者线程等待的时间。 线程调度并不受到 Java 虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。 线程的调度策略线程调度器选择优先级最高的线程运行，但是，如果发生以下情况，就会终止线程的运行： （1）线程体中调用了 yield 方法让出了对 cpu 的占用权利 （2）线程体中调用了 sleep 方法使线程进入睡眠状态 （3）线程由于 IO 操作受到阻塞 （4）另外一个更高优先级线程出现 （5）在支持时间片的系统中，该线程的时间片用完 Thread 类中的 yield 方法有什么作用？使当前线程从执行状态（运行状态）变为可执行态（就绪状态）。 当前线程到了就绪状态，那么接下来哪个线程会从就绪状态变成执行状态呢？可能是当前线程，也可能是其他线程，看系统的分配了。 为什么 Thread 类的 sleep()和 yield ()方法是静态的？Thread 类的 sleep()和 yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。 线程的 sleep()方法和 yield()方法有什么区别？（1） sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会； （2） 线程执行 sleep()方法后转入阻塞（blocked）状态，而执行 yield()方法后转入就绪（ready）状态； （3）sleep()方法声明抛出 InterruptedException，而 yield()方法没有声明任何异常； （4）sleep()方法比 yield()方法（跟操作系统 CPU 调度相关）具有更好的可移植性，通常不建议使用yield()方法来控制并发线程的执行。 请说出与线程同步以及线程调度相关的方法。（1） wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁； （2）sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理 InterruptedException 异常； （3）notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由 JVM 确定唤醒哪个线程，而且与优先级无关； （4）notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态； sleep() 和 wait() 有什么区别？两者都可以暂停线程的执行 类的不同：sleep() 是 Thread线程类的静态方法，wait() 是 Object类的方法。 是否释放锁：sleep() 不释放锁；wait() 释放锁。 用途不同：Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。 用法不同：wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用wait(long timeout)超时后线程会自动苏醒。 你是如何调用 wait() 方法的？使用 if 块还是循环？为什么？处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。 wait() 方法应该在循环调用，因为当线程获取到 CPU 开始执行的时候，其他条件可能还没有满足，所以在处理前，循环检测条件是否满足会更好。下面是一段标准的使用 wait 和 notify 方法的代码： 12345678synchronized (monitor) { // 判断条件谓词是否得到满足 while(!locked) { // 等待唤醒 monitor.wait(); } // 处理其他的业务逻辑} 为什么线程通信的方法 wait(), notify()和 notifyAll()被定义在 Object 类里？Java中，任何对象都可以作为锁，并且 wait()，notify()等方法用于等待对象的锁或者唤醒线程，在 Java 的线程中并没有可供任何对象使用的锁，所以任意对象调用方法一定定义在Object类中。 wait(), notify()和 notifyAll()这些方法在同步代码块中调用 有的人会说，既然是线程放弃对象锁，那也可以把wait()定义在Thread类里面啊，新定义的线程继承于Thread类，也不需要重新定义wait()方法的实现。然而，这样做有一个非常大的问题，一个线程完全可以持有很多锁，你一个线程放弃锁的时候，到底要放弃哪个锁？当然了，这种设计并不是不能实现，只是管理起来更加复杂。 综上所述，wait()、notify()和notifyAll()方法要定义在Object类中。 为什么 wait(), notify()和 notifyAll()必须在同步方法或者同步块中被调用？当一个线程需要调用对象的 wait()方法的时候，这个线程必须拥有该对象的锁，接着它就会释放这个对象锁并进入等待状态直到其他线程调用这个对象上的 notify()方法。同样的，当一个线程需要调用对象的 notify()方法时，它会释放这个对象的锁，以便其他在等待的线程就可以得到这个对象锁。由于所有的这些方法都需要线程持有对象的锁，这样就只能通过同步来实现，所以他们只能在同步方法或者同步块中被调用。 如何停止一个正在运行的线程？在java中有以下3种方法可以终止正在运行的线程： 使用退出标志，使线程正常退出，也就是当run方法完成后线程终止。 使用stop方法强行终止，但是不推荐这个方法，因为stop和suspend及resume一样都是过期作废的方法。 使用interrupt方法中断线程。 Java 中 interrupted 和 isInterrupted 方法的区别？interrupt：用于中断线程。调用该方法的线程的状态为将被置为”中断”状态。 注意：线程中断仅仅是置线程的中断状态位，不会停止线程。需要用户自己去监视线程的状态为并做处理。支持线程中断的方法（也就是线程中断后会抛出interruptedException 的方法）就是在监视线程的中断状态，一旦线程的中断状态被置为“中断状态”，就会抛出中断异常。 interrupted：是静态方法，查看当前中断信号是true还是false并且清除中断信号。如果一个线程被中断了，第一次调用 interrupted 则返回 true，第二次和后面的就返回 false 了。 isInterrupted：查看当前中断信号是true还是false 什么是阻塞式方法？阻塞式方法是指程序会一直等待该方法完成期间不做其他事情，ServerSocket 的accept()方法就是一直等待客户端连接。这里的阻塞是指调用结果返回之前，当前线程会被挂起，直到得到结果之后才会返回。此外，还有异步和非阻塞式方法在任务完成前就返回。 Java 中你怎样唤醒一个阻塞的线程？首先 ，wait()、notify() 方法是针对对象的，调用任意对象的 wait()方法都将导致线程阻塞，阻塞的同时也将释放该对象的锁，相应地，调用任意对象的 notify()方法则将随机解除该对象阻塞的线程，但它需要重新获取该对象的锁，直到获取成功才能往下执行； 其次，wait、notify 方法必须在 synchronized 块或方法中被调用，并且要保证同步块或方法的锁对象与调用 wait、notify 方法的对象是同一个，如此一来在调用 wait 之前当前线程就已经成功获取某对象的锁，执行 wait 阻塞后当前线程就将之前获取的对象锁释放。 notify() 和 notifyAll() 有什么区别？如果线程调用了对象的 wait()方法，那么线程便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁。 notifyAll() 会唤醒所有的线程，notify() 只会唤醒一个线程。 notifyAll() 调用后，会将全部线程由等待池移到锁池，然后参与锁的竞争，竞争成功则继续执行，如果不成功则留在锁池等待锁被释放后再次参与竞争。而 notify()只会唤醒一个线程，具体唤醒哪一个线程由虚拟机控制。 如何在两个线程间共享数据？在两个线程间共享变量即可实现共享。 一般来说，共享变量要求变量本身是线程安全的，然后在线程内使用的时候，如果有对共享变量的复合操作，那么也得保证复合操作的线程安全性。 Java 如何实现多线程之间的通讯和协作？可以通过中断 和 共享变量的方式实现线程间的通讯和协作 比如说最经典的生产者-消费者模型：当队列满时，生产者需要等待队列有空间才能继续往里面放入商品，而在等待的期间内，生产者必须释放对临界资源（即队列）的占用权。因为生产者如果不释放对临界资源的占用权，那么消费者就无法消费队列中的商品，就不会让队列有空间，那么生产者就会一直无限等待下去。因此，一般情况下，当队列满时，会让生产者交出对临界资源的占用权，并进入挂起状态。然后等待消费者消费了商品，然后消费者通知生产者队列有空间了。同样地，当队列空时，消费者也必须等待，等待生产者通知它队列中有商品了。这种互相通信的过程就是线程间的协作。 Java中线程通信协作的最常见的两种方式： 一.syncrhoized加锁的线程的Object类的wait()、notify()、notifyAll() 二.ReentrantLock类加锁的线程的Condition类的await()、signal()、signalAll() 线程间直接的数据交换： 三.通过管道进行线程间通信：1）字节流；2）字符流 同步方法和同步块，哪个是更好的选择？同步块是更好的选择，因为它不会锁住整个对象（当然你也可以让它锁住整个对象）。同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。 同步块更要符合开放调用的原则，只在需要锁住的代码块锁住相应的对象，这样从侧面来说也可以避免死锁。 请知道一条原则：同步的范围越小越好。 什么是线程同步和线程互斥，有哪几种实现方式？当一个线程对共享的数据进行操作时，应使之成为一个”原子操作“，即在没有完成相关操作之前，不允许其他线程打断它，否则，就会破坏数据的完整性，必然会得到错误的处理结果，这就是线程的同步。 在多线程应用中，考虑不同线程之间的数据同步和防止死锁。当两个或多个线程之间同时等待对方释放资源的时候就会形成线程之间的死锁。为了防止死锁的发生，需要通过同步来实现线程安全。 线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。 线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。 用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。内核模式下的方法有：事件，信号量，互斥量。 实现线程同步的方法 同步代码方法：sychronized 关键字修饰的方法 同步代码块：sychronized 关键字修饰的代码块 使用特殊变量域volatile实现线程同步：volatile关键字为域变量的访问提供了一种免锁机制 使用重入锁实现线程同步：reentrantlock类是可重入、互斥、实现了lock接口的锁，它与sychronized方法具有相同的基本行为和语义 在监视器(Monitor)内部，是如何做线程同步的？程序应该做哪种级别的同步？在 java 虚拟机中，每个对象( Object 和 class )通过某种逻辑关联监视器,每个监视器和一个对象引用相关联，为了实现监视器的互斥功能，每个对象都关联着一把锁。 一旦方法或者代码块被 synchronized 修饰，那么这个部分就放入了监视器的监视区域，确保一次只能有一个线程执行该部分的代码，线程在获取锁之前不允许执行该部分的代码 另外 java 还提供了显式监视器( Lock )和隐式监视器( synchronized )两种锁方案 如果你提交任务时，线程池队列已满，这时会发生什么这里区分一下： （1）如果使用的是无界队列 LinkedBlockingQueue，也就是无界队列的话，没关系，继续添加任务到阻塞队列中等待执行，因为 LinkedBlockingQueue 可以近乎认为是一个无穷大的队列，可以无限存放任务 （2）如果使用的是有界队列比如 ArrayBlockingQueue，任务首先会被添加到ArrayBlockingQueue 中，ArrayBlockingQueue 满了，会根据maximumPoolSize 的值增加线程数量，如果增加了线程数量还是处理不过来，ArrayBlockingQueue 继续满，那么则会使用拒绝策略RejectedExecutionHandler 处理满了的任务，默认是 AbortPolicy 什么叫线程安全？servlet 是线程安全吗?线程安全是编程中的术语，指某个方法在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。 Servlet 不是线程安全的，servlet 是单实例多线程的，当多个线程同时访问同一个方法，是不能保证共享变量的线程安全性的。 Struts2 的 action 是多实例多线程的，是线程安全的，每个请求过来都会 new 一个新的 action 分配给这个请求，请求完成后销毁。 SpringMVC 的 Controller 是线程安全的吗？不是的，和 Servlet 类似的处理流程。 Struts2 好处是不用考虑线程安全问题；Servlet 和 SpringMVC 需要考虑线程安全问题，但是性能可以提升不用处理太多的 gc[垃圾回收器(garbage colector)]，可以使用 ThreadLocal 来处理多线程的问题。 在 Java 程序中怎么保证多线程的运行安全？ 方法一：使用安全类，比如 java.util.concurrent 下的类，使用原子类AtomicInteger 方法二：使用自动锁 synchronized。 方法三：使用手动锁 Lock。 手动锁 Java 示例代码如下： 12345678910Lock lock = new ReentrantLock();lock.lock();try { System. out. println(&quot;获得锁&quot;);} catch (Exception e) { // TODO: handle exception} finally { System. out. println(&quot;释放锁&quot;); lock.unlock();} 你对线程优先级的理解是什么？每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个 int 变量(从 1-10)，1 代表最低优先级，10 代表最高优先级。 Java 的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，如非特别需要，一般无需设置线程优先级。 线程类的构造方法、静态块是被哪个线程调用的这是一个非常刁钻和狡猾的问题。请记住：线程类的构造方法、静态块是被 new这个线程类所在的线程所调用的，而 run 方法里面的代码才是被线程自身所调用的。 如果说上面的说法让你感到困惑，那么我举个例子，假设 Thread2 中 new 了Thread1，main 函数中 new 了 Thread2，那么： （1）Thread2 的构造方法、静态块是 main 线程调用的，Thread2 的 run()方法是Thread2 自己调用的 （2）Thread1 的构造方法、静态块是 Thread2 调用的，Thread1 的 run()方法是Thread1 自己调用的 Java 中怎么获取一份线程 dump 文件？你如何在 Java 中获取线程堆栈？Dump文件是进程的内存镜像。可以把程序的执行状态通过调试器保存到dump文件中。 在 Linux 下，你可以通过命令 kill -3 PID （Java 进程的进程 ID）来获取 Java应用的 dump 文件。 在 Windows 下，你可以按下 Ctrl + Break 来获取。这样 JVM 就会将线程的 dump 文件打印到标准输出或错误文件中，它可能打印在控制台或者日志文件中，具体位置依赖应用的配置。 一个线程运行时发生异常会怎样？如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候，JVM 会使用Thread.getUncaughtExceptionHandler()来查询线程的 UncaughtExceptionHandler 并将线程和异常作为参数传递给 handler 的 uncaughtException()方法进行处理。 Java 线程数过多会造成什么异常？ 线程的生命周期开销非常高 消耗过多的 CPU 资源如果可运行的线程数量多于可用处理器的数量，那么有线程将会被闲置。大量空闲的线程会占用许多内存，给垃圾回收器带来压力，而且大量的线程在竞争 CPU资源时还将产生其他性能的开销。 降低稳定性JVM 在可创建线程的数量上存在一个限制，这个限制值将随着平台的不同而不同，并且承受着多个因素制约，包括 JVM 的启动参数、Thread 构造函数中请求栈的大小，以及底层操作系统对线程的限制等。如果破坏了这些限制，那么可能抛出OutOfMemoryError 异常。 并发理论Java内存模型Java中垃圾回收有什么目的？什么时候进行垃圾回收？垃圾回收是在内存中存在没有引用的对象或超过作用域的对象时进行的。 垃圾回收的目的是识别并且丢弃应用不再使用的对象来释放和重用资源。 如果对象的引用被置为null，垃圾收集器是否会立即释放对象占用的内存？不会，在下一个垃圾回调周期中，这个对象将是被可回收的。 也就是说并不会立即被垃圾收集器立刻回收，而是在下一次垃圾回收时才会释放其占用的内存。 finalize()方法什么时候被调用？析构函数(finalization)的目的是什么？1）垃圾回收器（garbage colector）决定回收某对象时，就会运行该对象的finalize()方法；finalize是Object类的一个方法，该方法在Object类中的声明 protected void finalize() throws Throwable { }在垃圾回收器执行时会调用被回收对象的finalize()方法，可以覆盖此方法来实现对其资源的回收。注意：一旦垃圾回收器准备释放对象占用的内存，将首先调用该对象的finalize()方法，并且下一次垃圾回收动作发生时，才真正回收对象占用的内存空间 2）GC本来就是内存回收了，应用还需要在finalization做什么呢？ 答案是大部分时候，什么都不用做(也就是不需要重载)。只有在某些很特殊的情况下，比如你调用了一些native的方法(一般是C写的)，可以要在finaliztion里去调用C的释放函数。 重排序与数据依赖性为什么代码会重排序？在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，不是你想怎么排序就怎么排序，它需要满足以下两个条件： 在单线程环境下不能改变程序运行的结果； 存在数据依赖关系的不允许重排序 需要注意的是：重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义。 as-if-serial规则和happens-before规则的区别 as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。 as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。 as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。 并发关键字synchronizedsynchronized 的作用？在 Java 中，synchronized 关键字是用来控制线程同步的，就是在多线程的环境下，控制 synchronized 代码段不被多个线程同时执行。synchronized 可以修饰类、方法、变量。 另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗synchronized关键字最主要的三种使用方式： 修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁 修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。 修饰代码块: 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 总结： synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！ 下面我以一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。 面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！” 双重校验锁实现对象单例（线程安全） 1234567891011121314151617181920public class Singleton { private volatile static Singleton uniqueInstance; private Singleton() { } public static Singleton getUniqueInstance() { //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) { //类对象加锁 synchronized (Singleton.class) { if (uniqueInstance == null) { uniqueInstance = new Singleton(); } } } return uniqueInstance; }} 另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。 uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行： 为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将 uniqueInstance 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。 使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。 说一下 synchronized 底层实现原理？synchronized是Java中的一个关键字，在使用的过程中并没有看到显示的加锁和解锁过程。因此有必要通过javap命令，查看相应的字节码文件。 synchronized 同步语句块的情况 1234567public class SynchronizedDemo { public void method() { synchronized (this) { System.out.println(&quot;synchronized 代码块&quot;); } }} 通过JDK 反汇编指令 javap -c -v SynchronizedDemo 可以看出在执行同步代码块之前之后都有一个monitor字样，其中前面的是monitorenter，后面的是离开monitorexit，不难想象一个线程也执行同步代码块，首先要获取锁，而获取锁的过程就是monitorenter ，在执行完代码块之后，要释放锁，释放锁就是执行monitorexit指令。 为什么会有两个monitorexit呢？ 这个主要是防止在同步代码块中线程因异常退出，而锁没有得到释放，这必然会造成死锁（等待的线程永远获取不到锁）。因此最后一个monitorexit是保证在异常情况下，锁也可以得到释放，避免死锁。仅有ACC_SYNCHRONIZED这么一个标志，该标记表明线程进入该方法时，需要monitorenter，退出该方法时需要monitorexit。 synchronized可重入的原理 重入锁是指一个线程获取到该锁之后，该线程可以继续获得该锁。底层原理维护一个计数器，当线程获取该锁时，计数器加一，再次获得该锁时继续加一，释放锁时，计数器减一，当计数器值为0时，表明该锁未被任何线程所持有，其它线程可以竞争获取锁。 什么是自旋很多 synchronized 里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然 synchronized 里面的代码执行得非常快，不妨让等待锁的线程不要被阻塞，而是在 synchronized 的边界做忙循环，这就是自旋。如果做了多次循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。 多线程中 synchronized 锁升级的原理是什么？synchronized 锁升级原理：在锁对象的对象头里面有一个 threadid 字段，在第一次访问的时候 threadid 为空，jvm 让其持有偏向锁，并将 threadid 设置为其线程 id，再次进入的时候会先判断 threadid 是否与其线程 id 一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 synchronized 锁的升级。 锁的升级的目的：锁升级是为了减低了锁带来的性能消耗。在 Java 6 之后优化 synchronized 的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。 线程 B 怎么知道线程 A 修改了变量（1）volatile 修饰变量 （2）synchronized 修饰修改变量的方法 （3）wait/notify （4）while 轮询 当一个线程进入一个对象的 synchronized 方法 A 之后，其它线程是否可进入此对象的 synchronized 方法 B？不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的 synchronized 修饰符要求执行方法时要获得对象的锁，如果已经进入A 方法说明对象锁已经被取走，那么试图进入 B 方法的线程就只能在等锁池（注意不是等待池哦）中等待对象的锁。 synchronized、volatile、CAS 比较（1）synchronized 是悲观锁，属于抢占式，会引起其他线程阻塞。 （2）volatile 提供多线程共享变量可见性和禁止指令重排序优化。 （3）CAS 是基于冲突检测的乐观锁（非阻塞） synchronized 和 Lock 有什么区别？ 首先synchronized是Java内置关键字，在JVM层面，Lock是个Java类； synchronized 可以给类、方法、代码块加锁；而 lock 只能给代码块加锁。 synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁；而 lock 需要自己加锁和释放锁，如果使用不当没有 unLock()去释放锁就会造成死锁。 当线程进入到synchronized方法或者synchronized代码块时，线程切换到的是BLOCKED(线程阻塞)状态，而使用java.util.concurrent.locks下lock进行加锁的时候线程切换的是WAITING(等待状态)或者TIMED_WAITING(超时等待)状态，因为lock会调用LockSupport的方法。 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。 synchronized 和 ReentrantLock 区别是什么？synchronized 是和 if、else、for、while 一样的关键字，ReentrantLock 是类，这是二者的本质区别。既然 ReentrantLock 是类，那么它就提供了比synchronized 更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量 synchronized 早期的实现比较低效，对比 ReentrantLock，大多数场景性能都相差较大，但是在 Java 6 中对 synchronized 进行了非常多的改进。 相同点：两者都是可重入锁 两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。 主要区别如下： ReentrantLock 使用起来比较灵活，但是必须有释放锁的配合动作； ReentrantLock 必须手动获取与释放锁，而 synchronized 不需要手动释放和开启锁； ReentrantLock 只适用于代码块锁，而 synchronized 可以修饰类、方法、变量等。 二者的锁机制其实也是不一样的。ReentrantLock 底层调用的是 Unsafe 的park 方法加锁，synchronized 操作的应该是对象头中 mark word Java中每一个对象都可以作为锁，这是synchronized实现同步的基础： 普通同步方法，锁是当前实例对象 静态同步方法，锁是当前类的class对象 同步方法块，锁是括号里面的对象 volatilevolatile 关键字的作用对于可见性，Java 提供了 volatile 关键字来保证可见性和禁止指令重排。 volatile 提供 happens-before 的保证，确保一个线程的修改能对其他线程是可见的。当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 从实践角度而言，volatile 的一个重要作用就是和 CAS 结合，保证了原子性，详细的可以参见 java.util.concurrent.atomic 包下的类，比如 AtomicInteger。 volatile 常用于多线程环境下的单次操作(单次读或者单次写)。 Java 中能创建 volatile 数组吗？能，Java 中可以创建 volatile 类型数组，不过只是一个指向数组的引用，而不是整个数组。意思是，如果改变引用指向的数组，将会受到 volatile 的保护，但是如果多个线程同时改变数组的元素，volatile 标示符就不能起到之前的保护作用了。 volatile 变量和 atomic 变量有什么不同？volatile 变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用 volatile 修饰 count 变量，那么 count++ 操作就不是原子性的。 而 AtomicInteger 类提供的 atomic 方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。 volatile 能使得一个非原子操作变成原子操作吗？关键字volatile的主要作用是使变量在多个线程间可见，但无法保证原子性，对于多个线程访问同一个实例变量需要加锁进行同步。 虽然volatile只能保证可见性不能保证原子性，但用volatile修饰long和double可以保证其操作原子性。 所以从Oracle Java Spec里面可以看到： 对于64位的long和double，如果没有被volatile修饰，那么对其操作可以不是原子的。在操作的时候，可以分成两步，每次对32位操作。 如果使用volatile修饰long和double，那么其读写都是原子操作 对于64位的引用地址的读写，都是原子操作 在实现JVM时，可以自由选择是否把读写long和double作为原子操作 推荐JVM实现为原子操作 volatile 修饰符的有过什么实践？单例模式 是否 Lazy 初始化：是 是否多线程安全：是 实现难度：较复杂 描述：对于Double-Check这种可能出现的问题（当然这种概率已经非常小了，但毕竟还是有的嘛~），解决方案是：只需要给instance的声明加上volatile关键字即可volatile关键字的一个作用是禁止指令重排，把instance声明为volatile之后，对它的写操作就会有一个内存屏障（什么是内存屏障？），这样，在它的赋值完成之前，就不用会调用读操作。注意：volatile阻止的不是singleton = newSingleton()这句话内部[1-2-3]的指令重排，而是保证了在一个写操作（[1-2-3]）完成之前，不会调用读操作（if (instance == null)）。 12345678910111213141516171819public class Singleton7 { private static volatile Singleton7 instance = null; private Singleton7() {} public static Singleton7 getInstance() { if (instance == null) { synchronized (Singleton7.class) { if (instance == null) { instance = new Singleton7(); } } } return instance; }} synchronized 和 volatile 的区别是什么？synchronized 表示只有一个线程可以获取作用对象的锁，执行代码，阻塞其他线程。 volatile 表示变量在 CPU 的寄存器中是不确定的，必须从主存中读取。保证多线程环境下变量的可见性；禁止指令重排序。 区别 volatile 是变量修饰符；synchronized 可以修饰类、方法、变量。 volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的修改可见性和原子性。 volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。 volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。 volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。 final什么是不可变对象，它对写并发应用有什么帮助？不可变对象(Immutable Objects)即对象一旦被创建它的状态（对象的数据，也即对象属性值）就不能改变，反之即为可变对象(Mutable Objects)。 不可变对象的类即为不可变类(Immutable Class)。Java 平台类库中包含许多不可变类，如 String、基本类型的包装类、BigInteger 和 BigDecimal 等。 只有满足如下状态，一个对象才是不可变的； 它的状态不能在创建后再被修改； 所有域都是 final 类型；并且，它被正确创建（创建期间没有发生 this 引用的逸出）。 不可变对象保证了对象的内存可见性，对不可变对象的读取不需要进行额外的同步手段，提升了代码执行效率。 Lock体系Lock简介与初识AQSJava Concurrency API 中的 Lock 接口(Lock interface)是什么？对比同步它有什么优势？Lock 接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。 它的优势有： （1）可以使锁更公平 （2）可以使线程在等待锁的时候响应中断 （3）可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间 （4）可以在不同的范围，以不同的顺序获取和释放锁 整体上来说 Lock 是 synchronized 的扩展版，Lock 提供了无条件的、可轮询的(tryLock 方法)、定时的(tryLock 带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition 方法)锁操作。另外 Lock 的实现类基本都支持非公平锁(默认)和公平锁，synchronized 只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。 乐观锁和悲观锁的理解及如何实现，有哪些实现方式？悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如 Java 里面的同步原语 synchronized 关键字的实现也是悲观锁。 乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于 write_condition 机制，其实都是提供的乐观锁。在 Java中 java.util.concurrent.atomic 包下面的原子变量类就是使用了乐观锁的一种实现方式 CAS 实现的。 乐观锁的实现方式： 1、使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略。 2、java 中的 Compare and Swap 即 CAS ，当多个线程尝试使用 CAS 同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS 操作中包含三个操作数 —— 需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值(B)。如果内存位置 V 的值与预期原值 A 相匹配，那么处理器会自动将该位置值更新为新值 B。否则处理器不做任何操作。 什么是 CASCAS 是 compare and swap 的缩写，即我们所说的比较交换。 cas 是一种基于锁的操作，而且是乐观锁。在 java 中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加 version 来获取数据，性能较悲观锁有很大的提高。 CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和 A 的值是一样的，那么就将内存里面的值更新成 B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a 线程获取地址里面的值被b 线程修改了，那么 a 线程需要自旋，到下次循环才有可能机会执行。 java.util.concurrent.atomic 包下的类大多是使用 CAS 操作来实现的(AtomicInteger,AtomicBoolean,AtomicLong)。 CAS 的会产生什么问题？1、ABA 问题： 比如说一个线程 one 从内存位置 V 中取出 A，这时候另一个线程 two 也从内存中取出 A，并且 two 进行了一些操作变成了 B，然后 two 又将 V 位置的数据变成 A，这时候线程 one 进行 CAS 操作发现内存中仍然是 A，然后 one 操作成功。尽管线程 one 的 CAS 操作成功，但可能存在潜藏的问题。从 Java1.5 开始 JDK 的 atomic包里提供了一个类 AtomicStampedReference 来解决 ABA 问题。 2、循环时间长开销大： 对于资源竞争严重（线程冲突严重）的情况，CAS 自旋的概率会比较大，从而浪费更多的 CPU 资源，效率低于 synchronized。 3、只能保证一个共享变量的原子操作： 当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候就可以用锁。 什么是死锁？当线程 A 持有独占锁a，并尝试去获取独占锁 b 的同时，线程 B 持有独占锁 b，并尝试获取独占锁 a 的情况下，就会发生 AB 两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。 产生死锁的条件是什么？怎么防止死锁？产生死锁的必要条件： 1、互斥条件：所谓互斥就是进程在某一时间内独占资源。 2、请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 3、不剥夺条件：进程已获得资源，在末使用完之前，不能强行剥夺。 4、循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。 这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之 一不满足，就不会发生死锁。 理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和 解除死锁。 防止死锁可以采用以下的方法： 尽量使用 tryLock(long timeout, TimeUnit unit)的方法(ReentrantLock、ReentrantReadWriteLock)，设置超时时间，超时可以退出防止死锁。 尽量使用 Java. util. concurrent 并发类代替自己手写锁。 尽量降低锁的使用粒度，尽量不要几个功能用同一把锁。 尽量减少同步的代码块。 死锁与活锁的区别，死锁与饥饿的区别？死锁：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。 活锁：任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。 活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，这就是所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。 饥饿：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。 Java 中导致饥饿的原因： 1、高优先级线程吞噬所有的低优先级线程的 CPU 时间。 2、线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。 3、线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的 wait 方法)，因为其他线程总是被持续地获得唤醒。 多线程锁的升级原理是什么？在Java中，锁共有4种状态，级别从低到高依次为：无状态锁，偏向锁，轻量级锁和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级。 AQS(AbstractQueuedSynchronizer)详解与源码分析AQS 介绍AQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。 AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。 AQS 原理分析下面大部分内容其实在AQS类注释上已经给出了，不过是英语看着比较吃力一点，感兴趣的话可以看看源码。 AQS 原理概览 AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。 看个AQS(AbstractQueuedSynchronizer)原理图： AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。 12private volatile int state;//共享变量，使用volatile修饰保证线程可见性1 状态信息通过protected类型的getState，setState，compareAndSetState进行操作 123456789101112//返回同步状态的当前值protected final int getState() { return state;} // 设置同步状态的值protected final void setState(int newState) { state = newState;}//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) { return unsafe.compareAndSwapInt(this, stateOffset, expect, update);} AQS 对资源的共享方式 AQS定义两种资源共享方式 Exclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。 ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。 AQS底层使用了模板方法模式 同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）： 使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放） 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。 这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用。 AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法： 12345isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。 默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 ReentrantLock(重入锁)实现原理与公平锁非公平锁区别什么是可重入锁（ReentrantLock）？ReentrantLock重入锁，是实现Lock接口的一个类，也是在实际编程中使用频率很高的一个锁，支持重入性，表示能够对共享资源能够重复加锁，即当前线程获取该锁再次获取不会被阻塞。 在java关键字synchronized隐式支持重入性，synchronized通过获取自增，释放自减的方式实现重入。与此同时，ReentrantLock还支持公平锁和非公平锁两种方式。那么，要想完完全全的弄懂ReentrantLock的话，主要也就是ReentrantLock同步语义的学习：1. 重入性的实现原理；2. 公平锁和非公平锁。 重入性的实现原理 要想支持重入性，就要解决两个问题：1. 在线程获取锁的时候，如果已经获取锁的线程是当前线程的话则直接再次获取成功；2. 由于锁会被获取n次，那么只有锁在被释放同样的n次之后，该锁才算是完全释放成功。 ReentrantLock支持两种锁：公平锁和非公平锁。何谓公平性，是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求上的绝对时间顺序，满足FIFO。 读写锁ReentrantReadWriteLock源码分析ReadWriteLock 是什么首先明确一下，不是说 ReentrantLock 不好，只是 ReentrantLock 某些时候有局限。如果使用 ReentrantLock，可能本身是为了防止线程 A 在写数据、线程 B 在读数据造成的数据不一致，但这样，如果线程 C 在读数据、线程 D 也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。因为这个，才诞生了读写锁 ReadWriteLock。 ReadWriteLock 是一个读写锁接口，读写锁是用来提升并发程序性能的锁分离技术，ReentrantReadWriteLock 是 ReadWriteLock 接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。 而读写锁有以下三个重要的特性： （1）公平选择性：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平优于公平。 （2）重进入：读锁和写锁都支持线程重进入。 （3）锁降级：遵循获取写锁、获取读锁再释放写锁的次序，写锁能够降级成为读锁。 Condition源码分析与等待通知机制LockSupport详解并发容器并发容器之ConcurrentHashMap详解(JDK1.8版本)与源码分析什么是ConcurrentHashMap？ConcurrentHashMap是Java中的一个线程安全且高效的HashMap实现。平时涉及高并发如果要用map结构，那第一时间想到的就是它。相对于hashmap来说，ConcurrentHashMap就是线程安全的map，其中利用了锁分段的思想提高了并发度。 那么它到底是如何实现线程安全的？ JDK 1.6版本关键要素： segment继承了ReentrantLock充当锁的角色，为每一个segment提供了线程安全的保障； segment维护了哈希散列表的若干个桶，每个桶由HashEntry构成的链表。 JDK1.8后，ConcurrentHashMap抛弃了原有的Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。 Java 中 ConcurrentHashMap 的并发度是什么？ConcurrentHashMap 把实际 map 划分成若干部分来实现它的可扩展性和线程安全。这种划分是使用并发度获得的，它是 ConcurrentHashMap 类构造函数的一个可选参数，默认值为 16，这样在多线程情况下就能避免争用。 在 JDK8 后，它摒弃了 Segment（锁段）的概念，而是启用了一种全新的方式实现,利用 CAS 算法。同时加入了更多的辅助变量来提高并发度，具体内容还是查看源码吧。 什么是并发容器的实现？何为同步容器：可以简单地理解为通过 synchronized 来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。比如 Vector，Hashtable，以及 Collections.synchronizedSet，synchronizedList 等方法返回的容器。可以通过查看 Vector，Hashtable 等这些同步容器的实现代码，可以看到这些容器实现线程安全的方式就是将它们的状态封装起来，并在需要同步的方法上加上关键字 synchronized。 并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性，例如在 ConcurrentHashMap 中采用了一种粒度更细的加锁机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问 map，并且执行读操作的线程和写操作的线程也可以并发的访问 map，同时允许一定数量的写操作线程并发地修改 map，所以它可以在并发环境下实现更高的吞吐量。 Java 中的同步集合与并发集合有什么区别？同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。在 Java1.5 之前程序员们只有同步集合来用且在多线程并发的时候会导致争用，阻碍了系统的扩展性。Java5 介绍了并发集合像ConcurrentHashMap，不仅提供线程安全还用锁分离和内部分区等现代技术提高了可扩展性。 SynchronizedMap 和 ConcurrentHashMap 有什么区别？SynchronizedMap 一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为 map。 ConcurrentHashMap 使用分段锁来保证在多线程下的性能。 ConcurrentHashMap 中则是一次锁住一个桶。ConcurrentHashMap 默认将hash 表分为 16 个桶，诸如 get，put，remove 等常用操作只锁当前需要用到的桶。 这样，原来只能一个线程进入，现在却能同时有 16 个写线程执行，并发性能的提升是显而易见的。 另外 ConcurrentHashMap 使用了一种不同的迭代方式。在这种迭代方式中，当iterator 被创建后集合再发生改变就不再是抛出ConcurrentModificationException，取而代之的是在改变时 new 新的数据从而不影响原有的数据，iterator 完成后再将头指针替换为新的数据 ，这样 iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变。 并发容器之CopyOnWriteArrayList详解CopyOnWriteArrayList 是什么，可以用于什么应用场景？有哪些优缺点？CopyOnWriteArrayList 是一个并发容器。有很多人称它是线程安全的，我认为这句话不严谨，缺少一个前提条件，那就是非复合场景下操作它是线程安全的。 CopyOnWriteArrayList(免锁容器)的好处之一是当多个迭代器同时遍历和修改这个列表时，不会抛出 ConcurrentModificationException。在CopyOnWriteArrayList 中，写入将导致创建整个底层数组的副本，而源数组将保留在原地，使得复制的数组在被修改时，读取操作可以安全地执行。 CopyOnWriteArrayList 的使用场景 通过源码分析，我们看出它的优缺点比较明显，所以使用场景也就比较明显。就是合适读多写少的场景。 CopyOnWriteArrayList 的缺点 由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致 young gc 或者 full gc。 不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个 set 操作后，读取到数据可能还是旧的，虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求。 由于实际使用中可能没法保证 CopyOnWriteArrayList 到底要放置多少数据，万一数据稍微有点多，每次 add/set 都要重新复制数组，这个代价实在太高昂了。在高性能的互联网应用中，这种操作分分钟引起故障。 CopyOnWriteArrayList 的设计思想 读写分离，读和写分开 最终一致性 使用另外开辟空间的思路，来解决并发冲突 并发容器之ThreadLocal详解ThreadLocal 是什么？有哪些使用场景？ThreadLocal 是一个本地线程副本变量工具类，在每个线程中都创建了一个 ThreadLocalMap 对象，简单说 ThreadLocal 就是一种以空间换时间的做法，每个线程可以访问自己内部 ThreadLocalMap 对象内的 value。通过这种方式，避免资源在多线程间共享。 原理：线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java提供ThreadLocal类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如 web 服务器）使用线程局部变量的时候要特别小心，在这种情况下，工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java 应用就存在内存泄露的风险。 经典的使用场景是为每个线程分配一个 JDBC 连接 Connection。这样就可以保证每个线程的都在各自的 Connection 上进行数据库的操作，不会出现 A 线程关了 B线程正在使用的 Connection； 还有 Session 管理 等问题。 ThreadLocal 使用例子： 123456789101112131415161718192021222324252627282930313233343536public class TestThreadLocal { //线程本地存储变量 private static final ThreadLocal&lt;Integer&gt; THREAD_LOCAL_NUM = new ThreadLocal&lt;Integer&gt;() { @Override protected Integer initialValue() { return 0; } }; public static void main(String[] args) { for (int i = 0; i &lt;3; i++) {//启动三个线程 Thread t = new Thread() { @Override public void run() { add10ByThreadLocal(); } }; t.start(); } } /** * 线程本地存储变量加 5 */ private static void add10ByThreadLocal() { for (int i = 0; i &lt;5; i++) { Integer n = THREAD_LOCAL_NUM.get(); n += 1; THREAD_LOCAL_NUM.set(n); System.out.println(Thread.currentThread().getName() + &quot; : ThreadLocal num=&quot; + n); } } } 打印结果：启动了 3 个线程，每个线程最后都打印到 “ThreadLocal num=5”，而不是 num 一直在累加直到值等于 15 123456789101112131415Thread-0 : ThreadLocal num=1Thread-1 : ThreadLocal num=1Thread-0 : ThreadLocal num=2Thread-0 : ThreadLocal num=3Thread-1 : ThreadLocal num=2Thread-2 : ThreadLocal num=1Thread-0 : ThreadLocal num=4Thread-2 : ThreadLocal num=2Thread-1 : ThreadLocal num=3Thread-1 : ThreadLocal num=4Thread-2 : ThreadLocal num=3Thread-0 : ThreadLocal num=5Thread-2 : ThreadLocal num=4Thread-2 : ThreadLocal num=5Thread-1 : ThreadLocal num=5 什么是线程局部变量？线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java 提供 ThreadLocal 类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如 web 服务器）使用线程局部变量的时候要特别小心，在这种情况下，工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java 应用就存在内存泄露的风险。 ThreadLocal内存泄漏分析与解决方案ThreadLocal造成内存泄漏的原因？ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法 ThreadLocal内存泄漏解决方案？ 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。 在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。 并发容器之BlockingQueue详解什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者-消费者模型？阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。 这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。 阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。 JDK7 提供了 7 个阻塞队列。分别是： ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。 PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。 DelayQueue：一个使用优先级队列实现的无界阻塞队列。 SynchronousQueue：一个不存储元素的阻塞队列。 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。 Java 5 之前实现同步存取时，可以使用普通的一个集合，然后在使用线程的协作和线程同步可以实现生产者，消费者模式，主要的技术就是用好，wait,notify,notifyAll,sychronized 这些关键字。而在 java 5 之后，可以使用阻塞队列来实现，此方式大大简少了代码量，使得多线程编程更加容易，安全方面也有保障。 BlockingQueue 接口是 Queue 的子接口，它的主要用途并不是作为容器，而是作为线程同步的的工具，因此他具有一个很明显的特性，当生产者线程试图向 BlockingQueue 放入元素时，如果队列已满，则线程被阻塞，当消费者线程试图从中取出一个元素时，如果队列为空，则该线程会被阻塞，正是因为它所具有这个特性，所以在程序中多个线程交替向 BlockingQueue 中放入元素，取出元素，它可以很好的控制线程之间的通信。 阻塞队列使用最经典的场景就是 socket 客户端数据的读取和解析，读取数据的线程不断将数据放入队列，然后解析线程不断从队列取数据解析。 并发容器之ConcurrentLinkedQueue详解与源码分析并发容器之ArrayBlockingQueue与LinkedBlockingQueue详解线程池Executors类创建四种常见线程池什么是线程池？有哪几种创建方式？ 池化技术相比大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。 在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。在 Java 中更是如此，虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。 线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。Java 5+中的 Executor 接口定义一个执行线程的工具。它的子类型即线程池接口是 ExecutorService。要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，因此在工具类 Executors 面提供了一些静态工厂方法，生成一些常用的线程池，如下所示： （1）newSingleThreadExecutor：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 （2）newFixedThreadPool：创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。如果希望在服务器上使用线程池，建议使用 newFixedThreadPool方法来创建线程池，这样能获得更好的性能。 （3） newCachedThreadPool：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60 秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说 JVM）能够创建的最大线程大小。 （4）newScheduledThreadPool：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 线程池有什么优点？ 降低资源消耗：重用存在的线程，减少对象创建销毁的开销。 提高响应速度。可有效的控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 附加功能：提供定时执行、定期执行、单线程、并发数控制等功能。 综上所述使用线程池框架 Executor 能更好的管理线程、提供系统资源使用率。 线程池都有哪些状态？ RUNNING：这是最正常的状态，接受新的任务，处理等待队列中的任务。 SHUTDOWN：不接受新的任务提交，但是会继续处理等待队列中的任务。 STOP：不接受新的任务提交，不再处理等待队列中的任务，中断正在执行任务的线程。 TIDYING：所有的任务都销毁了，workCount 为 0，线程池的状态在转换为 TIDYING 状态时，会执行钩子方法 terminated()。 TERMINATED：terminated()方法结束后，线程池的状态就会变成这个。 什么是 Executor 框架？为什么使用 Executor 框架？Executor 框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。 每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的，而且无限制的创建线程会引起应用程序内存溢出。 所以创建一个线程池是个更好的的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。利用Executors 框架可以非常方便的创建一个线程池。 在 Java 中 Executor 和 Executors 的区别？ Executors 工具类的不同方法按照我们的需求创建了不同的线程池，来满足业务的需求。 Executor 接口对象能执行我们的线程任务。 ExecutorService 接口继承了 Executor 接口并进行了扩展，提供了更多的方法我们能获得任务执行的状态并且可以获取任务的返回值。 使用 ThreadPoolExecutor 可以创建自定义线程池。 Future 表示异步计算的结果，他提供了检查计算是否完成的方法，以等待计算的完成，并可以使用 get()方法获取计算的结果。 线程池中 submit() 和 execute() 方法有什么区别？接收参数：execute()只能执行 Runnable 类型的任务。submit()可以执行 Runnable 和 Callable 类型的任务。 返回值：submit()方法可以返回持有计算结果的 Future 对象，而execute()没有 异常处理：submit()方便Exception处理 什么是线程组，为什么在 Java 中不推荐使用？ThreadGroup 类，可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程，这样的组织结构有点类似于树的形式。 线程组和线程池是两个不同的概念，他们的作用完全不同，前者是为了方便线程的管理，后者是为了管理线程的生命周期，复用线程，减少创建销毁线程的开销。 为什么不推荐使用线程组？因为使用有很多的安全隐患吧，没有具体追究，如果需要使用，推荐使用线程池。 线程池之ThreadPoolExecutor详解Executors和ThreaPoolExecutor创建线程池的区别《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 各个方法的弊端： newFixedThreadPool 和 newSingleThreadExecutor:主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至 OOM。 newCachedThreadPool 和 newScheduledThreadPool:主要问题是线程数最大数是 Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至 OOM。 ThreaPoolExecutor创建线程池方式只有一种，就是走它的构造函数，参数自己指定 你知道怎么创建线程池吗？创建线程池的方式有多种，这里你只需要答 ThreadPoolExecutor 即可。 ThreadPoolExecutor() 是最原始的线程池创建，也是阿里巴巴 Java 开发手册中明确规范的创建线程池的方式。 ThreadPoolExecutor构造函数重要参数分析ThreadPoolExecutor 3 个最重要的参数： corePoolSize ：核心线程数，线程数定义了最小可以同时运行的线程数量。 maximumPoolSize ：线程池中允许存在的工作线程的最大数量 **workQueue**：当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，任务就会被存放在队列中。 ThreadPoolExecutor其他常见参数: **keepAliveTime**：线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁； unit ：keepAliveTime 参数的时间单位。 **threadFactory**：为线程池提供创建新线程的线程工厂 handler ：线程池任务队列超过 maxinumPoolSize 之后的拒绝策略 ThreadPoolExecutor饱和策略ThreadPoolExecutor 饱和策略定义: 如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，ThreadPoolTaskExecutor 定义一些策略: **ThreadPoolExecutor.AbortPolicy**：抛出 RejectedExecutionException来拒绝新任务的处理。 **ThreadPoolExecutor.CallerRunsPolicy**：调用执行自己的线程运行任务。您不会任务请求。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。 **ThreadPoolExecutor.DiscardPolicy**：不处理新任务，直接丢弃掉。 **ThreadPoolExecutor.DiscardOldestPolicy**： 此策略将丢弃最早的未处理的任务请求。 举个例子： Spring 通过 ThreadPoolTaskExecutor 或者我们直接通过 ThreadPoolExecutor 的构造函数创建线程池的时候，当我们不指定 RejectedExecutionHandler 饱和策略的话来配置线程池的时候默认使用的是 ThreadPoolExecutor.AbortPolicy。在默认情况下，ThreadPoolExecutor 将抛出 RejectedExecutionException 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 对于可伸缩的应用程序，建议使用 ThreadPoolExecutor.CallerRunsPolicy。当最大池被填满时，此策略为我们提供可伸缩队列。（这个直接查看 ThreadPoolExecutor 的构造函数源码就可以看出，比较简单的原因，这里就不贴代码了） 一个简单的线程池Demo:Runnable+ThreadPoolExecutor线程池实现原理 为了让大家更清楚上面的面试题中的一些概念，我写了一个简单的线程池 Demo。 首先创建一个 Runnable 接口的实现类（当然也可以是 Callable 接口，我们上面也说了两者的区别。） 123456789101112131415161718192021222324252627282930313233import java.util.Date;/** * 这是一个简单的Runnable类，需要大约5秒钟来执行其任务。 */public class MyRunnable implements Runnable { private String command; public MyRunnable(String s) { this.command = s; } @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot; Start. Time = &quot; + new Date()); processCommand(); System.out.println(Thread.currentThread().getName() + &quot; End. Time = &quot; + new Date()); } private void processCommand() { try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } } @Override public String toString() { return this.command; }} 编写测试程序，我们这里以阿里巴巴推荐的使用 ThreadPoolExecutor 构造函数自定义参数的方式来创建线程池。 1234567891011121314151617181920212223242526272829303132333435import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class ThreadPoolExecutorDemo { private static final int CORE_POOL_SIZE = 5; private static final int MAX_POOL_SIZE = 10; private static final int QUEUE_CAPACITY = 100; private static final Long KEEP_ALIVE_TIME = 1L; public static void main(String[] args) { //使用阿里巴巴推荐的创建线程池的方式 //通过ThreadPoolExecutor构造函数自定义参数创建 ThreadPoolExecutor executor = new ThreadPoolExecutor( CORE_POOL_SIZE, MAX_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(QUEUE_CAPACITY), new ThreadPoolExecutor.CallerRunsPolicy()); for (int i = 0; i &lt; 10; i++) { //创建WorkerThread对象（WorkerThread类实现了Runnable 接口） Runnable worker = new MyRunnable(&quot;&quot; + i); //执行Runnable executor.execute(worker); } //终止线程池 executor.shutdown(); while (!executor.isTerminated()) { } System.out.println(&quot;Finished all threads&quot;); }} 可以看到我们上面的代码指定了： corePoolSize: 核心线程数为 5。 maximumPoolSize ：最大线程数 10 keepAliveTime : 等待时间为 1L。 unit: 等待时间的单位为 TimeUnit.SECONDS。 workQueue：任务队列为 ArrayBlockingQueue，并且容量为 100; handler:饱和策略为 CallerRunsPolicy。 Output： 1234567891011121314151617181920pool-1-thread-2 Start. Time = Tue Nov 12 20:59:44 CST 2019pool-1-thread-5 Start. Time = Tue Nov 12 20:59:44 CST 2019pool-1-thread-4 Start. Time = Tue Nov 12 20:59:44 CST 2019pool-1-thread-1 Start. Time = Tue Nov 12 20:59:44 CST 2019pool-1-thread-3 Start. Time = Tue Nov 12 20:59:44 CST 2019pool-1-thread-5 End. Time = Tue Nov 12 20:59:49 CST 2019pool-1-thread-3 End. Time = Tue Nov 12 20:59:49 CST 2019pool-1-thread-2 End. Time = Tue Nov 12 20:59:49 CST 2019pool-1-thread-4 End. Time = Tue Nov 12 20:59:49 CST 2019pool-1-thread-1 End. Time = Tue Nov 12 20:59:49 CST 2019pool-1-thread-2 Start. Time = Tue Nov 12 20:59:49 CST 2019pool-1-thread-1 Start. Time = Tue Nov 12 20:59:49 CST 2019pool-1-thread-4 Start. Time = Tue Nov 12 20:59:49 CST 2019pool-1-thread-3 Start. Time = Tue Nov 12 20:59:49 CST 2019pool-1-thread-5 Start. Time = Tue Nov 12 20:59:49 CST 2019pool-1-thread-2 End. Time = Tue Nov 12 20:59:54 CST 2019pool-1-thread-3 End. Time = Tue Nov 12 20:59:54 CST 2019pool-1-thread-4 End. Time = Tue Nov 12 20:59:54 CST 2019pool-1-thread-5 End. Time = Tue Nov 12 20:59:54 CST 2019pool-1-thread-1 End. Time = Tue Nov 12 20:59:54 CST 2019 线程池之ScheduledThreadPoolExecutor详解FutureTask详解原子操作类什么是原子操作？在 Java Concurrency API 中有哪些原子类(atomic classes)？原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。 处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。在 Java 中可以通过锁和循环 CAS 的方式来实现原子操作。 CAS 操作——Compare &amp; Set，或是 Compare &amp; Swap，现在几乎所有的 CPU 指令都支持 CAS 的原子操作。 原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。 int++并不是一个原子操作，所以当一个线程读取它的值并加 1 时，另外一个线程有可能会读到之前的值，这就会引发错误。 为了解决这个问题，必须保证增加操作是原子的，在 JDK1.5 之前我们可以使用同步技术来做到这一点。到 JDK1.5，java.util.concurrent.atomic 包提供了 int 和long 类型的原子包装类，它们可以自动的保证对于他们的操作是原子的并且不需要使用同步。 java.util.concurrent 这个包里面提供了一组原子类。其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由 JVM 从等待队列中选择另一个线程进入，这只是一种逻辑上的理解。 原子类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference 原子数组：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray 原子属性更新器：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater 解决 ABA 问题的原子类：AtomicMarkableReference（通过引入一个 boolean来反映中间有没有变过），AtomicStampedReference（通过引入一个 int 来累加来反映中间有没有变过） 说一下 atomic 的原理？Atomic包中的类基本的特性就是在多线程环境下，当有多个线程同时对单个（包括基本类型及引用类型）变量进行操作时，具有排他性，即当多个线程同时对该变量的值进行更新时，仅有一个线程能成功，而未成功的线程可以向自旋锁一样，继续尝试，一直等到执行成功。 AtomicInteger 类的部分源码： 123456789101112// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）private static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); }}private volatile int value; AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。 并发工具并发工具之CountDownLatch与CyclicBarrier在 Java 中 CycliBarriar 和 CountdownLatch 有什么区别？CountDownLatch与CyclicBarrier都是用于控制并发的工具类，都可以理解成维护的就是一个计数器，但是这两者还是各有不同侧重点的： CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；CountDownLatch强调一个线程等多个线程完成某件事情。CyclicBarrier是多个线程互等，等大家都完成，再携手共进。 调用CountDownLatch的countDown方法后，当前线程并不会阻塞，会继续往下执行；而调用CyclicBarrier的await方法，会阻塞当前线程，直到CyclicBarrier指定的线程全部都到达了指定点的时候，才能继续往下执行； CountDownLatch方法比较少，操作比较简单，而CyclicBarrier提供的方法更多，比如能够通过getNumberWaiting()，isBroken()这些方法获取当前多个线程的状态，并且CyclicBarrier的构造方法可以传入barrierAction，指定当所有线程都到达时执行的业务功能； CountDownLatch是不能复用的，而CyclicLatch是可以复用的。 并发工具之Semaphore与ExchangerSemaphore 有什么作用Semaphore 就是一个信号量，它的作用是限制某段代码块的并发数。Semaphore有一个构造函数，可以传入一个 int 型整数 n，表示某段代码最多只有 n 个线程可以访问，如果超出了 n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果 Semaphore 构造函数中传入的 int 型整数 n=1，相当于变成了一个 synchronized 了。 Semaphore(信号量)-允许多个线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。 什么是线程间交换数据的工具ExchangerExchanger是一个用于线程间协作的工具类，用于两个线程间交换数据。它提供了一个交换的同步点，在这个同步点两个线程能够交换数据。交换数据是通过exchange方法来实现的，如果一个线程先执行exchange方法，那么它会同步等待另一个线程也执行exchange方法，这个时候两个线程就都达到了同步点，两个线程就可以交换数据。 常用的并发工具类有哪些？ Semaphore(信号量)-允许多个线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。 CountDownLatch(倒计时器)： CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。 CyclicBarrier(循环栅栏)： CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。 并发实践参考：https://blog.csdn.net/ThinkWon","link":"/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"},{"title":"微信小程序后端Java接口开发","text":"HelloWorld实现SpringBoot项目提供helloworld接口HelloWorldController.java12345678910111213/** * @comment: * @author: buubiu * @create: 2021/11/26 13:59 */@RestControllerpublic class HelloWorldController { @GetMapping(&quot;/helloworld&quot;) public String helloworld(Integer id) { return &quot;helloworld &quot; + id; }} application.yml123456server: port: 80 servlet: context-path: / tomcat: uri-encoding: utf-8 浏览器访问:http://localhost/helloWorld?id=1 页面显示: helloWorld 1 新建helloworld微信小程序请求后端通过微信小程序API wx.request调用后端接口 helloworld.js12345678910111213141516171819202122232425262728293031323334353637// pages/helloworld/helloworld.jsPage({ /** * 页面的初始数据 */ data: { result: &quot;请求后台中...&quot; }, /** * 生命周期函数--监听页面加载 */ onLoad: function (options) { var that = this; this.getData(that); }, getData(that){ wx.request({ url: 'http://localhost/helloworld', method: 'GET', data: { id: 222 }, header: { 'content-type': 'application/json' }, success(res){ console.log(res.data); that.setData({ result: res.data }) } }) }}) helloworld.wxml12&lt;!--pages/helloworld/helloworld.wxml--&gt;&lt;text&gt;后端返回的数据：{{result}}&lt;/text&gt; 运行报错： 这里我们需要设置下: 详情-&gt;本地设置-&gt;勾选 “不校验合法域名、web-view (业务域名)、TLS版本以及HITPS证书” 开发环境配置域名 参考： https://developers.weixin.qq.com/miniprogram/dev/framework/ability/network.html 服务器域名请在 「小程序后台-开发-开发设置-服务器域名」 中进行配置，配置时需要注意： 域名只支持 https (wx.request、wx.uploadFile、wx.downloadFile) 和 wss (wx.connectSocket) 协议； 域名不能使用 IP 地址（小程序的局域网 IP 除外）或 localhost； 可以配置端口，如 https://myserver.com:8080，但是配置后只能向 https://myserver.com:8080 发起请求。如果向 https://myserver.com、https://myserver.com:9091 等 URL 请求则会失败。 如果不配置端口。如 https://myserver.com，那么请求的 URL 中也不能包含端口，甚至是默认的 443 端口也不可以。如果向 https://myserver.com:443 请求则会失败。 域名必须经过 ICP 备案； 出于安全考虑，api.weixin.qq.com 不能被配置为服务器域名，相关API也不能在小程序内调用。 开发者应将 AppSecret 保存到后台服务器中，通过服务器使用 getAccessToken 接口获取 access_token，并调用相关 API； 不支持配置父域名，使用子域名。 图书搜索实现模拟实现一个微信小程序端关键字图书，然后显示图书列表的功能，如下图: 实现大体思路，前端用户输入关键字，通过 bindtap 事件，事件里得到用户输入的关键字，通过 wx.request请求后端，后端返回json数据，最后页面通过wx:for遍历显示图书信息; 具体实现步骤: 后端实现后端实现接口，传入参数，模拟返回图书json数据 Book.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.buubiu.entity;/** * @comment: * @author: buubiu * @create: 2021/11/26 15:53 */public class Book { /** * 编号 */ private Integer id; /** * 图书名称 */ private String title; /** * 作者 */ private String author; /** * 价格 */ private float price; /** * 图片名称 */ private String image; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getTitle() { return title; } public void setTitle(String title) { this.title = title; } public String getAuthor() { return author; } public void setAuthor(String author) { this.author = author; } public float getPrice() { return price; } public void setPrice(float price) { this.price = price; } public String getImage() { return image; } public void setImage(String image) { this.image = image; }} BookController.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.buubiu.controller;import com.buubiu.entity.Book;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;import javax.annotation.PostConstruct;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @comment: * @author: buubiu * @create: 2021/11/26 16:02 */@RestController@RequestMapping(&quot;book&quot;)public class BookController { List&lt;Book&gt; bookList = new ArrayList&lt;&gt;(); /** * 初始化数据 */ @PostConstruct public void iniData() { Book book1 = new Book(); book1.setId(1); book1.setTitle(&quot;Java从入门到精通(第五版)&quot;); book1.setAuthor(&quot;明日科技&quot;); book1.setPrice(47.50f); book1.setImage(&quot;img01.jpg&quot;); bookList.add(book1); Book book2 = new Book(); book2.setId(2); book2.setTitle(&quot;Java项目开发实战入门&quot;); book2.setAuthor(&quot;明日科技&quot;); book2.setPrice(52.10f); book2.setImage(&quot;img02.jpg&quot;); bookList.add(book2); Book book3 = new Book(); book3.setId(3); book3.setTitle(&quot;Java编程思想(第四版)&quot;); book3.setAuthor(&quot;Bruce Eckel&quot;); book3.setPrice(70.20f); book3.setImage(&quot;img03.jpg&quot;); bookList.add(book3); Book book4 = new Book(); book4.setId(4); book4.setTitle(&quot;码出高效:Java开发手册&quot;); book4.setAuthor(&quot;杨冠宝&quot;); book4.setPrice(99.00f); book4.setImage(&quot;img04.jpg&quot;); bookList.add(book4); } @GetMapping(&quot;search&quot;) public Map search(String searchContent) { HashMap&lt;String, Object&gt; resultMap = new HashMap&lt;&gt;(); if (&quot;java&quot;.equals(searchContent)) { resultMap.put(&quot;bookList&quot;, bookList); } return resultMap; }} 启动项目，浏览器地址栏输入:http://localhost/book/search?searchContent=java 页面显示: 小程序实现搭建搜索框book.wxml1234567891011121314151617&lt;!--pages/book/book.wxml--&gt;&lt;view&gt; &lt;view&gt; &lt;view class=&quot;weui-search-bar&quot;&gt; &lt;view class=&quot;weui-search-bar__form&quot;&gt; &lt;!-- 搜索框 --&gt; &lt;view class=&quot;weui-search-bar__box&quot;&gt; &lt;icon class=&quot;weui-icon-search_in-box&quot; type=&quot;search&quot; size=&quot;14&quot;&gt;&lt;/icon&gt; &lt;input type=&quot;text&quot; class=&quot;weui-search-bar__input&quot; model:value=&quot;{{searchContent}}&quot; placeholder=&quot;请输入搜索内容&quot; /&gt; &lt;/view&gt; &lt;/view&gt; &lt;!-- 搜索按钮,调用搜索查询方法 --&gt; &lt;view class=&quot;weui-search-bar__cancel-btn&quot; bindtap='searchBook'&gt;搜索 &lt;/view&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; book.wxss1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* pages/book/book.wxss */.weui-search-bar { position: relative; padding: 8px 10px; display: -webkit-box; display: -webkit-flex; display: flex; box-sizing: border-box; background-color: #EFEFF4; border-top: 1rpx solid #D7D6DC; border-bottom: 1rpx solid #D7D6DC;}.weui-icon-search_in-box { position: absolute; left: 10px; top: 7px;}.weui-search-bar__form { position: relative; -webkit-box-flex: 1; -webkit-flex: auto; flex: auto; border-radius: 5px; background: #FFFFFF; border: 1rpx solid #E6E6EA;}.weui-search-bar__box { position: relative; padding-left: 30px; padding-right: 30px; width: 100%; box-sizing: border-box; z-index: 1;}.weui-search-bar__input { height: 28px; line-height: 28px; font-size: 14px;}.weui-search-bar__cancel-btn { margin-left: 10px; line-height: 28px; color: #09BB07; white-space: nowrap;} 效果： 实现静态图书列表book.wxml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;view class=&quot;book&quot;&gt; &lt;view class=&quot;book-left&quot;&gt; &lt;image src=&quot;/imgs/img01.jpg&quot; alt=&quot;&quot; /&gt; &lt;/view&gt; &lt;view class=&quot;book-right&quot;&gt; &lt;view id=&quot;title&quot;&gt;Java从入门到精通(第五版)&lt;/view&gt; &lt;view id=&quot;author&quot;&gt;明日科技&lt;/view&gt; &lt;view id=&quot;price&quot;&gt;¥ 47.50&lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;book&quot;&gt; &lt;view class=&quot;book-left&quot;&gt; &lt;image src=&quot;/imgs/img02.jpg&quot; alt=&quot;&quot; /&gt; &lt;/view&gt; &lt;view class=&quot;book-right&quot;&gt; &lt;view id=&quot;title&quot;&gt;Java项目开发实战入门&lt;/view&gt; &lt;view id=&quot;author&quot;&gt;明日科技&lt;/view&gt; &lt;view id=&quot;price&quot;&gt;¥ 52.10&lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;book&quot;&gt; &lt;view class=&quot;book-left&quot;&gt; &lt;image src=&quot;/imgs/img03.jpg&quot; alt=&quot;&quot; /&gt; &lt;/view&gt; &lt;view class=&quot;book-right&quot;&gt; &lt;view id=&quot;title&quot;&gt;Java编程思想(第四版)&lt;/view&gt; &lt;view id=&quot;author&quot;&gt;Bruce Eckel&lt;/view&gt; &lt;view id=&quot;price&quot;&gt;¥ 70.20&lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;book&quot;&gt; &lt;view class=&quot;book-left&quot;&gt; &lt;image src=&quot;/imgs/img04.jpg&quot; alt=&quot;&quot; /&gt; &lt;/view&gt; &lt;view class=&quot;book-right&quot;&gt; &lt;view id=&quot;title&quot;&gt;Java从入门到精通 精粹版&lt;/view&gt; &lt;view id=&quot;author&quot;&gt;张玉宏&lt;/view&gt; &lt;view id=&quot;price&quot;&gt;¥ 63.00&lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;book&quot;&gt; &lt;view class=&quot;book-left&quot;&gt; &lt;image src=&quot;/imgs/img05.jpg&quot; alt=&quot;&quot; /&gt; &lt;/view&gt; &lt;view class=&quot;book-right&quot;&gt; &lt;view id=&quot;title&quot;&gt;码出高效:Java开发手册&lt;/view&gt; &lt;view id=&quot;author&quot;&gt;杨冠宝&lt;/view&gt; &lt;view id=&quot;price&quot;&gt;¥ 99.00&lt;/view&gt; &lt;/view&gt; &lt;/view&gt; book.wxss12345678910111213141516171819202122232425262728293031323334353637.book { padding: 5px 5px 3px 3px;}.book-left { float: left; width: 200rpx; text-align: center;}.book-left image { width: 180rpx; height: 80px;}.book-right { padding-top: 0px; margin-left: 200rpx; height: 80px; line-height: 50rpx; border-bottom: 1px solid gray;}.book-right #title { font-size: 14px;}.book-right #author { font-size: 12px; color: gray;}.book-right #price { font-size: 14px; color: red; font-weight: bold;} 运行效果： 微信小程序通过bindtap获取后端数据book.js12345678910111213141516171819202122232425262728293031323334353637383940// pages/book/book.jsPage({ /** * 页面的初始数据 */ data: { searchContent: &quot;&quot;, bookList: null }, searchBook(e){ console.log(this.data.searchContent); var searchContent = this.data.searchContent; var that = this; //重置数据 that.setData({ bookList: null }) wx.request({ url: 'http://127.0.0.1/book/search', method: 'GET', data: { searchContent: searchContent }, header: { 'content-type': 'application/json' }, success(res){ console.log(res.data); var bookList = res.data.bookList; that.setData({ bookList: bookList }) } }) }}) 点击请求，获取数据： 微信小程序获取数据后动态渲染页面通过wx:for遍历数据，渲染页面： book.wxml12345678910&lt;view class=&quot;book&quot; wx:for=&quot;{{bookList}}&quot;&gt; &lt;view class=&quot;book-left&quot;&gt; &lt;image src=&quot;/imgs/{{item.image}}&quot; alt=&quot;&quot;/&gt; &lt;/view&gt; &lt;view class=&quot;book-right&quot;&gt; &lt;view id=&quot;title&quot;&gt;{{item.title}}&lt;/view&gt; &lt;view id=&quot;author&quot;&gt;{{item.author}}&lt;/view&gt; &lt;view id=&quot;price&quot;&gt;{{item.price}}&lt;/view&gt; &lt;/view&gt;&lt;/view&gt; 效果：","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%90%8E%E7%AB%AFJava%E6%8E%A5%E5%8F%A3%E5%BC%80%E5%8F%91/"},{"title":"微信小程序应用和页面生命周期","text":"小程序应用生命周期App(Object object)注册小程序。接受一个 Object 参数，其指定小程序的生命周期回调等。 App() 必须在 app.js 中调用，必须调用且只能调用一次。不然会出现无法预期的后果。 参数Object object 属性 类型 默认值 必填 说明 最低版本 onLaunch function 否 生命周期回调——监听小程序初始化。 onShow function 否 生命周期回调——监听小程序启动或切前台。 onHide function 否 生命周期回调——监听小程序切后台。 onError function 否 错误监听函数。 onPageNotFound function 否 页面不存在监听函数。 1.9.90 onUnhandledRejection function 否 未处理的 Promise 拒绝事件监听函数。 2.10.0 onThemeChange function 否 监听系统主题变化 2.11.0 其他 any 否 开发者可以添加任意的函数或数据变量到 Object 参数中，用 this 可以访问 关于小程序前后台的定义和小程序的运行机制，请参考运行机制章节。 onLaunch(Object object)小程序初始化完成时触发，全局只触发一次。参数也可以使用 wx.getLaunchOptionsSync 获取。 参数：与 wx.getLaunchOptionsSync 一致 onShow(Object object)小程序启动，或从后台进入前台显示时触发。也可以使用 wx.onAppShow 绑定监听。 参数：与 wx.onAppShow 一致 onHide()小程序从前台进入后台时触发。也可以使用 wx.onAppHide 绑定监听。 onError(String error)小程序发生脚本错误或 API 调用报错时触发。也可以使用 wx.onError 绑定监听。 参数：与 wx.onError 一致 onPageNotFound(Object object) 基础库 1.9.90 开始支持，低版本需做兼容处理。 小程序要打开的页面不存在时触发。也可以使用 wx.onPageNotFound 绑定监听。注意事项请参考 wx.onPageNotFound。 参数：与 wx.onPageNotFound 一致 示例代码： 1234567App({ onPageNotFound(res) { wx.redirectTo({ url: 'pages/...' }) // 如果是 tabbar 页面，请使用 wx.switchTab }}) onUnhandledRejection(Object object) 基础库 2.10.0 开始支持，低版本需做兼容处理。 小程序有未处理的 Promise 拒绝时触发。也可以使用 wx.onUnhandledRejection 绑定监听。注意事项请参考 wx.onUnhandledRejection。 参数：与 wx.onUnhandledRejection 一致 onThemeChange(Object object) 基础库 2.11.0 开始支持，低版本需做兼容处理。 系统切换主题时触发。也可以使用 wx.onThemeChange 绑定监听。 参数：与 wx.onThemeChange 一致 示例代码123456789101112131415161718192021222324252627282930// app.jsApp({ onLaunch() { console.log(&quot;onLaunch:监听小程序 初始化&quot;) // 展示本地存储能力 const logs = wx.getStorageSync('logs') || [] logs.unshift(Date.now()) wx.setStorageSync('logs', logs) // 登录 wx.login({ success: res =&gt; { // 发送 res.code 到后台换取 openId, sessionKey, unionId } }) }, onShow(){ console.log(&quot;onShow:监听小程序 启动或切前台&quot;) }, onHide(){ console.log(&quot;onHide:监听小程序 切后台&quot;) }, onError(error){ console.log(&quot;onError:错误监听函数&quot; + error) }, globalData: { userInfo: null }}) 小程序页面生命周期Page(Object object)注册小程序中的一个页面。接受一个 Object 类型参数，其指定页面的初始数据、生命周期回调、事件处理函数等。 参数Object object 属性 类型 默认值 必填 说明 data Object 页面的初始数据 options Object 页面的组件选项，同 Component 构造器 中的 options ，需要基础库版本 2.10.1 onLoad function 生命周期回调—监听页面加载 onShow function 生命周期回调—监听页面显示 onReady function 生命周期回调—监听页面初次渲染完成 onHide function 生命周期回调—监听页面隐藏 onUnload function 生命周期回调—监听页面卸载 onPullDownRefresh function 监听用户下拉动作 onReachBottom function 页面上拉触底事件的处理函数 onShareAppMessage function 用户点击右上角转发 onShareTimeline function 用户点击右上角转发到朋友圈 onAddToFavorites function 用户点击右上角收藏 onPageScroll function 页面滚动触发事件的处理函数 onResize function 页面尺寸改变时触发，详见 响应显示区域变化 onTabItemTap function 当前是 tab 页时，点击 tab 时触发 onSaveExitState function 页面销毁前保留状态回调 其他 any 开发者可以添加任意的函数或数据到 Object 参数中，在页面的函数中用 this 可以访问 个别参数使用说明 onLoad，经常用作异步加载数据，页面显示用; onHide， 监听页面隐藏，onUnload 页面卸载 链接组件跳转可以处罚切换/隐藏 1234//navigate只是隐藏，可以返回//redirect是重定向页面，不可以返回，触发的是onUnload 页面卸载&lt;navigator url=&quot;/pages/index/index&quot; open-type=&quot;navigate&quot;&gt;index navigate&lt;/navigator&gt;&lt;navigator url=&quot;/pages/index/index&quot; open-type=&quot;redirect&quot;&gt;index redirect&lt;/navigator&gt; onPullDownRefresh 先全局设置允许下拉刷新 app.json1234567{ ... &quot;window&quot;:{ &quot;enablePullDownRefresh&quot;: true } ...} onReachBottom 小技巧 view{$}*100 可以复制100个view标签 onResize 先在需要横屏竖屏的页面json中加入配置，开发工具可是界面右上角就会出现横屏的按钮 demo01.json123{ &quot;pageOrientation&quot;: &quot;auto&quot;} 示例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// pages/demo01/demo01.jsPage({ /** * 页面的初始数据 */ data: { }, /** * 生命周期函数--监听页面加载 */ onLoad: function (options) { console.log(&quot;onLoad:监听页面加载&quot;) }, /** * 生命周期函数--监听页面显示 */ onShow: function () { console.log(&quot;onShow:监听页面显示&quot;) }, /** * 生命周期函数--监听页面初次渲染完成 */ onReady: function () { console.log(&quot;onReady:监听页面初次渲染完成&quot;) }, /** * 生命周期函数--监听页面隐藏 */ onHide: function () { console.log(&quot;onHide:监听页面隐藏&quot;) }, /** * 生命周期函数--监听页面卸载 */ onUnload: function () { console.log(&quot;onUnload:监听页面卸载&quot;) }, /** * 页面相关事件处理函数--监听用户下拉动作 */ onPullDownRefresh: function () { console.log(&quot;onPullDownRefresh:监听用户下拉动作&quot;) }, /** * 页面上拉触底事件的处理函数 */ onReachBottom: function () { console.log(&quot;onReachBottom:页面上拉触底事件的处理函数&quot;) }, /** * 用户点击右上角分享 */ onShareAppMessage: function () { console.log(&quot;onShareAppMessage:用户点击右上角分享&quot;) }, /** * 页面滚动触发事件的处理函数 */ onPageScroll:function(){ console.log(&quot;onPageScroll:页面滚动触发事件的处理函数&quot;) }, /** * 页面尺寸改变时触发 */ onResize:function(){ console.log(&quot;onResize:页面尺寸改变时触发&quot;) }}) 生命周期原理图","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BA%94%E7%94%A8%E5%92%8C%E9%A1%B5%E9%9D%A2%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"},{"title":"微信小程序框架介绍与项目目录结构","text":"框架介绍微信团队为小程序提供的框架命名为MINA。MINA框架通过封装微信客户端提供的文件系统、网络通信、任务管理、数据安全等基础功能，对上层提供一整套JavaScript API，让开发者方便的使用微信 客户端提供的各种基础功能与能力，快速构建应用。 小程序开发框架的目标是通过尽可能简单、高效的方式让开发者可以在微信中开发具有原生 APP 体验的 服务。 整个小程序框架系统分为两部分:逻辑层(App Service)和 视图层(View)。小程序提供了自己的视 图层描述语言 WXML 和 WXSS，以及基于 JavaScript 的逻辑层框架，并在视图层与逻辑层间提供了数据传输和事件系统，让开发者能够专注于数据与逻辑。 项目目录结构官方文档： https://developers.weixin.qq.com/miniprogram/dev/framework/structure.html 小程序包含一个描述整体程序的 app 和多个描述各自页面的 page 。 一个小程序主体部分由三个文件组成，必须放在项目的根目录，如下： 文件 必需 作用 app.js 是 小程序逻辑 app.json 是 小程序公共配置 app.wxss 否 小程序公共样式表 一个小程序页面由四个文件组成，分别是： 文件类型 必需 作用 js 是 页面逻辑 wxml 是 页面结构 json 否 页面配置 wxss 否 页面样式表 注意：为了方便开发者减少配置项，描述页面的四个文件必须具有相同的路径与文件名。 允许上传的文件在项目目录中，以下文件会经过编译，因此上传之后无法直接访问到：.js、app.json、.wxml、 *.wxss（其中 wxml 和 wxss 文件仅针对在 app.json 中配置了的页面）。除此之外，只有后 名在白名单内的文件可以被上传，不在白名单列表内文件在开发工具能被访问到，但无法被上传。具体白名单列表如下： wxs png jpg jpeg gif svg json cer mp3 aac m4a mp4 wav ogg silk wasm br","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D%E4%B8%8E%E9%A1%B9%E7%9B%AE%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"title":"微信小程序框架API","text":"微信小程序框架所提供的API接口也是相当完备的,如果说小程序组件是用来构建小程序的视图层,那么小 程序API则在小程序逻辑层担当重任。随着小程序版本的更新迭代,目前小程序框架 API分类已经达到了 19个大类,如下图所示。 当然这么多API并不需要读者一个个去详细研究,而是建议大家重点掌握其中常用的API如何查阅和使用,然 后即可触类旁通使用其他的API。其实查阅API有点类似于查词典,我们只需要知道如何去查阅的方法即可, 而没必要将整部词典学会,故而掌握查阅API定义以及如何使用才是至关重要的。 接下来,就开始重点讲解小程序框架中一些常用的API,通过这些API的学习和理解,希望读者能够对小程序 API如何查阅和使用形成一定的思维认知。 基础微信小程序基础API包含一些环境变量，转码，系统信息，更新，小程序生命周期，应用及事件，调试， 性能，加密等功能; wx.getSystemInfo 获取系统信息实例wx.getSystemInfo(Object object) 以 Promise 风格 调用：支持 小程序插件：支持，需要小程序基础库版本不低于 1.9.6 微信 Windows 版：支持 微信 Mac 版：支持 获取系统信息。由于历史原因，wx.getSystemInfo 是异步的调用格式，但是是同步返回，需要异步获取系统信息请使用 wx.getSystemInfoAsync。 参数 Object object 属性 类型 默认值 必填 说明 success function 否 接口调用成功的回调函数 fail function 否 接口调用失败的回调函数 complete function 否 接口调用结束的回调函数（调用成功、失败都会执行） object.success 回调函数 参数 Object res 属性 类型 说明 最低版本 brand string 设备品牌 1.5.0 model string 设备型号。新机型刚推出一段时间会显示unknown，微信会尽快进行适配。 pixelRatio number 设备像素比 screenWidth number 屏幕宽度，单位px 1.1.0 screenHeight number 屏幕高度，单位px 1.1.0 windowWidth number 可使用窗口宽度，单位px windowHeight number 可使用窗口高度，单位px statusBarHeight number 状态栏的高度，单位px 1.9.0 language string 微信设置的语言 version string 微信版本号 system string 操作系统及版本 platform string 客户端平台 fontSizeSetting number 用户字体大小（单位px）。以微信客户端「我-设置-通用-字体大小」中的设置为准 1.5.0 SDKVersion string 客户端基础库版本 1.1.0 benchmarkLevel number 设备性能等级（仅 Android）。取值为：-2 或 0（该设备无法运行小游戏），-1（性能未知），&gt;=1（设备性能值，该值越高，设备性能越好，目前最高不到50） 1.8.0 albumAuthorized boolean 允许微信使用相册的开关（仅 iOS 有效） 2.6.0 cameraAuthorized boolean 允许微信使用摄像头的开关 2.6.0 locationAuthorized boolean 允许微信使用定位的开关 2.6.0 microphoneAuthorized boolean 允许微信使用麦克风的开关 2.6.0 notificationAuthorized boolean 允许微信通知的开关 2.6.0 notificationAlertAuthorized boolean 允许微信通知带有提醒的开关（仅 iOS 有效） 2.6.0 notificationBadgeAuthorized boolean 允许微信通知带有标记的开关（仅 iOS 有效） 2.6.0 notificationSoundAuthorized boolean 允许微信通知带有声音的开关（仅 iOS 有效） 2.6.0 phoneCalendarAuthorized boolean 允许微信使用日历的开关 2.19.3 bluetoothEnabled boolean 蓝牙的系统开关 2.6.0 locationEnabled boolean 地理位置的系统开关 2.6.0 wifiEnabled boolean Wi-Fi 的系统开关 2.6.0 safeArea Object 在竖屏正方向下的安全区域 2.7.0 locationReducedAccuracy boolean true 表示模糊定位，false 表示精确定位，仅 iOS 支持 theme string 系统当前主题，取值为light或dark，全局配置&quot;darkmode&quot;:true时才能获取，否则为 undefined （不支持小游戏） 2.11.0 host Object 当前小程序运行的宿主环境 2.12.3 enableDebug boolean 是否已打开调试。可通过右上角菜单或 wx.setEnableDebug 打开调试。 2.15.0 deviceOrientation string 设备方向 safeArea 的结构 属性 类型 说明 left number 安全区域左上角横坐标 right number 安全区域右下角横坐标 top number 安全区域左上角纵坐标 bottom number 安全区域右下角纵坐标 width number 安全区域的宽度，单位逻辑像素 height number 安全区域的高度，单位逻辑像素 theme 的合法值 值 说明 最低版本 dark 深色主题 light 浅色主题 host 的结构 属性 类型 说明 appId string 宿主 app 对应的 appId deviceOrientation 的合法值 值 说明 最低版本 portrait 竖屏 landscape 横屏 示例代码 在开发者工具中预览效果 1234567891011121314151617181920212223wx.getSystemInfo({ success (res) { console.log(res.model) console.log(res.pixelRatio) console.log(res.windowWidth) console.log(res.windowHeight) console.log(res.language) console.log(res.version) console.log(res.platform) }})try { const res = wx.getSystemInfoSync() console.log(res.model) console.log(res.pixelRatio) console.log(res.windowWidth) console.log(res.windowHeight) console.log(res.language) console.log(res.version) console.log(res.platform)} catch (e) { // Do something when catch error} 路由路由API主要提供一些页面跳转，关闭页面以及页面之间的通信接口; 跳转跳转API主要提供打开另外一个小程序，退出小程序和关闭小程序操作接口; 转发转发API，主要提供转发属性设置，打开分享弹窗，转发视频或者文件，以及显示和隐藏转发按钮，验证 私密消息等接口; 界面界面API主要提供交互，导航栏，背景，Tab Bar，字体，下拉刷新，滚动，动画，置顶，自定义组件， 菜单，窗口等接口! 网络网络API主要提供发起请求，下载，上传，WebSocket，mDNS，TCP通信，UDP通信接口; 支付支付API主要提供发起微信支付和创建自定义版交易组件订单等接口 数据缓存数据缓存API主要提供本地缓存的添加，获取，销毁以及内存中数据的操作和周期性更新接口; 数据分析数据分析接口主要提供自定义分析数据上报，事件上报，监控等接口; 画布画布API主要提供画布相关接口。 媒体媒体API主要提供地图，图片，视频，音频，背景音频，实时音视频，录音，相机，富文本，音视频合 成，实时语音，画面录制器，视频解码器等接口; 位置位置API主要提供位置相关接口 文件文件API主要提供文件操作相关接口。 开放接口开放接口API主要提供登录，账号信息，用户信息，授权，设置，收货地址，卡券，发票，生物认证，微信运动，订阅信息，微信红包，收藏，微信群等接口。 设备设备API主要提供外围设备，iBeacon，NFC，Wi-Fi，日历，联系人，无障碍，低功耗蓝牙，电量，剪贴 板，网络，加密，屏幕，键盘，电话，加速计，罗盘，设备方向，陀螺仪，内存，扫码，震动等接口。 WorkerWorker API主要提供Worker线程操作接口; WXMLWXML API提供主要提供WXML节点相关操作接口; 第三方平台第三方平台API主要提供第三方平台相关调用接口。 广告广告API主要提供广告操作相关API接口。 AIAI API主要提供人工智能相关的API接口。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6API/"},{"title":"微信小程序框架组件-地图组件","text":"map 地图 组件 基础库 1.0.0 开始支持，低版本需做兼容处理。 地图（v2.7.0 起支持同层渲染，相关api wx.createMapContext。 小程序解决方案除本章节介绍的小程序地图基础属性外，腾讯位置服务推出《微信小程序解决方案》，从检索API、基础地图组件、个性化、插件、行业方案等多个层面，为不同场景需求的小程序开发者提供完整的地图能力。 个性化地图个性化地图样式是腾讯位置服务开放的一项高级能力，开发者可以根据自身产品的使用场景，UI风格， 选取或者创建风格匹配的地图样式。小程序内地图组件应使用同一 subkey，可通过 layer-style（位置服务官网设置的样式 style 编号）属性配置，并支持动态切换样式。 组件属性的长度单位默认为px，2.4.0起支持传入单位(rpx/px)。详情见：个性化地图使用指南 小程序插件腾讯位置服务基于微信提供的小程序插件能力，专注于（围绕）地图功能，打造一系列小程序插件，可以帮助开发者简单、快速的构建小程序，是您实现地图功能的最佳伙伴。目前插件提供路线规划、地铁图、地图选点服务，详情见：小程序地图插件使用指南。 地图检索腾讯位置服务在微信开放社区的服务平台上线了一系列地图检索服务，包含4个POI数据类（逆地址解析、地址解析、地点搜索、关键词输入提示）、2个路线规划类（驾车路线规划、步行路线规划）、1个坐标工具类（坐标转换），覆盖了绝大部分地图应用场景。或者登陆位置服务官网的Webservice使用指南了解详细介绍。 微信小程序开发者可以使用海外地图进行展示，若需要海外检索能力，可在海外位置服务进行申请。 小程序示例中心包含Map组件、API、插件等功能使用方法，全面了解小程序下的所有地图能力。示例内容源码开放，降低各位开发者接入成本。 近期新增功能 支持点聚合，适用于marker过多场景。 支持彩虹蚯蚓线，常用于路线规划场景。 覆盖物支持调整与其它地图元素的压盖关系。 支持marker（小车）平移动画，适用于轨迹回放场景。 地图基础属性 属性 类型 默认值 必填 说明 最低版本 longitude number 是 中心经度 1.0.0 latitude number 是 中心纬度 1.0.0 scale number 16 否 缩放级别，取值范围为3-20 1.0.0 min-scale number 3 否 最小缩放级别 2.13.0 max-scale number 20 否 最大缩放级别 2.13.0 markers Array. 否 标记点 1.0.0 covers Array. 否 即将移除，请使用 markers 1.0.0 polyline Array. 否 路线 1.0.0 circles Array. 否 圆 1.0.0 controls Array. 否 控件（即将废弃，建议使用 cover-view 代替） 1.0.0 include-points Array. 否 缩放视野以包含所有给定的坐标点 1.0.0 show-location boolean false 否 显示带有方向的当前定位点 1.0.0 polygons Array. 否 多边形 2.3.0 subkey string 否 个性化地图使用的key 2.3.0 layer-style number 1 否 个性化地图配置的 style，不支持动态修改 rotate number 0 否 旋转角度，范围 0 ~ 360, 地图正北和设备 y 轴角度的夹角 2.5.0 skew number 0 否 倾斜角度，范围 0 ~ 40 , 关于 z 轴的倾角 2.5.0 enable-3D boolean false 否 展示3D楼块(工具暂不支持） 2.3.0 show-compass boolean false 否 显示指南针 2.3.0 show-scale boolean false 否 显示比例尺，工具暂不支持 2.8.0 enable-overlooking boolean false 否 开启俯视 2.3.0 enable-zoom boolean true 否 是否支持缩放 2.3.0 enable-scroll boolean true 否 是否支持拖动 2.3.0 enable-rotate boolean false 否 是否支持旋转 2.3.0 enable-satellite boolean false 否 是否开启卫星图 2.7.0 enable-traffic boolean false 否 是否开启实时路况 2.7.0 enable-poi boolean true 否 是否展示 POI 点 2.14.0 enable-building boolean 否 是否展示建筑物 2.14.0 setting object 否 配置项 2.8.2 bindtap eventhandle 否 点击地图时触发，2.9.0起返回经纬度信息 1.0.0 bindmarkertap eventhandle 否 点击标记点时触发，e.detail = {markerId} 1.0.0 bindlabeltap eventhandle 否 点击label时触发，e.detail = {markerId} 2.9.0 bindcontroltap eventhandle 否 点击控件时触发，e.detail = {controlId} 1.0.0 bindcallouttap eventhandle 否 点击标记点对应的气泡时触发e.detail = {markerId} 1.2.0 bindupdated eventhandle 否 在地图渲染更新完成时触发 1.6.0 bindregionchange eventhandle 否 视野发生变化时触发， 2.3.0 bindpoitap eventhandle 否 点击地图poi点时触发，e.detail = {name, longitude, latitude} 2.3.0 bindanchorpointtap eventhandle 否 点击定位标时触发，e.detail = {longitude, latitude} 2.13.0 regionchange 返回值视野改变时，regionchange 会触发两次，返回的 type 值分别为 begin 和 end。 2.8.0 起 begin 阶段返回 causedBy，有效值为 gesture（手势触发） &amp; update（接口触发） 2.3.0 起 end 阶段返回 causedBy，有效值为 drag（拖动导致）、scale（缩放导致）、update（调用更新接口导致）。 1e = {causedBy, type, detail: {rotate, skew, scale, centerLocation, region}} setting提供 setting 对象统一设置地图配置。同时对于一些动画属性如 rotate 和 skew，通过 setData 分开设置时无法同时生效，需通过 settting 统一修改。 12345678910111213141516171819202122232425// 默认值const setting = { skew: 0, rotate: 0, showLocation: false, showScale: false, subKey: '', layerStyle: 1, enableZoom: true, enableScroll: true, enableRotate: false, showCompass: false, enable3D: false, enableOverlooking: false, enableSatellite: false, enableTraffic: false,}this.setData({ // 仅设置的属性会生效，其它的不受影响 setting: { enable3D: true, enableTraffic: true }}) marker标记点用于在地图上显示标记的位置 属性 说明 类型 必填 备注 最低版本 id 标记点 id number 否 marker 点击事件回调会返回此 id。建议为每个 marker 设置上 number 类型 id，保证更新 marker 时有更好的性能。 clusterId 聚合簇的 id Number 否 自定义点聚合簇效果时使用 joinCluster 是否参与点聚合 Boolean 否 默认不参与点聚合 latitude 纬度 number 是 浮点数，范围 -90 ~ 90 longitude 经度 number 是 浮点数，范围 -180 ~ 180 title 标注点名 string 否 点击时显示，callout存在时将被忽略 zIndex 显示层级 number 否 2.3.0 iconPath 显示的图标 string 是 项目目录下的图片路径，支持网络路径、本地路径、代码包路径（2.3.0） rotate 旋转角度 number 否 顺时针旋转的角度，范围 0 ~ 360，默认为 0 alpha 标注的透明度 number 否 默认 1，无透明，范围 0 ~ 1 width 标注图标宽度 number/string 否 默认为图片实际宽度 height 标注图标高度 number/string 否 默认为图片实际高度 callout 标记点上方的气泡窗口 Object 否 支持的属性见下表，可识别换行符。 1.2.0 customCallout 自定义气泡窗口 Object 否 支持的属性见下表 label 为标记点旁边增加标签 Object 否 支持的属性见下表，可识别换行符。 1.2.0 anchor 经纬度在标注图标的锚点，默认底边中点 Object 否 {x, y}，x 表示横向(0-1)，y 表示竖向(0-1)。{x: .5, y: 1} 表示底边中点 1.2.0 aria-label 无障碍访问，（属性）元素的额外描述 string 否 2.5.0 marker 上的气泡 callout 属性 说明 类型 最低版本 content 文本 string 1.2.0 color 文本颜色 string 1.2.0 fontSize 文字大小 number 1.2.0 borderRadius 边框圆角 number 1.2.0 borderWidth 边框宽度 number 2.3.0 borderColor 边框颜色 string 2.3.0 bgColor 背景色 string 1.2.0 padding 文本边缘留白 number 1.2.0 display ‘BYCLICK’:点击显示; ‘ALWAYS’:常显 string 1.2.0 textAlign 文本对齐方式。有效值: left, right, center string 1.6.0 anchorX 横向偏移量，向右为正数 number 2.11.0 anchorY 纵向偏移量，向下为正数 number 2.11.0 marker 上的自定义气泡 customCalloutcustomCallout 存在时将忽略 callout 与 title 属性。自定义气泡采用采用 cover-view 定制，灵活度更高。 属性 说明 类型 最低版本 display ‘BYCLICK’:点击显示; ‘ALWAYS’:常显 string 2.12.0 anchorX 横向偏移量，向右为正数 number 2.12.0 anchorY 纵向偏移量，向下为正数 number 2.12.0 使用方式如下，map 组件下添加名为 callout 的 slot 节点，其内部的 cover-view 通过 marker-id 属性与 marker 绑定。当 marker 创建时，该 cover-view 显示的内容将作为 callout 显示在标记点上方。 123456&lt;map&gt; &lt;cover-view slot=&quot;callout&quot;&gt; &lt;cover-view marker-id=&quot;1&quot;&gt;&lt;/cover-view&gt; &lt;cover-view marker-id=&quot;2&quot;&gt;&lt;/cover-view&gt; &lt;/cover-view&gt;&lt;/map&gt; 示例DEMO： 在开发者工具中预览效果 marker 上的气泡 label 属性 说明 类型 最低版本 content 文本 string 1.2.0 color 文本颜色 string 1.2.0 fontSize 文字大小 number 1.2.0 x label的坐标（废弃） number 1.2.0 y label的坐标（废弃） number 1.2.0 anchorX label的坐标，原点是 marker 对应的经纬度 number 2.1.0 anchorY label的坐标，原点是 marker 对应的经纬度 number 2.1.0 borderWidth 边框宽度 number 1.6.0 borderColor 边框颜色 string 1.6.0 borderRadius 边框圆角 number 1.6.0 bgColor 背景色 string 1.6.0 padding 文本边缘留白 number 1.6.0 textAlign 文本对齐方式。有效值: left, right, center string 1.6.0 点聚合当地图上需要展示的标记点 marker 过多时，可能会导致界面上 marker 出现压盖，展示不全，并导致整体性能变差。针对此类问题，推出点聚合能力。 使用流程如下： MapContext.initMarkerCluster 对聚合点进行初始化配置（可选）； MapContext.addMarkers 指定参与聚合的 marker； MapContext.on('markerClusterCreate', callback) 触发时，通过 MapContext.addMarkers 更新聚合簇的样式 （可选）； MapContext.removeMarkers 移除参与聚合的 marker； 示例代码在开发者工具中预览效果 需注意的是： 地图上的 marker 分为普通的 marker 与参与聚合的 marker，参与聚合时需指定属性 joinCluster 为 true； 自定义聚合簇样式时，同样通过 MapContext.addMarkers 进行绘制，此时需携带 clusterId。 polyline指定一系列坐标点，从数组第一项连线至最后一项。绘制彩虹线时，需指定不同分段的颜色，如 points 包含 5 个点，则 colorList 应传入 4 个颜色值；若 colorList 长度小于 points.length - 1，则剩下的分段颜色与最后一项保持一致。 属性 说明 类型 必填 备注 最低版本 points 经纬度数组 array 是 [{latitude: 0, longitude: 0}] color 线的颜色 string 否 十六进制 colorList 彩虹线 array 否 存在时忽略 color 值 2.13.0 width 线的宽度 number 否 dottedLine 是否虚线 boolean 否 默认 false arrowLine 带箭头的线 boolean 否 默认 false，开发者工具暂不支持该属性 1.2.0 arrowIconPath 更换箭头图标 string 否 在 arrowLine 为 true 时生效 1.6.0 borderColor 线的边框颜色 string 否 1.2.0 borderWidth 线的厚度 number 否 1.2.0 level 压盖关系 string 否 默认为 abovelabels 2.14.0 level 字段表示与其它地图元素的压盖关系，可选值如下： 值 说明 最低版本 abovelabels 显示在所有 POI 之上 2.14.0 abovebuildings 显示在楼块之上 POI 之下 2.14.0 aboveroads 显示在道路之上楼块之下 2.14.0 polygon指定一系列坐标点，根据 points 坐标数据生成闭合多边形 属性 说明 类型 必填 备注 最低版本 points 经纬度数组 array 是 [{latitude: 0, longitude: 0}] 2.3.0 strokeWidth 描边的宽度 number 否 2.3.0 strokeColor 描边的颜色 string 否 十六进制 2.3.0 fillColor 填充颜色 string 否 十六进制 zIndex 设置多边形Z轴数值 number 否 2.3.0 level 压盖关系 string 否 默认为 abovelabels 2.14.0 circle在地图上显示圆 属性 说明 类型 必填 备注 latitude 纬度 number 是 浮点数，范围 -90 ~ 90 longitude 经度 number 是 浮点数，范围 -180 ~ 180 color 描边的颜色 string 否 十六进制 fillColor 填充颜色 string 否 十六进制 radius 半径 number 是 strokeWidth 描边的宽度 number 否 level 压盖关系 string 否 默认为 abovelabels control在地图上显示控件，控件不随着地图移动。即将废弃，请使用 cover-view 属性 说明 类型 必填 备注 id 控件id number 否 在控件点击事件回调会返回此id position 控件在地图的位置 object 是 控件相对地图位置 iconPath 显示的图标 string 是 项目目录下的图片路径，支持本地路径、代码包路径 clickable 是否可点击 boolean 否 默认不可点击 position 属性 说明 类型 必填 备注 left 距离地图的左边界多远 number 否 默认为0 top 距离地图的上边界多远 number 否 默认为0 width 控件宽度 number 否 默认为图片宽度 height 控件高度 number 否 默认为图片高度 bindregionchange 返回值 属性 说明 类型 备注 type 视野变化开始、结束时触发 string 视野变化开始为begin，结束为end causedBy 导致视野变化的原因 string 拖动地图导致(drag)、缩放导致(scale)、调用接口导致(update) 比例尺 scale 3 4 5 6 7 8 9 10 11 比例 1000km 500km 200km 100km 50km 50km 20km 10km 5km scale 12 13 14 15 16 17 18 19 20 比例 2km 1km 500m 200m 100m 50m 50m 20m 10m 示例代码在开发者工具中预览效果 Bug &amp; Tip tip：个性化地图暂不支持工具中调试。请先使用微信客户端进行测试。 tip：地图中的颜色值color/borderColor/bgColor等需使用6位（8位）十六进制表示，8位时后两位表示alpha值，如：#000000AA tip：地图组件的经纬度必填, 如果不填经纬度则默认值是北京的经纬度。 tip: map 组件使用的经纬度是火星坐标系，调用 wx.getLocation 接口需要指定 type 为 gcj02 tip：从 2.8.0 起 map 支持同层渲染，更多请参考原生组件使用限制 tip：请注意原生组件使用限制。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E7%BB%84%E4%BB%B6-%E5%9C%B0%E5%9B%BE%E7%BB%84%E4%BB%B6/"},{"title":"微信小程序框架组件-原生组件说明","text":"native-component 原生组件小程序中的部分组件是由客户端创建的原生组件，这些组件有： camera canvas input（仅在focus时表现为原生组件） live-player live-pusher map textarea video 原生组件同层渲染同层渲染是为了解决原生组件的层级问题，在支持同层渲染后，原生组件与其它组件可以随意叠加，有关层级的限制将不再存在。但需要注意的是，组件内部仍由原生渲染，样式一般还是对原生组件内部无效。当前所有原生组件（除 input 组件 focus 状态）均已支持同层渲染。 原生组件的使用限制除事件相关，同层渲染下已无以下限制 由于原生组件脱离在 WebView 渲染流程外，因此在使用时有以下限制： 原生组件的层级是最高的，所以页面中的其他组件无论设置 z-index 为多少，都无法盖在原生组件上。 后插入的原生组件可以覆盖之前的原生组件。 原生组件还无法在 picker-view 中使用。 基础库 2.4.4 以下版本，原生组件不支持在 scroll-view、swiper、movable-view 中使用。 部分 CSS 样式无法应用于原生组件，例如： 无法对原生组件设置 CSS 动画 无法定义原生组件为 position: fixed 不能在父级节点使用 overflow: hidden 来裁剪原生组件的显示区域 原生组件的事件监听不能使用 bind:eventname 的写法，只支持 bindeventname。原生组件也不支持 catch 和 capture 的事件绑定方式。 原生组件会遮挡 vConsole 弹出的调试面板。 在工具上，原生组件是用web组件模拟的，因此很多情况并不能很好的还原真机的表现，建议开发者在使用到原生组件时尽量在真机上进行调试。 cover-view 与 cover-image为了解决原生组件层级最高的限制。小程序专门提供了 cover-view 和 cover-image 组件，可以覆盖在部分原生组件上面。这两个组件也是原生组件，但是使用限制与其他原生组件有所不同。 原生组件相对层级同层渲染下已无以下问题 为了可以调整原生组件之间的相对层级位置，小程序在 v2.7.0 及以上版本支持在样式中声明 z-index 来指定原生组件的层级。该 z-index 仅调整原生组件之间的层级顺序，其层级仍高于其他非原生组件。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E7%BB%84%E4%BB%B6-%E5%8E%9F%E7%94%9F%E7%BB%84%E4%BB%B6%E8%AF%B4%E6%98%8E/"},{"title":"微信小程序框架组件-导航组件","text":"页面导航 navigator页面导航(navigator)组件,它类似于HTML中的a标签; 基础库 1.0.0 开始支持，低版本需做兼容处理。 页面链接。 在小程序插件中使用需要基础库版本 2.1.0 起。 属性 类型 默认值 必填 说明 最低版本 target string self 否 在哪个目标上发生跳转，默认当前小程序 2.0.7 url string 否 当前小程序内的跳转链接 1.0.0 open-type string navigate 否 跳转方式 1.0.0 delta number 1 否 当 open-type 为 ‘navigateBack’ 时有效，表示回退的层数 1.0.0 app-id string 否 当target=&quot;miniProgram&quot;时有效，要打开的小程序 appId 2.0.7 path string 否 当target=&quot;miniProgram&quot;时有效，打开的页面路径，如果为空则打开首页 2.0.7 extra-data object 否 当target=&quot;miniProgram&quot;时有效，需要传递给目标小程序的数据，目标小程序可在 App.onLaunch()，App.onShow() 中获取到这份数据。详情 2.0.7 version string release 否 当target=&quot;miniProgram&quot;时有效，要打开的小程序版本 2.0.7 short-link string 否 当target=&quot;miniProgram&quot;时有效，当传递该参数后，可以不传 app-id 和 path。链接可以通过【小程序菜单】-&gt;【复制链接】获取。 2.18.1 hover-class string navigator-hover 否 指定点击时的样式类，当hover-class=&quot;none&quot;时，没有点击态效果 1.0.0 hover-stop-propagation boolean false 否 指定是否阻止本节点的祖先节点出现点击态 1.5.0 hover-start-time number 50 否 按住后多久出现点击态，单位毫秒 1.0.0 hover-stay-time number 600 否 手指松开后点击态保留时间，单位毫秒 1.0.0 bindsuccess string 否 当target=&quot;miniProgram&quot;时有效，跳转小程序成功 2.0.7 bindfail string 否 当target=&quot;miniProgram&quot;时有效，跳转小程序失败 2.0.7 bindcomplete string 否 当target=&quot;miniProgram&quot;时有效，跳转小程序完成 2.0.7 target 的合法值 值 说明 最低版本 self 当前小程序 miniProgram 其它小程序 open-type 的合法值 值 说明 最低版本 navigate 对应 wx.navigateTo 或 wx.navigateToMiniProgram 的功能 redirect 对应 wx.redirectTo 的功能 switchTab 对应 wx.switchTab 的功能 reLaunch 对应 wx.reLaunch 的功能 1.1.0 navigateBack 对应 wx.navigateBack 的功能 1.1.0 exit 退出小程序，target=&quot;miniProgram&quot;时生效 2.1.0 version 的合法值 值 说明 最低版本 develop 开发版 trial 体验版 release 正式版，仅在当前小程序为开发版或体验版时此参数有效；如果当前小程序是正式版，则打开的小程序必定是正式版。 使用限制 需要用户确认跳转 从 2.3.0 版本开始，在跳转至其他小程序前，将统一增加弹窗，询问是否跳转，用户确认后才可以跳转其他小程序。如果用户点击取消，则回调 fail cancel。 每个小程序可跳转的其他小程序数量限制为不超过 10 个 从 2.4.0 版本以及指定日期（具体待定）开始，开发者提交新版小程序代码时，如使用了跳转其他小程序功能，则需要在代码配置中声明将要跳转的小程序名单，限定不超过 10 个，否则将无法通过审核。该名单可在发布新版时更新，不支持动态修改。配置方法详见 配置。调用此接口时，所跳转的 appId 必须在配置列表中，否则回调 fail appId &quot;${appId}&quot; is not in navigateToMiniProgramAppIdList。 无需声明跳转名单，不限跳转数量（众测中） 从2020年4月24日起，使用跳转其他小程序功能将无需在全局配置中声明跳转名单，调用此接口时将不再校验所跳转的 AppID 是否在 navigateToMiniProgramAppIdList 中。 从2020年4月24日起，跳转其他小程序将不再受数量限制，使用此功能时请注意遵守运营规范。 关于调试 在开发者工具上调用此 API 并不会真实的跳转到另外的小程序，但是开发者工具会校验本次调用跳转是否成功。详情 开发者工具上支持被跳转的小程序处理接收参数的调试。详情 Bug &amp; Tip tip：navigator-hover 默认为 {background-color: rgba(0, 0, 0, 0.1); opacity: 0.7;}, navigator 的子节点背景色应为透明色 示例代码在开发者工具中预览效果 index.wxml123456&lt;!-- sample.wxml --&gt;&lt;view class=&quot;btn-area&quot;&gt; &lt;navigator url=&quot;/navigate/navigate?title=navigate&quot; hover-class=&quot;navigator-hover&quot;&gt;跳转到新页面&lt;/navigator&gt; &lt;navigator url=&quot;../redirect/redirect?title=redirect&quot; open-type=&quot;redirect&quot; hover-class=&quot;other-navigator-hover&quot;&gt;在当前页打开&lt;/navigator&gt; &lt;!-- &lt;navigator url=&quot;/index/index&quot; open-type=&quot;switchTab&quot; hover-class=&quot;other-navigator-hover&quot;&gt;切换 Tab&lt;/navigator&gt; --&gt;&lt;/view&gt; index.js12345678// redirect.js navigator.jsPage({ onLoad: function (options) { this.setData({ title: options.title }) }}) index.wxss12345678910@import '../lib/weui.wxss'/** wxss **//** 修改默认的navigator点击态 **/.navigator-hover { color:blue;}/** 自定义其他点击态样式类 **/.other-navigator-hover { color:red;} navigate.wxml123&lt;!-- navigator.wxml --&gt;&lt;view style=&quot;text-align:center&quot;&gt; {{title}} &lt;/view&gt;&lt;view&gt; 点击左上角返回回到之前页面 &lt;/view&gt; navigate.js12345678// redirect.js navigator.jsPage({ onLoad: function (options) { this.setData({ title: options.title }) }}) redirect.wxml123&lt;!-- redirect.wxml --&gt;&lt;view style=&quot;text-align:center&quot;&gt; {{title}} &lt;/view&gt;&lt;view&gt; 点击左上角返回回到上级页面 &lt;/view&gt; redirect.js12345678// redirect.js navigator.jsPage({ onLoad: function (options) { this.setData({ title: options.title }) }}) 功能页导航 functional-page-navigator 基础库 2.1.0 开始支持，低版本需做兼容处理。 仅在插件中有效，用于跳转到插件功能页。 属性 类型 默认值 必填 说明 最低版本 version string release 否 跳转到的小程序版本，线上版本必须设置为 release 2.1.0 name string 否 要跳转到的功能页 2.1.0 args object 否 功能页参数，参数格式与具体功能页相关 2.1.0 bindsuccess eventhandler 否 功能页返回，且操作成功时触发， detail 格式与具体功能页相关 2.1.0 bindfail eventhandler 否 功能页返回，且操作失败时触发， detail 格式与具体功能页相关 2.1.0 bindcancel eventhandler 否 因用户操作从功能页返回时触发 2.4.1 version 的合法值 值 说明 最低版本 develop 开发版 trial 体验版 release 正式版 name 的合法值 值 说明 最低版本 loginAndGetUserInfo 用户信息功能页 2.1.0 requestPayment 支付功能页 2.1.0 chooseAddress 收货地址功能页 2.4.0 chooseInvoice 获取发票功能页 2.14.1 chooseInvoiceTitle 获取发票抬头功能页 2.14.1 Bug &amp; Tip tip: 功能页是插件所有者小程序中的一个特殊页面，开发者不能自定义这个页面的外观。 tip: 在功能页展示时，一些与界面展示相关的接口将被禁用（接口调用返回 fail ）。 tip: 这个组件本身可以在开发者工具中使用，但功能页的跳转目前不支持在开发者工具中调试，请在真机上测试。 示例代码1234&lt;!-- sample.wxml --&gt;&lt;functional-page-navigator name=&quot;loginAndGetUserInfo&quot; bind:success=&quot;loginSuccess&quot;&gt; &lt;button&gt;登录到插件&lt;/button&gt;&lt;/functional-page-navigator&gt; 123456789// redirect.js navigator.jsComponent({ methods: { loginSuccess: function(e) { console.log(e.detail.code) // wx.login 的 code console.log(e.detail.userInfo) // wx.getUserInfo 的 userInfo } }})","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E7%BB%84%E4%BB%B6-%E5%AF%BC%E8%88%AA%E7%BB%84%E4%BB%B6/"},{"title":"微信小程序框架组件-开放能力组件","text":"简介开放能力组件大多为新增组件,且使用频率较低,属于相对比较冷门的组件。可以先简单了解一下。 open-data 展示开放数据 组件 基础库 1.4.0 开始支持，低版本需做兼容处理。 用于展示微信开放的数据。 小程序插件中不能使用。 属性 类型 默认值 必填 说明 最低版本 type string 否 开放数据类型 1.4.0 open-gid string 否 当 type=”groupName” 时生效, 群id 1.4.0 lang string en 否 当 type=”user*” 时生效，以哪种语言展示 userInfo 1.4.0 default-text string 否 数据为空时的默认文案 2.8.1 default-avatar string 否 用户头像为空时的默认图片，支持相对路径和网络图片路径 2.8.1 binderror eventhandle 否 群名称或用户信息为空时触发 2.8.1 type 的合法值 值 说明 最低版本 groupName 拉取群名称 1.4.0 userNickName 用户昵称 1.9.90 userAvatarUrl 用户头像 1.9.90 userGender 用户性别 1.9.90 userCity 用户所在城市 1.9.90 userProvince 用户所在省份 1.9.90 userCountry 用户所在国家 1.9.90 userLanguage 用户的语言 1.9.90 lang 的合法值 值 说明 最低版本 en 英文 zh_CN 简体中文 zh_TW 繁体中文 Bug &amp; Tip tip：只有当前用户在此群内才能拉取到群名称 tip：关于open-gid的获取请使用 wx.getShareInfo 示例代码在开发者工具中预览效果 index.wxml123&lt;open-data type=&quot;groupName&quot; open-gid=&quot;xxxxxx&quot;&gt;&lt;/open-data&gt;&lt;open-data type=&quot;userAvatarUrl&quot;&gt;&lt;/open-data&gt;&lt;open-data type=&quot;userGender&quot; lang=&quot;zh_CN&quot;&gt;&lt;/open-data&gt; index.js123456789101112const app = getApp()Page({ data: { }, onLoad: function () { console.log('代码片段是一种迷你、可分享的小程序或小游戏项目，可用于分享小程序和小游戏的开发经验、展示组件和 API 的使用、复现开发问题和 Bug 等。可点击以下链接查看代码片段的详细文档：') console.log('https://mp.weixin.qq.com/debug/wxadoc/dev/devtools/devtools.html') },}) web-view 网页容器 组件 基础库 1.6.4 开始支持，低版本需做兼容处理。 承载网页的容器。会自动铺满整个小程序页面，个人类型的小程序暂不支持使用。 客户端 6.7.2 版本开始，navigationStyle: custom 对 web-view 组件无效 小程序插件中不能使用。 属性 类型 默认值 必填 说明 最低版本 src string 否 webview 指向网页的链接。可打开关联的公众号的文章，其它网页需登录小程序管理后台配置业务域名。 1.6.4 bindmessage eventhandler 否 网页向小程序 postMessage 时，会在特定时机（小程序后退、组件销毁、分享）触发并收到消息。e.detail = { data }，data是多次 postMessage 的参数组成的数组 1.6.4 bindload eventhandler 否 网页加载成功时候触发此事件。e.detail = { src } 1.6.4 binderror eventhandler 否 网页加载失败的时候触发此事件。e.detail = { src } 1.6.4 相关接口 1web-view网页中可使用JSSDK 1.3.2提供的接口返回小程序页面。 支持的接口有： 接口名 说明 最低版本 wx.miniProgram.navigateTo 参数与小程序接口一致 1.6.4 wx.miniProgram.navigateBack 参数与小程序接口一致 1.6.4 wx.miniProgram.switchTab 参数与小程序接口一致 1.6.5 wx.miniProgram.reLaunch 参数与小程序接口一致 1.6.5 wx.miniProgram.redirectTo 参数与小程序接口一致 1.6.5 wx.miniProgram.postMessage 向小程序发送消息，会在特定时机（小程序后退、组件销毁、分享）触发组件的message事件 1.7.1 wx.miniProgram.getEnv 获取当前环境 1.7.1 示例代码在开发者工具中预览效果 index.wxml12345&lt;view class=&quot;page-body&quot;&gt; &lt;view class=&quot;page-section page-section-gap&quot;&gt; &lt;web-view src=&quot;https://mp.weixin.qq.com/&quot;&gt;&lt;/web-view&gt; &lt;/view&gt;&lt;/view&gt; index.js1Page({}) 相关接口 2web-view网页中**仅支持以下JSSDK接口**： 接口模块 接口说明 具体接口 判断客户端是否支持js checkJSApi 图像接口 拍照或上传 chooseImage 预览图片 previewImage 上传图片 uploadImage 下载图片 downloadImage 获取本地图片 getLocalImgData 音频接口 开始录音 startRecord 停止录音 stopRecord 监听录音自动停止 onVoiceRecordEnd 播放语音 playVoice 暂停播放 pauseVoice 停止播放 stopVoice 监听语音播放完毕 onVoicePlayEnd 上传接口 uploadVoice 下载接口 downloadVoice 智能接口 识别音频 translateVoice 设备信息 获取网络状态 getNetworkType 地理位置 使用内置地图打开地点 openLocation 获取地理位置 getLocation 摇一摇周边 开启ibeacon startSearchBeacons 关闭ibeacon stopSearchBeacons 监听ibeacon onSearchBeacons 微信扫一扫 调起微信扫一扫 scanQRCode 微信卡券 拉取使用卡券列表 chooseCard 批量添加卡券接口 addCard 查看微信卡包的卡券 openCard 长按识别 小程序圆形码 无 相关接口 3用户分享时可获取当前web-view的URL，即在onShareAppMessage回调中返回webViewUrl参数。 示例代码示例代码： 12345Page({ onShareAppMessage(options) { console.log(options.webViewUrl) }}) 相关接口 4在网页内可通过window.__wxjs_environment变量判断是否在小程序环境，建议在WeixinJSBridgeReady回调中使用，也可以使用JSSDK 1.3.2提供的getEnv接口。 示例代码1234567891011121314// web-view下的页面内function ready() { console.log(window.__wxjs_environment === 'miniprogram') // true}if (!window.WeixinJSBridge || !WeixinJSBridge.invoke) { document.addEventListener('WeixinJSBridgeReady', ready, false)} else { ready()}// 或者wx.miniProgram.getEnv(function(res) { console.log(res.miniprogram) // true}) 相关接口 5从微信7.0.0开始，可以通过判断userAgent中包含miniProgram字样来判断小程序web-view环境。 相关接口 6从微信7.0.3开始，webview内可以通过判断下面的方式判断小程序是否在前台： 123WeixinJSBridge.on('onPageStateChange', function(res) { console.log('res is active', res.active)}) Bug &amp; Tip tip：网页内 iframe 的域名也需要配置到域名白名单。 tip：开发者工具上，可以在 web-view 组件上通过右键 - 调试，打开 web-view 组件的调试。 tip：每个页面只能有一个 web-view，web-view 会自动铺满整个页面，并覆盖其他组件。 tip：web-view 网页与小程序之间不支持除 JSSDK 提供的接口之外的通信。 tip：在 iOS 中，若存在JSSDK接口调用无响应的情况，可在 web-view 的 src 后面加个#wechat_redirect解决。 tip：避免在链接中带有中文字符，在 iOS 中会有打开白屏的问题，建议加一下 encodeURIComponent ad 广告 组件 基础库 1.9.94 开始支持，低版本需做兼容处理。 Banner 广告。 属性 类型 默认值 必填 说明 最低版本 unit-id string 是 广告单元id，可在小程序管理后台的流量主模块新建 1.9.94 ad-intervals number 否 广告自动刷新的间隔时间，单位为秒，参数值必须大于等于30（该参数不传入时 Banner 广告不会自动刷新） 2.3.1 ad-type string banner 否 广告类型，默认为展示banner，可通过设置该属性为video展示视频广告, grid为格子广告 2.8.0 ad-theme string white 否 2.8.0 bindload eventhandle 否 广告加载成功的回调 2.2.1 binderror eventhandle 否 广告加载失败的回调，event.detail = {errCode: 1002} 2.2.1 bindclose eventhandle 否 广告关闭的回调 2.6.5 错误码信息与解决方案表错误码是通过binderror回调获取到的错误信息。 代码 异常情况 理由 解决方案 1000 后端错误调用失败 该项错误不是开发者的异常情况 一般情况下忽略一段时间即可恢复。 1001 参数错误 使用方法错误 可以前往developers.weixin.qq.com确认具体教程（小程序和小游戏分别有各自的教程，可以在顶部选项中，“设计”一栏的右侧进行切换。 1002 广告单元无效 可能是拼写错误、或者误用了其他APP的广告ID 请重新前往mp.weixin.qq.com确认广告位ID。 1003 内部错误 该项错误不是开发者的异常情况 一般情况下忽略一段时间即可恢复。 1004 无适合的广告 广告不是每一次都会出现，这次没有出现可能是由于该用户不适合浏览广告 属于正常情况，且开发者需要针对这种情况做形态上的兼容。 1005 广告组件审核中 你的广告正在被审核，无法展现广告 请前往mp.weixin.qq.com确认审核状态，且开发者需要针对这种情况做形态上的兼容。 1006 广告组件被驳回 你的广告审核失败，无法展现广告 请前往mp.weixin.qq.com确认审核状态，且开发者需要针对这种情况做形态上的兼容。 1007 广告组件被驳回 你的广告能力已经被封禁，封禁期间无法展现广告 请前往mp.weixin.qq.com确认小程序广告封禁状态。 1008 广告单元已关闭 该广告位的广告能力已经被关闭 请前往mp.weixin.qq.com重新打开对应广告位的展现。 Bug &amp; Tip tip：在无广告展示时，ad 标签不会占用高度 tip：ad 组件不支持触发 bindtap 等触摸相关事件 tip：目前可以给 ad 标签设置 wxss 样式调整广告宽度，以使广告与页面更融洽，但请遵循小程序流量主应用规范 tip：监听到error回调后，开发者可以针对性的处理，比如隐藏广告组件的父容器，以保证用户体验，但不要移除广告组件，否则将无法收到bindload的回调。 ad-custom 原生模板广告 组件 基础库 2.10.4 开始支持，低版本需做兼容处理。 原生模板 广告。 属性 类型 默认值 必填 说明 最低版本 unit-id string 是 广告单元id，可在小程序管理后台的流量主模块新建 2.10.4 ad-intervals number 否 广告自动刷新的间隔时间，单位为秒，参数值必须大于等于30（该参数不传入时 模板 广告不会自动刷新） 2.10.4 bindload eventhandle 否 广告加载成功的回调 2.10.4 binderror eventhandle 否 广告加载失败的回调，event.detail = {errCode: 1002} 2.10.4 错误码信息与解决方案表错误码是通过binderror回调获取到的错误信息。 代码 异常情况 理由 解决方案 1000 后端错误调用失败 该项错误不是开发者的异常情况 一般情况下忽略一段时间即可恢复。 1001 参数错误 使用方法错误 可以前往developers.weixin.qq.com确认具体教程（小程序和小游戏分别有各自的教程，可以在顶部选项中，“设计”一栏的右侧进行切换。 1002 广告单元无效 可能是拼写错误、或者误用了其他APP的广告ID 请重新前往mp.weixin.qq.com确认广告位ID。 1003 内部错误 该项错误不是开发者的异常情况 一般情况下忽略一段时间即可恢复。 1004 无适合的广告 广告不是每一次都会出现，这次没有出现可能是由于该用户不适合浏览广告 属于正常情况，且开发者需要针对这种情况做形态上的兼容。 1005 广告组件审核中 你的广告正在被审核，无法展现广告 请前往mp.weixin.qq.com确认审核状态，且开发者需要针对这种情况做形态上的兼容。 1006 广告组件被驳回 你的广告审核失败，无法展现广告 请前往mp.weixin.qq.com确认审核状态，且开发者需要针对这种情况做形态上的兼容。 1007 广告组件被驳回 你的广告能力已经被封禁，封禁期间无法展现广告 请前往mp.weixin.qq.com确认小程序广告封禁状态。 1008 广告单元已关闭 该广告位的广告能力已经被关闭 请前往mp.weixin.qq.com重新打开对应广告位的展现。 Bug &amp; Tip tip：在无广告展示时，ad-custom 标签不会占用高度 tip：ad-custom 组件不支持触发 bindtap 等触摸相关事件 tip：目前可以给 ad-custom 标签设置 wxss 样式调整广告宽度，以使广告与页面更融洽，但请遵循小程序流量主应用规范 tip：监听到error回调后，开发者可以针对性的处理，比如隐藏广告组件的父容器，以保证用户体验，但不要移除广告组件，否则将无法收到bindload的回调 tip：不同模板涉及一些不同的使用场景，具体方式请参考模板编辑器 official-account 公众号关注 组件 基础库 2.3.0 开始支持，低版本需做兼容处理。 公众号关注组件。当用户扫小程序码打开小程序时，开发者可在小程序内配置公众号关注组件，方便用户快捷关注公众号，可嵌套在原生组件内。 基础库 2.18.1 起，公众号关注组件显示场景值变更如下： 小程序场景值命中以下值时，可展示关注公众号组件： 1011 扫描二维码 1017 前往小程序体验版的入口页 1025 扫描一维码 1047 扫描小程序码 1124 扫“一物一码”打开小程序 小程序热启动场景值命中以下值时，冷启动场景值在【1011、1017、1025、1047、1124】中，可展示关注公众号组件： 1001 发现栏小程序主入口，「最近使用」列表 1038 从另一个小程序返回 1041 从插件小程序返回小程序 1089 微信聊天主界面下拉，「最近使用」栏 1090 长按小程序右上角菜单唤出最近使用历史 1104 微信聊天主界面下拉，「我的小程序」栏 1131 浮窗 1187 新版浮窗，微信8.0起 Tips 使用组件前，需前往小程序后台，在“设置”-&gt;“关注公众号”中设置要展示的公众号。注：设置的公众号需与小程序主体一致。 在一个小程序的生命周期内，只有从以下场景进入小程序，才具有展示引导关注公众号组件的能力: 当小程序从扫小程序码场景（场景值1047，场景值1124）打开时 当小程序从聊天顶部场景（场景值1089）中的「最近使用」内打开时，若小程序之前未被销毁，则该组件保持上一次打开小程序时的状态 当从其他小程序返回小程序（场景值1038）时，若小程序之前未被销毁，则该组件保持上一次打开小程序时的状态 为便于开发者调试，基础库 2.7.3 版本起开发版小程序增加以下场景展示公众号组件： 开发版小程序从扫二维码（场景值 1011）打开 — 体验版小程序打开 组件限定最小宽度为300px，高度为定值84px。 每个页面只能配置一个该组件。 属性名 类型 说明 bindload EventHandle 组件加载成功时触发 binderror EventHandle 组件加载失败时触发 detail 对象 属性名 类型 说明 status Number 状态码 errMsg String 错误信息 status 有效值 值 说明 -2 网络错误 -1 数据解析错误 0 加载成功 1 小程序关注公众号功能被封禁 2 关联公众号被封禁 3 关联关系解除或未选中关联公众号 4 未开启关注公众号功能 5 场景值错误 6 重复创建 示例代码1&lt;official-account&gt;&lt;/official-account&gt;","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E7%BB%84%E4%BB%B6-%E5%BC%80%E6%94%BE%E8%83%BD%E5%8A%9B%E7%BB%84%E4%BB%B6/"},{"title":"微信小程序框架组件-媒体组件","text":"audio音频组件 基础库 1.0.0 开始支持，低版本需做兼容处理。 音频。1.6.0版本开始，该组件不再维护。建议使用能力更强的 wx.createInnerAudioContext 接口 属性 类型 默认值 必填 说明 最低版本 id string 否 audio 组件的唯一标识符 1.0.0 src string 否 要播放音频的资源地址 1.0.0 loop boolean false 否 是否循环播放 1.0.0 controls boolean false 否 是否显示默认控件 1.0.0 poster string 否 默认控件上的音频封面的图片资源地址，如果 controls 属性值为 false 则设置 poster 无效 1.0.0 name string 未知音频 否 默认控件上的音频名字，如果 controls 属性值为 false 则设置 name 无效 1.0.0 author string 未知作者 否 默认控件上的作者名字，如果 controls 属性值为 false 则设置 author 无效 1.0.0 binderror eventhandle 否 当发生错误时触发 error 事件，detail = {errMsg:MediaError.code} 1.0.0 bindplay eventhandle 否 当开始/继续播放时触发play事件 1.0.0 bindpause eventhandle 否 当暂停播放时触发 pause 事件 1.0.0 bindtimeupdate eventhandle 否 当播放进度改变时触发 timeupdate 事件，detail = {currentTime, duration} 1.0.0 bindended eventhandle 否 当播放到末尾时触发 ended 事件 1.0.0 MediaError.code 返回错误码 描述 1 获取资源被用户禁止 2 网络错误 3 解码错误 4 不合适资源 示例代码在开发者工具中预览效果 index.wxml1234567891011121314151617181920212223242526272829303132333435363738&lt;view class=&quot;page&quot;&gt; &lt;view class=&quot;page__hd&quot;&gt; &lt;text class=&quot;page__title&quot;&gt;audio&lt;/text&gt; &lt;text class=&quot;page__desc&quot;&gt;音频&lt;/text&gt; &lt;/view&gt; &lt;view class=&quot;page__bd&quot;&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;audio src=&quot;{{current.src}}&quot; poster=&quot;{{current.poster}}&quot; name=&quot;{{current.name}}&quot; author=&quot;{{current.author}}&quot; action=&quot;{{audioAction}}&quot; bindplay=&quot;audioPlayed&quot; bindtimeupdate=&quot;audioTimeUpdated&quot; controls&gt;&lt;/audio&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;text class=&quot;section__title&quot;&gt;播放&lt;/text&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;button bindtap=&quot;playAudio&quot;&gt;播放&lt;/button&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;text class=&quot;section__title&quot;&gt;暂停&lt;/text&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;button bindtap=&quot;pauseAudio&quot;&gt;暂停&lt;/button&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;text class=&quot;section__title&quot;&gt;进度&lt;/text&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;slider bindchange=&quot;timeSliderChanged&quot; left-icon=&quot;cancel&quot; right-icon=&quot;success_no_circle&quot;/&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;text class=&quot;section__title&quot;&gt;播放速率&lt;/text&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;slider min=&quot;1&quot; max=&quot;4&quot; bindchange=&quot;playbackRateSliderChanged&quot; left-icon=&quot;cancel&quot; right-icon=&quot;success_no_circle&quot;/&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; index.js1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556Page({ data: { current: { poster: 'http://y.gtimg.cn/music/photo_new/T002R300x300M000003rsKF44GyaSk.jpg?max_age=2592000', name: '此时此刻', author: '许巍', src: 'http://ws.stream.qqmusic.qq.com/M500001VfvsJ21xFqb.mp3?guid=ffffffff82def4af4b12b3cd9337d5e7&amp;uin=346897220&amp;vkey=6292F51E1E384E06DCBDC9AB7C49FD713D632D313AC4858BACB8DDD29067D3C601481D36E62053BF8DFEAF74C0A5CCFADD6471160CAF3E6A&amp;fromtag=46', }, audioAction: { method: 'pause' } }, audioPlayed: function (e) { console.log('audio is played') }, audioTimeUpdated: function (e) { this.duration = e.detail.duration; }, timeSliderChanged: function (e) { if (!this.duration) return; var time = this.duration * e.detail.value / 100; this.setData({ audioAction: { method: 'setCurrentTime', data: time } }); }, playbackRateSliderChanged: function (e) { this.setData({ audioAction: { method: 'setPlaybackRate', data: e.detail.value } }) }, playAudio: function () { this.setData({ audioAction: { method: 'play' } }); }, pauseAudio: function () { this.setData({ audioAction: { method: 'pause' } }); }}) camera 系统相机 组件 基础库 1.6.0 开始支持，低版本需做兼容处理。 系统相机。扫码二维码功能，需升级微信客户端至6.7.3。需要用户授权 scope.camera。 2.10.0起 initdone 事件返回 maxZoom，最大变焦范围，相关接口 CameraContext.setZoom。 相关api：wx.createCameraContext 属性 类型 默认值 必填 说明 最低版本 mode string normal 否 应用模式，只在初始化时有效，不能动态变更 2.1.0 resolution string medium 否 分辨率，不支持动态修改 2.10.0 device-position string back 否 摄像头朝向 1.0.0 flash string auto 否 闪光灯，值为auto, on, off 1.0.0 frame-size string medium 否 指定期望的相机帧数据尺寸 2.7.0 bindstop eventhandle 否 摄像头在非正常终止时触发，如退出后台等情况 1.0.0 binderror eventhandle 否 用户不允许使用摄像头时触发 1.0.0 bindinitdone eventhandle 否 相机初始化完成时触发，e.detail = {maxZoom} 2.7.0 bindscancode eventhandle 否 在扫码识别成功时触发，仅在 mode=”scanCode” 时生效 2.1.0 mode 的合法值 值 说明 最低版本 normal 相机模式 scanCode 扫码模式 resolution 的合法值 值 说明 最低版本 low 低 medium 中 high 高 device-position 的合法值 值 说明 最低版本 front 前置 back 后置 flash 的合法值 值 说明 最低版本 auto 自动 on 打开 off 关闭 torch 常亮 2.8.0 frame-size 的合法值 值 说明 最低版本 small 小尺寸帧数据 medium 中尺寸帧数据 large 大尺寸帧数据 Bug &amp; Tip tip: 同一页面只能插入一个 camera 组件 tip:请注意原生组件使用限制 tip:onCameraFrame 接口根据 frame-size 返回不同尺寸的原始帧数据，与 Camera 组件展示的图像不同，其实际像素值由系统决定 示例代码在开发者工具中预览效果 index.wxml1234567891011121314151617&lt;view class=&quot;page-body&quot;&gt; &lt;view class=&quot;page-body-wrapper&quot;&gt; &lt;camera device-position=&quot;back&quot; flash=&quot;off&quot; binderror=&quot;error&quot; style=&quot;width: 100%; height: 300px;&quot;&gt;&lt;/camera&gt; &lt;view class=&quot;btn-area&quot;&gt; &lt;button type=&quot;primary&quot; bindtap=&quot;takePhoto&quot;&gt;拍照&lt;/button&gt; &lt;/view&gt; &lt;view class=&quot;btn-area&quot;&gt; &lt;button type=&quot;primary&quot; bindtap=&quot;startRecord&quot;&gt;开始录像&lt;/button&gt; &lt;/view&gt; &lt;view class=&quot;btn-area&quot;&gt; &lt;button type=&quot;primary&quot; bindtap=&quot;stopRecord&quot;&gt;结束录像&lt;/button&gt; &lt;/view&gt; &lt;view class=&quot;preview-tips&quot;&gt;预览&lt;/view&gt; &lt;image wx:if=&quot;{{src}}&quot; mode=&quot;widthFix&quot; src=&quot;{{src}}&quot;&gt;&lt;/image&gt; &lt;video wx:if=&quot;{{videoSrc}}&quot; class=&quot;video&quot; src=&quot;{{videoSrc}}&quot;&gt;&lt;/video&gt; &lt;/view&gt;&lt;/view&gt; index.js1234567891011121314151617181920212223242526272829303132333435Page({ onLoad() { this.ctx = wx.createCameraContext() }, takePhoto() { this.ctx.takePhoto({ quality: 'high', success: (res) =&gt; { this.setData({ src: res.tempImagePath }) } }) }, startRecord() { this.ctx.startRecord({ success: (res) =&gt; { console.log('startRecord') } }) }, stopRecord() { this.ctx.stopRecord({ success: (res) =&gt; { this.setData({ src: res.tempThumbPath, videoSrc: res.tempVideoPath }) } }) }, error(e) { console.log(e.detail) }}) 真机调试效果： image图片组件 基础库 1.0.0 开始支持，低版本需做兼容处理。 图片。支持 JPG、PNG、SVG、WEBP、GIF 等格式，2.3.0 起支持云文件ID。 属性 类型 默认值 必填 说明 最低版本 src string 否 图片资源地址 1.0.0 mode string scaleToFill 否 图片裁剪、缩放的模式 1.0.0 webp boolean false 否 默认不解析 webP 格式，只支持网络资源 2.9.0 lazy-load boolean false 否 图片懒加载，在即将进入一定范围（上下三屏）时才开始加载 1.5.0 show-menu-by-longpress boolean false 否 长按图片显示发送给朋友、收藏、保存图片、搜一搜、打开名片/前往群聊/打开小程序（若图片中包含对应二维码或小程序码）的菜单 2.7.0 binderror eventhandle 否 当错误发生时触发，event.detail = {errMsg} 1.0.0 bindload eventhandle 否 当图片载入完毕时触发，event.detail = {height, width} 1.0.0 mode 的合法值 值 说明 最低版本 scaleToFill 缩放模式，不保持纵横比缩放图片，使图片的宽高完全拉伸至填满 image 元素 aspectFit 缩放模式，保持纵横比缩放图片，使图片的长边能完全显示出来。也就是说，可以完整地将图片显示出来。 aspectFill 缩放模式，保持纵横比缩放图片，只保证图片的短边能完全显示出来。也就是说，图片通常只在水平或垂直方向是完整的，另一个方向将会发生截取。 widthFix 缩放模式，宽度不变，高度自动变化，保持原图宽高比不变 heightFix 缩放模式，高度不变，宽度自动变化，保持原图宽高比不变 2.10.3 top 裁剪模式，不缩放图片，只显示图片的顶部区域 bottom 裁剪模式，不缩放图片，只显示图片的底部区域 center 裁剪模式，不缩放图片，只显示图片的中间区域 left 裁剪模式，不缩放图片，只显示图片的左边区域 right 裁剪模式，不缩放图片，只显示图片的右边区域 top left 裁剪模式，不缩放图片，只显示图片的左上边区域 top right 裁剪模式，不缩放图片，只显示图片的右上边区域 bottom left 裁剪模式，不缩放图片，只显示图片的左下边区域 bottom right 裁剪模式，不缩放图片，只显示图片的右下边区域 Bug &amp; Tip tip：image组件默认宽度320px、高度240px tip：image组件中二维码/小程序码图片不支持长按识别。仅在wx.previewImage中支持长按识别 示例代码在开发者工具中预览效果 原图 index.wxml1234567891011121314&lt;view class=&quot;page&quot;&gt; &lt;view class=&quot;page__hd&quot;&gt; &lt;text class=&quot;page__title&quot;&gt;image&lt;/text&gt; &lt;text class=&quot;page__desc&quot;&gt;图片&lt;/text&gt; &lt;/view&gt; &lt;view class=&quot;page__bd&quot;&gt; &lt;view class=&quot;section section_gap&quot; wx:for-items=&quot;{{array}}&quot; wx:for-item=&quot;item&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;{{item.text}}&lt;/view&gt; &lt;view class=&quot;section__ctn&quot;&gt; &lt;image style=&quot;width: 200px; height: 200px; background-color: #eeeeee;&quot; mode=&quot;{{item.mode}}&quot; src=&quot;{{src}}&quot;&gt;&lt;/image&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; index.js123456789101112131415161718192021222324252627282930313233343536373839404142434445Page({ data: { array: [{ mode: 'scaleToFill', text: 'scaleToFill：不保持纵横比缩放图片，使图片完全适应' }, { mode: 'aspectFit', text: 'aspectFit：保持纵横比缩放图片，使图片的长边能完全显示出来' }, { mode: 'aspectFill', text: 'aspectFill：保持纵横比缩放图片，只保证图片的短边能完全显示出来' }, { mode: 'top', text: 'top：不缩放图片，只显示图片的顶部区域' }, { mode: 'bottom', text: 'bottom：不缩放图片，只显示图片的底部区域' }, { mode: 'center', text: 'center：不缩放图片，只显示图片的中间区域' }, { mode: 'left', text: 'left：不缩放图片，只显示图片的左边区域' }, { mode: 'right', text: 'right：不缩放图片，只显示图片的右边边区域' }, { mode: 'top left', text: 'top left：不缩放图片，只显示图片的左上边区域' }, { mode: 'top right', text: 'top right：不缩放图片，只显示图片的右上边区域' }, { mode: 'bottom left', text: 'bottom left：不缩放图片，只显示图片的左下边区域' }, { mode: 'bottom right', text: 'bottom right：不缩放图片，只显示图片的右下边区域' }], src: '../resources/cat.jpg' }, imageError: function (e) { console.log('image3发生error事件，携带值为', e.detail.errMsg) }}) live-player 实时音视频播放 组件 基础库 1.7.0 开始支持，低版本需做兼容处理。 实时音视频播放（v2.9.1 起支持同层渲染）。相关api：wx.createLivePlayerContext 暂只针对国内主体如下类目的小程序开放，需要先通过类目审核，再在小程序管理后台，「开发」-「接口设置」中自助开通该组件权限。 一级类目/主体类型 二级类目 小程序内容场景 社交 直播 涉及娱乐性质，如明星直播、生活趣事直播、宠物直播等。选择该类目后首次提交代码审核，需经当地互联网主管机关审核确认，预计审核时长 7 天左右 教育 在线视频课程 网课、在线培训、讲座等教育类直播 医疗 互联网医院，公立医疗机构，私立医疗机构 问诊、大型健康讲座等直播 金融 银行、信托、公募基金、私募基金、证券/期货、证券、期货投资咨询、保险、征信业务、新三板信息服务平台、股票信息服务平台（港股/美股）、消费金融 金融产品视频客服理赔、金融产品推广直播等 汽车 汽车预售服务 汽车预售、推广直播 政府主体帐号 / 政府相关工作推广直播、领导讲话直播等 工具 视频客服 不涉及以上几类内容的一对一视频客服服务，如企业售后一对一视频服务等 IT科技 多方通信；音视频设备 为多方提供电话会议/视频会议等服务；智能家居场景下控制摄像头 在小程序插件中使用需要基础库版本 2.3.0 起。 属性 类型 默认值 必填 说明 最低版本 src string 否 音视频地址。目前仅支持 flv, rtmp 格式 1.7.0 mode string live 否 模式 1.7.0 autoplay boolean false 否 自动播放 1.7.0 muted boolean false 否 是否静音 1.7.0 orientation string vertical 否 画面方向 1.7.0 object-fit string contain 否 填充模式，可选值有 contain，fillCrop 1.7.0 background-mute boolean false 否 进入后台时是否静音（已废弃，默认退后台静音） 1.7.0 min-cache number 1 否 最小缓冲区，单位s（RTC 模式推荐 0.2s） 1.7.0 max-cache number 3 否 最大缓冲区，单位s（RTC 模式推荐 0.8s）。缓冲区用来抵抗网络波动，缓冲数据越多，网络抗性越好，但时延越大。 1.7.0 sound-mode string speaker 否 声音输出方式 1.9.90 auto-pause-if-navigate boolean true 否 当跳转到本小程序的其他页面时，是否自动暂停本页面的实时音视频播放 2.5.0 auto-pause-if-open-native boolean true 否 当跳转到其它微信原生页面时，是否自动暂停本页面的实时音视频播放 2.5.0 picture-in-picture-mode string/Array 否 设置小窗模式： push, pop，空字符串或通过数组形式设置多种模式（如： [“push”, “pop”]） 2.10.3 referrer-policy string no-referrer 否 格式固定为 https://servicewechat.com/{appid}/{version}/page-frame.html，其中 {appid} 为小程序的 appid，{version} 为小程序的版本号，版本号为 0 表示为开发版、体验版以及审核版本，版本号为 devtools 表示为开发者工具，其余为正式版本； 2.13.0 bindstatechange eventhandle 否 播放状态变化事件，detail = {code} 1.7.0 bindfullscreenchange eventhandle 否 全屏变化事件，detail = {direction, fullScreen} 1.7.0 bindnetstatus eventhandle 否 网络状态通知，detail = {info} 1.9.0 bindaudiovolumenotify eventhandler 否 播放音量大小通知，detail = {} 2.10.0 bindenterpictureinpicture eventhandler 否 播放器进入小窗 2.11.0 bindleavepictureinpicture eventhandler 否 播放器退出小窗 2.11.0 mode 的合法值 值 说明 最低版本 live 直播 RTC 实时通话，该模式时延更低 orientation 的合法值 值 说明 最低版本 vertical 竖直 horizontal 水平 object-fit 的合法值 值 说明 最低版本 contain 图像长边填满屏幕，短边区域会被填充⿊⾊ fillCrop 图像铺满屏幕，超出显示区域的部分将被截掉 sound-mode 的合法值 值 说明 最低版本 speaker 扬声器 ear 听筒 picture-in-picture-mode 的合法值 值 说明 最低版本 [] 取消小窗 push 路由 push 时触发小窗 pop 路由 pop 时触发小窗 referrer-policy 的合法值 值 说明 最低版本 origin 发送完整的referrer no-referrer 不发送 状态码 代码 说明 2001 已经连接服务器 2002 已经连接 RTMP 服务器,开始拉流 2003 网络接收到首个视频数据包(IDR) 2004 视频播放开始 2005 视频播放进度 2006 视频播放结束 2007 视频播放Loading 2008 解码器启动 2009 视频分辨率改变 -2301 网络断连，且经多次重连抢救无效，更多重试请自行重启播放 -2302 获取加速拉流地址失败 2101 当前视频帧解码失败 2102 当前音频帧解码失败 2103 网络断连, 已启动自动重连 2104 网络来包不稳：可能是下行带宽不足，或由于主播端出流不均匀 2105 当前视频播放出现卡顿 2106 硬解启动失败，采用软解 2107 当前视频帧不连续，可能丢帧 2108 当前流硬解第一个I帧失败，SDK自动切软解 3001 RTMP -DNS解析失败 3002 RTMP服务器连接失败 3003 RTMP服务器握手失败 3005 RTMP 读/写失败，之后会发起网络重试 网络状态数据 键名 说明 videoBitrate 当前视频编/码器输出的比特率，单位 kbps audioBitrate 当前音频编/码器输出的比特率，单位 kbps videoFPS 当前视频帧率 videoGOP 当前视频 GOP,也就是每两个关键帧(I帧)间隔时长，单位 s netSpeed 当前的发送/接收速度 netJitter 网络抖动情况，为 0 时表示没有任何抖动，值越大表明网络抖动越大，网络越不稳定 netQualityLevel 网络质量：0：未定义 1：最好 2：好 3：一般 4：差 5：很差 6：不可用 videoWidth 视频画面的宽度 videoHeight 视频画面的高度 videoCache 缓冲的视频总时长，单位毫秒 audioCache 缓冲的音频总时长，单位毫秒 vDecCacheSize 解码器中缓存的视频帧数 (Android 端硬解码时存在） vSumCacheSize 缓冲的总视频帧数，该数值越大，播放延迟越高 avPlayInterval 音画同步错位时间（播放），单位 ms，此数值越小，音画同步越好 avRecvInterval 音画同步错位时间（网络），单位 ms，此数值越小，音画同步越好 audioCacheThreshold 音频缓冲时长阈值，缓冲超过该阈值后，播放器会开始调控延时 小窗特性说明live-player 小窗支持以下三种触发模式（在组件上设置 picture-in-picture-mode 属性）： push 模式，即从当前页跳转至下一页时出现小窗（页面栈push） pop 模式，即离开当前页面时触发（页面栈pop） 以上两种路由行为均触发小窗 此外，小窗还支持以下特性： 小窗容器尺寸会根据原组件尺寸自动判断 点击小窗，用户会被导航回小窗对应的播放器页面 小窗出现后，用户可点击小窗右上角的关闭按钮或调用 context.exitPictureInPicture() 接口关闭小窗 当播放器进入小窗模式后，播放器所在页面处于 hide 状态(触发 onHide 生命周期)，该页面不会被销毁。当小窗被关闭时，播放器所在页面会被 unload (触发 onUnload 生命周期)。 Bug &amp; Tip tip：live-player 默认宽度300px、高度225px，可通过wxss设置宽高。 tip：开发者工具上暂不支持。 tip: 相关介绍和原理可参考此文章 示例代码在开发者工具中预览效果 index.wxml1234567891011121314&lt;view class=&quot;page-body&quot;&gt; &lt;view class=&quot;page-section tc&quot;&gt; &lt;live-player id=&quot;player&quot; src=&quot;https://domain/pull_stream&quot; mode=&quot;RTC&quot; autoplay bindstatechange=&quot;statechange&quot; binderror=&quot;error&quot; /&gt; &lt;view class=&quot;btn-area&quot;&gt; &lt;button bindtap=&quot;bindPlay&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;播放&lt;/button&gt; &lt;button bindtap=&quot;bindPause&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;暂停&lt;/button&gt; &lt;button bindtap=&quot;bindStop&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;停止&lt;/button&gt; &lt;button bindtap=&quot;bindResume&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;恢复&lt;/button&gt; &lt;button bindtap=&quot;bindMute&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;静音&lt;/button&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; index.js12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061Page({ onReady(res) { this.ctx = wx.createLivePlayerContext('player') }, statechange(e) { console.log('live-player code:', e.detail.code) }, error(e) { console.error('live-player error:', e.detail.errMsg) }, bindPlay() { this.ctx.play({ success: res =&gt; { console.log('play success') }, fail: res =&gt; { console.log('play fail') } }) }, bindPause() { this.ctx.pause({ success: res =&gt; { console.log('pause success') }, fail: res =&gt; { console.log('pause fail') } }) }, bindStop() { this.ctx.stop({ success: res =&gt; { console.log('stop success') }, fail: res =&gt; { console.log('stop fail') } }) }, bindResume() { this.ctx.resume({ success: res =&gt; { console.log('resume success') }, fail: res =&gt; { console.log('resume fail') } }) }, bindMute() { this.ctx.mute({ success: res =&gt; { console.log('mute success') }, fail: res =&gt; { console.log('mute fail') } }) }}) live-pusher 实时音视频录制 组件 基础库 1.7.0 开始支持，低版本需做兼容处理。 实时音视频录制（v2.9.1 起支持同层渲染）。需要用户授权 scope.camera、scope.record。 暂只针对国内主体如下类目的小程序开放，需要先通过类目审核，再在小程序管理后台，「开发」-「接口设置」中自助开通该组件权限。 一级类目/主体类型 二级类目 小程序内容场景 社交 直播 涉及娱乐性质，如明星直播、生活趣事直播、宠物直播等。选择该类目后首次提交代码审核，需经当地互联网主管机关审核确认，预计审核时长7天左右 教育 在线视频课程 网课、在线培训、讲座等教育类直播 医疗 互联网医院，公立医疗机构，私立医疗机构 问诊、大型健康讲座等直播 金融 银行、信托、公募基金、私募基金、证券/期货、证券、期货投资咨询、保险、征信业务、新三板信息服务平台、股票信息服务平台（港股/美股）、消费金融 金融产品视频客服理赔、金融产品推广直播等 汽车 汽车预售服务 汽车预售、推广直播 政府主体帐号 / 政府相关工作推广直播、领导讲话直播等 工具 视频客服 不涉及以上几类内容的一对一视频客服服务，如企业售后一对一视频服务等 IT科技 多方通信；音视频设备 为多方提供电话会议/视频会议等服务；智能家居场景下控制摄像头 相关api：wx.createLivePusherContext 属性 类型 默认值 必填 说明 最低版本 url string 否 推流地址。目前仅支持 rtmp 格式 1.7.0 mode string RTC 否 SD（标清）, HD（高清）, FHD（超清）, RTC（实时通话） 1.7.0 autopush boolean false 否 自动推流 1.7.0 muted boolean false 否 是否静音。即将废弃，可用 enable-mic 替代 1.7.0 enable-camera boolean true 否 开启摄像头 1.7.0 auto-focus boolean true 否 自动聚集 1.7.0 orientation string vertical 否 画面方向 1.7.0 beauty number 0 否 美颜，取值范围 0-9 ，0 表示关闭 1.7.0 whiteness number 0 否 美白，取值范围 0-9 ，0 表示关闭 1.7.0 aspect string 9:16 否 宽高比，可选值有 3:4, 9:16 1.7.0 min-bitrate number 200 否 最小码率 1.7.0 max-bitrate number 1000 否 最大码率 1.7.0 audio-quality string high 否 高音质(48KHz)或低音质(16KHz)，值为high, low 1.7.0 waiting-image string 否 进入后台时推流的等待画面 1.7.0 waiting-image-hash string 否 等待画面资源的MD5值 1.7.0 zoom boolean false 否 调整焦距 2.1.0 device-position string front 否 前置或后置，值为front, back 2.3.0 background-mute boolean false 否 进入后台时是否静音（已废弃，默认退后台静音） 1.7.0 mirror boolean false 否 设置推流画面是否镜像，产生的效果在 live-player 反应到 2.7.0 remote-mirror boolean false 否 同 mirror 属性，后续 mirror 将废弃 2.10.0 local-mirror string auto 否 控制本地预览画面是否镜像 2.10.0 audio-reverb-type number 0 否 音频混响类型 2.10.0 enable-mic boolean true 否 开启或关闭麦克风 2.10.0 enable-agc boolean false 否 是否开启音频自动增益 2.10.0 enable-ans boolean false 否 是否开启音频噪声抑制 2.10.0 audio-volume-type string auto 否 音量类型 2.10.0 video-width number 360 否 上推的视频流的分辨率宽度 2.10.0 video-height number 640 否 上推的视频流的分辨率高度 2.10.0 beauty-style string smooth 否 设置美颜类型 2.12.0 filter string standard 否 设置色彩滤镜 2.12.0 bindstatechange eventhandle 否 状态变化事件，detail = {code} 1.7.0 bindnetstatus eventhandle 否 网络状态通知，detail = {info} 1.9.0 binderror eventhandle 否 渲染错误事件，detail = {errMsg, errCode} 1.7.4 bindbgmstart eventhandle 否 背景音开始播放时触发 2.4.0 bindbgmprogress eventhandle 否 背景音进度变化时触发，detail = {progress, duration} 2.4.0 bindbgmcomplete eventhandle 否 背景音播放完成时触发 2.4.0 bindaudiovolumenotify eventhandle 否 返回麦克风采集的音量大小 2.12.0 orientation 的合法值 值 说明 最低版本 vertical 竖直 horizontal 水平 local-mirror 的合法值 值 说明 最低版本 auto 前置摄像头镜像，后置摄像头不镜像 enable 前后置摄像头均镜像 disable 前后置摄像头均不镜像 audio-reverb-type 的合法值 值 说明 最低版本 0 关闭 1 KTV 2 小房间 3 大会堂 4 低沉 5 洪亮 6 金属声 7 磁性 audio-volume-type 的合法值 值 说明 最低版本 auto 自动 media 媒体音量 voicecall 通话音量 beauty-style 的合法值 值 说明 最低版本 smooth 光滑美颜 nature 自然美颜 filter 的合法值 值 说明 最低版本 standard 标准 pink 粉嫩 nostalgia 怀旧 blues 蓝调 romantic 浪漫 cool 清凉 fresher 清新 solor 日系 aestheticism 唯美 whitening 美白 cerisered 樱红 Bug &amp; Tip tip：开发者工具上暂不支持。 tip：live-pusher 默认宽度为100%、无默认高度，请通过wxss设置宽高。 tip：waiting-image 属性在 2.3.0 起完整支持网络路径、临时文件和包内路径。 tip：请注意原生组件使用限制。 tip: 相关介绍和原理可参考此文章 错误码（errCode） 代码 说明 10001 用户禁止使用摄像头 10002 用户禁止使用录音 10003 背景音资源（BGM）加载失败 10004 等待画面资源（waiting-image）加载失败 状态码（code） 代码 说明 1001 已经连接推流服务器 1002 已经与服务器握手完毕,开始推流 1003 打开摄像头成功 1004 录屏启动成功 1005 推流动态调整分辨率 1006 推流动态调整码率 1007 首帧画面采集完成 1008 编码器启动 -1301 打开摄像头失败 -1302 打开麦克风失败 -1303 视频编码失败 -1304 音频编码失败 -1305 不支持的视频分辨率 -1306 不支持的音频采样率 -1307 网络断连，且经多次重连抢救无效，更多重试请自行重启推流 -1308 开始录屏失败，可能是被用户拒绝 -1309 录屏失败，不支持的Android系统版本，需要5.0以上的系统 -1310 录屏被其他应用打断了 -1311 Android Mic打开成功，但是录不到音频数据 -1312 录屏动态切横竖屏失败 1101 网络状况不佳：上行带宽太小，上传数据受阻 1102 网络断连, 已启动自动重连 1103 硬编码启动失败,采用软编码 1104 视频编码失败 1105 新美颜软编码启动失败，采用老的软编码 1106 新美颜软编码启动失败，采用老的软编码 3001 RTMP -DNS解析失败 3002 RTMP服务器连接失败 3003 RTMP服务器握手失败 3004 RTMP服务器主动断开，请检查推流地址的合法性或防盗链有效期 3005 RTMP 读/写失败 网络状态数据（info） 键名 说明 videoBitrate 当前视频编/码器输出的比特率，单位 kbps audioBitrate 当前音频编/码器输出的比特率，单位 kbps videoFPS 当前视频帧率 videoGOP 当前视频 GOP,也就是每两个关键帧(I帧)间隔时长，单位 s netSpeed 当前的发送/接收速度 netJitter 网络抖动情况，抖动越大，网络越不稳定 netQualityLevel 网络质量：0：未定义 1：最好 2：好 3：一般 4：差 5：很差 6：不可用 videoWidth 视频画面的宽度 videoHeight 视频画面的高度 videoCache 主播端堆积的视频帧数 audioCache 主播端堆积的音频帧数 示例代码在开发者工具中预览效果 index.wxml1234567891011121314&lt;view class=&quot;page-body&quot;&gt; &lt;view class=&quot;page-section tc&quot;&gt; &lt;live-pusher id=&quot;pusher&quot; url=&quot;https://domain/push_stream&quot; mode=&quot;RTC&quot; autopush bindstatechange=&quot;statechange&quot; /&gt; &lt;view class=&quot;btn-area&quot;&gt; &lt;button bindtap=&quot;bindStart&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;播放推流&lt;/button&gt; &lt;button bindtap=&quot;bindPause&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;暂停推流&lt;/button&gt; &lt;button bindtap=&quot;bindStop&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;停止推流&lt;/button&gt; &lt;button bindtap=&quot;bindResume&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;恢复推流&lt;/button&gt; &lt;button bindtap=&quot;bindSwitchCamera&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;切换前后摄像头&lt;/button&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; index.js12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758Page({ onReady(res) { this.ctx = wx.createLivePusherContext('pusher') }, statechange(e) { console.log('live-pusher code:', e.detail.code) }, bindStart() { this.ctx.start({ success: res =&gt; { console.log('start success') }, fail: res =&gt; { console.log('start fail') } }) }, bindPause() { this.ctx.pause({ success: res =&gt; { console.log('pause success') }, fail: res =&gt; { console.log('pause fail') } }) }, bindStop() { this.ctx.stop({ success: res =&gt; { console.log('stop success') }, fail: res =&gt; { console.log('stop fail') } }) }, bindResume() { this.ctx.resume({ success: res =&gt; { console.log('resume success') }, fail: res =&gt; { console.log('resume fail') } }) }, bindSwitchCamera() { this.ctx.switchCamera({ success: res =&gt; { console.log('switchCamera success') }, fail: res =&gt; { console.log('switchCamera fail') } }) }}) video 视频 组件 基础库 1.0.0 开始支持，低版本需做兼容处理。 视频（v2.4.0 起支持同层渲染）。相关api：wx.createVideoContext 属性 类型 默认值 必填 说明 最低版本 src string 是 要播放视频的资源地址，支持网络路径、本地临时路径、云文件ID（2.3.0） 1.0.0 duration number 否 指定视频时长 1.1.0 controls boolean true 否 是否显示默认播放控件（播放/暂停按钮、播放进度、时间） 1.0.0 danmu-list Array. 否 弹幕列表 1.0.0 danmu-btn boolean false 否 是否显示弹幕按钮，只在初始化时有效，不能动态变更 1.0.0 enable-danmu boolean false 否 是否展示弹幕，只在初始化时有效，不能动态变更 1.0.0 autoplay boolean false 否 是否自动播放 1.0.0 loop boolean false 否 是否循环播放 1.4.0 muted boolean false 否 是否静音播放 1.4.0 initial-time number 0 否 指定视频初始播放位置 1.6.0 page-gesture boolean false 否 在非全屏模式下，是否开启亮度与音量调节手势（废弃，见 vslide-gesture） 1.6.0 direction number 否 设置全屏时视频的方向，不指定则根据宽高比自动判断 1.7.0 show-progress boolean true 否 若不设置，宽度大于240时才会显示 1.9.0 show-fullscreen-btn boolean true 否 是否显示全屏按钮 1.9.0 show-play-btn boolean true 否 是否显示视频底部控制栏的播放按钮 1.9.0 show-center-play-btn boolean true 否 是否显示视频中间的播放按钮 1.9.0 enable-progress-gesture boolean true 否 是否开启控制进度的手势 1.9.0 object-fit string contain 否 当视频大小与 video 容器大小不一致时，视频的表现形式 1.0.0 poster string 否 视频封面的图片网络资源地址或云文件ID（2.3.0）。若 controls 属性值为 false 则设置 poster 无效 1.0.0 show-mute-btn boolean false 否 是否显示静音按钮 2.4.0 title string 否 视频的标题，全屏时在顶部展示 2.4.0 play-btn-position string bottom 否 播放按钮的位置 2.4.0 enable-play-gesture boolean false 否 是否开启播放手势，即双击切换播放/暂停 2.4.0 auto-pause-if-navigate boolean true 否 当跳转到本小程序的其他页面时，是否自动暂停本页面的视频播放 2.5.0 auto-pause-if-open-native boolean true 否 当跳转到其它微信原生页面时，是否自动暂停本页面的视频 2.5.0 vslide-gesture boolean false 否 在非全屏模式下，是否开启亮度与音量调节手势（同 page-gesture） 2.6.2 vslide-gesture-in-fullscreen boolean true 否 在全屏模式下，是否开启亮度与音量调节手势 2.6.2 ad-unit-id string 是 视频前贴广告单元ID，更多详情可参考开放能力视频前贴广告 2.8.1 poster-for-crawler string 是 用于给搜索等场景作为视频封面展示，建议使用无播放 icon 的视频封面图，只支持网络地址 show-casting-button boolean false 否 显示投屏按钮。安卓在同层渲染下生效，支持 DLNA 协议；iOS 支持 AirPlay 和 DLNA 协议 2.10.2 picture-in-picture-mode string/Array 否 设置小窗模式： push, pop，空字符串或通过数组形式设置多种模式（如： [“push”, “pop”]） 2.11.0 picture-in-picture-show-progress boolean false 否 是否在小窗模式下显示播放进度 2.11.0 enable-auto-rotation boolean false 否 是否开启手机横屏时自动全屏，当系统设置开启自动旋转时生效 2.11.0 show-screen-lock-button boolean false 否 是否显示锁屏按钮，仅在全屏时显示，锁屏后控制栏的操作 2.11.0 show-snapshot-button boolean false 否 是否显示截屏按钮，仅在全屏时显示 2.13.0 show-background-playback-button boolean false 否 是否展示后台音频播放按钮 2.14.3 background-poster string 否 进入后台音频播放后的通知栏图标（Android 独有） 2.14.3 referrer-policy string no-referrer 否 格式固定为 https://servicewechat.com/{appid}/{version}/page-frame.html，其中 {appid} 为小程序的 appid，{version} 为小程序的版本号，版本号为 0 表示为开发版、体验版以及审核版本，版本号为 devtools 表示为开发者工具，其余为正式版本； 2.13.0 is-drm boolean 否 是否是 DRM 视频源 2.19.3 provision-url string 否 DRM 设备身份认证 url，仅 is-drm 为 true 时生效 (Android) 2.19.3 certificate-url string 否 DRM 设备身份认证 url，仅 is-drm 为 true 时生效 (iOS) 2.19.3 license-url string 否 DRM 获取加密信息 url，仅 is-drm 为 true 时生效 2.19.3 bindplay eventhandle 否 当开始/继续播放时触发play事件 1.0.0 bindpause eventhandle 否 当暂停播放时触发 pause 事件 1.0.0 bindended eventhandle 否 当播放到末尾时触发 ended 事件 1.0.0 bindtimeupdate eventhandle 否 播放进度变化时触发，event.detail = {currentTime, duration} 。触发频率 250ms 一次 1.0.0 bindfullscreenchange eventhandle 否 视频进入和退出全屏时触发，event.detail = {fullScreen, direction}，direction 有效值为 vertical 或 horizontal 1.4.0 bindwaiting eventhandle 否 视频出现缓冲时触发 1.7.0 binderror eventhandle 否 视频播放出错时触发 1.7.0 bindprogress eventhandle 否 加载进度变化时触发，只支持一段加载。event.detail = {buffered}，百分比 2.4.0 bindloadedmetadata eventhandle 否 视频元数据加载完成时触发。event.detail = {width, height, duration} 2.7.0 bindcontrolstoggle eventhandle 否 切换 controls 显示隐藏时触发。event.detail = {show} 2.9.5 bindenterpictureinpicture eventhandler 否 播放器进入小窗 2.11.0 bindleavepictureinpicture eventhandler 否 播放器退出小窗 2.11.0 bindseekcomplete eventhandler 否 seek 完成时触发 (position iOS 单位 s, Android 单位 ms) 2.12.0 direction 的合法值 值 说明 最低版本 0 正常竖向 90 屏幕逆时针90度 -90 屏幕顺时针90度 object-fit 的合法值 值 说明 最低版本 contain 包含 fill 填充 cover 覆盖 play-btn-position 的合法值 值 说明 最低版本 bottom controls bar上 center 视频中间 picture-in-picture-mode 的合法值 值 说明 最低版本 [] 取消小窗 push 路由 push 时触发小窗 pop 路由 pop 时触发小窗 referrer-policy 的合法值 值 说明 最低版本 origin 发送完整的referrer no-referrer 不发送 Bug &amp; Tip tip：`video 默认宽度 300px、高度 225px，可通过 wxss 设置宽高。 tip：从 2.4.0 起 video 支持同层渲染，更多请参考原生组件使用限制 支持的格式 格式 iOS Android mp4 √ √ mov √ x m4v √ x 3gp √ √ avi √ x m3u8 √ √ webm x √ 支持的编码格式 格式 iOS Android H.264 √ √ HEVC √ √ MPEG-4 √ √ VP9 x √ 小窗特性说明video 小窗支持以下三种触发模式（在组件上设置 picture-in-picture-mode 属性）： push 模式，即从当前页跳转至下一页时出现小窗（页面栈push） pop 模式，即离开当前页面时触发（页面栈pop） 以上两种路由行为均触发小窗 此外，小窗还支持以下特性： 小窗容器尺寸会根据原组件尺寸自动判断 点击小窗，用户会被导航回小窗对应的播放器页面 小窗出现后，用户可点击小窗右上角的关闭按钮或调用 context.exitPictureInPicture() 接口关闭小窗 当播放器进入小窗模式后，播放器所在页面处于 hide 状态(触发 onHide 生命周期)，该页面不会被销毁。当小窗被关闭时，播放器所在页面会被 unload (触发 onUnload 生命周期)。 示例代码在开发者工具中预览效果 index.wxml12345678910111213141516171819202122&lt;view class=&quot;page-body&quot;&gt; &lt;view class=&quot;page-section tc&quot;&gt; &lt;video id=&quot;myVideo&quot; src=&quot;http://wxsnsdy.tc.qq.com/105/20210/snsdyvideodownload?filekey=30280201010421301f0201690402534804102ca905ce620b1241b726bc41dcff44e00204012882540400&amp;bizid=1023&amp;hy=SH&amp;fileparam=302c020101042530230204136ffd93020457e3c4ff02024ef202031e8d7f02030f42400204045a320a0201000400&quot; binderror=&quot;videoErrorCallback&quot; danmu-list=&quot;{{danmuList}}&quot; enable-danmu danmu-btn controls&gt;&lt;/video&gt; &lt;view class=&quot;weui-cells&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;view class=&quot;weui-cell__hd&quot;&gt; &lt;view class=&quot;weui-label&quot;&gt;弹幕内容&lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;weui-cell__bd&quot;&gt; &lt;input bindblur=&quot;bindInputBlur&quot; class=&quot;weui-input&quot; type=&quot;text&quot; placeholder=&quot;在此处输入弹幕内容&quot; /&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;btn-area&quot;&gt; &lt;button bindtap=&quot;bindSendDanmu&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot; formType=&quot;submit&quot;&gt;发送弹幕&lt;/button&gt; &lt;button bindtap=&quot;bindPlay&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;播放&lt;/button&gt; &lt;button bindtap=&quot;bindPause&quot; class=&quot;page-body-button&quot; type=&quot;primary&quot;&gt;暂停&lt;/button&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; index.js12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849function getRandomColor () { const rgb = [] for (let i = 0 ; i &lt; 3; ++i){ let color = Math.floor(Math.random() * 256).toString(16) color = color.length == 1 ? '0' + color : color rgb.push(color) } return '#' + rgb.join('')}Page({ onReady: function (res) { this.videoContext = wx.createVideoContext('myVideo') }, inputValue: '', data: { src: '', danmuList: [{ text: '第 1s 出现的弹幕', color: '#ff0000', time: 1 }, { text: '第 3s 出现的弹幕', color: '#ff00ff', time: 3 }] }, bindInputBlur: function(e) { this.inputValue = e.detail.value }, bindSendDanmu: function () { this.videoContext.sendDanmu({ text: this.inputValue, color: getRandomColor() }) }, bindPlay: function() { this.videoContext.play() }, bindPause: function() { this.videoContext.pause() }, videoErrorCallback: function(e) { console.log('视频错误信息:') console.log(e.detail.errMsg) }}) voip-room 多人视频对话 组件 基础库 2.11.0 开始支持，低版本需做兼容处理。 多人音视频对话。需用户授权 scope.camera、scope.record。相关接口： wx.joinVoIPChat 暂只针对国内主体如下类目的小程序开放，需要先通过类目审核，再在小程序管理后台，「开发」-「接口设置」中自助开通该组件权限。 一级类目/主体类型 二级类目 小程序内容场景 教育 在线视频课程 网课、在线培训、讲座等教育类直播 医疗 互联网医院，公立医院 问诊、大型健康讲座等直播 医疗 私立医疗机构 / 金融 银行、信托、基金、证券/期货、证券、期货投资咨询、保险、征信业务、新三板信息服务平台、股票信息服务平台（港股/美股）、消费金融 金融产品视频客服理赔、金融产品推广直播等 汽车 汽车预售服务 汽车预售、推广直播 政府主体帐号 / 政府相关工作推广直播、领导讲话直播等 IT 科技 多方通信 在线会议 IT 科技 硬件设备 智能硬件 开通该组件权限后，开发者可在 joinVoIPChat 成功后，获取房间成员的 openid，传递给 voip-room 组件，以显示成员画面。 属性 类型 默认值 必填 说明 最低版本 openid string 是 进入房间用户的 openid 2.11.0 mode string camera 否 对话窗口类型，自身传入 camera，其它用户传入 video 2.11.0 device-position string front 否 仅在 mode 为 camera 时有效，前置或后置，值为front, back 2.11.0 binderror eventhandle 否 创建对话窗口失败时触发 2.11.0 Bug &amp; Tip tip：开发者工具上暂不支持 tip：请注意原生组件使用限制 示例代码123456&lt;block wx:for=&quot;{{openIdList}}&quot; wx:key=&quot;*this&quot;&gt; &lt;voip-room openid=&quot;{{item}}&quot; mode=&quot;{{selfOpenId === item ? 'camera' : 'video'}}&quot;&gt; &lt;/voip-room&gt;&lt;/block&gt;","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E7%BB%84%E4%BB%B6-%E5%AA%92%E4%BD%93%E7%BB%84%E4%BB%B6/"},{"title":"微信小程序框架组件-组件基础内容","text":"组件基础内容分类，如下图: 图标icon 基础库 1.0.0 开始支持，低版本需做兼容处理。 图标。组件属性的长度单位默认为px，2.4.0起支持传入单位(rpx/px)。 属性 类型 默认值 必填 说明 最低版本 type string 是 icon的类型，有效值：success, success_no_circle, info, warn, waiting, cancel, download, search, clear 1.0.0 size number/string 23 否 icon的大小 1.0.0 color string 否 icon的颜色，同css的color 1.0.0 示例代码在开发者工具中预览效果 index.wxml123456789101112131415161718&lt;view class=&quot;group&quot;&gt; &lt;block wx:for=&quot;{{iconSize}}&quot;&gt; &lt;icon type=&quot;success&quot; size=&quot;{{item}}&quot;/&gt; &lt;/block&gt;&lt;/view&gt;&lt;view class=&quot;group&quot;&gt; &lt;block wx:for=&quot;{{iconType}}&quot;&gt; &lt;icon type=&quot;{{item}}&quot; size=&quot;40&quot;/&gt; &lt;/block&gt;&lt;/view&gt;&lt;view class=&quot;group&quot;&gt; &lt;block wx:for=&quot;{{iconColor}}&quot;&gt; &lt;icon type=&quot;success&quot; size=&quot;40&quot; color=&quot;{{item}}&quot;/&gt; &lt;/block&gt;&lt;/view&gt; index.js1234567891011Page({ data: { iconSize: [20, 30, 40, 50, 60, 70], iconColor: [ 'red', 'orange', 'yellow', 'green', 'rgb(0,255,255)', 'blue', 'purple' ], iconType: [ 'success', 'success_no_circle', 'info', 'warn', 'waiting', 'cancel', 'download', 'search', 'clear' ] }}) 进度条progress 基础库 1.0.0 开始支持，低版本需做兼容处理。 进度条。组件属性的长度单位默认为px，2.4.0起支持传入单位(rpx/px)。 属性 类型 默认值 必填 说明 最低版本 percent number 否 百分比0~100 1.0.0 show-info boolean false 否 在进度条右侧显示百分比 1.0.0 border-radius number/string 0 否 圆角大小 2.3.1 font-size number/string 16 否 右侧百分比字体大小 2.3.1 stroke-width number/string 6 否 进度条线的宽度 1.0.0 color string #09BB07 否 进度条颜色（请使用activeColor） 1.0.0 activeColor string #09BB07 否 已选择的进度条的颜色 1.0.0 backgroundColor string #EBEBEB 否 未选择的进度条的颜色 1.0.0 active boolean false 否 进度条从左往右的动画 1.0.0 active-mode string backwards 否 backwards: 动画从头播；forwards：动画从上次结束点接着播 1.7.0 duration number 30 否 进度增加1%所需毫秒数 2.8.2 bindactiveend eventhandle 否 动画完成事件 2.4.1 示例代码在开发者工具中预览效果 index.wxml1234&lt;progress percent=&quot;20&quot; show-info /&gt;&lt;progress percent=&quot;40&quot; stroke-width=&quot;12&quot; /&gt;&lt;progress percent=&quot;60&quot; color=&quot;pink&quot; /&gt;&lt;progress percent=&quot;80&quot; active /&gt; 富文本rich-text 基础库 1.4.0 开始支持，低版本需做兼容处理。 富文本。 属性 类型 默认值 必填 说明 最低版本 nodes array/string [] 否 节点列表/HTML String 1.4.0 space string 否 显示连续空格 2.4.1 space 的合法值 值 说明 最低版本 ensp 中文字符空格一半大小 emsp 中文字符空格大小 nbsp 根据字体设置的空格大小 nodes现支持两种节点，通过type来区分，分别是元素节点和文本节点，默认是元素节点，在富文本区域里显示的HTML节点 元素节点：type = node 属性 说明 类型 必填 备注 name 标签名 string 是 支持部分受信任的 HTML 节点 attrs 属性 object 否 支持部分受信任的属性，遵循 Pascal 命名法 children 子节点列表 array 否 结构和 nodes 一致 文本节点：type = text 属性 说明 类型 必填 备注 text 文本 string 是 支持entities 受信任的HTML节点及属性全局支持class和style属性，不支持id属性。 节点 属性 a abbr address article aside b bdi bdo dir big blockquote br caption center cite code col span，width colgroup span，width dd del div dl dt em fieldset font footer h1 h2 h3 h4 h5 h6 header hr i img alt，src，height，width ins label legend li mark nav ol start，type p pre q rt ruby s section small span strong sub sup table width tbody td colspan，height，rowspan，width tfoot th colspan，height，rowspan，width thead tr colspan，height，rowspan，width tt u ul Bug &amp; Tip tip: nodes 不推荐使用 String 类型，性能会有所下降。 tip: rich-text 组件内屏蔽所有节点的事件。 tip: attrs 属性不支持 id ，支持 class 。 tip: name 属性大小写不敏感。 tip: 如果使用了不受信任的HTML节点，该节点及其所有子节点将会被移除。 tip: img 标签仅支持网络图片。 tip: 如果在自定义组件中使用 rich-text 组件，那么仅自定义组件的 wxss 样式对 rich-text 中的 class 生效。 示例代码在开发者工具中预览效果 index.wxml123456789101112131415&lt;view class=&quot;page-body&quot;&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;page-section-title&quot;&gt;传入html字符串&lt;/view&gt; &lt;view class=&quot;rich-text-wrp&quot;&gt; &lt;rich-text nodes=&quot;{{html}}&quot; bindtap=&quot;tap&quot;&gt;&lt;/rich-text&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;page-section-title&quot;&gt;传入节点列表&lt;/view&gt; &lt;view class=&quot;rich-text-wrp&quot;&gt; &lt;rich-text nodes=&quot;{{nodes}}&quot; bindtap=&quot;tap&quot;&gt;&lt;/rich-text&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; index.js12345678910111213141516171819Page({ data: { html: '&lt;div class=&quot;div_class&quot; style=&quot;line-height: 60px; color: red;&quot;&gt;Hello&amp;nbsp;World!&lt;/div&gt;', nodes: [{ name: 'div', attrs: { class: 'div_class', style: 'line-height: 60px; color: red;' }, children: [{ type: 'text', text: 'Hello&amp;nbsp;World!' }] }] }, tap() { console.log('tap') }}) 文本text 基础库 1.0.0 开始支持，低版本需做兼容处理。 文本。 属性 类型 默认值 必填 说明 最低版本 selectable boolean false 否 文本是否可选 (已废弃) 1.1.0 user-select boolean false 否 文本是否可选，该属性会使文本节点显示为 inline-block 2.12.1 space string 否 显示连续空格 1.4.0 decode boolean false 否 是否解码 1.4.0 space 的合法值 值 说明 最低版本 ensp 中文字符空格一半大小 emsp 中文字符空格大小 nbsp 根据字体设置的空格大小 Bug &amp; Tip tip: decode可以解析的有 &lt; &gt; &amp; ' tip: 各个操作系统的空格标准并不一致。 tip:text 组件内只支持 text 嵌套。 tip: 除了文本节点以外的其他节点都无法长按选中。 bug: 基础库版本低于 2.1.0 时， text 组件内嵌的 text style 设置可能不会生效。 示例代码在开发者工具中预览效果 index.wxml1234567891011&lt;view class=&quot;btn-area&quot;&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;text&gt;{{text}}&lt;/text&gt; &lt;button bindtap=&quot;add&quot;&gt;add line&lt;/button&gt; &lt;button bindtap=&quot;remove&quot;&gt;remove line&lt;/button&gt; &lt;/view&gt;&lt;/view&gt;&lt;view&gt;&lt;text user-select&gt;bb iu&lt;/text&gt;&lt;/view&gt;&lt;view&gt;&lt;text user-select space=&quot;nbsp&quot;&gt;bb i&amp;nbsp; &amp;lt; &amp;gt; &amp;amp; &amp;apos; &amp;ensp; &amp;emsp;u&lt;/text&gt;&lt;/view&gt;&lt;view&gt;&lt;text user-select space=&quot;nbsp&quot; decode&gt;bb i&amp;nbsp; &amp;lt; &amp;gt; &amp;amp; &amp;apos; &amp;ensp; &amp;emsp;u&lt;/text&gt;&lt;/view&gt; index.js123456789101112131415161718192021var initData = 'this is first line\\nthis is second line'var extraLine = [];Page({ data: { text: initData }, add: function (e) { extraLine.push('other line') this.setData({ text: initData + '\\n' + extraLine.join('\\n') }) }, remove: function (e) { if (extraLine.length &gt; 0) { extraLine.pop() this.setData({ text: initData + '\\n' + extraLine.join('\\n') }) } }})","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E7%BB%84%E4%BB%B6-%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9/"},{"title":"微信小程序框架组件-视图容器组件","text":"视图容器view 基础库 1.0.0 开始支持，低版本需做兼容处理。 视图容器(View)是小程序框架组件中最常见的基础组件,它的作用跟 HTML中的DIV功能非常相似,用来布 局 WXML界面。 属性 类型 默认值 必填 说明 最低版本 hover-class string none 否 指定按下去的样式类。当 hover-class=&quot;none&quot; 时，没有点击态效果 1.0.0 hover-stop-propagation boolean false 否 指定是否阻止本节点的祖先节点出现点击态 1.5.0 hover-start-time number 50 否 按住后多久出现点击态，单位毫秒 1.0.0 hover-stay-time number 400 否 手指松开后点击态保留时间，单位毫秒 1.0.0 案例一:设置长按点击效果，以及时间;12&lt;!--pages/viewTest/viewTest.wxml--&gt;&lt;view hover-class=&quot;hc&quot; hover-start-time=&quot;1000&quot; hover-stay-time=&quot;2000&quot;&gt;buubiu&lt;/view&gt; 1234/* pages/viewTest/viewTest.wxss */.hc{ border: 1px solid red;} 案例二:flex布局在开发者工具中预览效果 视图容器分类: 可滚动视图区域scroll-view 基础库 1.0.0 开始支持，低版本需做兼容处理。 可滚动视图区域。使用竖向滚动时，需要给scroll-view一个固定高度，通过 WXSS 设置 height。组件属性的长度单位默认为px，2.4.0起支持传入单位(rpx/px)。 属性 类型 默认值 必填 说明 最低版本 scroll-x boolean false 否 允许横向滚动 1.0.0 scroll-y boolean false 否 允许纵向滚动 1.0.0 upper-threshold number/string 50 否 距顶部/左边多远时，触发 scrolltoupper 事件 1.0.0 lower-threshold number/string 50 否 距底部/右边多远时，触发 scrolltolower 事件 1.0.0 scroll-top number/string 否 设置竖向滚动条位置 1.0.0 scroll-left number/string 否 设置横向滚动条位置 1.0.0 scroll-into-view string 否 值应为某子元素id（id不能以数字开头）。设置哪个方向可滚动，则在哪个方向滚动到该元素 1.0.0 scroll-with-animation boolean false 否 在设置滚动条位置时使用动画过渡 1.0.0 enable-back-to-top boolean false 否 iOS点击顶部状态栏、安卓双击标题栏时，滚动条返回顶部，只支持竖向 1.0.0 enable-flex boolean false 否 启用 flexbox 布局。开启后，当前节点声明了 display: flex 就会成为 flex container，并作用于其孩子节点。 2.7.3 scroll-anchoring boolean false 否 开启 scroll anchoring 特性，即控制滚动位置不随内容变化而抖动，仅在 iOS 下生效，安卓下可参考 CSS overflow-anchor 属性。 2.8.2 refresher-enabled boolean false 否 开启自定义下拉刷新 2.10.1 refresher-threshold number 45 否 设置自定义下拉刷新阈值 2.10.1 refresher-default-style string “black” 否 设置自定义下拉刷新默认样式，支持设置 `black white refresher-background string “#FFF” 否 设置自定义下拉刷新区域背景颜色 2.10.1 refresher-triggered boolean false 否 设置当前下拉刷新状态，true 表示下拉刷新已经被触发，false 表示下拉刷新未被触发 2.10.1 enhanced boolean false 否 启用 scroll-view 增强特性，启用后可通过 ScrollViewContext 操作 scroll-view 2.12.0 bounces boolean true 否 iOS 下 scroll-view 边界弹性控制 (同时开启 enhanced 属性后生效) 2.12.0 show-scrollbar boolean true 否 滚动条显隐控制 (同时开启 enhanced 属性后生效) 2.12.0 paging-enabled boolean false 否 分页滑动效果 (同时开启 enhanced 属性后生效) 2.12.0 fast-deceleration boolean false 否 滑动减速速率控制 (同时开启 enhanced 属性后生效) 2.12.0 binddragstart eventhandle 否 滑动开始事件 (同时开启 enhanced 属性后生效) detail { scrollTop, scrollLeft } 2.12.0 binddragging eventhandle 否 滑动事件 (同时开启 enhanced 属性后生效) detail { scrollTop, scrollLeft } 2.12.0 binddragend eventhandle 否 滑动结束事件 (同时开启 enhanced 属性后生效) detail { scrollTop, scrollLeft, velocity } 2.12.0 bindscrolltoupper eventhandle 否 滚动到顶部/左边时触发 1.0.0 bindscrolltolower eventhandle 否 滚动到底部/右边时触发 1.0.0 bindscroll eventhandle 否 滚动时触发，event.detail = {scrollLeft, scrollTop, scrollHeight, scrollWidth, deltaX, deltaY} 1.0.0 bindrefresherpulling eventhandle 否 自定义下拉刷新控件被下拉 2.10.1 bindrefresherrefresh eventhandle 否 自定义下拉刷新被触发 2.10.1 bindrefresherrestore eventhandle 否 自定义下拉刷新被复位 2.10.1 bindrefresherabort eventhandle 否 自定义下拉刷新被中止 2.10.1 示例代码在开发者工具中预览效果 滑块视图容器swiper 基础库 1.0.0 开始支持，低版本需做兼容处理。 滑块视图容器。其中只可放置swiper-item组件，否则会导致未定义的行为。 属性 类型 默认值 必填 说明 最低版本 indicator-dots boolean false 否 是否显示面板指示点 1.0.0 indicator-color color rgba(0, 0, 0, .3) 否 指示点颜色 1.1.0 indicator-active-color color #000000 否 当前选中的指示点颜色 1.1.0 autoplay boolean false 否 是否自动切换 1.0.0 current number 0 否 当前所在滑块的 index 1.0.0 interval number 5000 否 自动切换时间间隔 1.0.0 duration number 500 否 滑动动画时长 1.0.0 circular boolean false 否 是否采用衔接滑动 1.0.0 vertical boolean false 否 滑动方向是否为纵向 1.0.0 previous-margin string “0px” 否 前边距，可用于露出前一项的一小部分，接受 px 和 rpx 值 1.9.0 next-margin string “0px” 否 后边距，可用于露出后一项的一小部分，接受 px 和 rpx 值 1.9.0 snap-to-edge boolean “false” 否 当 swiper-item 的个数大于等于 2，关闭 circular 并且开启 previous-margin 或 next-margin 的时候，可以指定这个边距是否应用到第一个、最后一个元素 2.12.1 display-multiple-items number 1 否 同时显示的滑块数量 1.9.0 easing-function string “default” 否 指定 swiper 切换缓动动画类型 2.6.5 bindchange eventhandle 否 current 改变时会触发 change 事件，event.detail = {current, source} 1.0.0 bindtransition eventhandle 否 swiper-item 的位置发生改变时会触发 transition 事件，event.detail = {dx: dx, dy: dy} 2.4.3 bindanimationfinish eventhandle 否 动画结束时会触发 animationfinish 事件，event.detail 同上 1.9.0 easing-function 的合法值 值 说明 最低版本 default 默认缓动函数 linear 线性动画 easeInCubic 缓入动画 easeOutCubic 缓出动画 easeInOutCubic 缓入缓出动画 change事件 source 返回值 从 1.4.0 开始，change事件增加 source字段，表示导致变更的原因，可能值如下： autoplay 自动播放导致swiper变化； touch 用户划动引起swiper变化； 其它原因将用空字符串表示。 示例代码在开发者工具中预览效果 swiper-item 基础库 1.0.0 开始支持，低版本需做兼容处理。 仅可放置在swiper组件中，宽高自动设置为100%。 属性 类型 默认值 必填 说明 最低版本 item-id string 否 该 swiper-item 的标识符 1.9.0 skip-hidden-item-layout boolean false 否 是否跳过未显示的滑块布局，设为 true 可优化复杂情况下的滑动性能，但会丢失隐藏状态滑块的布局信息 1.9.0 可移动的视图容器movable-view 基础库 1.2.0 开始支持，低版本需做兼容处理。 可移动的视图容器，在页面中可以拖拽滑动。movable-view必须在 movable-area 组件中，并且必须是直接子节点，否则不能移动。 属性 类型 默认值 必填 说明 最低版本 direction string none 否 movable-view的移动方向，属性值有all、vertical、horizontal、none 1.2.0 inertia boolean false 否 movable-view是否带有惯性 1.2.0 out-of-bounds boolean false 否 超过可移动区域后，movable-view是否还可以移动 1.2.0 x number/string 否 定义x轴方向的偏移，如果x的值不在可移动范围内，会自动移动到可移动范围；改变x的值会触发动画；单位支持px（默认）、rpx； 1.2.0 y number/string 否 定义y轴方向的偏移，如果y的值不在可移动范围内，会自动移动到可移动范围；改变y的值会触发动画；单位支持px（默认）、rpx； 1.2.0 damping number 20 否 阻尼系数，用于控制x或y改变时的动画和过界回弹的动画，值越大移动越快 1.2.0 friction number 2 否 摩擦系数，用于控制惯性滑动的动画，值越大摩擦力越大，滑动越快停止；必须大于0，否则会被设置成默认值 1.2.0 disabled boolean false 否 是否禁用 1.9.90 scale boolean false 否 是否支持双指缩放，默认缩放手势生效区域是在movable-view内 1.9.90 scale-min number 0.5 否 定义缩放倍数最小值 1.9.90 scale-max number 10 否 定义缩放倍数最大值 1.9.90 scale-value number 1 否 定义缩放倍数，取值范围为 0.5 - 10 1.9.90 animation boolean true 否 是否使用动画 2.1.0 bindchange eventhandle 否 拖动过程中触发的事件，event.detail = {x, y, source} 1.9.90 bindscale eventhandle 否 缩放过程中触发的事件，event.detail = {x, y, scale}，x和y字段在2.1.0之后支持 1.9.90 htouchmove eventhandle 否 初次手指触摸后移动为横向的移动时触发，如果catch此事件，则意味着touchmove事件也被catch 1.9.90 vtouchmove eventhandle 否 初次手指触摸后移动为纵向的移动时触发，如果catch此事件，则意味着touchmove事件也被catch 1.9.90 bindchange 返回的 source 表示产生移动的原因 值 说明 touch 拖动 touch-out-of-bounds 超出移动范围 out-of-bounds 超出移动范围后的回弹 friction 惯性 空字符串 setData movable-area 基础库 1.2.0 开始支持，低版本需做兼容处理。 movable-view的可移动区域。 属性 类型 默认值 必填 说明 最低版本 scale-area Boolean false 否 当里面的movable-view设置为支持双指缩放时，设置此值可将缩放手势生效区域修改为整个movable-area 1.9.90 示例代码在开发者工具中预览效果 覆盖在原生组件之上的文本视图cover-view 基础库 1.4.0 开始支持，低版本需做兼容处理。 覆盖在原生组件之上的文本视图。 目前原生组件均已支持同层渲染，建议使用 view 替代。可覆盖的原生组件包括 map、video、canvas、camera、live-player、live-pusher 只支持嵌套 cover-view、cover-image，可在 cover-view 中使用 button。组件属性的长度单位默认为px，2.4.0起支持传入单位(rpx/px)。 属性 类型 默认值 必填 说明 最低版本 scroll-top number/string 否 设置顶部滚动偏移量，仅在设置了 overflow-y: scroll 成为滚动元素后生效 2.1.0 示例代码在开发者工具中预览效果 覆盖在原生组件之上的图片视图cover-image 基础库 1.4.0 开始支持，低版本需做兼容处理。 覆盖在原生组件之上的图片视图。 目前原生组件均已支持同层渲染，建议使用 image 替代。可覆盖的原生组件同cover-view，支持嵌套在cover-view里。 属性 类型 默认值 必填 说明 最低版本 src string 否 图标路径，支持临时路径、网络地址（1.6.0起支持）、云文件ID（2.2.3起支持）。 1.4.0 referrer-policy string no-referrer 否 格式固定为 https://servicewechat.com/{appid}/{version}/page-frame.html，其中 {appid} 为小程序的 appid，{version} 为小程序的版本号，版本号为 0 表示为开发版、体验版以及审核版本，版本号为 devtools 表示为开发者工具，其余为正式版本； 2.13.0 bindload eventhandle 否 图片加载成功时触发 2.1.0 binderror eventhandle 否 图片加载失败时触发 2.1.0 referrer-policy 的合法值 值 说明 最低版本 origin 发送完整的referrer no-referrer 不发送 支持的格式 格式 iOS Android JPG √ √ PNG √ √ SVG x x WEBP √ √ GIF √ √ BASE64 x x 共享元素share-element 基础库 2.16.0 开始支持，低版本需做兼容处理。 共享元素。 共享元素是一种动画形式，类似于 flutter Hero动画，表现为元素像是在页面间穿越一样。该组件需与 page-container 组件结合使用。 使用时需在当前页放置 share-element 组件，同时在 page-container 容器中放置对应的 share-element 组件，对应关系通过属性值 key 映射。当设置 page-container 显示时，transform 属性为 true 的共享元素会产生动画。当前页面容器退出时，会产生返回动画。 属性 类型 默认值 必填 说明 最低版本 key string 是 映射标记 2.16.0 transform boolean false 否 是否进行动画 2.16.0 duration number 300 否 动画时长，单位毫秒 2.16.0 easing-function string ease-out 否 css缓动函数 2.16.0 示例代码在开发者工具中预览效果 规则匹配match-media 基础库 2.11.1 开始支持，低版本需做兼容处理。 media query 匹配检测节点。可以指定一组 media query 规则，满足时，这个节点才会被展示。 通过这个节点可以实现“页面宽高在某个范围时才展示某个区域”这样的效果。 属性 类型 默认值 必填 说明 最低版本 min-width number 否 页面最小宽度（ px 为单位） 2.11.1 max-width number 否 页面最大宽度（ px 为单位） 2.11.1 width number 否 页面宽度（ px 为单位） 2.11.1 min-height number 否 页面最小高度（ px 为单位） 2.11.1 max-height number 否 页面最大高度（ px 为单位） 2.11.1 height number 否 页面高度（ px 为单位） 2.11.1 orientation string 否 屏幕方向（ landscape 或 portrait ） 2.11.1 示例代码1234567&lt;match-media min-width=&quot;300&quot; max-width=&quot;600&quot;&gt; &lt;view&gt;当页面宽度在 300 ~ 500 px 之间时展示这里&lt;/view&gt;&lt;/match-media&gt;&lt;match-media min-height=&quot;400&quot; orientation=&quot;landscape&quot;&gt; &lt;view&gt;当页面高度不小于 400 px 且屏幕方向为纵向时展示这里&lt;/view&gt;&lt;/match-media&gt;","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E7%BB%84%E4%BB%B6-%E8%A7%86%E5%9B%BE%E5%AE%B9%E5%99%A8%E7%BB%84%E4%BB%B6/"},{"title":"微信小程序框架组件简单介绍","text":"组件介绍微信小程序框架为开发者提供了一系列完备的UI组件,方便开发者快速构建小程序UI界面。借助这些UI组 件开发者可以像搭积木一样快速地拼装出一栋房子的样子,这非常类似于当下建筑行业比较流行的装配式 建筑,UI组件就好比预先定制好的建筑构件,只需要按照设计图纸即可快速组装各个组件,便捷迅速地完成 界面布局和渲染工作。 下方思维导图是小程序的组件，重点掌握核心组件和重点组件，了解扩展;","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E7%BB%84%E4%BB%B6%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/"},{"title":"微信小程序自定义组件-Component 构造器","text":"Component 构造器可用于定义组件，调用 Component 构造器时可以指定组件的属性、数据、方法等。 详细的参数含义和使用请参考 Component 参考文档。 Component(Object object)创建自定义组件，接受一个 Object 类型的参数。 参数Object object 定义段 类型 是否必填 描述 最低版本 properties Object Map 否 组件的对外属性，是属性名到属性设置的映射表 data Object 否 组件的内部数据，和 properties 一同用于组件的模板渲染 observers Object 否 组件数据字段监听器，用于监听 properties 和 data 的变化，参见 数据监听器 2.6.1 methods Object 否 组件的方法，包括事件响应函数和任意的自定义方法，关于事件响应函数的使用，参见 组件间通信与事件 behaviors String Array 否 类似于mixins和traits的组件间代码复用机制，参见 behaviors created Function 否 组件生命周期函数-在组件实例刚刚被创建时执行，注意此时不能调用 setData ) attached Function 否 组件生命周期函数-在组件实例进入页面节点树时执行) ready Function 否 组件生命周期函数-在组件布局完成后执行) moved Function 否 组件生命周期函数-在组件实例被移动到节点树另一个位置时执行) detached Function 否 组件生命周期函数-在组件实例被从页面节点树移除时执行) relations Object 否 组件间关系定义，参见 组件间关系 externalClasses String Array 否 组件接受的外部样式类，参见 外部样式类 options Object Map 否 一些选项（文档中介绍相关特性时会涉及具体的选项设置，这里暂不列举） lifetimes Object 否 组件生命周期声明对象，参见 组件生命周期 2.2.3 pageLifetimes Object 否 组件所在页面的生命周期声明对象，参见 组件生命周期 2.2.3 definitionFilter Function 否 定义段过滤器，用于自定义组件扩展，参见 自定义组件扩展 2.2.3 生成的组件实例可以在组件的方法、生命周期函数和属性 observer 中通过 this 访问。组件包含一些通用属性和方法。 属性名 类型 描述 is String 组件的文件路径 id String 节点id dataset String 节点dataset data Object 组件数据，包括内部数据和属性值 properties Object 组件数据，包括内部数据和属性值（与 data 一致） router Object 相对于当前自定义组件的 Router 对象 pageRouter Object 相对于当前自定义组件所在页面的 Router 对象 方法名 参数 描述 最低版本 setData Object newData 设置data并执行视图层渲染 hasBehavior Object behavior 检查组件是否具有 behavior （检查时会递归检查被直接或间接引入的所有behavior） triggerEvent String name, Object detail, Object options 触发事件，参见 组件间通信与事件 createSelectorQuery 创建一个 SelectorQuery 对象，选择器选取范围为这个组件实例内 createIntersectionObserver 创建一个 IntersectionObserver 对象，选择器选取范围为这个组件实例内 createMediaQueryObserver 创建一个 MediaQueryObserver 对象 2.11.1 selectComponent String selector 使用选择器选择组件实例节点，返回匹配到的第一个组件实例对象（会被 wx://component-export 影响） selectAllComponents String selector 使用选择器选择组件实例节点，返回匹配到的全部组件实例对象组成的数组（会被 wx://component-export 影响） selectOwnerComponent 选取当前组件节点所在的组件实例（即组件的引用者），返回它的组件实例对象（会被 wx://component-export 影响） 2.8.2 getRelationNodes String relationKey 获取这个关系所对应的所有关联节点，参见 组件间关系 groupSetData Function callback 立刻执行 callback ，其中的多个 setData 之间不会触发界面绘制（只有某些特殊场景中需要，如用于在不同组件同时 setData 时进行界面绘制同步） 2.4.0 getTabBar 返回当前页面的 custom-tab-bar 的组件实例，详见自定义 tabBar 2.6.2 getPageId 返回页面标识符（一个字符串），可以用来判断几个自定义组件实例是不是在同一个页面内 2.7.1 animate String selector, Array keyframes, Number duration, Function callback 执行关键帧动画，详见动画 2.9.0 clearAnimation String selector, Object options, Function callback 清除关键帧动画，详见动画 2.9.0 setUpdatePerformanceListener Object options, Function listener 清除关键帧动画，详见动画 2.12.0 示例代码在开发者工具中预览效果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152Component({ behaviors: [], // 属性定义（详情参见下文） properties: { myProperty: { // 属性名 type: String, value: '' }, myProperty2: String // 简化的定义方式 }, data: {}, // 私有数据，可用于模板渲染 lifetimes: { // 生命周期函数，可以为函数，或一个在methods段中定义的方法名 attached: function () { }, moved: function () { }, detached: function () { }, }, // 生命周期函数，可以为函数，或一个在methods段中定义的方法名 attached: function () { }, // 此处attached的声明会被lifetimes字段中的声明覆盖 ready: function() { }, pageLifetimes: { // 组件所在页面的生命周期函数 show: function () { }, hide: function () { }, resize: function () { }, }, methods: { onMyButtonTap: function(){ this.setData({ // 更新属性和数据的方法与更新页面数据的方法类似 }) }, // 内部方法建议以下划线开头 _myPrivateMethod: function(){ // 这里将 data.A[0].B 设为 'myPrivateData' this.setData({ 'A[0].B': 'myPrivateData' }) }, _propertyChange: function(newVal, oldVal) { } }}) 注意：在 properties 定义段中，属性名采用驼峰写法（propertyName）；在 wxml 中，指定属性值时则对应使用连字符写法（component-tag-name property-name=&quot;attr value&quot;），应用于数据绑定时采用驼峰写法（attr=&quot;&quot;）。 properties 定义 定义段 类型 是否必填 描述 最低版本 type 是 属性的类型 optionalTypes Array 否 属性的类型（可以指定多个） 2.6.5 value 否 属性的初始值 observer Function 否 属性值变化时的回调函数 属性值的改变情况可以使用 observer 来监听。目前，在新版本基础库中不推荐使用这个字段，而是使用 Component 构造器的 observers 字段代替，它更加强大且性能更好。 示例代码123456789101112131415161718192021Component({ properties: { min: { type: Number, value: 0 }, min: { type: Number, value: 0, observer: function(newVal, oldVal) { // 属性值变化时执行 } }, lastLeaf: { // 这个属性可以是 Number 、 String 、 Boolean 三种类型中的一种 type: Number, optionalTypes: [String, Object], value: 0 } }}) 属性的类型可以为 String Number Boolean Object Array 其一，也可以为 null 表示不限制类型。 多数情况下，属性最好指定一个确切的类型。这样，在 WXML 中以字面量指定属性值时，值可以获得一个确切的类型，如： 1&lt;custom-comp min=&quot;1&quot; max=&quot;5&quot; /&gt; 此时，由于自定义组件的对应属性被规定为 Number 类型， min 和 max 会被赋值为 1 和 5 ，而非 &quot;1&quot; 和 &quot;5&quot; ，即： 12this.data.min === 1 // truethis.data.max === 5 // true Bug &amp; Tip 使用 this.data 可以获取内部数据和属性值；但直接修改它不会将变更应用到界面上，应使用 setData 修改。 生命周期函数无法在组件方法中通过 this 访问到。 属性名应避免以 data 开头，即不要命名成 dataXyz 这样的形式，因为在 WXML 中， data-xyz=&quot;&quot; 会被作为节点 dataset 来处理，而不是组件属性。 在一个组件的定义和使用时，组件的属性名和 data 字段相互间都不能冲突（尽管它们位于不同的定义段中）。 从基础库 2.0.9 开始，对象类型的属性和 data 字段中可以包含函数类型的子字段，即可以通过对象类型的属性字段来传递函数。低于这一版本的基础库不支持这一特性。 bug : 位于 slot 中的自定义组件没有触发 pageLifetimes 中声明的页面生命周期，此问题在 2.5.2 中修复。 bug : 对于 type 为 Object 或 Array 的属性，如果通过该组件自身的 this.setData 来改变属性值的一个子字段，则依旧会触发属性 observer ，且 observer 接收到的 newVal 是变化的那个子字段的值， oldVal 为空， changedPath 包含子字段的字段名相关信息；目前推荐使用 observers 定义段代替。 使用 Component 构造器构造页面事实上，小程序的页面也可以视为自定义组件。因而，页面也可以使用 Component 构造器构造，拥有与普通组件一样的定义段与实例方法。但此时要求对应 json 文件中包含 usingComponents 定义段。 此时，组件的属性可以用于接收页面的参数，如访问页面 /pages/index/index?paramA=123&amp;paramB=xyz ，如果声明有属性 paramA 或 paramB ，则它们会被赋值为 123 或 xyz 。 页面的生命周期方法（即 on 开头的方法），应写在 methods 定义段中。 代码示例： 123{ &quot;usingComponents&quot;: {}} 123456789101112131415Component({ properties: { paramA: Number, paramB: String, }, methods: { onLoad: function() { this.data.paramA // 页面参数 paramA 的值 this.data.paramB // 页面参数 paramB 的值 } }}) 使用 Component 构造器来构造页面的一个好处是可以使用 behaviors 来提取所有页面中公用的代码段。 例如，在所有页面被创建和销毁时都要执行同一段代码，就可以把这段代码提取到 behaviors 中。 代码示例： 1234567891011// page-common-behavior.jsmodule.exports = Behavior({ attached: function() { // 页面创建时执行 console.info('Page loaded!') }, detached: function() { // 页面销毁时执行 console.info('Page unloaded!') }}) 1234567// 页面 Avar pageCommonBehavior = require('./page-common-behavior')Component({ behaviors: [pageCommonBehavior], data: { /* ... */ }, methods: { /* ... */ },}) 1234567// 页面 Bvar pageCommonBehavior = require('./page-common-behavior')Component({ behaviors: [pageCommonBehavior], data: { /* ... */ }, methods: { /* ... */ },})","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-Component-%E6%9E%84%E9%80%A0%E5%99%A8/"},{"title":"微信小程序自定义组件-behaviors","text":"behaviors 是用于组件间代码共享的特性，类似于一些编程语言中的 “mixins” 或 “traits”。 每个 behavior 可以包含一组属性、数据、生命周期函数和方法。组件引用它时，它的属性、数据和方法会被合并到组件中，生命周期函数也会在对应时机被调用。 每个组件可以引用多个 behavior ，behavior 也可以引用其它 behavior 。 详细的参数含义和使用请参考 Behavior 参考文档。 组件中使用组件引用时，在 behaviors 定义段中将它们逐个列出即可。 代码示例： 在开发者工具中预览效果 123456789101112131415161718192021222324252627// my-component.jsvar myBehavior = require('my-behavior')Component({ behaviors: [myBehavior], properties: { myProperty: { type: String } }, data: { myData: 'my-component-data' }, created: function () { console.log('[my-component] created') }, attached: function () { console.log('[my-component] attached') }, ready: function () { console.log('[my-component] ready') }, methods: { myMethod: function () { console.log('[my-component] log by myMethod') }, }}) 在上例中， my-component 组件定义中加入了 my-behavior， 而 my-behavior 结构为： 属性：myBehaviorProperty 数据字段：myBehaviorData 方法：myBehaviorMethod 生命周期函数：attached、created、ready 这将使 my-component 最终结构为： 属性：myBehaviorProperty、myProperty 数据字段：myBehaviorData、myData 方法：myBehaviorMethod、myMethod 生命周期函数：attached、created、ready 当组件触发生命周期时，上例生命周期函数执行顺序为： [my-behavior] created [my-component] created [my-behavior] attached [my-component] attached [my-behavior] ready [my-component] ready 详细规则参考 同名字段的覆盖和组合规则。 同名字段的覆盖和组合规则组件和它引用的 behavior 中可以包含同名的字段，对这些字段的处理方法如下： 如果有同名的属性 (properties) 或方法 (methods)： 若组件本身有这个属性或方法，则组件的属性或方法会覆盖 behavior 中的同名属性或方法； 若组件本身无这个属性或方法，则在组件的 behaviors 字段中定义靠后的 behavior 的属性或方法会覆盖靠前的同名属性或方法； 在 2 的基础上，若存在嵌套引用 behavior 的情况，则规则为：父 behavior 覆盖 子 behavior 中的同名属性或方法。 如果有同名的数据字段 (data)： 若同名的数据字段都是对象类型，会进行对象合并； 其余情况会进行数据覆盖，覆盖规则为：组件 &gt; 父 behavior &gt; 子 behavior 、 靠后的 behavior &gt; 靠前的 behavior。（优先级高的覆盖优先级低的，最大的为优先级最高） 生命周期函数不会相互覆盖，而是在对应触发时机被逐个调用： 对于不同的生命周期函数之间，遵循组件生命周期函数的执行顺序； 对于同种生命周期函数，遵循如下规则： behavior 优先于组件执行； 子 behavior 优先于 父 behavior 执行； 靠前的 behavior 优先于 靠后的 behavior 执行； 如果同一个 behavior 被一个组件多次引用，它定义的生命周期函数只会被执行一次。 代码示例： 在开发者工具中预览效果 内置 behaviors自定义组件可以通过引用内置的 behavior 来获得内置组件的一些行为。 123Component({ behaviors: ['wx://form-field']}) 在上例中， wx://form-field 代表一个内置 behavior ，它使得这个自定义组件有类似于表单控件的行为。 内置 behavior 往往会为组件添加一些属性。在没有特殊说明时，组件可以覆盖这些属性来改变它的 type 或添加 observer 。 wx://form-field使自定义组件有类似于表单控件的行为。 form 组件可以识别这些自定义组件，并在 submit 事件中返回组件的字段名及其对应字段值。 详细用法以及代码示例可见：form 组件参考文档 wx://form-field-group从基础库版本 2.10.2 开始提供支持。 使 form 组件可以识别到这个自定义组件内部的所有表单控件。 详细用法以及代码示例可见：form 组件参考文档 wx://form-field-button从基础库版本 2.10.3 开始提供支持。 使 form 组件可以识别到这个自定义组件内部的 button 。如果自定义组件内部有设置了 form-type 的 button ，它将被组件外的 form 接受。 详细用法以及代码示例可见：form 组件参考文档 wx://component-export从基础库版本 2.2.3 开始提供支持。 使自定义组件支持 export 定义段。这个定义段可以用于指定组件被 selectComponent 调用时的返回值。 详细用法以及代码示例可见：selectComponent 参考文档","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-behaviors/"},{"title":"微信小程序自定义组件-单元测试","text":"在编写高质量的自定义组件过程中，单元测试是永远避不开的一个话题。完善的测试用例是提高自定义组件可用性的保证，同时测试代码覆盖率也是必不可少的一个环节。小程序从基础库版本 2.2.1 开始拥抱开源，支持使用 npm 安装自定义组件，那针对自定义组件的单元测试也是必须支持的。 以下就来介绍如何对自定义组件进行单元测试。 测试框架现在市面上流行的测试框架均可使用，只要它能兼顾 nodejs 端和 dom 环境。因为我们需要依赖到 nodejs 的一些库来完善测试环境，同时 dom 环境也是必须的，因为我们需要建成完整的 dom 树结构，才能更好的模拟自定义组件的运行。例如可以选用 mocha + jsdom 的组合，亦可选用 jest，下述例子选用 jest 作为测试框架来说明。 自定义组件测试工具集小程序的运行环境比较特殊，不同于常见的浏览器环境，它采用的是双线程的架构。而在进行单元测试时，我们并不需要用到这样复杂的架构带来的利好，我们进行的是功能测试而无需苛求性能、安全等因素，因此我们提供了一个测试工具集以支持自定义组件在 nodejs 单线程中也能运行起来。 我们先安装一下测试工具集——miniprogram-simulate： 1npm i --save-dev miniprogram-simulate 编写测试用例假设我们有如下自定义组件： 123456789101112131415&lt;!-- /components/index.wmxl --&gt;&lt;view class=&quot;index&quot;&gt;{{prop}}&lt;/view&gt;// /components/index.jsComponent({ properties: { prop: { type: String, value: 'index.properties' }, },})/* /components/index.wxss */.index { color: green;} 我们想要测试渲染的结果，可以按照如下方式编写测试用例： 1234567891011121314// /test/components/index.test.jsconst simulate = require('miniprogram-simulate')test('components/index', () =&gt; { const id = simulate.load('/components/index') // 此处必须传入绝对路径 const comp = simulate.render(id) // 渲染成自定义组件树实例 const parent = document.createElement('parent-wrapper') // 创建父亲节点 comp.attach(parent) // attach 到父亲节点上，此时会触发自定义组件的 attached 钩子 const view = comp.querySelector('.index') // 获取子组件 view expect(view.dom.innerHTML).toBe('index.properties') // 测试渲染结果 expect(window.getComputedStyle(view.dom).color).toBe('green') // 测试渲染结果}) PS：测试工具集中的 wx 对象和内置组件都不会实现真正的功能，如果需要测试一些特殊场景的话，可以自行覆盖掉测试工具集中的 api 接口和内置组件。 PS：目前因为有部分自定义组件功能仍未支持（如抽象节点等），故测试工具暂无法全部覆盖自定义组件的特性，后续会继续完善。 测试工具集中提供了一些方便测试的接口，比如： 模拟 touch 事件、自定义事件触发 选取子节点 更新自定义组件数据 触发生命周期 … 更多详细的用法可以参阅 github 仓库上的文档。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"title":"微信小程序框架组件-画布组件","text":"canvas 组件 基础库 1.0.0 开始支持，低版本需做兼容处理。 画布，我们可以做一些绘图和动画效果。2.9.0 起支持一套新 Canvas 2D 接口（需指定 type 属性），同时支持同层渲染，原有接口不再维护。相关api：获取 canvas 实例。 属性 类型 默认值 必填 说明 最低版本 type string 否 指定 canvas 类型，支持 2d (2.9.0) 和 webgl (2.7.0) 2.7.0 canvas-id string 否 canvas 组件的唯一标识符，若指定了 type 则无需再指定该属性 1.0.0 disable-scroll boolean false 否 当在 canvas 中移动时且有绑定手势事件时，禁止屏幕滚动以及下拉刷新 1.0.0 bindtouchstart eventhandle 否 手指触摸动作开始 1.0.0 bindtouchmove eventhandle 否 手指触摸后移动 1.0.0 bindtouchend eventhandle 否 手指触摸动作结束 1.0.0 bindtouchcancel eventhandle 否 手指触摸动作被打断，如来电提醒，弹窗 1.0.0 bindlongtap eventhandle 否 手指长按 500ms 之后触发，触发了长按事件后进行移动不会触发屏幕的滚动 1.0.0 binderror eventhandle 否 当发生错误时触发 error 事件，detail = {errMsg} 1.0.0 Bug &amp; Tip tip：canvas 标签默认宽度300px、高度150px tip：同一页面中的 canvas-id 不可重复，如果使用一个已经出现过的 canvas-id，该 canvas 标签对应的画布将被隐藏并不再正常工作 tip：请注意原生组件使用限制 tip：开发者工具中默认关闭了 GPU 硬件加速，可在开发者工具的设置中开启“硬件加速”提高 WebGL 的渲染性能 tip: WebGL 支持通过 getContext(‘webgl’, { alpha: true }) 获取透明背景的画布 tip: Canvas 2D（新接口）需要显式设置画布宽高，默认：300*150，最大：1365*1365 bug: 避免设置过大的宽高，在安卓下会有crash的问题 tip: iOS 暂不支持 pointer-events Canvas 2D 示例代码在开发者工具中预览效果 index.wxml12345&lt;canvas type=&quot;2d&quot; id=&quot;canvas&quot; style=&quot;width: 300px; height: 300px;&quot;&gt;&lt;/canvas&gt; index.js123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101const app = getApp()Page({ data: {}, onLoad: function () { this.position = { x: 150, y: 150, vx: 2, vy: 2 } this.x = -100 // 通过 SelectorQuery 获取 Canvas 节点 wx.createSelectorQuery() .select('#canvas') .fields({ node: true, size: true, }) .exec(this.init.bind(this)) }, init(res) { const width = res[0].width const height = res[0].height const canvas = res[0].node const ctx = canvas.getContext('2d') const dpr = wx.getSystemInfoSync().pixelRatio canvas.width = width * dpr canvas.height = height * dpr ctx.scale(dpr, dpr) const renderLoop = () =&gt; { this.render(canvas, ctx) canvas.requestAnimationFrame(renderLoop) } canvas.requestAnimationFrame(renderLoop) const img = canvas.createImage() img.onload = () =&gt; { this._img = img } img.src = './car.png' }, render(canvas, ctx) { ctx.clearRect(0, 0, 300, 300) this.drawBall(ctx) this.drawCar(ctx) }, drawBall(ctx) { const p = this.position p.x += p.vx p.y += p.vy if (p.x &gt;= 300) { p.vx = -2 } if (p.x &lt;= 7) { p.vx = 2 } if (p.y &gt;= 300) { p.vy = -2 } if (p.y &lt;= 7) { p.vy = 2 } function ball(x, y) { ctx.beginPath() ctx.arc(x, y, 5, 0, Math.PI * 2) ctx.fillStyle = '#1aad19' ctx.strokeStyle = 'rgba(1,1,1,0)' ctx.fill() ctx.stroke() } ball(p.x, 150) ball(150, p.y) ball(300 - p.x, 150) ball(150, 300 - p.y) ball(p.x, p.y) ball(300 - p.x, 300 - p.y) ball(p.x, 300 - p.y) ball(300 - p.x, p.y) }, drawCar(ctx) { if (!this._img) return if (this.x &gt; 350) { this.x = -100 } ctx.drawImage(this._img, this.x++, 150 - 25, 100, 50) ctx.restore() }}) WebGL 示例代码在开发者工具中预览效果 index.wxml1&lt;canvas type=&quot;webgl&quot; id=&quot;myCanvas&quot; style=&quot;width: 300px; height: 300px;&quot;&gt;&lt;/canvas&gt; index.js12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394const vs = ` precision mediump float; attribute vec2 vertPosition; attribute vec3 vertColor; varying vec3 fragColor; void main() { gl_Position = vec4(vertPosition, 0.0, 1.0); fragColor = vertColor; }`const fs = ` precision mediump float; varying vec3 fragColor; void main() { gl_FragColor = vec4(fragColor, 1.0); }`const triangleVertices = [ 0.0, 0.5, 1.0, 1.0, 0.0, -0.5, -0.5, 0.7, 0.0, 1.0, 0.5, -0.5, 0.1, 1.0, 0.6];Page({ onLoad() { const query = wx.createSelectorQuery() query.select('#myCanvas').node().exec((res) =&gt; { const canvas = res[0].node this._render(canvas) }) }, _render(canvas) { const gl = canvas.getContext('webgl') if (!gl) { console.error('gl init failed', gl) return } gl.viewport(0, 0, 300, 300) const vertShader = gl.createShader(gl.VERTEX_SHADER) gl.shaderSource(vertShader, vs) gl.compileShader(vertShader) const fragShader = gl.createShader(gl.FRAGMENT_SHADER) gl.shaderSource(fragShader, fs) gl.compileShader(fragShader) const prog = gl.createProgram() gl.attachShader(prog, vertShader) gl.attachShader(prog, fragShader) gl.deleteShader(vertShader) gl.deleteShader(fragShader) gl.linkProgram(prog) gl.useProgram(prog) const draw = () =&gt; { const triangleVertexBufferObject = gl.createBuffer() gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexBufferObject) gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(triangleVertices), gl.STATIC_DRAW) const positionAttribLocation = gl.getAttribLocation(prog, 'vertPosition') const colorAttribLocation = gl.getAttribLocation(prog, 'vertColor') gl.vertexAttribPointer( positionAttribLocation, 2, gl.FLOAT, gl.FALSE, 5 * Float32Array.BYTES_PER_ELEMENT, 0 ) gl.vertexAttribPointer( colorAttribLocation, 3, gl.FLOAT, gl.FALSE, 5 * Float32Array.BYTES_PER_ELEMENT, 2 * Float32Array.BYTES_PER_ELEMENT ) gl.enableVertexAttribArray(positionAttribLocation) gl.enableVertexAttribArray(colorAttribLocation) gl.drawArrays(gl.TRIANGLES, 0, 3) canvas.requestAnimationFrame(draw) } canvas.requestAnimationFrame(draw) }}) (可惜报错了，无法运行，等待官方修复) 示例代码（旧的接口）在开发者工具中预览效果 index.wxml12345&lt;view class=&quot;page-body&quot;&gt; &lt;view class=&quot;page-body-wrapper&quot;&gt; &lt;canvas canvas-id=&quot;canvas&quot; class=&quot;canvas&quot;&gt;&lt;/canvas&gt; &lt;/view&gt;&lt;/view&gt; index.js1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859Page({ onReady: function () { this.position = { x: 150, y: 150, vx: 2, vy: 2 } this.drawBall() this.interval = setInterval(this.drawBall, 17) }, drawBall: function () { var p = this.position p.x += p.vx p.y += p.vy if (p.x &gt;= 300) { p.vx = -2 } if (p.x &lt;= 7) { p.vx = 2 } if (p.y &gt;= 300) { p.vy = -2 } if (p.y &lt;= 7) { p.vy = 2 } var context = wx.createContext() function ball(x, y) { context.beginPath(0) context.arc(x, y, 5, 0, Math.PI * 2) context.setFillStyle('#1aad19') context.setStrokeStyle('rgba(1,1,1,0)') context.fill() context.stroke() } ball(p.x, 150) ball(150, p.y) ball(300 - p.x, 150) ball(150, 300 - p.y) ball(p.x, p.y) ball(300 - p.x, 300 - p.y) ball(p.x, 300 - p.y) ball(300 - p.x, p.y) wx.drawCanvas({ canvasId: 'canvas', actions: context.getActions() }) }, onUnload: function () { clearInterval(this.interval) }})","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E7%BB%84%E4%BB%B6-%E7%94%BB%E5%B8%83%E7%BB%84%E4%BB%B6/"},{"title":"微信小程序自定义组件-占位组件","text":"基础库 2.17.3 及以上版本支持，2.17.3 以下和未配置的效果相同 在使用如 分包异步化 或 用时注入 等特性时，自定义组件所引用的其他自定义组件，在刚开始进行渲染时可能处于不可用的状态。此时，为了使渲染过程不被阻塞，不可用的自定义组件需要一个 「占位组件」（Component placeholder）。基础库会用占位组件替代不可用组件进行渲染，在该组件可用后再将占位组件替换回该组件。 一个自定义组件的占位组件可以是另一个自定义组件、或一个内置组件。 配置页面或自定义组件对应的 JSON 配置中的 componentPlaceholder 字段用于指定占位组件，如： 1234567891011{ &quot;usingComponents&quot;: { &quot;comp-a&quot;: &quot;../comp/compA&quot;, &quot;comp-b&quot;: &quot;../comp/compB&quot;, &quot;comp-c&quot;: &quot;../comp/compC&quot; }, &quot;componentPlaceholder&quot;: { &quot;comp-a&quot;: &quot;view&quot;, &quot;comp-b&quot;: &quot;comp-c&quot; }} 该配置表示： 组件 comp-a 的占位组件为内置组件 view 组件 comp-b 的占位组件为自定义组件 comp-c（其路径在 usingComponents 中配置） 假设该配置对应的模板如下： 1234&lt;button ontap=&quot;onTap&quot;&gt;显示组件&lt;/button&gt;&lt;comp-a wx-if=&quot;{{ visible }}&quot;&gt; &lt;comp-b prop=&quot;{{ p }}&quot;&gt;text in slot&lt;/comp-b&gt;&lt;/comp-a&gt; 小程序启动时 visible 为 false，那么只有 button 会被渲染；点击按钮后，this.setData({ visible: true }) 被执行，此时如果 comp-a, comp-b 均不可用，则页面将被渲染为： 1234&lt;button&gt;显示组件&lt;/button&gt;&lt;view&gt; &lt;comp-c prop=&quot;{{ p }}&quot;&gt;text in slot&lt;/comp-c&gt;&lt;/view&gt; comp-a 与 comp-b 准备完成后，页面被替换为： 1234&lt;button&gt;显示组件&lt;/button&gt;&lt;comp-a&gt; &lt;comp-b prop=&quot;{{ p }}&quot;&gt;text in slot&lt;/comp-b&gt;&lt;/comp-a&gt; 注意事项 当一个组件被指定为占位组件时（如上例中的 comp-c），为其指定占位组件是无效的。可以理解为如果一个组件需要作为其他组件的占位组件，则它必须在一开始就是可用的； 目前自定义组件不可用的情况包括： 使用分包异步化特性的情况下，引用了其他分包的组件，而对应分包还未下载； 使用用时注入特性的情况下，该组件还未注入； 如果一个组件不可用，且其占位组件不存在，则渲染时会报错并抛出； 如果一个组件不存在，但为其指定了可用的占位组件，则占位组件可以被正常渲染，但后续尝试准备替换时会报错并抛出。 附：有占位组件参与的渲染流程基础库尝试渲染一个组件时，会首先递归检查 usingComponents，收集其将使用到的所有组件的信息；在这个过程中，如果某个被使用到的组件不可用，基础库会先检查其是否有对应的占位组件。如果没有，基础库会中断渲染并抛出错误；如果有，则会标记并在后续渲染流程中使用占位组件替换该不可用的组件进行渲染。不可用的组件会在当前渲染流程结束后尝试准备（下载分包或注入代码等）；等到准备过程完成后，再尝试渲染该组件（实际上也是在执行这个流程），并替换掉之前渲染的占位组件。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E5%8D%A0%E4%BD%8D%E7%BB%84%E4%BB%B6/"},{"title":"微信小程序自定义组件-开发第三方自定义组件","text":"小程序从基础库版本 2.2.1 开始支持使用 npm 安装第三方包，因此也支持开发和使用第三方自定义组件包。关于 npm 功能的详情可先阅读相关文档。 准备开发一个开源的自定义组件包给他人使用，首先需要明确他人是要如何使用这个包的，如果只是拷贝小程序目录下直接使用的话，可以跳过此文档。此文档中后续内容是以 npm 管理自定义组件包的前提下进行说明的。 在开发之前，要求开发者具有基础的 node.js 和 npm 相关的知识，同时需要准备好支持 npm 功能的开发者工具，点此下载。 下载模板为了方便开发者能够快速搭建好一个可用于开发、调试、测试的自定义组件包项目，官方提供了一个项目模板，下载使用模板的方式有三种： 直接从 github 上下载 zip 文件并解压。 直接将 github 上的仓库 clone 下来。 使用官方提供的命令行工具初始化项目，下面会进行介绍。 项目模板中的构建是基于 gulp + webpack 来执行的，支持开发、构建、测试等命令，详情可参阅项目模板的 README.md 文件。 命令行工具官方提供了命令行工具，用于快速初始化一个项目。执行如下命令安装命令行工具： 1npm install -g @wechat-miniprogram/miniprogram-cli 然后新建一个空目录作为项目根目录，在此根目录下执行： 1miniprogram init --type custom-component 命令执行完毕后会发现项目根目录下生成了许多文件，这是根据官方的项目模板生成的完整项目，之后开发者可直接在此之上进行开发修改。 命令行工具的更多用法可以查看 github 仓库上的 README.md 文件。 PS：第一次使用 miniprogram init 初始化项目会去 github 上拉取模板，因此需要保证网络畅通。 测试工具针对自定义组件的单元测试，可参阅文档单元测试。 自定义组件示例以下为官方提供的自定义组件，可以参考并使用： weui-miniprogram recycle-view 自定义组件扩展示例以下为官方提供的自定义组件扩展，可以参考并使用： computed","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E5%BC%80%E5%8F%91%E7%AC%AC%E4%B8%89%E6%96%B9%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6/"},{"title":"微信小程序框架组件-表单组件","text":"表单组件由一系列组件组成,包括: button、checkbox、form、 input、 label、 picker、picker - view 、radio、slider 、switch和 textarea。熟悉WEB开发的朋友应该知道表单在WEB开发中应用非常广泛, 表单主要用来构建与用户进行的交互,因而建议大家务必重点掌握表单组件的应用。 按钮button 基础库 1.0.0 开始支持，低版本需做兼容处理。 按钮。 属性 类型 默认值 必填 说明 最低版本 size string default 否 按钮的大小 1.0.0 type string default 否 按钮的样式类型 1.0.0 plain boolean false 否 按钮是否镂空，背景色透明 1.0.0 disabled boolean false 否 是否禁用 1.0.0 loading boolean false 否 名称前是否带 loading 图标 1.0.0 form-type string 否 用于 form 组件，点击分别会触发 form 组件的 submit/reset 事件 1.0.0 open-type string 否 微信开放能力 1.1.0 hover-class string button-hover 否 指定按钮按下去的样式类。当 hover-class=&quot;none&quot; 时，没有点击态效果 1.0.0 hover-stop-propagation boolean false 否 指定是否阻止本节点的祖先节点出现点击态 1.5.0 hover-start-time number 20 否 按住后多久出现点击态，单位毫秒 1.0.0 hover-stay-time number 70 否 手指松开后点击态保留时间，单位毫秒 1.0.0 lang string en 否 指定返回用户信息的语言，zh_CN 简体中文，zh_TW 繁体中文，en 英文。 1.3.0 session-from string 否 会话来源，open-type=”contact”时有效 1.4.0 send-message-title string 当前标题 否 会话内消息卡片标题，open-type=”contact”时有效 1.5.0 send-message-path string 当前分享路径 否 会话内消息卡片点击跳转小程序路径，open-type=”contact”时有效 1.5.0 send-message-img string 截图 否 会话内消息卡片图片，open-type=”contact”时有效 1.5.0 app-parameter string 否 打开 APP 时，向 APP 传递的参数，open-type=launchApp时有效 1.9.5 show-message-card boolean false 否 是否显示会话内消息卡片，设置此参数为 true，用户进入客服会话会在右下角显示”可能要发送的小程序”提示，用户点击后可以快速发送小程序消息，open-type=”contact”时有效 1.5.0 bindgetuserinfo eventhandle 否 用户点击该按钮时，会返回获取到的用户信息，回调的detail数据与wx.getUserInfo返回的一致，open-type=”getUserInfo”时有效 1.3.0 bindcontact eventhandle 否 客服消息回调，open-type=”contact”时有效 1.5.0 bindgetphonenumber eventhandle 否 获取用户手机号回调，open-type=getPhoneNumber时有效 1.2.0 binderror eventhandle 否 当使用开放能力时，发生错误的回调，open-type=launchApp时有效 1.9.5 bindopensetting eventhandle 否 在打开授权设置页后回调，open-type=openSetting时有效 2.0.7 bindlaunchapp eventhandle 否 打开 APP 成功的回调，open-type=launchApp时有效 2.4.4 size 的合法值 值 说明 最低版本 default 默认大小 mini 小尺寸 type 的合法值 值 说明 最低版本 primary 绿色 default 白色 warn 红色 form-type 的合法值 值 说明 最低版本 submit 提交表单 reset 重置表单 open-type 的合法值 值 说明 最低版本 contact 打开客服会话，如果用户在会话中点击消息卡片后返回小程序，可以从 bindcontact 回调中获得具体信息，具体说明 （小程序插件中不能使用） 1.1.0 share 触发用户转发，使用前建议先阅读使用指引 1.2.0 getPhoneNumber 获取用户手机号，可以从bindgetphonenumber回调中获取到用户信息，具体说明 （小程序插件中不能使用） 1.2.0 getUserInfo 获取用户信息，可以从bindgetuserinfo回调中获取到用户信息 （小程序插件中不能使用） 1.3.0 launchApp 打开APP，可以通过app-parameter属性设定向APP传的参数具体说明 1.9.5 openSetting 打开授权设置页 2.0.7 feedback 打开“意见反馈”页面，用户可提交反馈内容并上传日志，开发者可以登录小程序管理后台后进入左侧菜单“客服反馈”页面获取到反馈内容 2.1.0 lang 的合法值 值 说明 最低版本 en 英文 zh_CN 简体中文 zh_TW 繁体中文 Bug &amp; Tip tip: button-hover 默认为{background-color: rgba(0, 0, 0, 0.1); opacity: 0.7;} tip: bindgetphonenumber 从1.2.0 开始支持，但是在1.5.3以下版本中无法使用wx.canIUse进行检测，建议使用基础库版本进行判断。 tip: 在bindgetphonenumber 等返回加密信息的回调中调用 wx.login 登录，可能会刷新登录态。此时服务器使用 code 换取的 sessionKey 不是加密时使用的 sessionKey，导致解密失败。建议开发者提前进行 login；或者在回调中先使用 checkSession 进行登录态检查，避免 login 刷新登录态。 tip: 从 2.1.0 起，button 可作为原生组件的子节点嵌入，以便在原生组件上使用 open-type 的能力。 tip: 目前设置了 form-type 的 button 只会对当前组件中的 form 有效。因而，将 button 封装在自定义组件中，而 form 在自定义组件外，将会使这个 button 的 form-type 失效。 示例代码在开发者工具中预览效果 index.wxml1234567891011&lt;button type=&quot;default&quot; size=&quot;{{defaultSize}}&quot; loading=&quot;{{loading}}&quot; plain=&quot;{{plain}}&quot; disabled=&quot;{{disabled}}&quot; bindtap=&quot;default&quot; hover-class=&quot;other-button-hover&quot;&gt; default &lt;/button&gt;&lt;button type=&quot;primary&quot; size=&quot;{{primarySize}}&quot; loading=&quot;{{loading}}&quot; plain=&quot;{{plain}}&quot; disabled=&quot;{{disabled}}&quot; bindtap=&quot;primary&quot;&gt; primary &lt;/button&gt;&lt;button type=&quot;warn&quot; size=&quot;{{warnSize}}&quot; loading=&quot;{{loading}}&quot; plain=&quot;{{plain}}&quot; disabled=&quot;{{disabled}}&quot; bindtap=&quot;warn&quot;&gt; warn &lt;/button&gt;&lt;button bindtap=&quot;setDisabled&quot;&gt;点击设置以上按钮disabled属性&lt;/button&gt;&lt;button bindtap=&quot;setPlain&quot;&gt;点击设置以上按钮plain属性&lt;/button&gt;&lt;button bindtap=&quot;setLoading&quot;&gt;点击设置以上按钮loading属性&lt;/button&gt;&lt;button open-type=&quot;contact&quot;&gt;进入客服会话&lt;/button&gt;&lt;button open-type=&quot;getUserInfo&quot; lang=&quot;zh_CN&quot; bindgetuserinfo=&quot;onGotUserInfo&quot;&gt;获取用户信息&lt;/button&gt; index.js123456789101112131415161718192021222324252627282930313233343536373839404142434445var types = ['default', 'primary', 'warn']var pageObject = { data: { defaultSize: 'default', primarySize: 'default', warnSize: 'default', disabled: false, plain: false, loading: false }, setDisabled: function (e) { this.setData({ disabled: !this.data.disabled }) }, setPlain: function (e) { this.setData({ plain: !this.data.plain }) }, setLoading: function (e) { this.setData({ loading: !this.data.loading }) }, onGotUserInfo: function (e) { console.log(e.detail.errMsg) console.log(e.detail.userInfo) console.log(e.detail.rawData) },}for (var i = 0; i &lt; types.length; ++i) { (function (type) { pageObject[type] = function (e) { var key = type + 'Size' var changedData = {} changedData[key] = this.data[key] === 'default' ? 'mini' : 'default' this.setData(changedData) } })(types[i])}Page(pageObject) 多项选择器checkbox-group 基础库 1.0.0 开始支持，低版本需做兼容处理。 多项选择器，内部由多个checkbox组成。 属性 类型 默认值 必填 说明 最低版本 bindchange EventHandle 否 checkbox-group中选中项发生改变时触发 change 事件，detail = {value:[选中的checkbox的value的数组]} 1.0.0 多选项目checkbox 基础库 1.0.0 开始支持，低版本需做兼容处理。 多选项目。 属性 类型 默认值 必填 说明 最低版本 value string 否 checkbox标识，选中时触发checkbox-group的 change 事件，并携带 checkbox 的 value 1.0.0 disabled boolean false 否 是否禁用 1.0.0 checked boolean false 否 当前是否选中，可用来设置默认选中 1.0.0 color string #09BB07 否 checkbox的颜色，同css的color 1.0.0 示例代码在开发者工具中预览效果 12345&lt;checkbox-group bindchange=&quot;checkboxChange&quot;&gt; &lt;label class=&quot;checkbox&quot; wx:for=&quot;{{items}}&quot;&gt; &lt;checkbox value=&quot;{{item.name}}&quot; checked=&quot;{{item.checked}}&quot;/&gt;{{item.value}} &lt;/label&gt;&lt;/checkbox-group&gt; 123456789101112131415Page({ data: { items: [ { name: 'USA', value: '美国' }, { name: 'CHN', value: '中国', checked: 'true' }, { name: 'BRA', value: '巴西' }, { name: 'JPN', value: '日本' }, { name: 'ENG', value: '英国' }, { name: 'TUR', value: '法国' }, ] }, checkboxChange: function (e) { console.log('checkbox发生change事件，携带value值为：', e.detail.value) }}) 富文本编辑器editor 基础库 2.7.0 开始支持，低版本需做兼容处理。 富文本编辑器，可以对图片、文字进行编辑。 编辑器导出内容支持带标签的 html和纯文本的 text，编辑器内部采用 delta 格式进行存储。 通过setContents接口设置内容时，解析插入的 html 可能会由于一些非法标签导致解析错误，建议开发者在小程序内使用时通过 delta 进行插入。 富文本组件内部引入了一些基本的样式使得内容可以正确的展示，开发时可以进行覆盖。需要注意的是，在其它组件或环境中使用富文本组件导出的html时，需要额外引入 这段样式，并维护&lt;ql-container&gt;&lt;ql-editor&gt;&lt;/ql-editor&gt;&lt;/ql-container&gt;的结构。 图片控件仅初始化时设置有效。 相关 api：EditorContext 属性 类型 默认值 必填 说明 最低版本 read-only boolean false 否 设置编辑器为只读 2.7.0 placeholder string 否 提示信息 2.7.0 show-img-size boolean false 否 点击图片时显示图片大小控件 2.7.0 show-img-toolbar boolean false 否 点击图片时显示工具栏控件 2.7.0 show-img-resize boolean false 否 点击图片时显示修改尺寸控件 2.7.0 bindready eventhandle 否 编辑器初始化完成时触发 2.7.0 bindfocus eventhandle 否 编辑器聚焦时触发，event.detail = {html, text, delta} 2.7.0 bindblur eventhandle 否 编辑器失去焦点时触发，detail = {html, text, delta} 2.7.0 bindinput eventhandle 否 编辑器内容改变时触发，detail = {html, text, delta} 2.7.0 bindstatuschange eventhandle 否 通过 Context 方法改变编辑器内样式时触发，返回选区已设置的样式 2.7.0 编辑器内支持部分 HTML 标签和内联样式，不支持class和id 支持的标签不满足的标签会被忽略，&lt;div&gt;会被转行为&lt;p&gt;储存。 类型 节点 行内元素 &lt;span&gt; &lt;strong&gt; &lt;b&gt; &lt;ins&gt; &lt;em&gt; &lt;i&gt; &lt;u&gt; &lt;a&gt; &lt;del&gt; &lt;s&gt; &lt;sub&gt; &lt;sup&gt; &lt;img&gt; 块级元素 &lt;p&gt; &lt;h1&gt; &lt;h2&gt; &lt;h3&gt; &lt;h4&gt; &lt;h5&gt; &lt;h6&gt; &lt;hr&gt; &lt;ol&gt; &lt;ul&gt; &lt;li&gt; 支持的内联样式内联样式仅能设置在行内元素或块级元素上，不能同时设置。例如 font-size 归类为行内元素属性，在 p 标签上设置是无效的。 类型 样式 块级样式 text-align direction margin margin-top margin-left margin-right margin-bottom padding padding-top padding-left padding-right padding-bottom line-height text-indent 行内样式 font font-size font-style font-variant font-weight font-family letter-spacing text-decoration color background-color Bug &amp; Tip tip: 使用 catchtouchend 绑定事件则不会使编辑器失去焦点(2.8.3) tip: 插入的 html 中事件绑定会被移除 tip: formats 中的 color 属性会统一以 hex 格式返回 tip: 粘贴时仅纯文本内容会被拷贝进编辑器 tip: 插入 html 到编辑器内时，编辑器会删除一些不必要的标签，以保证内容的统一。例如&lt;p&gt;&lt;span&gt;xxx&lt;/span&gt;&lt;/p&gt;会改写为&lt;p&gt;xxx&lt;/p&gt; tip: 编辑器聚焦时页面会被上推，系统行为以保证编辑区可见 示例代码在开发者工具中预览效果 12345678910111213141516&lt;view class=&quot;container&quot; style=&quot;height:{{editorHeight}}px;&quot;&gt; &lt;editor id=&quot;editor&quot; class=&quot;ql-container&quot; placeholder=&quot;{{placeholder}}&quot; bindstatuschange=&quot;onStatusChange&quot; bindready=&quot;onEditorReady&quot;&gt; &lt;/editor&gt;&lt;/view&gt;&lt;view class=&quot;toolbar&quot; catchtouchend=&quot;format&quot; hidden=&quot;{{keyboardHeight &gt; 0 ? false : true}}&quot; style=&quot;bottom: {{isIOS ? keyboardHeight : 0}}px&quot;&gt; &lt;i class=&quot;iconfont icon-charutupian&quot; catchtouchend=&quot;insertImage&quot;&gt;&lt;/i&gt; &lt;i class=&quot;iconfont icon-format-header-2 {{formats.header === 2 ? 'ql-active' : ''}}&quot; data-name=&quot;header&quot; data-value=&quot;{{2}}&quot;&gt;&lt;/i&gt; &lt;i class=&quot;iconfont icon-format-header-3 {{formats.header === 3 ? 'ql-active' : ''}}&quot; data-name=&quot;header&quot; data-value=&quot;{{3}}&quot;&gt;&lt;/i&gt; &lt;i class=&quot;iconfont icon-zitijiacu {{formats.bold ? 'ql-active' : ''}}&quot; data-name=&quot;bold&quot;&gt;&lt;/i&gt; &lt;i class=&quot;iconfont icon-zitixieti {{formats.italic ? 'ql-active' : ''}}&quot; data-name=&quot;italic&quot;&gt;&lt;/i&gt; &lt;i class=&quot;iconfont icon-zitixiahuaxian {{formats.underline ? 'ql-active' : ''}}&quot; data-name=&quot;underline&quot;&gt;&lt;/i&gt; &lt;i class=&quot;iconfont icon--checklist&quot; data-name=&quot;list&quot; data-value=&quot;check&quot;&gt;&lt;/i&gt; &lt;i class=&quot;iconfont icon-youxupailie {{formats.list === 'ordered' ? 'ql-active' : ''}}&quot; data-name=&quot;list&quot; data-value=&quot;ordered&quot;&gt;&lt;/i&gt; &lt;i class=&quot;iconfont icon-wuxupailie {{formats.list === 'bullet' ? 'ql-active' : ''}}&quot; data-name=&quot;list&quot; data-value=&quot;bullet&quot;&gt;&lt;/i&gt;&lt;/view&gt; 123456789101112{ &quot;pages&quot;: [ &quot;editor/editor&quot; ], &quot;window&quot;: { &quot;backgroundTextStyle&quot;: &quot;light&quot;, &quot;navigationBarBackgroundColor&quot;: &quot;#fff&quot;, &quot;navigationBarTitleText&quot;: &quot;WeChat&quot;, &quot;navigationBarTextStyle&quot;: &quot;black&quot; }, &quot;sitemapLocation&quot;: &quot;sitemap.json&quot;} 表单form 基础库 1.0.0 开始支持，低版本需做兼容处理。 表单。将组件内的用户输入的switch input checkbox slider radio picker 提交。 当点击 form 表单中 form-type 为 submit 的 button 组件时，会将表单组件中的 value 值进行提交，需要在表单组件中加上 name 来作为 key。 属性 类型 默认值 必填 说明 最低版本 report-submit boolean false 否 是否返回 formId 用于发送模板消息 1.0.0 report-submit-timeout number 0 否 等待一段时间（毫秒数）以确认 formId 是否生效。如果未指定这个参数，formId 有很小的概率是无效的（如遇到网络失败的情况）。指定这个参数将可以检测 formId 是否有效，以这个参数的时间作为这项检测的超时时间。如果失败，将返回 requestFormId:fail 开头的 formId 2.6.2 bindsubmit eventhandle 否 携带 form 中的数据触发 submit 事件，event.detail = {value : {‘name’: ‘value’} , formId: ‘’} 1.0.0 bindreset eventhandle 否 表单重置时会触发 reset 事件 1.0.0 示例代码// 在开发者工具中预览效果 123456789101112131415161718192021222324252627282930313233&lt;form bindsubmit=&quot;formSubmit&quot; bindreset=&quot;formReset&quot;&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;switch&lt;/view&gt; &lt;switch name=&quot;switch&quot;/&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;slider&lt;/view&gt; &lt;slider name=&quot;slider&quot; show-value &gt;&lt;/slider&gt; &lt;/view&gt; &lt;view class=&quot;section&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;input&lt;/view&gt; &lt;input name=&quot;input&quot; placeholder=&quot;please input here&quot; /&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;radio&lt;/view&gt; &lt;radio-group name=&quot;radio-group&quot;&gt; &lt;label&gt;&lt;radio value=&quot;radio1&quot;/&gt;radio1&lt;/label&gt; &lt;label&gt;&lt;radio value=&quot;radio2&quot;/&gt;radio2&lt;/label&gt; &lt;/radio-group&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;checkbox&lt;/view&gt; &lt;checkbox-group name=&quot;checkbox&quot;&gt; &lt;label&gt;&lt;checkbox value=&quot;checkbox1&quot;/&gt;checkbox1&lt;/label&gt; &lt;label&gt;&lt;checkbox value=&quot;checkbox2&quot;/&gt;checkbox2&lt;/label&gt; &lt;/checkbox-group&gt; &lt;/view&gt; &lt;view class=&quot;btn-area&quot;&gt; &lt;button formType=&quot;submit&quot;&gt;Submit&lt;/button&gt; &lt;button formType=&quot;reset&quot;&gt;Reset&lt;/button&gt; &lt;/view&gt;&lt;/form&gt; 12345678Page({ formSubmit: function (e) { console.log('form发生了submit事件，携带数据为：', e.detail.value) }, formReset: function () { console.log('form发生了reset事件') }}) 点击Submit提交，控制台输出： 输入框input 基础库 1.0.0 开始支持，低版本需做兼容处理。 输入框。该组件是原生组件，使用时请注意相关限制 属性 类型 默认值 必填 说明 最低版本 value string 是 输入框的初始内容 1.0.0 type string text 否 input 的类型 1.0.0 password boolean false 否 是否是密码类型 1.0.0 placeholder string 是 输入框为空时占位符 1.0.0 placeholder-style string 是 指定 placeholder 的样式 1.0.0 placeholder-class string input-placeholder 否 指定 placeholder 的样式类 1.0.0 disabled boolean false 否 是否禁用 1.0.0 maxlength number 140 否 最大输入长度，设置为 -1 的时候不限制最大长度 1.0.0 cursor-spacing number 0 否 指定光标与键盘的距离，取 input 距离底部的距离和 cursor-spacing 指定的距离的最小值作为光标与键盘的距离 1.0.0 auto-focus boolean false 否 (即将废弃，请直接使用 focus )自动聚焦，拉起键盘 1.0.0 focus boolean false 否 获取焦点 1.0.0 confirm-type string done 否 设置键盘右下角按钮的文字，仅在type=’text’时生效 1.1.0 always-embed boolean false 否 强制 input 处于同层状态，默认 focus 时 input 会切到非同层状态 (仅在 iOS 下生效) 2.10.4 confirm-hold boolean false 否 点击键盘右下角按钮时是否保持键盘不收起 1.1.0 cursor number 是 指定focus时的光标位置 1.5.0 selection-start number -1 否 光标起始位置，自动聚集时有效，需与selection-end搭配使用 1.9.0 selection-end number -1 否 光标结束位置，自动聚集时有效，需与selection-start搭配使用 1.9.0 adjust-position boolean true 否 键盘弹起时，是否自动上推页面 1.9.90 hold-keyboard boolean false 否 focus时，点击页面的时候不收起键盘 2.8.2 safe-password-cert-path string 否 安全键盘加密公钥的路径，只支持包内路径 2.18.0 safe-password-length number 否 安全键盘输入密码长度 2.18.0 safe-password-time-stamp number 否 安全键盘加密时间戳 2.18.0 safe-password-nonce string 否 安全键盘加密盐值 2.18.0 safe-password-salt string 否 安全键盘计算hash盐值，若指定custom-hash 则无效 2.18.0 safe-password-custom-hash string 否 安全键盘计算hash的算法表达式，如 md5(sha1('foo' + sha256(sm3(password + 'bar')))) 2.18.0 bindinput eventhandle 是 键盘输入时触发，event.detail = {value, cursor, keyCode}，keyCode 为键值，2.1.0 起支持，处理函数可以直接 return 一个字符串，将替换输入框的内容。 1.0.0 bindfocus eventhandle 是 输入框聚焦时触发，event.detail = { value, height }，height 为键盘高度，在基础库 1.9.90 起支持 1.0.0 bindblur eventhandle 是 输入框失去焦点时触发，event.detail = { value, encryptedValue, encryptError } 1.0.0 bindconfirm eventhandle 是 点击完成按钮时触发，event.detail = { value } 1.0.0 bindkeyboardheightchange eventhandle 是 键盘高度发生变化的时候触发此事件，event.detail = {height: height, duration: duration} 2.7.0 type 的合法值 值 说明 最低版本 text 文本输入键盘 number 数字输入键盘 idcard 身份证输入键盘 digit 带小数点的数字键盘 safe-password 密码安全输入键盘 指引 2.18.0 confirm-type 的合法值 值 说明 最低版本 send 右下角按钮为“发送” search 右下角按钮为“搜索” next 右下角按钮为“下一个” go 右下角按钮为“前往” done 右下角按钮为“完成” Bug &amp; Tip tip: confirm-type的最终表现与手机输入法本身的实现有关，部分安卓系统输入法和第三方输入法可能不支持或不完全支持 tip : input 组件是一个原生组件，字体是系统字体，所以无法设置 font-family tip : 在 input 聚焦期间，避免使用 css 动画 tip : 对于将 input 封装在自定义组件中、而 form 在自定义组件外的情况， form 将不能获得这个自定义组件中 input 的值。此时需要使用自定义组件的 内置 behaviors wx://form-field tip : 键盘高度发生变化，keyboardheightchange事件可能会多次触发，开发者对于相同的height值应该忽略掉 bug : 微信版本 6.3.30, focus 属性设置无效 bug : 微信版本 6.3.30, placeholder 在聚焦时出现重影问题 示例代码在开发者工具中预览效果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283&lt;view class=&quot;page-body&quot;&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;weui-cells__title&quot;&gt;可以自动聚焦的input&lt;/view&gt; &lt;view class=&quot;weui-cells weui-cells_after-title&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;input class=&quot;weui-input&quot; auto-focus placeholder=&quot;将会获取焦点&quot;/&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;weui-cells__title&quot;&gt;控制最大输入长度的input&lt;/view&gt; &lt;view class=&quot;weui-cells weui-cells_after-title&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;input class=&quot;weui-input&quot; maxlength=&quot;10&quot; placeholder=&quot;最大输入长度为10&quot; /&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;weui-cells__title&quot;&gt;实时获取输入值：{{inputValue}}&lt;/view&gt; &lt;view class=&quot;weui-cells weui-cells_after-title&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;input class=&quot;weui-input&quot; maxlength=&quot;10&quot; bindinput=&quot;bindKeyInput&quot; placeholder=&quot;输入同步到view中&quot;/&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;weui-cells__title&quot;&gt;控制输入的input&lt;/view&gt; &lt;view class=&quot;weui-cells weui-cells_after-title&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;input class=&quot;weui-input&quot; bindinput=&quot;bindReplaceInput&quot; placeholder=&quot;连续的两个1会变成2&quot; /&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;weui-cells__title&quot;&gt;控制键盘的input&lt;/view&gt; &lt;view class=&quot;weui-cells weui-cells_after-title&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;input class=&quot;weui-input&quot; bindinput=&quot;bindHideKeyboard&quot; placeholder=&quot;输入123自动收起键盘&quot; /&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;weui-cells__title&quot;&gt;数字输入的input&lt;/view&gt; &lt;view class=&quot;weui-cells weui-cells_after-title&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;input class=&quot;weui-input&quot; type=&quot;number&quot; placeholder=&quot;这是一个数字输入框&quot; /&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;weui-cells__title&quot;&gt;密码输入的input&lt;/view&gt; &lt;view class=&quot;weui-cells weui-cells_after-title&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;input class=&quot;weui-input&quot; password type=&quot;text&quot; placeholder=&quot;这是一个密码输入框&quot; /&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;weui-cells__title&quot;&gt;带小数点的input&lt;/view&gt; &lt;view class=&quot;weui-cells weui-cells_after-title&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;input class=&quot;weui-input&quot; type=&quot;digit&quot; placeholder=&quot;带小数点的数字键盘&quot;/&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;weui-cells__title&quot;&gt;身份证输入的input&lt;/view&gt; &lt;view class=&quot;weui-cells weui-cells_after-title&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;input class=&quot;weui-input&quot; type=&quot;idcard&quot; placeholder=&quot;身份证输入键盘&quot; /&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;weui-cells__title&quot;&gt;控制占位符颜色的input&lt;/view&gt; &lt;view class=&quot;weui-cells weui-cells_after-title&quot;&gt; &lt;view class=&quot;weui-cell weui-cell_input&quot;&gt; &lt;input class=&quot;weui-input&quot; placeholder-style=&quot;color:#F76260&quot; placeholder=&quot;占位符字体是红色的&quot; /&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; 1234567891011121314151617181920212223242526272829303132333435363738Page({ data: { focus: false, inputValue: '' }, bindKeyInput: function (e) { this.setData({ inputValue: e.detail.value }) }, bindReplaceInput: function (e) { var value = e.detail.value var pos = e.detail.cursor var left if (pos !== -1) { // 光标在中间 left = e.detail.value.slice(0, pos) // 计算光标的位置 pos = left.replace(/11/g, '2').length } // 直接返回对象，可以对输入进行过滤处理，同时可以控制光标的位置 return { value: value.replace(/11/g, '2'), cursor: pos } // 或者直接返回字符串,光标在最后边 // return value.replace(/11/g,'2'), }, bindHideKeyboard: function (e) { if (e.detail.value === '123') { // 收起键盘 wx.hideKeyboard() } }}) keyboard-accessory 基础库 2.15.0 开始支持，低版本需做兼容处理。 设置 input / textarea 聚焦时键盘上方 cover-view / cover-image 工具栏视图 Bug &amp; Tip tip: 视图最大高度为 200px 示例代码在开发者工具中预览效果 1234567891011121314151617&lt;input style=&quot;margin-top: 200px;&quot; placeholder=&quot;input&quot; bindfocus=&quot;focus1&quot; bindblur=&quot;blur1&quot; hold-keyboard&gt; &lt;keyboard-accessory class=&quot;container&quot; style=&quot;height: 100px;&quot;&gt; &lt;cover-view bindtap=&quot;tap&quot; style=&quot;flex: 1; width: 50px; background: green;&quot;&gt; &lt;button&gt;click&lt;/button&gt; &lt;/cover-view&gt; &lt;cover-image bindtap=&quot;tap&quot; src=&quot;https://images.unsplash.com/photo-1593642632823-8f785ba67e45?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=500&amp;q=60&quot; style=&quot;flex: 1; width: 50px; background: red;&quot;&gt; &lt;/cover-image&gt; &lt;/keyboard-accessory&gt;&lt;/input&gt;&lt;textarea hold-keyboard=&quot;{{true}}&quot; style=&quot;margin-top: 200px;&quot; placeholder=&quot;textarea1&quot; bindfocus=&quot;focus2&quot; bindblur=&quot;blur2&quot;&gt; &lt;keyboard-accessory class=&quot;container&quot; style=&quot;height: 50px;&quot;&gt; &lt;cover-view bindtap=&quot;tap&quot; style=&quot;flex: 1; width: 50px; background: green;&quot;&gt;textarea1&lt;/cover-view&gt; &lt;cover-view bindtap=&quot;tap&quot; style=&quot;flex: 1; width: 50px; background: red;&quot;&gt;2&lt;/cover-view&gt; &lt;/keyboard-accessory&gt;&lt;/textarea&gt; 123456789101112131415161718192021222324252627282930const app = getApp()Page({ data: { height: 50, flex: 1, show: true, }, onLoad: function () { console.log('代码片段是一种迷你、可分享的小程序或小游戏项目，可用于分享小程序和小游戏的开发经验、展示组件和 API 的使用、复现开发问题和 Bug 等。可点击以下链接查看代码片段的详细文档：') console.log('https://mp.weixin.qq.com/debug/wxadoc/dev/devtools/devtools.html') }, focus1() { console.log('focus input\\n') }, blur1() { console.log('blur input') }, focus2() { console.log('focus textarea') }, blur2() { console.log('blur textarea') },}) 用真机测试效果： input输入框获取焦点： textarea获取焦点： label标签 基础库 1.0.0 开始支持，低版本需做兼容处理。 用来改进表单组件的可用性。 使用for属性找到对应的id，或者将控件放在该标签下，当点击时，就会触发对应的控件。 for优先级高于内部控件，内部有多个控件的时候默认触发第一个控件。 目前可以绑定的控件有：button, checkbox, radio, switch。 属性 类型 默认值 必填 说明 最低版本 for string 否 绑定控件的 id 1.0.0 示例代码在开发者工具中预览效果 123456789101112131415161718192021222324252627&lt;view class=&quot;section section_gap&quot;&gt;&lt;view class=&quot;section__title&quot;&gt;表单组件在label内&lt;/view&gt;&lt;checkbox-group class=&quot;group&quot; bindchange=&quot;checkboxChange&quot;&gt; &lt;view class=&quot;label-1&quot; wx:for=&quot;{{checkboxItems}}&quot;&gt; &lt;label&gt; &lt;checkbox hidden value=&quot;{{item.name}}&quot; checked=&quot;{{item.checked}}&quot;&gt;&lt;/checkbox&gt; &lt;view class=&quot;label-1__icon&quot;&gt; &lt;view class=&quot;label-1__icon-checked&quot; style=&quot;opacity:{{item.checked ? 1: 0}}&quot;&gt;&lt;/view&gt; &lt;/view&gt; &lt;text class=&quot;label-1__text&quot;&gt;{{item.value}}&lt;/text&gt; &lt;/label&gt; &lt;/view&gt;&lt;/checkbox-group&gt;&lt;/view&gt;&lt;view class=&quot;section section_gap&quot;&gt;&lt;view class=&quot;section__title&quot;&gt;label用for标识表单组件&lt;/view&gt;&lt;radio-group class=&quot;group&quot; bindchange=&quot;radioChange&quot;&gt; &lt;view class=&quot;label-2&quot; wx:for=&quot;{{radioItems}}&quot;&gt; &lt;radio id=&quot;{{item.name}}&quot; hidden value=&quot;{{item.name}}&quot; checked=&quot;{{item.checked}}&quot;&gt;&lt;/radio&gt; &lt;view class=&quot;label-2__icon&quot;&gt; &lt;view class=&quot;label-2__icon-checked&quot; style=&quot;opacity:{{item.checked ? 1: 0}}&quot;&gt;&lt;/view&gt; &lt;/view&gt; &lt;label class=&quot;label-2__text&quot; for=&quot;{{item.name}}&quot;&gt;&lt;text&gt;{{item.name}}&lt;/text&gt;&lt;/label&gt; &lt;/view&gt;&lt;/radio-group&gt;&lt;/view&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445Page({ data: { checkboxItems: [ { name: 'USA', value: '美国' }, { name: 'CHN', value: '中国', checked: 'true' }, { name: 'BRA', value: '巴西' }, { name: 'JPN', value: '日本', checked: 'true' }, { name: 'ENG', value: '英国' }, { name: 'TUR', value: '法国' }, ], radioItems: [ { name: 'USA', value: '美国' }, { name: 'CHN', value: '中国', checked: 'true' }, { name: 'BRA', value: '巴西' }, { name: 'JPN', value: '日本' }, { name: 'ENG', value: '英国' }, { name: 'TUR', value: '法国' }, ], hidden: false }, checkboxChange: function (e) { var checked = e.detail.value var changed = {} for (var i = 0; i &lt; this.data.checkboxItems.length; i++) { if (checked.indexOf(this.data.checkboxItems[i].name) !== -1) { changed['checkboxItems[' + i + '].checked'] = true } else { changed['checkboxItems[' + i + '].checked'] = false } } this.setData(changed) }, radioChange: function (e) { var checked = e.detail.value var changed = {} for (var i = 0; i &lt; this.data.radioItems.length; i++) { if (checked.indexOf(this.data.radioItems[i].name) !== -1) { changed['radioItems[' + i + '].checked'] = true } else { changed['radioItems[' + i + '].checked'] = false } } this.setData(changed) }}) 从底部弹起的滚动选择器picker 基础库 1.0.0 开始支持，低版本需做兼容处理。 从底部弹起的滚动选择器。 属性 类型 默认值 必填 说明 最低版本 header-text string 否 选择器的标题，仅安卓可用 2.11.0 mode string selector 否 选择器类型 1.0.0 disabled boolean false 否 是否禁用 1.0.0 bindcancel eventhandle 否 取消选择时触发 1.9.90 mode 的合法值 值 说明 最低版本 selector 普通选择器 multiSelector 多列选择器 time 时间选择器 date 日期选择器 region 省市区选择器 除了上述通用的属性，对于不同的mode，picker拥有不同的属性。 普通选择器：mode = selector 属性名 类型 默认值 说明 最低版本 range array/object array [] mode 为 selector 或 multiSelector 时，range 有效 range-key string 当 range 是一个 Object Array 时，通过 range-key 来指定 Object 中 key 的值作为选择器显示内容 value number 0 表示选择了 range 中的第几个（下标从 0 开始） bindchange eventhandle value 改变时触发 change 事件，event.detail = {value} 多列选择器：mode = multiSelector 属性名 类型 默认值 说明 最低版本 range array/object array [] mode 为 selector 或 multiSelector 时，range 有效 range-key string 当 range 是一个 Object Array 时，通过 range-key 来指定 Object 中 key 的值作为选择器显示内容 value array [] 表示选择了 range 中的第几个（下标从 0 开始） bindchange eventhandle value 改变时触发 change 事件，event.detail = {value} bindcolumnchange eventhandle 列改变时触发 时间选择器：mode = time 属性名 类型 默认值 说明 最低版本 value string 表示选中的时间，格式为”hh:mm” start string 表示有效时间范围的开始，字符串格式为”hh:mm” end string 表示有效时间范围的结束，字符串格式为”hh:mm” bindchange eventhandle value 改变时触发 change 事件，event.detail = {value} 日期选择器：mode = date 属性名 类型 默认值 说明 最低版本 value string 当天 表示选中的日期，格式为”YYYY-MM-DD” start string 表示有效日期范围的开始，字符串格式为”YYYY-MM-DD” end string 表示有效日期范围的结束，字符串格式为”YYYY-MM-DD” fields string day 有效值 year,month,day，表示选择器的粒度 bindchange eventhandle value 改变时触发 change 事件，event.detail = {value} fields 有效值： 值 说明 year 选择器粒度为年 month 选择器粒度为月份 day 选择器粒度为天 省市区选择器：mode = region 1.4.0 属性名 类型 默认值 说明 最低版本 value array [] 表示选中的省市区，默认选中每一列的第一个值 custom-item string 可为每一列的顶部添加一个自定义的项 1.5.0 bindchange eventhandle value 改变时触发 change 事件，event.detail = {value, code, postcode}，其中字段 code 是统计用区划代码，postcode 是邮政编码 示例代码在开发者工具中预览效果 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;view class=&quot;section&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;普通选择器&lt;/view&gt; &lt;picker bindchange=&quot;bindPickerChange&quot; value=&quot;{{index}}&quot; range=&quot;{{array}}&quot;&gt; &lt;view class=&quot;picker&quot;&gt; 当前选择：{{array[index]}} &lt;/view&gt; &lt;/picker&gt;&lt;/view&gt;&lt;view class=&quot;section&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;多列选择器&lt;/view&gt; &lt;picker mode=&quot;multiSelector&quot; bindchange=&quot;bindMultiPickerChange&quot; bindcolumnchange=&quot;bindMultiPickerColumnChange&quot; value=&quot;{{multiIndex}}&quot; range=&quot;{{multiArray}}&quot;&gt; &lt;view class=&quot;picker&quot;&gt; 当前选择：{{multiArray[0][multiIndex[0]]}}，{{multiArray[1][multiIndex[1]]}}，{{multiArray[2][multiIndex[2]]}} &lt;/view&gt; &lt;/picker&gt;&lt;/view&gt;&lt;view class=&quot;section&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;时间选择器&lt;/view&gt; &lt;picker mode=&quot;time&quot; value=&quot;{{time}}&quot; start=&quot;09:01&quot; end=&quot;21:01&quot; bindchange=&quot;bindTimeChange&quot;&gt; &lt;view class=&quot;picker&quot;&gt; 当前选择: {{time}} &lt;/view&gt; &lt;/picker&gt;&lt;/view&gt;&lt;view class=&quot;section&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;日期选择器&lt;/view&gt; &lt;picker mode=&quot;date&quot; value=&quot;{{date}}&quot; start=&quot;2015-09-01&quot; end=&quot;2017-09-01&quot; bindchange=&quot;bindDateChange&quot;&gt; &lt;view class=&quot;picker&quot;&gt; 当前选择: {{date}} &lt;/view&gt; &lt;/picker&gt;&lt;/view&gt;&lt;view class=&quot;section&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;省市区选择器&lt;/view&gt; &lt;picker mode=&quot;region&quot; bindchange=&quot;bindRegionChange&quot; value=&quot;{{region}}&quot; custom-item=&quot;{{customItem}}&quot;&gt; &lt;view class=&quot;picker&quot;&gt; 当前选择：{{region[0]}}，{{region[1]}}，{{region[2]}} &lt;/view&gt; &lt;/picker&gt;&lt;/view&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165Page({ data: { array: ['美国', '中国', '巴西', '日本'], objectArray: [ { id: 0, name: '美国' }, { id: 1, name: '中国' }, { id: 2, name: '巴西' }, { id: 3, name: '日本' } ], index: 0, multiArray: [['无脊柱动物', '脊柱动物'], ['扁性动物', '线形动物', '环节动物', '软体动物', '节肢动物'], ['猪肉绦虫', '吸血虫']], objectMultiArray: [ [ { id: 0, name: '无脊柱动物' }, { id: 1, name: '脊柱动物' } ], [ { id: 0, name: '扁性动物' }, { id: 1, name: '线形动物' }, { id: 2, name: '环节动物' }, { id: 3, name: '软体动物' }, { id: 3, name: '节肢动物' } ], [ { id: 0, name: '猪肉绦虫' }, { id: 1, name: '吸血虫' } ] ], multiIndex: [0, 0, 0], date: '2016-09-01', time: '12:01', region: ['广东省', '广州市', '海珠区'], customItem: '全部' }, bindPickerChange: function (e) { console.log('picker发送选择改变，携带值为', e.detail.value) this.setData({ index: e.detail.value }) }, bindMultiPickerChange: function (e) { console.log('picker发送选择改变，携带值为', e.detail.value) this.setData({ multiIndex: e.detail.value }) }, bindMultiPickerColumnChange: function (e) { console.log('修改的列为', e.detail.column, '，值为', e.detail.value); var data = { multiArray: this.data.multiArray, multiIndex: this.data.multiIndex }; data.multiIndex[e.detail.column] = e.detail.value; switch (e.detail.column) { case 0: switch (data.multiIndex[0]) { case 0: data.multiArray[1] = ['扁性动物', '线形动物', '环节动物', '软体动物', '节肢动物']; data.multiArray[2] = ['猪肉绦虫', '吸血虫']; break; case 1: data.multiArray[1] = ['鱼', '两栖动物', '爬行动物']; data.multiArray[2] = ['鲫鱼', '带鱼']; break; } data.multiIndex[1] = 0; data.multiIndex[2] = 0; break; case 1: switch (data.multiIndex[0]) { case 0: switch (data.multiIndex[1]) { case 0: data.multiArray[2] = ['猪肉绦虫', '吸血虫']; break; case 1: data.multiArray[2] = ['蛔虫']; break; case 2: data.multiArray[2] = ['蚂蚁', '蚂蟥']; break; case 3: data.multiArray[2] = ['河蚌', '蜗牛', '蛞蝓']; break; case 4: data.multiArray[2] = ['昆虫', '甲壳动物', '蛛形动物', '多足动物']; break; } break; case 1: switch (data.multiIndex[1]) { case 0: data.multiArray[2] = ['鲫鱼', '带鱼']; break; case 1: data.multiArray[2] = ['青蛙', '娃娃鱼']; break; case 2: data.multiArray[2] = ['蜥蜴', '龟', '壁虎']; break; } break; } data.multiIndex[2] = 0; console.log(data.multiIndex); break; } this.setData(data); }, bindDateChange: function (e) { console.log('picker发送选择改变，携带值为', e.detail.value) this.setData({ date: e.detail.value }) }, bindTimeChange: function (e) { console.log('picker发送选择改变，携带值为', e.detail.value) this.setData({ time: e.detail.value }) }, bindRegionChange: function (e) { console.log('picker发送选择改变，携带值为', e.detail.value) this.setData({ region: e.detail.value }) }}) 嵌入页面的滚动选择器 picker-view 基础库 1.0.0 开始支持，低版本需做兼容处理。 嵌入页面的滚动选择器。其中只可放置 picker-view-column组件，其它节点不会显示。 属性 类型 默认值 必填 说明 最低版本 value Array. 否 数组中的数字依次表示 picker-view 内的 picker-view-column 选择的第几项（下标从 0 开始），数字大于 picker-view-column 可选项长度时，选择最后一项。 1.0.0 indicator-style string 否 设置选择器中间选中框的样式 1.0.0 indicator-class string 否 设置选择器中间选中框的类名 1.1.0 mask-style string 否 设置蒙层的样式 1.5.0 mask-class string 否 设置蒙层的类名 1.5.0 bindchange eventhandle 否 滚动选择时触发change事件，event.detail = {value}；value为数组，表示 picker-view 内的 picker-view-column 当前选择的是第几项（下标从 0 开始） 1.0.0 bindpickstart eventhandle 否 当滚动选择开始时候触发事件 2.3.1 bindpickend eventhandle 否 当滚动选择结束时候触发事件 2.3.1 Bug &amp; Tip tip: 滚动时在iOS自带振动反馈，可在系统设置 -&gt; 声音与触感 -&gt; 系统触感反馈中关闭 示例代码在开发者工具中预览效果 1234567891011121314&lt;view&gt; &lt;view&gt;{{year}}年{{month}}月{{day}}日&lt;/view&gt; &lt;picker-view indicator-style=&quot;height: 50px;&quot; style=&quot;width: 100%; height: 300px;&quot; value=&quot;{{value}}&quot; bindchange=&quot;bindChange&quot;&gt; &lt;picker-view-column&gt; &lt;view wx:for=&quot;{{years}}&quot; style=&quot;line-height: 50px&quot;&gt;{{item}}年&lt;/view&gt; &lt;/picker-view-column&gt; &lt;picker-view-column&gt; &lt;view wx:for=&quot;{{months}}&quot; style=&quot;line-height: 50px&quot;&gt;{{item}}月&lt;/view&gt; &lt;/picker-view-column&gt; &lt;picker-view-column&gt; &lt;view wx:for=&quot;{{days}}&quot; style=&quot;line-height: 50px&quot;&gt;{{item}}日&lt;/view&gt; &lt;/picker-view-column&gt; &lt;/picker-view&gt;&lt;/view&gt; 123456789101112131415161718192021222324252627282930313233343536const date = new Date()const years = []const months = []const days = []for (let i = 1990; i &lt;= date.getFullYear(); i++) { years.push(i)}for (let i = 1; i &lt;= 12; i++) { months.push(i)}for (let i = 1; i &lt;= 31; i++) { days.push(i)}Page({ data: { years: years, year: date.getFullYear(), months: months, month: 2, days: days, day: 2, value: [9999, 1, 1], }, bindChange: function (e) { const val = e.detail.value this.setData({ year: this.data.years[val[0]], month: this.data.months[val[1]], day: this.data.days[val[2]] }) }}) 滚动选择器子项 picker-view-column 基础库 1.0.0 开始支持，低版本需做兼容处理。 滚动选择器子项。仅可放置于picker-view中，其孩子节点的高度会自动设置成与picker-view的选中框的高度一致 单选项目 radio 基础库 1.0.0 开始支持，低版本需做兼容处理。 单选项目。 属性 类型 默认值 必填 说明 最低版本 value string 否 radio 标识。当该radio 选中时，radio-group 的 change 事件会携带radio的value 1.0.0 checked boolean false 否 当前是否选中 1.0.0 disabled boolean false 否 是否禁用 1.0.0 color string #09BB07 否 radio的颜色，同css的color 1.0.0 示例代码在开发者工具中预览效果 123456789101112131415&lt;view class=&quot;page&quot;&gt; &lt;view class=&quot;page__hd&quot;&gt; &lt;text class=&quot;page__title&quot;&gt;radio&lt;/text&gt; &lt;text class=&quot;page__desc&quot;&gt;单选框&lt;/text&gt; &lt;/view&gt; &lt;view class=&quot;page__bd&quot;&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;radio-group class=&quot;radio-group&quot; bindchange=&quot;radioChange&quot;&gt; &lt;radio class=&quot;radio&quot; wx:for-items=&quot;{{items}}&quot; wx:key=&quot;name&quot; value=&quot;{{item.name}}&quot; checked=&quot;{{item.checked}}&quot;&gt; &lt;text&gt;{{item.value}}&lt;/text&gt; &lt;/radio&gt; &lt;/radio-group&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; 12345678910111213141516Page({ data: { items: [ { name: 'USA', value: '美国' }, { name: 'CHN', value: '中国', checked: 'true' }, { name: 'BRA', value: '巴西' }, { name: 'JPN', value: '日本' }, { name: 'ENG', value: '英国' }, { name: 'FRA', value: '法国' }, ] }, radioChange: function (e) { console.log('radio发生change事件，携带value值为：', e.detail.value) }}) 单项选择器 radio-group 基础库 1.0.0 开始支持，低版本需做兼容处理。 单项选择器，内部由多个 radio 组成。 属性 类型 默认值 必填 说明 最低版本 bindchange EventHandle 否 radio-group中选中项发生改变时触发 change 事件，detail = {value:[选中的radio的value的数组]} 1.0.0 滑动选择器 slider 基础库 1.0.0 开始支持，低版本需做兼容处理。 滑动选择器。 属性 类型 默认值 必填 说明 最低版本 min number 0 否 最小值 1.0.0 max number 100 否 最大值 1.0.0 step number 1 否 步长，取值必须大于 0，并且可被(max - min)整除 1.0.0 disabled boolean false 否 是否禁用 1.0.0 value number 0 否 当前取值 1.0.0 color color #e9e9e9 否 背景条的颜色（请使用 backgroundColor） 1.0.0 selected-color color #1aad19 否 已选择的颜色（请使用 activeColor） 1.0.0 activeColor color #1aad19 否 已选择的颜色 1.0.0 backgroundColor color #e9e9e9 否 背景条的颜色 1.0.0 block-size number 28 否 滑块的大小，取值范围为 12 - 28 1.9.0 block-color color #ffffff 否 滑块的颜色 1.9.0 show-value boolean false 否 是否显示当前 value 1.0.0 bindchange eventhandle 否 完成一次拖动后触发的事件，event.detail = {value} 1.0.0 bindchanging eventhandle 否 拖动过程中触发的事件，event.detail = {value} 1.7.0 示例代码在开发者工具中预览效果 1234567891011121314151617181920212223242526272829303132333435&lt;view class=&quot;page&quot;&gt; &lt;view class=&quot;page__hd&quot;&gt; &lt;text class=&quot;page__title&quot;&gt;slider&lt;/text&gt; &lt;text class=&quot;page__desc&quot;&gt;滑块&lt;/text&gt; &lt;/view&gt; &lt;view class=&quot;page__bd&quot;&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;text class=&quot;section__title&quot;&gt;设置left/right icon&lt;/text&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;slider bindchange=&quot;slider1change&quot; left-icon=&quot;cancel&quot; right-icon=&quot;success_no_circle&quot;/&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;text class=&quot;section__title&quot;&gt;设置step&lt;/text&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;slider bindchange=&quot;slider2change&quot; step=&quot;5&quot;/&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;text class=&quot;section__title&quot;&gt;显示当前value&lt;/text&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;slider bindchange=&quot;slider3change&quot; show-value/&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;text class=&quot;section__title&quot;&gt;设置最小/最大值&lt;/text&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;slider bindchange=&quot;slider4change&quot; min=&quot;50&quot; max=&quot;200&quot; show-value/&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; 123456789var pageData = {}for (var i = 1; i &lt; 5; ++i) { (function (index) { pageData[`slider${index}change`] = function (e) { console.log(`slider${index}发生change事件，携带值为`, e.detail.value) } })(i);}Page(pageData) 开关选择器 switch 基础库 1.0.0 开始支持，低版本需做兼容处理。 开关选择器。 属性 类型 默认值 必填 说明 最低版本 checked boolean false 否 是否选中 1.0.0 disabled boolean false 否 是否禁用 1.0.0 type string switch 否 样式，有效值：switch, checkbox 1.0.0 color string #04BE02 否 switch 的颜色，同 css 的 color 1.0.0 bindchange eventhandle 否 checked 改变时触发 change 事件，event.detail={ value} 1.0.0 Bug &amp; Tip tip: switch类型切换时在iOS自带振动反馈，可在系统设置 -&gt; 声音与触感 -&gt; 系统触感反馈中关闭 示例代码在开发者工具中预览效果 123456789101112131415161718192021&lt;view class=&quot;page&quot;&gt; &lt;view class=&quot;page__hd&quot;&gt; &lt;text class=&quot;page__title&quot;&gt;switch&lt;/text&gt; &lt;text class=&quot;page__desc&quot;&gt;开关&lt;/text&gt; &lt;/view&gt; &lt;view class=&quot;page__bd&quot;&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;type=&quot;switch&quot;&lt;/view&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;switch checked=&quot;{{switch1Checked}}&quot; bindchange=&quot;switch1Change&quot;/&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;section section_gap&quot;&gt; &lt;view class=&quot;section__title&quot;&gt;type=&quot;checkbox&quot;&lt;/view&gt; &lt;view class=&quot;body-view&quot;&gt; &lt;switch type=&quot;checkbox&quot; checked=&quot;{{switch2Checked}}&quot; bindchange=&quot;switch2Change&quot;/&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; 12345678910111213141516171819202122var pageData = { data: { switch1Checked: true, switch2Checked: false, switch1Style: '', switch2Style: 'text-decoration: line-through' }}for (var i = 1; i &lt;= 2; ++i) { (function (index) { pageData[`switch${index}Change`] = function (e) { console.log(`switch${index}发生change事件，携带值为`, e.detail.value) var obj = {} obj[`switch${index}Checked`] = e.detail.value this.setData(obj) obj = {} obj[`switch${index}Style`] = e.detail.value ? '' : 'text-decoration: line-through' this.setData(obj) } })(i)}Page(pageData) 多行输入框 textarea 基础库 1.0.0 开始支持，低版本需做兼容处理。 多行输入框。该组件是原生组件，使用时请注意相关限制。 属性 类型 默认值 必填 说明 最低版本 value string 否 输入框的内容 1.0.0 placeholder string 否 输入框为空时占位符 1.0.0 placeholder-style string 否 指定 placeholder 的样式，目前仅支持color,font-size和font-weight 1.0.0 placeholder-class string textarea-placeholder 否 指定 placeholder 的样式类 1.0.0 disabled boolean false 否 是否禁用 1.0.0 maxlength number 140 否 最大输入长度，设置为 -1 的时候不限制最大长度 1.0.0 auto-focus boolean false 否 自动聚焦，拉起键盘。 1.0.0 focus boolean false 否 获取焦点 1.0.0 auto-height boolean false 否 是否自动增高，设置auto-height时，style.height不生效 1.0.0 fixed boolean false 否 如果 textarea 是在一个 position:fixed 的区域，需要显示指定属性 fixed 为 true 1.0.0 cursor-spacing number 0 否 指定光标与键盘的距离。取textarea距离底部的距离和cursor-spacing指定的距离的最小值作为光标与键盘的距离 1.0.0 cursor number -1 否 指定focus时的光标位置 1.5.0 show-confirm-bar boolean true 否 是否显示键盘上方带有”完成“按钮那一栏 1.6.0 selection-start number -1 否 光标起始位置，自动聚集时有效，需与selection-end搭配使用 1.9.0 selection-end number -1 否 光标结束位置，自动聚集时有效，需与selection-start搭配使用 1.9.0 adjust-position boolean true 否 键盘弹起时，是否自动上推页面 1.9.90 hold-keyboard boolean false 否 focus时，点击页面的时候不收起键盘 2.8.2 disable-default-padding boolean false 否 是否去掉 iOS 下的默认内边距 2.10.0 confirm-type string return 否 设置键盘右下角按钮的文字 2.13.0 confirm-hold boolean false 否 点击键盘右下角按钮时是否保持键盘不收起 2.16.0 bindfocus eventhandle 否 输入框聚焦时触发，event.detail = { value, height }，height 为键盘高度，在基础库 1.9.90 起支持 1.0.0 bindblur eventhandle 否 输入框失去焦点时触发，event.detail = {value, cursor} 1.0.0 bindlinechange eventhandle 否 输入框行数变化时调用，event.detail = {height: 0, heightRpx: 0, lineCount: 0} 1.0.0 bindinput eventhandle 否 当键盘输入时，触发 input 事件，event.detail = {value, cursor, keyCode}，keyCode 为键值，目前工具还不支持返回keyCode参数。bindinput 处理函数的返回值并不会反映到 textarea 上 1.0.0 bindconfirm eventhandle 否 点击完成时， 触发 confirm 事件，event.detail = {value: value} 1.0.0 bindkeyboardheightchange eventhandle 否 键盘高度发生变化的时候触发此事件，event.detail = {height: height, duration: duration} 2.7.0 confirm-type 的合法值 值 说明 最低版本 send 右下角按钮为“发送” search 右下角按钮为“搜索” next 右下角按钮为“下一个” go 右下角按钮为“前往” done 右下角按钮为“完成” return 右下角按钮为“换行” Bug &amp; Tip tip: textarea 的 blur 事件会晚于页面上的 tap 事件，如果需要在 button 的点击事件获取 textarea，可以使用 form 的 bindsubmit。 tip: 不建议在多行文本上对用户的输入进行修改，所以 textarea 的 bindinput 处理函数并不会将返回值反映到 textarea 上。 tip : 键盘高度发生变化，keyboardheightchange事件可能会多次触发，开发者对于相同的height值应该忽略掉 bug: 微信版本 6.3.30，textarea 在列表渲染时，新增加的 textarea 在自动聚焦时的位置计算错误。 示例代码在开发者工具中预览效果 123456789101112131415&lt;view class=&quot;page-body&quot;&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;page-section-title&quot;&gt;输入区域高度自适应，不会出现滚动条&lt;/view&gt; &lt;view class=&quot;textarea-wrp&quot;&gt; &lt;textarea bindblur=&quot;bindTextAreaBlur&quot; auto-height /&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;page-section&quot;&gt; &lt;view class=&quot;page-section-title&quot;&gt;这是一个可以自动聚焦的textarea&lt;/view&gt; &lt;view class=&quot;textarea-wrp&quot;&gt; &lt;textarea auto-focus=&quot;true&quot; style=&quot;height: 3em&quot; /&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; 123456789Page({ data: { focus: false }, bindTextAreaBlur: function(e) { console.log(e.detail.value) }})","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6%E7%BB%84%E4%BB%B6-%E8%A1%A8%E5%8D%95%E7%BB%84%E4%BB%B6/"},{"title":"微信小程序自定义组件-抽象节点","text":"这个特性自小程序基础库版本 1.9.6 开始支持。 在组件中使用抽象节点有时，自定义组件模板中的一些节点，其对应的自定义组件不是由自定义组件本身确定的，而是自定义组件的调用者确定的。这时可以把这个节点声明为“抽象节点”。 例如，我们现在来实现一个“选框组”（selectable-group）组件，它其中可以放置单选框（custom-radio）或者复选框（custom-checkbox）。这个组件的 wxml 可以这样编写： 代码示例： 在开发者工具中预览效果 1234567&lt;!-- selectable-group.wxml --&gt;&lt;view wx:for=&quot;{{labels}}&quot;&gt; &lt;label&gt; &lt;selectable disabled=&quot;{{false}}&quot;&gt;&lt;/selectable&gt; {{item}} &lt;/label&gt;&lt;/view&gt; 其中，“selectable”不是任何在 json 文件的 usingComponents 字段中声明的组件，而是一个抽象节点。它需要在 componentGenerics 字段中声明： 12345{ &quot;componentGenerics&quot;: { &quot;selectable&quot;: true }} 使用包含抽象节点的组件在使用 selectable-group 组件时，必须指定“selectable”具体是哪个组件： 1&lt;selectable-group generic:selectable=&quot;custom-radio&quot; /&gt; 这样，在生成这个 selectable-group 组件的实例时，“selectable”节点会生成“custom-radio”组件实例。类似地，如果这样使用： 1&lt;selectable-group generic:selectable=&quot;custom-checkbox&quot; /&gt; “selectable”节点则会生成“custom-checkbox”组件实例。 注意：上述的 custom-radio 和 custom-checkbox 需要包含在这个 wxml 对应 json 文件的 usingComponents 定义段中。 123456{ &quot;usingComponents&quot;: { &quot;custom-radio&quot;: &quot;path/to/custom/radio&quot;, &quot;custom-checkbox&quot;: &quot;path/to/custom/checkbox&quot; }} 抽象节点的默认组件抽象节点可以指定一个默认组件，当具体组件未被指定时，将创建默认组件的实例。默认组件可以在 componentGenerics 字段中指定： 1234567{ &quot;componentGenerics&quot;: { &quot;selectable&quot;: { &quot;default&quot;: &quot;path/to/default/component&quot; } }} 注意事项 节点的 generic 引用 generic:xxx=&quot;yyy&quot; 中，值 yyy 只能是静态值，不能包含数据绑定。因而抽象节点特性并不适用于动态决定节点名的场景。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E6%8A%BD%E8%B1%A1%E8%8A%82%E7%82%B9/"},{"title":"微信小程序自定义组件-数据监听","text":"数据监听器可以用于监听和响应任何属性和数据字段的变化。从小程序基础库版本 2.6.1 开始支持。 使用数据监听器有时，在一些数据字段被 setData 设置时，需要执行一些操作。 例如， this.data.sum 永远是 this.data.numberA 与 this.data.numberB 的和。此时，可以使用数据监听器进行如下实现。 12345678910111213141516Component({ attached: function() { this.setData({ numberA: 1, numberB: 2, }) }, observers: { 'numberA, numberB': function(numberA, numberB) { // 在 numberA 或者 numberB 被设置时，执行这个函数 this.setData({ sum: numberA + numberB }) } }}) 在开发者工具中预览效果 监听字段语法数据监听器支持监听属性或内部数据的变化，可以同时监听多个。一次 setData 最多触发每个监听器一次。 同时，监听器可以监听子数据字段，如下例所示。 1234567891011121314Component({ observers: { 'some.subfield': function(subfield) { // 使用 setData 设置 this.data.some.subfield 时触发 // （除此以外，使用 setData 设置 this.data.some 也会触发） subfield === this.data.some.subfield }, 'arr[12]': function(arr12) { // 使用 setData 设置 this.data.arr[12] 时触发 // （除此以外，使用 setData 设置 this.data.arr 也会触发） arr12 === this.data.arr[12] }, }}) 如果需要监听所有子数据字段的变化，可以使用通配符 ** 。 1234567891011121314151617181920212223Component({ observers: { 'some.field.**': function(field) { // 使用 setData 设置 this.data.some.field 本身或其下任何子数据字段时触发 // （除此以外，使用 setData 设置 this.data.some 也会触发） field === this.data.some.field }, }, attached: function() { // 这样会触发上面的 observer this.setData({ 'some.field': { /* ... */ } }) // 这样也会触发上面的 observer this.setData({ 'some.field.xxx': { /* ... */ } }) // 这样还是会触发上面的 observer this.setData({ 'some': { /* ... */ } }) }}) 特别地，仅使用通配符 ** 可以监听全部 setData 。 1234567Component({ observers: { '**': function() { // 每次 setData 都触发 }, },}) 注意事项 数据监听器监听的是 setData 涉及到的数据字段，即使这些数据字段的值没有发生变化，数据监听器依然会被触发。 如果在数据监听器函数中使用 setData 设置本身监听的数据字段，可能会导致死循环，需要特别留意。 数据监听器和属性的 observer 相比，数据监听器更强大且通常具有更好的性能。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E6%95%B0%E6%8D%AE%E7%9B%91%E5%90%AC/"},{"title":"微信小程序自定义组件-简单入门","text":"自定义组件入门从小程序基础库版本 1.6.3 开始，小程序支持简洁的组件化编程。所有自定义组件相关特性都需要基础库版本 1.6.3 或更高。 开发者可以将页面内的功能模块抽象成自定义组件，以便在不同的页面中重复使用；也可以将复杂的页面拆分成多个低耦合的模块，有助于代码维护。自定义组件在使用时与基础组件非常相似。 创建自定义组件类似于页面，一个自定义组件由 json wxml wxss js 4个文件组成。要编写一个自定义组件，首先需要在 json 文件中进行自定义组件声明（将 component 字段设为 true 可将这一组文件设为自定义组件）： 123{ &quot;component&quot;: true} 同时，还要在 wxml 文件中编写组件模板，在 wxss 文件中加入组件样式，它们的写法与页面的写法类似。具体细节和注意事项参见 组件模板和样式 。 代码示例： 12345&lt;!-- 这是自定义组件的内部WXML结构 --&gt;&lt;view class=&quot;inner&quot;&gt; {{innerText}}&lt;/view&gt;&lt;slot&gt;&lt;/slot&gt; 1234/* 这里的样式只应用于这个自定义组件 */.inner { color: red;} 注意：在组件wxss中不应使用ID选择器、属性选择器和标签名选择器。 在自定义组件的 js 文件中，需要使用 Component() 来注册组件，并提供组件的属性定义、内部数据和自定义方法。 组件的属性值和内部数据将被用于组件 wxml 的渲染，其中，属性值是可由组件外部传入的。更多细节参见 Component构造器 。 代码示例： 1234567891011121314151617Component({ properties: { // 这里定义了innerText属性，属性值可以在组件使用时指定 innerText: { type: String, value: 'default value', } }, data: { // 这里是一些组件内部数据 someData: {} }, methods: { // 这里是一个自定义方法 customMethod: function(){} }}) 使用自定义组件使用已注册的自定义组件前，首先要在页面的 json 文件中进行引用声明。此时需要提供每个自定义组件的标签名和对应的自定义组件文件路径： 12345{ &quot;usingComponents&quot;: { &quot;component-tag-name&quot;: &quot;path/to/the/custom/component&quot; }} 这样，在页面的 wxml 中就可以像使用基础组件一样使用自定义组件。节点名即自定义组件的标签名，节点属性即传递给组件的属性值。 开发者工具 1.02.1810190 及以上版本支持在 app.json 中声明 usingComponents 字段，在此处声明的自定义组件视为全局自定义组件，在小程序内的页面或自定义组件中可以直接使用而无需再声明。 代码示例： 在开发者工具中预览效果 1234&lt;view&gt; &lt;!-- 以下是对一个自定义组件的引用 --&gt; &lt;component-tag-name inner-text=&quot;Some text&quot;&gt;&lt;/component-tag-name&gt;&lt;/view&gt; 自定义组件的 wxml 节点结构在与数据结合之后，将被插入到引用位置内。 运行效果： 注意事项一些需要注意的细节： 因为 WXML 节点标签名只能是小写字母、中划线和下划线的组合，所以自定义组件的标签名也只能包含这些字符。 自定义组件也是可以引用自定义组件的，引用方法类似于页面引用自定义组件的方式（使用 usingComponents 字段）。 自定义组件和页面所在项目根目录名不能以“wx-”为前缀，否则会报错。 注意，是否在页面文件中使用 usingComponents 会使得页面的 this 对象的原型稍有差异，包括： 使用 usingComponents 页面的原型与不使用时不一致，即 Object.getPrototypeOf(this) 结果不同。 使用 usingComponents 时会多一些方法，如 selectComponent 。 出于性能考虑，使用 usingComponents 时， setData 内容不会被直接深复制，即 this.setData({ field: obj }) 后 this.data.field === obj 。（深复制会在这个值被组件间传递时发生。） 如果页面比较复杂，新增或删除 usingComponents 定义段时建议重新测试一下。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E7%AE%80%E5%8D%95%E5%85%A5%E9%97%A8/"},{"title":"微信小程序自定义组件-纯数据字段","text":"纯数据字段是一些不用于界面渲染的 data 字段，可以用于提升页面更新性能。从小程序基础库版本 2.8.2 开始支持。 组件数据中的纯数据字段有些情况下，某些 data 中的字段（包括 setData 设置的字段）既不会展示在界面上，也不会传递给其他组件，仅仅在当前组件内部使用。 此时，可以指定这样的数据字段为“纯数据字段”，它们将仅仅被记录在 this.data 中，而不参与任何界面渲染过程，这样有助于提升页面更新性能。 指定“纯数据字段”的方法是在 Component 构造器的 options 定义段中指定 pureDataPattern 为一个正则表达式，字段名符合这个正则表达式的字段将成为纯数据字段。 在开发者工具中预览效果 代码示例： 123456789101112131415161718Component({ options: { pureDataPattern: /^_/ // 指定所有 _ 开头的数据字段为纯数据字段 }, data: { a: true, // 普通数据字段 _b: true, // 纯数据字段 }, methods: { myMethod() { this.data._b // 纯数据字段可以在 this.data 中获取 this.setData({ c: true, // 普通数据字段 _d: true, // 纯数据字段 }) } }}) 上述组件中的纯数据字段不会被应用到 WXML 上： 12&lt;view wx:if=&quot;{{a}}&quot;&gt; 这行会被展示 &lt;/view&gt;&lt;view wx:if=&quot;{{_b}}&quot;&gt; 这行不会被展示 &lt;/view&gt; 组件属性中的纯数据字段属性也可以被指定为纯数据字段（遵循 pureDataPattern 的正则表达式）。 属性中的纯数据字段可以像普通属性一样接收外部传入的属性值，但不能将它直接用于组件自身的 WXML 中。 代码示例： 1234567891011121314Component({ options: { pureDataPattern: /^_/ }, properties: { a: Boolean, _b: { type: Boolean, observer() { // 不要这样做！这个 observer 永远不会被触发 } }, }}) 注意：属性中的纯数据字段的属性 observer 永远不会触发！如果想要监听属性值变化，使用 数据监听器 代替。 从小程序基础库版本 2.10.1 开始，也可以在页面或自定义组件的 json 文件中配置 pureDataPattern （这样就不需在 js 文件的 options 中再配置）。此时，其值应当写成字符串形式： 123{ &quot;pureDataPattern&quot;: &quot;^_&quot;} 使用数据监听器监听纯数据字段数据监听器 可以用于监听纯数据字段（与普通数据字段一样）。这样，可以通过监听、响应纯数据字段的变化来改变界面。 下面的示例是一个将 JavaScript 时间戳转换为可读时间的自定义组件。 在开发者工具中预览效果 代码示例： 123456789101112131415161718Component({ options: { pureDataPattern: /^timestamp$/ // 将 timestamp 属性指定为纯数据字段 }, properties: { timestamp: Number, }, observers: { timestamp: function () { // timestamp 被设置时，将它展示为可读时间字符串 var timeString = new Date(this.data.timestamp).toLocaleString() this.setData({ timeString: timeString }) } }})&lt;view&gt;{{timeString}}&lt;/view&gt;","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E7%BA%AF%E6%95%B0%E6%8D%AE%E5%AD%97%E6%AE%B5/"},{"title":"微信小程序自定义组件-组件生命周期","text":"组件的生命周期，指的是组件自身的一些函数，这些函数在特殊的时间点或遇到一些特殊的框架事件时被自动触发。 其中，最重要的生命周期是 created attached detached ，包含一个组件实例生命流程的最主要时间点。 组件实例刚刚被创建好时， created 生命周期被触发。此时，组件数据 this.data 就是在 Component 构造器中定义的数据 data 。 此时还不能调用 setData 。 通常情况下，这个生命周期只应该用于给组件 this 添加一些自定义属性字段。 在组件完全初始化完毕、进入页面节点树后， attached 生命周期被触发。此时， this.data 已被初始化为组件的当前值。这个生命周期很有用，绝大多数初始化工作可以在这个时机进行。 在组件离开页面节点树后， detached 生命周期被触发。退出一个页面时，如果组件还在页面节点树中，则 detached 会被触发。 定义生命周期方法生命周期方法可以直接定义在 Component 构造器的第一级参数中。 自小程序基础库版本 2.2.3 起，组件的的生命周期也可以在 lifetimes 字段内进行声明（这是推荐的方式，其优先级最高）。 代码示例： 123456789101112131415161718Component({ lifetimes: { attached: function() { // 在组件实例进入页面节点树时执行 }, detached: function() { // 在组件实例被从页面节点树移除时执行 }, }, // 以下是旧式的定义方式，可以保持对 &lt;2.2.3 版本基础库的兼容 attached: function() { // 在组件实例进入页面节点树时执行 }, detached: function() { // 在组件实例被从页面节点树移除时执行 }, // ...}) 在 behaviors 中也可以编写生命周期方法，同时不会与其他 behaviors 中的同名生命周期相互覆盖。但要注意，如果一个组件多次直接或间接引用同一个 behavior ，这个 behavior 中的生命周期函数在一个执行时机内只会执行一次。 可用的全部生命周期如下表所示。 生命周期 参数 描述 最低版本 created 无 在组件实例刚刚被创建时执行 1.6.3 attached 无 在组件实例进入页面节点树时执行 1.6.3 ready 无 在组件在视图层布局完成后执行 1.6.3 moved 无 在组件实例被移动到节点树另一个位置时执行 1.6.3 detached 无 在组件实例被从页面节点树移除时执行 1.6.3 error Object Error 每当组件方法抛出错误时执行 2.4.1 组件所在页面的生命周期还有一些特殊的生命周期，它们并非与组件有很强的关联，但有时组件需要获知，以便组件内部处理。这样的生命周期称为“组件所在页面的生命周期”，在 pageLifetimes 定义段中定义。其中可用的生命周期包括： 生命周期 参数 描述 最低版本 show 无 组件所在的页面被展示时执行 2.2.3 hide 无 组件所在的页面被隐藏时执行 2.2.3 resize Object Size 组件所在的页面尺寸变化时执行 2.4.0 代码示例： 12345678910111213Component({ pageLifetimes: { show: function() { // 页面被展示 }, hide: function() { // 页面被隐藏 }, resize: function(size) { // 页面尺寸变化 } }})","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E7%BB%84%E4%BB%B6%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"},{"title":"微信小程序自定义组件-组件的模版与样式","text":"类似于页面，自定义组件拥有自己的 wxml 模板和 wxss 样式。 组件模板组件模板的写法与页面模板相同。组件模板与组件数据结合后生成的节点树，将被插入到组件的引用位置上。 在组件模板中可以提供一个 &lt;slot&gt; 节点，用于承载组件引用时提供的子节点。 代码示例： 在开发者工具中预览效果 12345&lt;!-- 组件模板 --&gt;&lt;view class=&quot;wrapper&quot;&gt; &lt;view&gt;这里是组件的内部节点&lt;/view&gt; &lt;slot&gt;&lt;/slot&gt;&lt;/view&gt; 1234567&lt;!-- 引用组件的页面模板 --&gt;&lt;view&gt; &lt;component-tag-name&gt; &lt;!-- 这部分内容将被放置在组件 &lt;slot&gt; 的位置上 --&gt; &lt;view&gt;这里是插入到组件slot中的内容&lt;/view&gt; &lt;/component-tag-name&gt;&lt;/view&gt; 注意，在模板中引用到的自定义组件及其对应的节点名需要在 json 文件中显式定义，否则会被当作一个无意义的节点。除此以外，节点名也可以被声明为抽象节点。 模板数据绑定与普通的 WXML 模板类似，可以使用数据绑定，这样就可以向子组件的属性传递动态数据。 代码示例： 在开发者工具中预览效果 index.wxml1234567&lt;!-- 引用组件的页面模板 --&gt;&lt;view&gt; &lt;component-tag-name prop-a=&quot;{{dataFieldA}}&quot; prop-b=&quot;{{dataFieldB}}&quot;&gt; &lt;!-- 这部分内容将被放置在组件 &lt;slot&gt; 的位置上 --&gt; &lt;view&gt;这里是插入到组件slot中的内容&lt;/view&gt; &lt;/component-tag-name&gt;&lt;/view&gt; index.js12345678const app = getApp()Page({ data: { dataFieldA: '123', dataFieldB: '456' }}) component-tag-name.wxml1234567&lt;!-- 组件模板 --&gt;&lt;view class=&quot;wrapper&quot;&gt; &lt;view&gt;这里是组件的内部节点&lt;/view&gt; &lt;text&gt;propA: {{propA}}&lt;/text&gt; &lt;text&gt;propB: {{propB}}&lt;/text&gt; &lt;slot&gt;&lt;/slot&gt;&lt;/view&gt; component-tag-name.js1234567891011// components/component-tag-name.jsComponent({ /** * 组件的属性列表 */ properties: { propA: String, propB: String }}) 在以上例子中，组件的属性 propA 和 propB 将收到页面传递的数据。页面可以通过 setData 来改变绑定的数据字段。 注意：这样的数据绑定只能传递 JSON 兼容数据。自基础库版本 2.0.9 开始，还可以在数据中包含函数（但这些函数不能在 WXML 中直接调用，只能传递给子组件）。 组件 wxml 的 slot在组件的 wxml 中可以包含 slot 节点，用于承载组件使用者提供的 wxml 结构。 默认情况下，一个组件的 wxml 中只能有一个 slot 。需要使用多 slot 时，可以在组件 js 中声明启用。 1234567Component({ options: { multipleSlots: true // 在组件定义时的选项中启用多slot支持 }, properties: { /* ... */ }, methods: { /* ... */ }}) 此时，可以在这个组件的 wxml 中使用多个 slot ，以不同的 name 来区分。 123456&lt;!-- 组件模板 --&gt;&lt;view class=&quot;wrapper&quot;&gt; &lt;slot name=&quot;before&quot;&gt;&lt;/slot&gt; &lt;view&gt;这里是组件的内部细节&lt;/view&gt; &lt;slot name=&quot;after&quot;&gt;&lt;/slot&gt;&lt;/view&gt; 使用时，用 slot 属性来将节点插入到不同的 slot 上。 123456789&lt;!-- 引用组件的页面模板 --&gt;&lt;view&gt; &lt;component-tag-name&gt; &lt;!-- 这部分内容将被放置在组件 &lt;slot name=&quot;before&quot;&gt; 的位置上 --&gt; &lt;view slot=&quot;before&quot;&gt;这里是插入到组件slot name=&quot;before&quot;中的内容&lt;/view&gt; &lt;!-- 这部分内容将被放置在组件 &lt;slot name=&quot;after&quot;&gt; 的位置上 --&gt; &lt;view slot=&quot;after&quot;&gt;这里是插入到组件slot name=&quot;after&quot;中的内容&lt;/view&gt; &lt;/component-tag-name&gt;&lt;/view&gt; 组件样式组件对应 wxss 文件的样式，只对组件wxml内的节点生效。编写组件样式时，需要注意以下几点： 组件和引用组件的页面不能使用id选择器（#a）、属性选择器（[a]）和标签名选择器，请改用class选择器。 组件和引用组件的页面中使用后代选择器（.a .b）在一些极端情况下会有非预期的表现，如遇，请避免使用。 子元素选择器（.a&gt;.b）只能用于 view 组件与其子节点之间，用于其他组件可能导致非预期的情况。 继承样式，如 font 、 color ，会从组件外继承到组件内。 除继承样式外， app.wxss 中的样式、组件所在页面的的样式对自定义组件无效（除非更改组件样式隔离选项）。 1234#a { } /* 在组件中不能使用 */[a] { } /* 在组件中不能使用 */button { } /* 在组件中不能使用 */.a &gt; .b { } /* 除非 .a 是 view 组件节点，否则不一定会生效 */ 除此以外，组件可以指定它所在节点的默认样式，使用 :host 选择器（需要包含基础库 1.7.2 或更高版本的开发者工具支持）。 代码示例： 在开发者工具中预览效果 123456/* 组件 custom-component.wxss */:host { color: yellow;}&lt;!-- 页面的 WXML --&gt;&lt;custom-component&gt;这段文本是黄色的&lt;/custom-component&gt; 组件样式隔离默认情况下，自定义组件的样式只受到自定义组件 wxss 的影响。除非以下两种情况： app.wxss 或页面的 wxss 中使用了标签名选择器（或一些其他特殊选择器）来直接指定样式，这些选择器会影响到页面和全部组件。通常情况下这是不推荐的做法。 指定特殊的样式隔离选项 styleIsolation 。 12345Component({ options: { styleIsolation: 'isolated' }}) 在开发者工具中预览效果 styleIsolation 选项从基础库版本 2.6.5 开始支持。它支持以下取值： isolated 表示启用样式隔离，在自定义组件内外，使用 class 指定的样式将不会相互影响（一般情况下的默认值）； apply-shared 表示页面 wxss 样式将影响到自定义组件，但自定义组件 wxss 中指定的样式不会影响页面； shared 表示页面 wxss 样式将影响到自定义组件，自定义组件 wxss 中指定的样式也会影响页面和其他设置了 apply-shared 或 shared 的自定义组件。（这个选项在插件中不可用。） 使用后两者时，请务必注意组件间样式的相互影响。 如果这个 Component 构造器用于构造页面 ，则默认值为 shared ，且还有以下几个额外的样式隔离选项可用： page-isolated 表示在这个页面禁用 app.wxss ，同时，页面的 wxss 不会影响到其他自定义组件； page-apply-shared 表示在这个页面禁用 app.wxss ，同时，页面 wxss 样式不会影响到其他自定义组件，但设为 shared 的自定义组件会影响到页面； page-shared 表示在这个页面禁用 app.wxss ，同时，页面 wxss 样式会影响到其他设为 apply-shared 或 shared 的自定义组件，也会受到设为 shared 的自定义组件的影响。 从小程序基础库版本 2.10.1 开始，也可以在页面或自定义组件的 json 文件中配置 styleIsolation （这样就不需在 js 文件的 options 中再配置）。例如： 123{ &quot;styleIsolation&quot;: &quot;isolated&quot;} 此外，小程序基础库版本 2.2.3 以上支持 addGlobalClass 选项，即在 Component 的 options 中设置 addGlobalClass: true 。 这个选项等价于设置 styleIsolation: apply-shared ，但设置了 styleIsolation 选项后这个选项会失效。 代码示例： 在开发者工具中预览效果 123456789101112/* 组件 custom-component.js */Component({ options: { addGlobalClass: true, }})&lt;!-- 组件 custom-component.wxml --&gt;&lt;text class=&quot;red-text&quot;&gt;这段文本的颜色由 `app.wxss` 和页面 `wxss` 中的样式定义来决定&lt;/text&gt;/* app.wxss */.red-text { color: red;} 外部样式类 基础库 1.9.90 开始支持，低版本需做兼容处理。 有时，组件希望接受外部传入的样式类。此时可以在 Component 中用 externalClasses 定义段定义若干个外部样式类。 这个特性可以用于实现类似于 view 组件的 hover-class 属性：页面可以提供一个样式类，赋予 view 的 hover-class ，这个样式类本身写在页面中而非 view 组件的实现中。 注意：在同一个节点上使用普通样式类和外部样式类时，两个类的优先级是未定义的，因此最好避免这种情况。 代码示例： 1234/* 组件 custom-component.js */Component({ externalClasses: ['my-class']}) 123&lt;!-- 组件 custom-component.wxml --&gt;&lt;custom-component class=&quot;my-class&quot;&gt;这段文本的颜色由组件外的 class 决定&lt;/custom-component&gt; 这样，组件的使用者可以指定这个样式类对应的 class ，就像使用普通属性一样。在 2.7.1 之后，可以指定多个对应的 class 。 代码示例： 在开发者工具中预览效果 1234567891011&lt;!-- 页面的 WXML --&gt;&lt;custom-component my-class=&quot;red-text&quot; /&gt;&lt;custom-component my-class=&quot;large-text&quot; /&gt;&lt;!-- 以下写法需要基础库版本 2.7.1 以上 --&gt;&lt;custom-component my-class=&quot;red-text large-text&quot; /&gt;.red-text { color: red;}.large-text { font-size: 1.5em;} 引用页面或父组件的样式 基础库 2.9.2 开始支持，低版本需做兼容处理。 即使启用了样式隔离 isolated ，组件仍然可以在局部引用组件所在页面的样式或父组件的样式。 例如，如果在页面 wxss 中定义了： 123.blue-text { color: blue;} 在这个组件中可以使用 ~ 来引用这个类的样式： 1&lt;view class=&quot;~blue-text&quot;&gt; 这段文本是蓝色的 &lt;/view&gt; 如果在一个组件的父组件 wxss 中定义了： 123.red-text { color: red;} 在这个组件中可以使用 ^ 来引用这个类的样式： 1&lt;view class=&quot;^red-text&quot;&gt; 这段文本是红色的 &lt;/view&gt; 也可以连续使用多个 ^ 来引用祖先组件中的样式。 注意：如果组件是比较独立、通用的组件，请优先使用外部样式类的方式，而非直接引用父组件或页面的样式。 虚拟化组件节点 基础库 2.11.2 开始支持，低版本需做兼容处理。 默认情况下，自定义组件本身的那个节点是一个“普通”的节点，使用时可以在这个节点上设置 class style 、动画、 flex 布局等，就如同普通的 view 组件节点一样。 index.wxml1234&lt;!-- 页面的 WXML --&gt;&lt;my-virtual-host class=&quot;class-in-virtual-host&quot; style=&quot;text-decoration: underline&quot;&gt; &lt;view&gt;这段文本是居中、蓝色、无下划线的&lt;/view&gt;&lt;/my-virtual-host&gt; index.wxss1234.class-in-virtual-host { display: block; color: red; text-align: center; 但有些时候，自定义组件并不希望这个节点本身可以设置样式、响应 flex 布局等，而是希望自定义组件内部的第一层节点能够响应 flex 布局或者样式由自定义组件本身完全决定。 这种情况下，可以将这个自定义组件设置为“虚拟的”： my-virtual-host.wxml1234&lt;view class=&quot;class blue&quot;&gt; &lt;slot /&gt;&lt;/view&gt;&lt;view style=&quot;{{style}}&quot;&gt;这段文本是居左、黑色、有下划线的&lt;/view&gt; my-virtual-host.js123456789Component({ options: { virtualHost: true, }, externalClasses: ['class'],// 可以将 class 设为 externalClasses properties: {// 定义 style 属性可以拿到 style 属性上设置的值 style: String },}) my-virtual-host.wxss123.blue { color: blue;} 需要注意的是，自定义组件节点上的 class style 和动画将不再生效，但仍可以： 将 style 定义成 properties 属性来获取 style 上设置的值； 将 class 定义成 externalClasses 外部样式类使得自定义组件 wxml 可以使用 class 值。 代码示例： 在开发者工具中预览效果 不设置virtualHost为true: 设置virtualHost为true：","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E7%BB%84%E4%BB%B6%E7%9A%84%E6%A8%A1%E7%89%88%E4%B8%8E%E6%A0%B7%E5%BC%8F/"},{"title":"微信小程序自定义组件-组件间关系","text":"定义和使用组件间关系有时需要实现这样的组件： 1234&lt;custom-ul&gt; &lt;custom-li&gt; item 1 &lt;/custom-li&gt; &lt;custom-li&gt; item 2 &lt;/custom-li&gt;&lt;/custom-ul&gt; 这个例子中， custom-ul 和 custom-li 都是自定义组件，它们有相互间的关系，相互间的通信往往比较复杂。此时在组件定义时加入 relations 定义段，可以解决这样的问题。示例： 在开发者工具中预览效果 1234567891011121314151617181920212223242526// path/to/custom-ul.jsComponent({ relations: { './custom-li': { type: 'child', // 关联的目标节点应为子节点 linked: function(target) { // 每次有custom-li被插入时执行，target是该节点实例对象，触发在该节点attached生命周期之后 }, linkChanged: function(target) { // 每次有custom-li被移动后执行，target是该节点实例对象，触发在该节点moved生命周期之后 }, unlinked: function(target) { // 每次有custom-li被移除时执行，target是该节点实例对象，触发在该节点detached生命周期之后 } } }, methods: { _getAllLi: function(){ // 使用getRelationNodes可以获得nodes数组，包含所有已关联的custom-li，且是有序的 var nodes = this.getRelationNodes('path/to/custom-li') } }, ready: function(){ this._getAllLi() }}) 1234567891011121314151617// path/to/custom-li.jsComponent({ relations: { './custom-ul': { type: 'parent', // 关联的目标节点应为父节点 linked: function(target) { // 每次被插入到custom-ul时执行，target是custom-ul节点实例对象，触发在attached生命周期之后 }, linkChanged: function(target) { // 每次被移动后执行，target是custom-ul节点实例对象，触发在moved生命周期之后 }, unlinked: function(target) { // 每次被移除时执行，target是custom-ul节点实例对象，触发在detached生命周期之后 } } }}) 注意：必须在两个组件定义中都加入relations定义，否则不会生效。 关联一类组件在开发者工具中预览效果 有时，需要关联的是一类组件，如： 1234567&lt;custom-form&gt; &lt;view&gt; input &lt;custom-input&gt;&lt;/custom-input&gt; &lt;/view&gt; &lt;custom-submit&gt; submit &lt;/custom-submit&gt;&lt;/custom-form&gt; custom-form 组件想要关联 custom-input 和 custom-submit 两个组件。此时，如果这两个组件都有同一个behavior： 1234// path/to/custom-form-controls.jsmodule.exports = Behavior({ // ...}) 12345678910// path/to/custom-input.jsvar customFormControls = require('./custom-form-controls')Component({ behaviors: [customFormControls], relations: { './custom-form': { type: 'ancestor', // 关联的目标节点应为祖先节点 } }}) 12345678910// path/to/custom-submit.jsvar customFormControls = require('./custom-form-controls')Component({ behaviors: [customFormControls], relations: { './custom-form': { type: 'ancestor', // 关联的目标节点应为祖先节点 } }}) 则在 relations 关系定义中，可使用这个behavior来代替组件路径作为关联的目标节点： 12345678910// path/to/custom-form.jsvar customFormControls = require('./custom-form-controls')Component({ relations: { 'customFormControls': { type: 'descendant', // 关联的目标节点应为子孙节点 target: customFormControls } }}) relations 定义段relations 定义段包含目标组件路径及其对应选项，可包含的选项见下表。 选项 类型 是否必填 描述 type String 是 目标组件的相对关系，可选的值为 parent 、 child 、 ancestor 、 descendant linked Function 否 关系生命周期函数，当关系被建立在页面节点树中时触发，触发时机在组件attached生命周期之后 linkChanged Function 否 关系生命周期函数，当关系在页面节点树中发生改变时触发，触发时机在组件moved生命周期之后 unlinked Function 否 关系生命周期函数，当关系脱离页面节点树时触发，触发时机在组件detached生命周期之后 target String 否 如果这一项被设置，则它表示关联的目标节点所应具有的behavior，所有拥有这一behavior的组件节点都会被关联","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E7%BB%84%E4%BB%B6%E9%97%B4%E5%85%B3%E7%B3%BB%20/"},{"title":"微信小程序自定义组件-组件间通信与事件","text":"组件间通信组件间的基本通信方式有以下几种。 WXML 数据绑定：用于父组件向子组件的指定属性设置数据，仅能设置 JSON 兼容数据（自基础库版本 2.0.9 开始，还可以在数据中包含函数）。具体在 组件模板和样式 章节中介绍。 事件：用于子组件向父组件传递数据，可以传递任意数据。 如果以上两种方式不足以满足需要，父组件还可以通过 this.selectComponent 方法获取子组件实例对象，这样就可以直接访问组件的任意数据和方法。 监听事件事件系统是组件间通信的主要方式之一。自定义组件可以触发任意的事件，引用组件的页面可以监听这些事件。关于事件的基本概念和用法，参见 事件 。 监听自定义组件事件的方法与监听基础组件事件的方法完全一致： 代码示例： 1234&lt;!-- 当自定义组件触发“myevent”事件时，调用“onMyEvent”方法 --&gt;&lt;component-tag-name bindmyevent=&quot;onMyEvent&quot; /&gt;&lt;!-- 或者可以写成 --&gt;&lt;component-tag-name bind:myevent=&quot;onMyEvent&quot; /&gt; 12345Page({ onMyEvent: function(e){ e.detail // 自定义组件触发事件时提供的detail对象 }}) 触发事件自定义组件触发事件时，需要使用 triggerEvent 方法，指定事件名、detail对象和事件选项： 代码示例： 在开发者工具中预览效果 123&lt;!-- 在自定义组件中 --&gt;&lt;button bindtap=&quot;onTap&quot;&gt;点击这个按钮将触发“myevent”事件&lt;/button&gt; 12345678910Component({ properties: {}, methods: { onTap: function(){ var myEventDetail = {} // detail对象，提供给事件监听函数 var myEventOption = {} // 触发事件的选项 this.triggerEvent('myevent', myEventDetail, myEventOption) } }}) 触发事件的选项包括： 选项名 类型 是否必填 默认值 描述 bubbles Boolean 否 false 事件是否冒泡 composed Boolean 否 false 事件是否可以穿越组件边界，为false时，事件将只能在引用组件的节点树上触发，不进入其他任何组件内部 capturePhase Boolean 否 false 事件是否拥有捕获阶段 关于冒泡和捕获阶段的概念，请阅读 事件 章节中的相关说明。 代码示例： 在开发者工具中预览效果 1234// 页面 page.wxml&lt;another-component bindcustomevent=&quot;pageEventListener1&quot;&gt; &lt;my-component bindcustomevent=&quot;pageEventListener2&quot;&gt;&lt;/my-component&gt;&lt;/another-component&gt; 1234// 组件 another-component.wxml&lt;view bindcustomevent=&quot;anotherEventListener&quot;&gt; &lt;slot /&gt;&lt;/view&gt; 1234// 组件 my-component.wxml&lt;view bindcustomevent=&quot;myEventListener&quot;&gt; &lt;slot /&gt;&lt;/view&gt; 12345678910// 组件 my-component.jsComponent({ methods: { onTap: function(){ this.triggerEvent('customevent', {}) // 只会触发 pageEventListener2 this.triggerEvent('customevent', {}, { bubbles: true }) // 会依次触发 pageEventListener2 、 pageEventListener1 this.triggerEvent('customevent', {}, { bubbles: true, composed: true }) // 会依次触发 pageEventListener2 、 anotherEventListener 、 pageEventListener1 } }}) 获取组件实例可在父组件里调用 this.selectComponent ，获取子组件的实例对象。 调用时需要传入一个匹配选择器 selector，如：this.selectComponent(&quot;.my-component&quot;)。 selector 详细语法可查看 selector 语法参考文档。 代码示例： 在开发者工具中预览效果 12345678// 父组件Page({ data: {}, getChildComponent: function () { const child = this.selectComponent('.my-component'); console.log(child) }}) 在上例中，父组件将会获取 class 为 my-component 的子组件实例对象，即子组件的 this 。 注意 ：默认情况下，小程序与插件之间、不同插件之间的组件将无法通过 selectComponent 得到组件实例（将返回 null）。如果想让一个组件在上述条件下依然能被 selectComponent 返回，可以自定义其返回结果（见下）。 自定义的组件实例获取结果若需要自定义 selectComponent 返回的数据，可使用内置 behavior: wx://component-export 从基础库版本 2.2.3 开始提供支持。 使用该 behavior 时，自定义组件中的 export 定义段将用于指定组件被 selectComponent 调用时的返回值。 代码示例： 在开发者工具中预览效果 1234567// 自定义组件 my-component 内部Component({ behaviors: ['wx://component-export'], export() { return { myField: 'myValue' } }}) 12&lt;!-- 使用自定义组件时 --&gt;&lt;my-component id=&quot;the-id&quot; /&gt; 12// 父组件调用const child = this.selectComponent('#the-id') // 等于 { myField: 'myValue' } 在上例中，父组件获取 id 为 the-id 的子组件实例的时候，得到的是对象 { myField: 'myValue' } 。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E7%BB%84%E4%BB%B6%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BA%8B%E4%BB%B6/"},{"title":"微信小程序自定义组件-自定义组件扩展","text":"为了更好定制自定义组件的功能，可以使用自定义组件扩展机制。从小程序基础库版本 2.2.3 开始支持。 扩展后的效果为了更好的理解扩展后的效果，先举一个例子： 在开发者工具中预览效果 1234567891011121314151617// behavior.jsmodule.exports = Behavior({ definitionFilter(defFields) { defFields.data.from = 'behavior' },})// component.jsComponent({ data: { from: 'component' }, behaviors: [require('behavior.js')], ready() { console.log(this.data.from) // 此处会发现输出 behavior 而不是 component }}) 通过例子可以发现，自定义组件的扩展其实就是提供了修改自定义组件定义段的能力，上述例子就是修改了自定义组件中的 data 定义段里的内容。 使用扩展Behavior() 构造器提供了新的定义段 definitionFilter ，用于支持自定义组件扩展。 definitionFilter 是一个函数，在被调用时会注入两个参数，第一个参数是使用该 behavior 的 component/behavior 的定义对象，第二个参数是该 behavior 所使用的 behavior 的 definitionFilter 函数列表。 以下举个例子来说明： 1234567891011121314151617181920212223// behavior3.jsmodule.exports = Behavior({ definitionFilter(defFields, definitionFilterArr) {},})// behavior2.jsmodule.exports = Behavior({ behaviors: [require('behavior3.js')], definitionFilter(defFields, definitionFilterArr) { // definitionFilterArr[0](defFields) },})// behavior1.jsmodule.exports = Behavior({ behaviors: [require('behavior2.js')], definitionFilter(defFields, definitionFilterArr) {},})// component.jsComponent({ behaviors: [require('behavior1.js')],}) 上述代码中声明了1个自定义组件和3个 behavior，每个 behavior 都使用了 definitionFilter 定义段。那么按照声明的顺序会有如下事情发生： 当进行 behavior2 的声明时就会调用 behavior3 的 definitionFilter 函数，其中 defFields 参数是 behavior2 的定义段， definitionFilterArr 参数即为空数组，因为 behavior3 没有使用其他的 behavior 。 当进行 behavior1 的声明时就会调用 behavior2 的 definitionFilter 函数，其中 defFields 参数是 behavior1 的定义段， definitionFilterArr 参数是一个长度为1的数组，definitionFilterArr[0] 即为 behavior3 的 definitionFilter 函数，因为 behavior2 使用了 behavior3。用户在此处可以自行决定在进行 behavior1 的声明时要不要调用 behavior3 的 definitionFilter 函数，如果需要调用，在此处补充代码 definitionFilterArr[0](defFields) 即可，definitionFilterArr 参数会由基础库补充传入。 同理，在进行 component 的声明时就会调用 behavior1 的 definitionFilter 函数。 简单概括，definitionFilter 函数可以理解为当 A 使用了 B 时，A 声明就会调用 B 的 definitionFilter 函数并传入 A 的定义对象让 B 去过滤。此时如果 B 还使用了 C 和 D ，那么 B 可以自行决定要不要调用 C 和 D 的 definitionFilter 函数去过滤 A 的定义对象。 代码示例： 在开发者工具中预览效果 真实案例下面利用扩展简单实现自定义组件的计算属性功能: 12345678910111213141516171819202122232425262728293031323334353637383940// behavior.jsmodule.exports = Behavior({ lifetimes: { created() { this._originalSetData = this.setData // 原始 setData this.setData = this._setData // 封装后的 setData } }, definitionFilter(defFields) { const computed = defFields.computed || {} const computedKeys = Object.keys(computed) const computedCache = {} // 计算 computed const calcComputed = (scope, insertToData) =&gt; { const needUpdate = {} const data = defFields.data = defFields.data || {} for (let key of computedKeys) { const value = computed[key].call(scope) // 计算新值 if (computedCache[key] !== value) needUpdate[key] = computedCache[key] = value if (insertToData) data[key] = needUpdate[key] // 直接插入到 data 中，初始化时才需要的操作 } return needUpdate } // 重写 setData 方法 defFields.methods = defFields.methods || {} defFields.methods._setData = function (data, callback) { const originalSetData = this._originalSetData // 原始 setData originalSetData.call(this, data, callback) // 做 data 的 setData const needUpdate = calcComputed(this) // 计算 computed originalSetData.call(this, needUpdate) // 做 computed 的 setData } // 初始化 computed calcComputed(defFields, true) // 计算 computed }}) 在组件中使用： 12345678910111213141516171819202122const beh = require('./behavior.js')Component({ behaviors: [beh], data: { a: 0, }, computed: { b() { return this.data.a + 100 }, }, methods: { onTap() { this.setData({ a: ++this.data.a, }) } }})&lt;view&gt;data: {{a}}&lt;/view&gt;&lt;view&gt;computed: {{b}}&lt;/view&gt;&lt;button bindtap=&quot;onTap&quot;&gt;click&lt;/button&gt; 实现原理很简单，对已有的 setData 进行二次封装，在每次 setData 的时候计算出 computed 里各字段的值，然后设到 data 中，以达到计算属性的效果。 此实现只是作为一个简单案例来展示，请勿直接在生产环境中使用。 官方扩展包 computed","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6%E6%89%A9%E5%B1%95/"},{"title":"微信小程序自定义组件-获取更新性能统计信息","text":"基础库 2.12.0 开始支持，低版本需做兼容处理。 如果想要知道 setData 引发界面更新的开销，可以使用更新性能统计信息接口。它将返回每次更新中主要更新步骤发生的时间戳，可以用来大体上估计自定义组件（或页面）更新性能。例如： 1234567Component({ attached() { // 调用时机不能早于 attached this.setUpdatePerformanceListener({withDataPaths: true}, (res) =&gt; { console.log(res) }) }}) setUpdatePerformanceListener 方法接受一个 options 对象和回调函数 listener 作为参数。 其中， options 对象包含以下字段： 字段 类型 说明 withDataPaths Boolean 是否返回变更的 data 字段信息 listeners 返回携带一个 res 对象，表示一次由 setData 引发的 更新过程 。根据 setData 调用时机的不同，更新过程大体可以分为三类： 基本更新 ，它有一个唯一的 updateProcessId ； 子更新 ，它是另一个基本更新的一个子步骤，也有唯一的 updateProcessId ，但还有一个 parentUpdateProcessId ； 被合并更新 ，它被合并到了另一个基本更新或子更新过程中，无法被独立统计。 每次成功的 setData 调用都会产生一个更新过程，使得 listener 回调一次。不过 setData 究竟触发了哪类更新过程很难判断，更新性能好坏与其具体是哪类更新也没有必然联系，只是它们的返回值参数有所不同。 res 中包含以下字段： 字段 类型 说明 updateProcessId Number \b此次\b更新过程的 ID parentUpdateProcessId Number 对于子更新，返回它所属的更新过程 ID isMergedUpdate Boolean 是否是被合并更新，如果是，\b\b则 updateProcessId 表示被合并到的更新过程 ID dataPaths Array 此次更新的 data 字段信息，只有 withDataPaths 设为 true 时才会返回 pendingStartTimestamp Number 此次更新进入等待队列时的时间戳 updateStartTimestamp Number 更新运算开始时的时间戳 updateEndTimestamp Number 更新运算结束时的时间戳 说明： setUpdatePerformanceListener 只会激活当前组件或页面的统计， parentUpdateProcessId 有可能是其他组件或者页面的更新过程 ID 而未被统计回调，如果想要知道页面内所有的更新过程，需要在所有组件中都调用 setUpdatePerformanceListener ； 统计本身有一点点开销，如果想要禁用统计，调用 setUpdatePerformanceListener 时传入第二个参数 listener 为 null 即可。","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6-%E8%8E%B7%E5%8F%96%E6%9B%B4%E6%96%B0%E6%80%A7%E8%83%BD%E7%BB%9F%E8%AE%A1%E4%BF%A1%E6%81%AF/"},{"title":"微信小程序配置","text":"全局配置app.json小程序根目录下的 app.json 文件用来对微信小程序进行全局配置。文件内容为一个 JSON 对象，有以下属性： 配置项 属性 类型 必填 描述 最低版本 entryPagePath string 否 小程序默认启动首页 pages string[] 是 页面路径列表 window Object 否 全局的默认窗口表现 tabBar Object 否 底部 tab 栏的表现 networkTimeout Object 否 网络超时时间 debug boolean 否 是否开启 debug 模式，默认关闭 functionalPages boolean 否 是否启用插件功能页，默认关闭 2.1.0 subpackages Object[] 否 分包结构配置 1.7.3 workers string 否 Worker 代码放置的目录 1.9.90 requiredBackgroundModes string[] 否 需要在后台使用的能力，如「音乐播放」 plugins Object 否 使用到的插件 1.9.6 preloadRule Object 否 分包预下载规则 2.3.0 resizable boolean 否 PC 小程序是否支持用户任意改变窗口大小（包括最大化窗口）；iPad 小程序是否支持屏幕旋转。默认关闭 2.3.0 usingComponents Object 否 全局自定义组件配置 开发者工具 1.02.1810190 permission Object 否 小程序接口权限相关设置 微信客户端 7.0.0 sitemapLocation string 是 指明 sitemap.json 的位置 style string 否 指定使用升级后的weui样式 2.8.0 useExtendedLib Object 否 指定需要引用的扩展库 2.2.1 entranceDeclare Object 否 微信消息用小程序打开 微信客户端7.0.9 darkmode boolean 否 小程序支持 DarkMode 2.11.0 themeLocation string 否 指明 theme.json 的位置，darkmode为true为必填 开发者工具 1.03.2004271 lazyCodeLoading string 否 配置自定义组件代码按需注入 2.11.1 singlePage Object 否 单页模式相关配置 2.12.0 supportedMaterials Object 否 聊天素材小程序打开相关配置 2.14.3 serviceProviderTicket string 否 定制化型服务商票据 embeddedAppIdList string[] 否 内嵌小程序 appId tabBar如果小程序是一个多 tab 应用（客户端窗口的底部或顶部有 tab 栏可以切换页面），可以通过 tabBar 配置项指定 tab 栏的表现，以及 tab 切换时显示的对应页面。 属性 类型 必填 默认值 描述 最低版本 color HexColor 是 tab 上的文字默认颜色，仅支持十六进制颜色 selectedColor HexColor 是 tab 上的文字选中时的颜色，仅支持十六进制颜色 backgroundColor HexColor 是 tab 的背景色，仅支持十六进制颜色 borderStyle string 否 black tabbar 上边框的颜色， 仅支持 black / white list Array 是 tab 的列表，详见 list 属性说明，最少 2 个、最多 5 个 tab position string 否 bottom tabBar 的位置，仅支持 bottom / top custom boolean 否 false 自定义 tabBar，见详情 2.5.0 其中 list 接受一个数组，只能配置最少 2 个、最多 5 个 tab。tab 按数组的顺序排序，每个项都是一个对象，其属性值如下： 属性 类型 必填 说明 pagePath string 是 页面路径，必须在 pages 中先定义 text string 是 tab 上按钮文字 iconPath string 否 图片路径，icon 大小限制为 40kb，建议尺寸为 81px * 81px，不支持网络图片。 当 position 为 top 时，不显示 icon。 selectedIconPath string 否 选中时的图片路径，icon 大小限制为 40kb，建议尺寸为 81px * 81px，不支持网络图片。 当 position 为 top 时，不显示 icon。 示例app.json12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849{ &quot;entryPagePath&quot;: &quot;pages/index/index&quot;, &quot;pages&quot;:[ &quot;pages/demo01/demo01&quot;, &quot;pages/classification/classification&quot;, &quot;pages/cart/cart&quot;, &quot;pages/my/my&quot;, &quot;pages/index/index&quot;, &quot;pages/logs/logs&quot; ], &quot;tabBar&quot;: { &quot;color&quot;: &quot;#bf2e2e&quot;, &quot;selectedColor&quot;: &quot;#0e0cc1&quot;, &quot;backgroundColor&quot;: &quot;#0cc112&quot;, &quot;borderStyle&quot;: &quot;white&quot;, &quot;position&quot;: &quot;bottom&quot;, &quot;list&quot;: [{ &quot;pagePath&quot;: &quot;pages/index/index&quot;, &quot;text&quot;: &quot;首页&quot;, &quot;iconPath&quot;: &quot;icon/_home.png&quot;, &quot;selectedIconPath&quot;: &quot;icon/home.png&quot; }, { &quot;pagePath&quot;: &quot;pages/classification/classification&quot;, &quot;text&quot;: &quot;分类&quot;, &quot;iconPath&quot;: &quot;icon/_classification.png&quot;, &quot;selectedIconPath&quot;: &quot;icon/classification.png&quot; }, { &quot;pagePath&quot;: &quot;pages/cart/cart&quot;, &quot;text&quot;: &quot;购物车&quot;, &quot;iconPath&quot;: &quot;icon/_cart.png&quot;, &quot;selectedIconPath&quot;: &quot;icon/cart.png&quot; }, { &quot;pagePath&quot;: &quot;pages/my/my&quot;, &quot;text&quot;: &quot;我的&quot;, &quot;iconPath&quot;: &quot;icon/_my.png&quot;, &quot;selectedIconPath&quot;: &quot;icon/my.png&quot; }] }, &quot;window&quot;:{ &quot;backgroundTextStyle&quot;:&quot;dark&quot;, &quot;navigationBarBackgroundColor&quot;: &quot;#5e6af3&quot;, &quot;navigationBarTitleText&quot;: &quot;Buubiu&quot;, &quot;navigationBarTextStyle&quot;:&quot;white&quot;, &quot;enablePullDownRefresh&quot;: true }, &quot;style&quot;: &quot;v2&quot;, &quot;sitemapLocation&quot;: &quot;sitemap.json&quot;} 页面配置每一个小程序页面也可以使用 .json 文件来对本页面的窗口表现进行配置。页面中配置项在当前页面会覆盖 app.json 的 window 中相同的配置项。文件内容为一个 JSON 对象，有以下属性： 配置项 属性 类型 默认值 描述 最低版本 navigationBarBackgroundColor HexColor #000000 导航栏背景颜色，如 #000000 navigationBarTextStyle string white 导航栏标题颜色，仅支持 black / white navigationBarTitleText string 导航栏标题文字内容 navigationStyle string default 导航栏样式，仅支持以下值： default 默认样式 custom 自定义导航栏，只保留右上角胶囊按钮。参见注 1。 iOS/Android 微信客户端 7.0.0，Windows 微信客户端不支持 backgroundColor HexColor #ffffff 窗口的背景色 backgroundTextStyle string dark 下拉 loading 的样式，仅支持 dark / light backgroundColorTop string #ffffff 顶部窗口的背景色，仅 iOS 支持 微信客户端 6.5.16 backgroundColorBottom string #ffffff 底部窗口的背景色，仅 iOS 支持 微信客户端 6.5.16 enablePullDownRefresh boolean false 是否开启当前页面下拉刷新。 详见 Page.onPullDownRefresh onReachBottomDistance number 50 页面上拉触底事件触发时距页面底部距离，单位为px。 详见 Page.onReachBottom pageOrientation string portrait 屏幕旋转设置，支持 auto / portrait / landscape 详见 响应显示区域变化 2.4.0 (auto) / 2.5.0 (landscape) disableScroll boolean false 设置为 true 则页面整体不能上下滚动。 只在页面配置中有效，无法在 app.json 中设置 usingComponents Object 否 页面自定义组件配置 1.6.3 initialRenderingCache string 页面初始渲染缓存配置，支持 static / dynamic 2.11.1 style string default 启用新版的组件样式 2.10.2 singlePage Object 否 单页模式相关配置 2.12.0 restartStrategy string homePage 重新启动策略配置 2.8.0 页面配置中只能设置 app.json 中 window 对应的配置项，以决定本页面的窗口表现，所以无需写 window 这个属性。 注 1：关于 1navigationStyle iOS/Android 客户端 7.0.0 以下版本，navigationStyle 只在 app.json 中生效。 iOS/Android 客户端 6.7.2 版本开始，navigationStyle: custom 对 web-view 组件无效 开启 custom 后，低版本客户端需要做好兼容。开发者工具基础库版本切到 1.7.0（不代表最低版本，只供调试用）可方便切到旧视觉 Windows 客户端 3.0 及以上版本，为了给用户提供更符合桌面软件的使用体验，统一了小程序窗口的导航栏，navigationStyle: custom 不再生效 singlePage 基础库 2.11.3 及以上版本支持，目前分享到朋友圈 (Beta) 后打开会进入单页模式 单页模式相关配置 属性 类型 必填 默认值 描述 navigationBarFit String 否 默认自动调整，若原页面是自定义导航栏，则为 float，否则为 squeezed 导航栏与页面的相交状态，值为 float 时表示导航栏浮在页面上，与页面相交；值为 squeezed 时表示页面被导航栏挤压，与页面不相交 restartStrategy 基础库 2.8.0 开始支持，低版本需做兼容处理。 重新启动策略配置，与 app.json 中一致。 配置示例index.json123456{ &quot;usingComponents&quot;: {}, &quot;navigationBarBackgroundColor&quot;: &quot;#d443ae&quot;, &quot;navigationBarTitleText&quot;: &quot;buubiu-首页&quot;, &quot;enablePullDownRefresh&quot;: true} sitemap配置微信现已开放小程序内搜索，开发者可以通过 sitemap.json 配置，或者管理后台页面收录开关来配置其小程序页面是否允许微信索引。当开发者允许微信索引时，微信会通过爬虫的形式，为小程序的页面内容建立索引。当用户的搜索词条触发该索引时，小程序的页面将可能展示在搜索结果中。 爬虫访问小程序内页面时，会携带特定的 user-agent：mpcrawler 及场景值：1129。需要注意的是，若小程序爬虫发现的页面数据和真实用户的呈现不一致，那么该页面将不会进入索引中。 小程序根目录下的 sitemap.json 文件用于配置小程序及其页面是否允许被微信索引，文件内容为一个 JSON 对象，如果没有 sitemap.json ，则默认为所有页面都允许被索引；sitemap.json 有以下属性： 配置项 属性 类型 必填 描述 rules Object[] 是 索引规则列表 rulesrules 配置项指定了索引规则，每项规则为一个JSON对象，属性如下所示： 属性 类型 必填 默认值 取值 取值说明 action string 否 “allow” “allow”、”disallow” 命中该规则的页面是否能被索引 page string 是 “*”、页面的路径 * 表示所有页面，不能作为通配符使用 params string[] 否 [] 当 page 字段指定的页面在被本规则匹配时可能使用的页面参数名称的列表（不含参数值） matching string 否 “inclusive” 参考 matching 取值说明 当 page 字段指定的页面在被本规则匹配时，此参数说明 params 匹配方式 priority Number 否 优先级，值越大则规则越早被匹配，否则默认从上到下匹配 matching 取值说明 值 说明 exact 当小程序页面的参数列表等于 params 时，规则命中 inclusive 当小程序页面的参数列表包含 params 时，规则命中 exclusive 当小程序页面的参数列表与 params 交集为空时，规则命中 partial 当小程序页面的参数列表与 params 交集不为空时，规则命中 配置示例示例1 1234567891011{ &quot;rules&quot;:[{ &quot;action&quot;: &quot;allow&quot;, &quot;page&quot;: &quot;path/to/page&quot;, &quot;params&quot;: [&quot;a&quot;, &quot;b&quot;], &quot;matching&quot;: &quot;exact&quot; }, { &quot;action&quot;: &quot;disallow&quot;, &quot;page&quot;: &quot;path/to/page&quot; }]} path/to/page?a=1&amp;b=2 =&gt; 优先索引 path/to/page =&gt; 不被索引 path/to/page?a=1 =&gt; 不被索引 path/to/page?a=1&amp;b=2&amp;c=3 =&gt; 不被索引 其他页面都会被索引 示例2 1234567891011{ &quot;rules&quot;:[{ &quot;action&quot;: &quot;allow&quot;, &quot;page&quot;: &quot;path/to/page&quot;, &quot;params&quot;: [&quot;a&quot;, &quot;b&quot;], &quot;matching&quot;: &quot;inclusive&quot; }, { &quot;action&quot;: &quot;disallow&quot;, &quot;page&quot;: &quot;path/to/page&quot; }]} path/to/page?a=1&amp;b=2 =&gt; 优先索引 path/to/page?a=1&amp;b=2&amp;c=3 =&gt; 优先索引 path/to/page =&gt; 不被索引 path/to/page?a=1 =&gt; 不被索引 其他页面都会被索引 示例3 1234567891011{ &quot;rules&quot;:[{ &quot;action&quot;: &quot;allow&quot;, &quot;page&quot;: &quot;path/to/page&quot;, &quot;params&quot;: [&quot;a&quot;, &quot;b&quot;], &quot;matching&quot;: &quot;exclusive&quot; }, { &quot;action&quot;: &quot;disallow&quot;, &quot;page&quot;: &quot;path/to/page&quot; }]} path/to/page =&gt; 优先索引 path/to/page?c=3 =&gt; 优先索引 path/to/page?a=1 =&gt; 不被索引 path/to/page?a=1&amp;b=2 =&gt; 不被索引 其他页面都会被索引 示例4 1234567891011{ &quot;rules&quot;:[{ &quot;action&quot;: &quot;allow&quot;, &quot;page&quot;: &quot;path/to/page&quot;, &quot;params&quot;: [&quot;a&quot;, &quot;b&quot;], &quot;matching&quot;: &quot;partial&quot; }, { &quot;action&quot;: &quot;disallow&quot;, &quot;page&quot;: &quot;path/to/page&quot; }]} path/to/page?a=1 =&gt; 优先索引 path/to/page?a=1&amp;b=2 =&gt; 优先索引 path/to/page =&gt; 不被索引 path/to/page?c=3 =&gt; 不被索引 其他页面都会被索引 注：没有 sitemap.json 则默认所有页面都能被索引 注：{&quot;action&quot;: &quot;allow&quot;, &quot;page&quot;: &quot;\\*&quot;} 是优先级最低的默认规则，未显式指明 “disallow” 的都默认被索引","link":"/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E9%85%8D%E7%BD%AE/"},{"title":"微服务介绍","text":"版本：Hoxton SR9 In short, the microservice architectural style is an approach to developing a single application as a suite of small services(一系列微小服务), each running in its own process(运行在自己的进程里) and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities(围绕自己的业务开发) and independently deployable(独立部署) by fully automated deployment machinery. There is a bare minimum of centralized management of these services(基于分布式管理), which may be written in different programming languages and use different data storage technologies. —–[摘自官网] 什么是微服务 官方定义: 微服务就是由一系列围绕自己业务开发的微小服务构成,他们独立部署运行在自己的进程里,基于分布式的管理 通俗定义: 微服务是一种架构，这种架构是将单个的整体应用程序分割成更小的项目关联的独立的服务。一个服务通常实现一组独立的特性或功能，包含自己的业务逻辑和适配器。各个微服务之间的关联通过暴露api来实现。这些独立的微服务不需要部署在同一个虚拟机，同一个系统和同一个应用服务器中。 为什么是微服务单体应用 优点 单一架构模式在项目初期很小的时候开发方便，测试方便，部署方便，运行良好。 缺点 应用随着时间的推进，加入的功能越来越多，最终会变得巨大，一个项目中很有可能数百万行的代码，互相之间繁琐的jar包。 久而久之，开发效率低，代码维护困难 还有一个如果想整体应用采用新的技术，新的框架或者语言，那是不可能的。 任意模块的漏洞或者错误都会影响这个应用，降低系统的可靠性 微服务架构应用 优点 将服务拆分成多个单一职责的小的服务，进行单独部署，服务之间通过网络进行通信 每个服务应该有自己单独的管理团队，高度自治 服务各自有自己单独的职责，服务之间松耦合，避免因一个模块的问题导致服务崩溃 缺点 开发人员要处理分布式系统的复杂性 多服务运维难度，随着服务的增加，运维的压力也在增大 服务治理 和 服务监控 关键 架构的演变架构的演变过程 [单一应用架构] ===&gt; [垂直应用架构] ===&gt; [分布式服务架构] ===&gt; [流动计算架构]||[微服务架构] ===&gt; [未知] All in One Application 单一架构起初当网站流量很小时,将所有功能都写在一个应用里面,对整个应用进行部署,以减少部署节点和成本。对于这个架构简化增删改查的工作量的数据访问框架（ORM）是关键。 Vertical Application 垂直架构当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，提升效率的方法之一是将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。 Distributed Service 分布式服务架构当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。 Elastic Computin 流动计算架构即微服务架构当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键 微服务的解决方案Dubbo(阿里系) 初出茅庐:2011年末，阿里巴巴在GitHub上开源了基于Java的分布式服务治理框架Dubbo，之后它成为了国内该类开源项目的佼佼者，许多开发者对其表示青睐。同时，先后有不少公司在实践中基于Dubbo进行分布式系统架构，目前在GitHub上，它的fork、star数均已破万。Dubbo致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案，使得应用可通过高性能RPC实现服务的输出、输入功能和Spring框架无缝集成。Dubbo包含远程通讯、集群容错和自动发现三个核心部分。 停止维护:从2012年10月23日Dubbo 2.5.3发布后，在Dubbo开源将满一周年之际，阿里基本停止了对Dubbo的主要升级。只在之后的2013年和2014年更新过2次对Dubbo 2.4的维护版本，然后停止了所有维护工作。Dubbo对Srping的支持也停留在了Spring 2.5.6版本上。 死而复生:多年漫长的等待，随着微服务的火热兴起，在国内外开发者对阿里不再升级维护Dubbo的吐槽声中，阿里终于开始重新对Dubbo的升级和维护工作。在2017年9月7日，阿里发布了Dubbo的2.5.4版本，距离上一个版本2.5.3发布已经接近快5年时间了。在随后的几个月中，阿里Dubbo开发团队以差不多每月一版本的速度开始快速升级迭代，修补了Dubbo老版本多年来存在的诸多bug，并对Spring等组件的支持进行了全面升级。 2018年1月8日，Dubbo创始人之一梁飞在Dubbo交流群里透露了Dubbo 3.0正在动工的消息。Dubbo 3.0内核与Dubbo 2.0完全不同，但兼容Dubbo 2.0。Dubbo 3.0将以Streaming为内核，不再是Dubbo 时代的RPC，但是RPC会在Dubbo 3.0中变成远程Streaming对接的一种可选形态。从Dubbo新版本的路线规划上可以看出，新版本的Dubbo在原有服务治理的功能基础上，将全面拥抱微服务解决方案。 结论:当前由于RPC协议、注册中心元数据不匹配等问题，在面临微服务基础框架选型时Dubbo与Spring Cloud是只能二选一，这也是为什么大家总是拿Dubbo和Spring Cloud做对比的原因之一。Dubbo之后会积极寻求适配到Spring Cloud生态，比如作为Spring Cloud的二进制通信方案来发挥Dubbo的性能优势，或者Dubbo通过模块化以及对http的支持适配到Spring Cloud。 Spring Cloud Spring Cloud NetFlix(美国 在线视频网站) 基于美国Netflix公司开源的组件进行封装,提供了微服务一栈式的解决方案。 G版本之前 Spring Cloud alibaba 在Spring cloud netflix基础上封装了阿里巴巴的微服务解决方案。 Spring Cloud 目前spring官方趋势正在逐渐吸收Netflix组件的精华,并在此基础进行二次封装优化,打造spring专有的解决方案","link":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D/"},{"title":"微服务统一登录认证JWT","text":"摘要：用户登录后，我们把登录者的信息保存在服务端 session 中，并且给用户一个 cookie 值，记录对应的 session。微服务集群中的每个服务，对外提供的都是 Rest 风格的接口。加密过程中不需要使用密钥，输入明文后由系统直接经过加密算法处理成密文，这种加密后的数据是无法被解密的，无法根据密文推算出明文。secret 是签名的关键，因此一定要保密，我们放到鉴权中心保存，其它任何服务中都不能获取 secret。 无状态登录原理1.1.什么是有状态？ 有状态服务，即服务端需要记录每次会话的客户端信息，从而识别客户端身份，根据用户身份进行请求的处理，典型的设计如 tomcat 中的 session。例如登录：用户登录后，我们把登录者的信息保存在服务端 session 中，并且给用户一个 cookie 值，记录对应的 session。然后下次请求，用户携带 cookie 值来，我们就能识别到对应 session，从而找到用户的信息。 缺点是什么？ 服务端保存大量数据，增加服务端压力 服务端保存用户状态，无法进行水平扩展 客户端请求依赖服务端，多次请求必须访问同一台服务器 1.2.什么是无状态微服务集群中的每个服务，对外提供的都是 Rest 风格的接口。而 Rest 风格的一个最重要的规范就是：服务的无状态性，即： 服务端不保存任何客户端请求者信息 客户端的每次请求必须具备自描述信息，通过这些信息识别客户端身份 带来的好处是什么呢？ 客户端请求不依赖服务端的信息，任何多次请求不需要必须访问到同一台服务 服务端的集群和状态对客户端透明 服务端可以任意的迁移和伸缩 减小服务端存储压力 1.3.如何实现无状态无状态登录的流程： 当客户端第一次请求服务时，服务端对用户进行信息认证（登录） 认证通过，将用户信息进行加密形成 token，返回给客户端，作为登录凭证 以后每次请求，客户端都携带认证的 token 服务端对 token 进行解密，判断是否有效。 流程图： 整个登录过程中，最关键的点是什么？ token 的安全性 token 是识别客户端身份的唯一标示，如果加密不够严密，被人伪造那就完蛋了。采用何种方式加密才是安全可靠的呢？我们将采用 JWT + RSA 非对称加密 1.4.JWT1.4.1.简介JWT，全称是 Json Web Token， 是 JSON 风格轻量级的授权和身份认证规范，可实现无状态、分布式的 Web 应用授权；官网：https://jwt.ioGitHub 上 jwt 的 java 客户端：https://github.com/jwtk/jjwt 1.4.2.数据格式JWT 包含三部分数据：Header：头部，通常头部有两部分信息： 声明类型，这里是 JWT 加密算法，自定义 我们会对头部进行 base64 加密（可解密），得到第一部分数据 Payload：载荷，就是有效数据，一般包含下面信息： 用户身份信息（注意，这里因为采用 base64 加密，可解密，因此不要存放敏感信息） 注册声明：如 token 的签发时间，过期时间，签发人等 这部分也会采用 base64 加密，得到第二部分数据 Signature：签名，是整个数据的认证信息。一般根据前两步的数据，再加上服务的密钥（secret）（不要泄漏，最好周期性更换），通过加密算法生成。用于验证整个数据完整和可靠性 生成的数据格式：可以看到分为 3 段，每段就是上面的一部分数据 1.4.3.JWT 交互流程流程图：步骤翻译： 用户登录 服务的认证，通过后根据 secret 生成 token 将生成的 token 返回给浏览器 用户每次请求携带 token 服务端利用公钥解读 jwt 签名，判断签名有效后，从 Payload 中获取用户信息 处理请求，返回响应结果 因为 JWT 签发的 token 中已经包含了用户的身份信息，并且每次请求都会携带，这样服务的就无需保存用户信息，甚至无需去数据库查询，完全符合了 Rest 的无状态规范。扩展：彻底理解 cookie，session，token 1.4.4.非对称加密加密技术是对信息进行编码和解码的技术，编码是把原来可读信息（又称明文）译成代码形式（又称密文），其逆过程就是解码（解密），加密技术的要点是加密算法，加密算法可以分为三类：对称加密，如 AES 基本原理： 将明文分成 N 个组，然后使用密钥对各个组进行加密，形成各自的密文，最后把所有的分组密文进行合并，形成最终的密文。 优势： 算法公开、计算量小、加密速度快、加密效率高 缺陷： 双方都使用同样密钥，安全性得不到保证 非对称加密，如 RSA 基本原理： 同时生成两把密钥：私钥和公钥，私钥隐秘保存，公钥可以下发给信任客户端 私钥加密， 持有私钥或公钥才可以解密 公钥加密， 持有私钥才可解密 优点： 安全，难以破解 缺点： 算法比较耗时 不可逆加密，如 MD5，SHA 基本原理： 加密过程中不需要使用密钥，输入明文后由系统直接经过加密算法处理成密文，这种加密后的数据是无法被解密的，无法根据密文推算出明文。 RSA 算法历史：1977 年，三位数学家 Rivest、Shamir 和 Adleman 设计了一种算法，可以实现非对称加密。这种算法用他们三个人的名字缩写：RSA 结合 Zuul 的鉴权流程 我们逐步演进系统架构设计。需要注意的是：secret 是签名的关键，因此一定要保密，我们放到鉴权中心保存，其它任何服务中都不能获取 secret。 1.5.1.没有 RSA 加密时在微服务架构中，我们可以把服务的鉴权操作放到网关中，将未通过鉴权的请求直接拦截，如图： 用户请求登录 Zuul 将请求转发到授权中心，请求授权 授权中心校验完成，颁发 JWT 凭证 客户端请求其它功能，携带 JWT Zuul 将 jwt 交给授权中心校验，通过后放行 用户请求到达微服务 微服务将 jwt 交给鉴权中心，鉴权同时解析用户信息 鉴权中心返回用户数据给微服务 微服务处理请求，返回响应 发现什么问题了？ 每次鉴权都需要访问鉴权中心，系统间的网络请求频率过高，效率略差，鉴权中心的压力较大。 结合 RSA 的鉴权 直接看图： 我们首先利用 RSA 生成公钥和私钥。私钥保存在授权中心，公钥保存在 Zuul 和各个微服务 用户请求登录 授权中心校验，通过后用私钥对 JWT 进行签名加密 返回 jwt 给用户 用户携带 JWT 访问 Zuul 直接通过公钥解密 JWT，进行验证，验证通过则放行 请求到达微服务，微服务直接用公钥解析 JWT，获取用户信息，无需访问授权中心 来源：微服务统一登录认证怎么做？JWT？","link":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BB%9F%E4%B8%80%E7%99%BB%E5%BD%95%E8%AE%A4%E8%AF%81JWT/"},{"title":"微服务自动部署命令说明","text":"基础命令12345678910111213141516171819202122# 显示当前目录$ basepath=$(cd `dirname $0`; pwd)$ echo $basepath# 获取本地IP$ LAN_IP=$(ip addr| grep inet|grep -v 127.0.0.1|grep -v inet6|awk '{print $2}'|cut -d &quot;/&quot; -f 1 | awk '{print $1}' | head -1)$ echo $LAN_IP# 禁用防火墙$ systemctl stop firewalld &amp;&amp; systemctl disable firewalld# 禁用selinux$ getenforce | grep -iq 'Enforcing' &amp;&amp; setenforce 0$ sed -i 's|SELINUX=\\(.*\\)|SELINUX=disabled|g' /etc/selinux/config# $? 用法：获取上一次命令的返回值。0表示执行成功，非零值表示出错$ result=$(rpm -qa|egrep &quot;httpd|ansible|createrepo&quot;)$ echo $?1# pushd 用法：另附文章说明# createrepo 用法：另附文章说明","link":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E5%91%BD%E4%BB%A4%E8%AF%B4%E6%98%8E/"},{"title":"扩展linux系统根目录大小","text":"情况说明：添加新的硬盘，然后扩容根目录大小 查看新增的磁盘分区，新增磁盘分区/dev/sdb ，大小 100GB 1[root@localhost ~]# fdisk -l 划分新的磁盘分区 注：对新增的磁盘分区进行分区，详见截图 1[root@localhost ~]# fdisk /dev/sdb 再次查看分区信息， 看到划分好的分区/dev/sdb1 创建 pv 卷 注：创建一个新的 pv 卷 1[root@localhost ~]# pvcreate /dev/sdb1 1[root@localhost ~]# pvdisplay 注：查看确认已经创建的 pv 卷 将 pv 添加进 vg 1[root@localhost ~]# vgdisplay 查看现有的 vg 卷，现有的 vg 名称为：centos将新建的 pv 添加进现有的 vg 内 1[root@localhost ~]# vgextend centos /dev/sdb1 注：centos 为 vg 的名称，这时的/dev/sdb1 为 pv 扩容 lv /dev/centos/root 是执行 lvdisplay 获得的 1[root@localhost ~]# lvextend -l +100%FREE /dev/centos/root 注：这里是添加 lv 所在的 vg 剩下的空余空间 1[root@localhost ~]# lvdisplay 注：查看 lv 卷现在的大小，原大小为 43G，已经增加了 100G 的空间 同步文件系统 1[root@localhost ~]# df -h 发现文件系统的大小没有改变，需要同步文件系统 1[root@localhost ~]# xfs_growfs /dev/centos/root 注：使用以上命令同步文件系统，centos7 的默认文件系统 XFS 如系统版本为 centos 6 请使用命令 resize2fs /dev/centos/root 再次查看文件系统的大小，确认已增加了 100G,扩容完成","link":"/%E6%89%A9%E5%B1%95linux%E7%B3%BB%E7%BB%9F%E6%A0%B9%E7%9B%AE%E5%BD%95%E5%A4%A7%E5%B0%8F/"},{"title":"数据结构-图说B+树","text":"了解了 B 树后再来了解下它的变形版：B+ 树，它比 B 树的查询性能更高。 一棵 B+ 树需要满足以下条件： 节点的子树数和关键字数相同（B 树是关键字数比子树数少一） 节点的关键字表示的是子树中的最大数，在子树中同样含有这个数据 叶子节点包含了全部数据，同时符合左小右大的顺序 一个m阶的B树具有如下几个特征： 根结点至少有两个子女。 每个中间节点都包含k-1个元素和k个孩子，其中 m/2 &lt;= k &lt;= m 每一个叶子节点都包含k-1个元素，其中 m/2 &lt;= k &lt;= m 所有的叶子结点都位于同一层。 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。 一个m阶的B+树具有如下几个特征： 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。 B+树的特征： 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。 B+树的优势： 单一节点存储更多的元素，使得查询的IO次数更少。 所有查询都要查找到叶子节点，查询性能稳定。 所有叶子节点形成有序链表，便于范围查询。 转自：漫画-什么是B+树","link":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%9B%BE%E8%AF%B4B+%E6%A0%91/"},{"title":"数据结构-图说B树","text":"本文提到的「B-树」，就是「B树」，都是 B-tree 的翻译，里面不是减号-，是连接符-。因为有人把 B-tree 翻成 「B-树」，让人以为「B树」和「B-树」是两种树，实际上两者就是同一种树。 下面来具体介绍一下B-树（Balance Tree），一个m阶的B树具有如下几个特征： 根结点至少有两个子女。 每个中间节点都包含k-1个元素和k个孩子，其中 m/2 &lt;= k &lt;= m 每一个叶子节点都包含k-1个元素，其中 m/2 &lt;= k &lt;= m 所有的叶子结点都位于同一层。 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。 转自：漫画：什么是B-树","link":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%9B%BE%E8%AF%B4B%E6%A0%91/"},{"title":"数据结构","text":"定义： 数据结构是指相互之间存在一种或多种特定关系的数据元素的集合 集合 数据结构中的元素之间除了“同属一个集合” 的相互关系外，别无其他关系； 线性结构 数据结构中的元素存在一对一的相互关系 树形结构 数据结构中的元素存在一对多的相互关系； 图形结构 数据结构中的元素存在多对多的相互关系。 常见的数据结构：数组、队列、栈、链表、树、图、堆、散列表 数组就是在内存中开辟一个连续的空间存放元素，就相当一群人站成一队，从第一个开始编号001,002….可以轻松的通过号码来找到对应的人，但是如果中间有一个人离队了（中间加了一个人），后面的人号码都要向前（向后）移动，如果队伍很长改的变得就越多，所以数组的特点就是：元素类型是固定的、长度是固定的、通过角标查询，查询快，增删慢。 队列线性结构，先进先出，就跟一群人排队过水管，先进水管的人的人先出去，后进水管的人后出去 栈线性结构，先进后出，就跟手枪上子弹一样，先上的子弹会被后上的子弹压到下面，打枪的时候最后上的子弹会第一个打出来，这个就是大家常说的压栈，底层实现同样用的是LinkedList 链表链表的类型有多种：单链表，双链表，有序链表 链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。链表由一系列结点（链表中每一个元素称为结点）组成，结点可以在运行时动态生成。 可以这样理解： 有一条街，小明住在街中一角，他有小红的地址，然后小红也是住在这条街，她有小花的地址，同样小花也有别人的地址。某天我想找小红玩，但是我不知道她住哪里，我可以问小明，就知道小红住在哪里了。那么小明小红小花这些人之间的关系就组成一个链表。 单链表： 就是小明只是右手握着小红的地址，他只有小红一个人的地址 双链表： 就是小明左手握着小白的地址，右手握着小红的地址，他有两个人的地址 循环链表： 就是小明握有小红的地址，小红握有小花的地址，而小花又握有小明的地址，这样就形成了一个循环 有序链表： 以某个标准，给链表的元素排序，比如比较内容大小、比较哈希值等 链表与数组比较： 优点：链表不需要确定长度大小，也不需要连续的内存空间， 缺点：由于不是连续的空间，所以查找元素比较吃力；相比数组只存储元素，链表的元素还要存储其它元素的地址，内存开销相对增大。 树什么是树 树结构是一种包括节点(nodes)和边(edges)的拥有层级关系的一种结构 树中的概念 根节点(root): 树的最上层的节点，任何非空的树都有一个节点 路径(path): 从起始节点到终止节点经历过的边 父亲(parent)：除了根节点，每个节点的上一层边连接的节点就是它的父亲(节点) 孩子(children): 每个节点由边指向的下一层节点 兄弟(siblings): 同一个父亲并且处在同一层的节点 叶子节点(leaf node)或终端节点: 没有孩子的节点成为叶子节点 二叉树每个父节点最多只有两个子节点的树称为二叉树 与二叉树相关的概念:节点深度(depth), 树的高度(height), 树的宽度(width), 树的 size 满二叉树除最后一层无任何子节点外，每一层上的所有结点都有两个子结点。也可以这样理解，除叶子结点外的所有结点均有两个子结点。节点数达到最大值，所有叶子结点必须在同一层上。 一棵深度为k且有2k-1（2的k次幂减1）个结点的二叉树称为满二叉树 完全二叉树若设二叉树的深度为h，除第 h 层外，其它各层 (1～(h-1)层) 的结点数都达到最大个数，第h层所有的结点都连续集中在最左边，这就是完全二叉树。 深度为k的，有n个结点的二叉树，当且仅当其每一个结点都与深度为k的满二叉树中编号从1至n的结点一一对应时，称之为完全二叉树。 二叉排序树（BST）二叉排序树（Binary Sort Tree）定义：又称为是二叉查找树或二叉搜索树。二叉排序树或者是一棵空树，或者是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉排序树； 没有键值相等的节点。 平衡二叉树平衡二叉树（Balanced Binary Tree）又被称为AVL树。它或者是一棵空树，或者是具有下列性质的二叉树： 它的左子树和右子树都是平衡二叉树，且左子树和右子树的深度之差的绝对值不超过1。（注：平衡二叉树应该是一棵二叉排序树） 红黑树红黑树，一种二叉查找树，但在每个结点上增加一个存储位表示结点的颜色，可以是Red或Black。通过对任何一条从根到叶子的简单路径上各个结点的颜色进行约束，红黑树确保没有一条路径会比其他路径长出2倍，因而是近似于平衡的。树中每个结点包含5个属性：color、key、left、right和p。如果一个结点没有子节点或父节点，则该结点相应的指针属性值为NIL，我们可以把这些NIL视为指向二叉搜索树的叶节点（外部结点）的指针，而把带关键字的结点视为树的内部结点。一棵红黑树是满足下面性质的二叉搜索树： 每个结点或是红色的，或是黑色的； 根结点是黑色的； 每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的； 如果一个结点是红色的，则它的两个子结点都是黑色的； 对每个结点，从该结点到其所有后代叶结点的简单路径上，均包含相同数目的黑色结点。 红黑树虽然本质上是一棵二叉查找树，但它在二叉查找树的基础上增加了着色和相关的性质使得红黑树相对平衡，从而保证了红黑树的查找、插入、删除的时间复杂度最坏为O(log n)。 B树B树也是一种用于查找的平衡树，但是它不是二叉树。 B树又称为B-树，是一种平衡的多路查找树。B-树的阶是所有结点的孩子结点树的最大值。一棵m阶B-树，或为空树，或为满足下列特性的m叉树： 一个m阶的B树具有如下几个特征： 根结点至少有两个子女 子树(节点)的个数(k)：m/2 &lt;= k &lt;= m 每个中间节点都包含k-1个元素(关键字或数据)和k个孩子，其中 m/2 &lt;= k &lt;= m，所以 子树个数(k)=元素个数+1 每一个叶子节点都包含k-1个元素，其中 m/2 &lt;= k &lt;= m 所有的叶子结点都位于同一层。 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。 添加元素的逻辑： 首先考虑要插入的子树是否已经超出了关键字数的限制 超出的话，如果要插入的位置是叶子节点，就只能拆一个关键字添加到要插入位置的父节点 如果非叶子节点，就得从其他子树拆子树给新插入的元素做孩子 删除也是一样的，要考虑删除孩子后，父节点是否还满足子树 k 介于 M/2 和 M 的条件，不满足就得从别的节点拆子树甚至修改相关子树结构来保持平衡。 具体讲解见：图说B树 B+树了解了 B 树后再来了解下它的变形版：B+ 树，它比 B 树的查询性能更高。 一棵 B+ 树需要满足以下条件： 节点的子树数和关键字数相同（B 树是关键字数比子树数少一） 节点的关键字表示的是子树中的最大数，在子树中同样含有这个数据 叶子节点包含了全部数据，同时符合左小右大的顺序 一个m阶的B+树具有如下几个特征： 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。 具体讲解见：图说B+树 B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针； B*树定义了非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为2/3(代替B+树的1/2)。 B树，B+树，B*树比较： 子树数范围(k) 关键字数范围(d) 子树数与关键字数关系 6阶B树 [3,4,5,6] [2,3,4,5] 关键字数=子树数-1 6阶B+树 [3,4,5,6] [3,4,5,6] 关键字数=子树数 6阶B*树 [2,3,4,5,6] [2,3,4,5,6] 关键字数=子树数 m阶B树 m/2 &lt;= k &lt;= m (m/2)-1 &lt;= d &lt;= (m-1) d = k-1 m阶B+树 m/2 &lt;= k &lt;= m m/2 &lt;= d &lt;= m d=k m阶B*树 m*2/3 &lt;= k &lt;= m m*2/3 &lt;= k &lt;= m d=k LSM 树引言与普通B树相比，B+树的非叶子节点只有索引，所有数据都位于叶子节点，并且叶子节点上的数据会形成有序链表。B+树的主要优点如下： 结构比较扁平，高度低（一般不超过4层），随机寻道次数少； 数据存储密度大，且都位于叶子节点，查询稳定，遍历方便； 叶子节点形成有序链表，范围查询转化为顺序读，效率高。相对而言B树必须通过中序遍历才能支持范围查询。 当然，B+树也不是十全十美的，它的主要缺点有两个： 如果写入的数据比较离散，那么寻找写入位置时，子节点有很大可能性不会在内存中，最终会产生大量的随机写，性能下降。下图来自[TokuDB的PPT]，说明了这一点。 如果B+树已经运行了很长时间，写入了很多数据，随着叶子节点分裂，其对应的块会不再顺序存储，而变得分散。这时执行范围查询也会变成随机读，效率降低了。 可见，B+树在多读少写（相对而言）的情境下比较有优势，在多写少读的情境下就不是很有威力了。当然，我们可以用SSD来获得成倍提升的读写速率，但成本同样高昂，对海量存储集群而言不太可行。日志结构合并树（LSM Tree）就是作为B+树的替代方案产生的。 认识LSM树LSM树由Patrick O’Neil等人在论文[《The Log-Structured Merge Tree》]中提出，它实际上不是一棵树，而是2个或者多个树或类似树的结构（注意这点）的集合。下图示出最简单的有2个结构的LSM树。 在LSM树中，最低一级也是最小的C0树位于内存里，而更高级的C1、C2…树都位于磁盘里。数据会先写入内存中的C0树，当它的大小达到一定阈值之后，C0树中的全部或部分数据就会刷入磁盘中的C1树，如下图所示。 由于内存的读写速率都比外存要快非常多，因此数据写入C0树的效率很高。并且数据从内存刷入磁盘时是预排序的，也就是说，LSM树将原本的随机写操作转化成了顺序写操作，写性能大幅提升。不过，它的tradeoff就是牺牲了一部分读性能，因为读取时需要将内存中的数据和磁盘中的数据合并。总体上来讲这种tradeoff还是值得的，因为： 可以先读取内存中C0树的缓存数据。内存的效率很高，并且根据局部性原理，最近写入的数据命中率也高。 写入数据未刷到磁盘时不会占用磁盘的I/O，不会与读取竞争。读取操作就能取得更长的磁盘时间，变相地弥补了读性能差距。 在实际应用中，为了防止内存因断电等原因丢失数据，写入内存的数据同时会顺序在磁盘上写日志，类似于我们常见的预写日志（WAL），这就是LSM这个词中Log一词的来历。另外，如果有多级树的话，低级的树在达到大小阈值后也会在磁盘中进行合并，如下图所示。","link":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"服务注册中心介绍","text":"服务注册中心什么是服务注册中心所谓服务注册中心就是在整个的微服务架构中单独提出一个服务，这个服务不完成系统的任何的业务功能，仅仅用来完成对整个微服务系统的服务注册和服务发现，以及对服务健康状态的监控和管理功能。 可以对所有的微服务的信息进行存储，如微服务的名称、IP、端口等 可以在进行服务调用时通过服务发现查询可用的微服务列表及网络地址进行服务调用 可以对所有的微服务进行心跳检测，如发现某实例长时间无法访问，就会从服务注册表移除该实例。 常用的注册中心springcloud支持的多种注册中心Eureka(netflix)、Consul、Zookeeper、以及阿里巴巴推出Nacos组件。这些注册中心在本质上都是用来管理服务的注册和发现以及服务状态的检查的。 EurekaEureka基本使用 ConsulConsul基本使用 不同注册中心区别CAP定理CAP定理：CAP定理又称CAP原则，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本） 可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性） 分区容忍性（P）：就是高可用性，一个节点崩了，并不影响其它的节点（100个节点，挂了几个，不影响服务，越多机器越好） Eureka特点（AP）Eureka中没有使用任何的数据强一致性算法保证不同集群间的Server的数据一致，仅通过数据拷贝的方式争取注册中心数据的最终一致性，虽然放弃数据强一致性但是换来了Server的可用性，降低了注册的代价，提高了集群运行的健壮性。 Consul特点（CP）基于Raft算法，Consul提供强一致性的注册中心服务，但是由于Leader节点承担了所有的处理工作，势必加大了注册和发现的代价，降低了服务的可用性。通过Gossip协议，Consul可以很好地监控Consul集群的运行，同时可以方便通知各类事件，如Leader选择发生、Server地址变更等。 zookeeper特点（CP）基于Zab协议，Zookeeper可以用于构建具备数据强一致性的服务注册与发现中心，而与此相对地牺牲了服务的可用性和提高了注册需要的时间。 Eureka、Consul与Zookeeper比较 组件名 语言 CAP 一致性算法 服务健康检查 对外暴漏接口 Spring Cloud集成 Eureka Java AP 无 可配支持 HTTP 已集成 Consul Go CP Raft 支持 HTTP/DNS 已集成 Zookeeper Java CP Paxos 支持 客户端 已集成","link":"/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E4%BB%8B%E7%BB%8D/"},{"title":"数据结构与算法概述","text":"数据结构定义： 数据结构是指相互之间存在一种或多种特定关系的数据元素的集合 集合 数据结构中的元素之间除了“同属一个集合” 的相互关系外，别无其他关系； 线性结构 数据结构中的元素存在一对一的相互关系 树形结构 数据结构中的元素存在一对多的相互关系； 图形结构 数据结构中的元素存在多对多的相互关系。 常见的数据结构：数组、队列、栈、链表、树、图、堆、散列表 算法算法包括： 排序算法： 冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序、计数排序、桶排序、基数排序 搜索算法：回溯、递归、剪枝 图论：最短路径、最小生成树、网络流建模 动态规划：背包问题、最长子序列、计数问题 基础技巧：分治、倍增、二分法、贪心算法 宽度优先搜索 深度优先搜索 广度优先 双指针 扫描线 朴素贝叶斯 推荐算法 数据结构和算法的关系 数据data结构(structure)是一门研究组织数据方式的学科，有了编程语言也就有了数据结构.学好数据结构可以编写出更加漂亮,更加有效率的代码。 要学习好数据结构就要多多考虑如何将生活中遇到的问题,用程序去实现解决. 程序=数据结构+算法 数据结构是算法的基础, 换言之，想要学好算法，需要把数据结构学到位。","link":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/"},{"title":"服务网关组件的使用","text":"什么是服务网关说明网关统一服务入口，可方便实现对平台众多服务接口进行管控，对访问服务的身份认证、防报文重放与防数据篡改、功能调用的业务鉴权、响应数据的脱敏、流量与并发控制，甚至基于API调用的计量或者计费等等。 网关 = 路由转发 + 过滤器 路由转发：接收一切外界请求，转发到后端的微服务上去； 过滤器:在服务网关中可以完成一系列的横切功能，例如权限校验、限流以及监控等，这些都可以通过过滤器完成。 为什么需要网关 网关可以实现服务的统一管理 网关可以解决微服务中通用代码的冗余问题（如权限控制，流量监控，限流等） 网关组件在微服务中的架构图 服务网关组件zuul组件的使用zuul组件的使用 Gateway组件的使用Gateway组件的使用","link":"/%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3%E7%BB%84%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"服务间通信方式及Ribbon使用","text":"在整个微服务架构中,我们比较关心的就是服务间的服务改如何调用,有哪些调用方式? 在springcloud中服务间调用方式主要是使用 http restful方式进行服务间调用 基于RestTemplate的服务调用说明 spring框架提供的RestTemplate类可用于在应用中调用rest服务，它简化了与http服务的通信方式，统一了RESTful的标准，封装了http链接， 我们只需要传入url及返回值类型即可。相较于之前常用的HttpClient，RestTemplate是一种更优雅的调用RESTful服务的方式。 创建两个服务并注册到consul注册中心中 users 代表用户服务 端口为 9999 products 代表商品服务 端口为 9998 注意:这里服务仅仅用来测试,没有实际业务意义 在商品服务中提供服务方法1234567891011121314151617/** * @author buubiu **/@RestController@Slf4jpublic class ProductController { @Value(&quot;${server.port}&quot;) private int port; @GetMapping(&quot;/product/findAll&quot;) public Map&lt;String,Object&gt; findAll(){ log.info(&quot;商品服务查询所有调用成功,当前服务端口:[{}]&quot;,port); Map&lt;String, Object&gt; map = new HashMap&lt;String,Object&gt;(); map.put(&quot;msg&quot;,&quot;服务调用成功,服务提供端口为: &quot;+port); map.put(&quot;status&quot;,true); return map; }} 在用户服务中使用restTemplate进行调用12345678910111213141516/** * @author buubiu **/@RestController@Slf4jpublic class UserController { @GetMapping(&quot;/user/findAll&quot;) public String findAll(){ log.info(&quot;调用用户服务...&quot;); //1.使用restTemplate调用商品服务 RestTemplate restTemplate = new RestTemplate(); String forObject = restTemplate.getForObject(&quot;http://localhost:9998/product/findAll&quot;, String.class); return forObject; }} 启动服务 测试服务调用浏览器访问用户服务 http://localhost:9999/user/findAll 总结 rest Template是直接基于服务地址调用没有在服务注册中心获取服务,也没有办法完成服务的负载均衡如果需要实现服务的负载均衡需要自己书写服务负载均衡策略。 restTemplate直接调用存在问题 1.直接使用restTemplate方式调用没有经过服务注册中心获取服务地址,代码写死不利于维护,当服务宕机时不能高效剔除 2.调用服务时没有负载均衡需要自己实现负载均衡策略 基于Ribbon的服务调用说明 官方网址: https://github.com/Netflix/ribbon Spring Cloud Ribbon是一个基于HTTP和TCP的客户端负载均衡工具，它基于Netflix Ribbon实现。通过Spring Cloud的封装，可以让我们轻松地将面向服务的REST模版请求自动转换成客户端负载均衡的服务调用。 项目中引入依赖说明 如果使用的是eureka client 和 consul client,无须引入依赖,因为在eureka,consul中默认集成了ribbon组件 如果使用的client中没有ribbon依赖需要显式引入如下依赖 12345&lt;!--引入ribbon依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 查看consul client 中依赖的ribbon 使用普通负载均衡进行服务调用1234567891011121314151617181920212223242526/** * @author buubiu **/@RestController@Slf4jpublic class UserController { @GetMapping(&quot;/user/findAllProduct&quot;) public String findAllProduct() { log.info(&quot;进入用户服务....&quot;); //1.使用resttemplate方式直接调用 RestTemplate restTemplate = new RestTemplate(); String forObject = restTemplate.getForObject(&quot;http://&quot;+randomHost()+&quot;/product/findAll&quot;, String.class); log.info(&quot;商品服务调用返回结果：[{}]&quot;,forObject); return forObject; } public static String randomHost() { List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;localhost:9998&quot;); list.add(&quot;localhost:9997&quot;); int i = new Random().nextInt(2); return list.get(i); }} 使用RestTemplate + Ribbon进行服务调用使用discovery client 进行客户端调用123456789101112131415161718192021222324/** * @author buubiu **/@RestController@Slf4jpublic class UserController { @Autowired private DiscoveryClient discoveryClient; @GetMapping(&quot;/user/findAllProduct&quot;) public List&lt;ServiceInstance&gt; findAllProduct() { log.info(&quot;进入用户服务....&quot;); //2.ribbon调用方式-discovery client List&lt;ServiceInstance&gt; serviceInstances = discoveryClient.getInstances(&quot;products&quot;); for (ServiceInstance serviceInstance : serviceInstances) { System.out.println(serviceInstance.getHost()); System.out.println(serviceInstance.getPort()); } return serviceInstances; }} 使用loadBalancerClient 进行客户端调用12345678910111213141516171819202122232425/** * @author buubiu **/@RestController@Slf4jpublic class UserController { @Autowired private LoadBalancerClient loadBalancerClient; @GetMapping(&quot;/user/findAllProduct&quot;) public String findAllProduct() { log.info(&quot;进入用户服务....&quot;); //3.ribbon调用方式-loadBalancerClient(默认负载均衡是：轮训) ServiceInstance serviceInstance = loadBalancerClient.choose(&quot;products&quot;); System.out.println(serviceInstance.getHost()); System.out.println(serviceInstance.getPort()); String url = &quot;http://&quot;+serviceInstance.getHost()+&quot;:&quot;+serviceInstance.getPort()+&quot;/product/findAll&quot;; RestTemplate restTemplate = new RestTemplate(); String forObject = restTemplate.getForObject(url, String.class); return forObject; }} 使用@loadBalance 进行客户端调用 首先要创建具有负载均衡作用的restTemplate 12345678910111213/** * @author buubiu **/@Configurationpublic class RestTemplateConfig { //在工厂中创建一个restTemplate对象 @Bean @LoadBalanced //代表ribbon负载均衡的restTemplate客户端对象 public RestTemplate getRestTemplate() { return new RestTemplate(); }} 然后在业务层进行服务调用 1234567891011121314151617181920/** * @author buubiu **/@RestController@Slf4jpublic class UserController { @Autowired //具有负载均衡作用的restTemplate private RestTemplate restTemplate; @GetMapping(&quot;/user/findAllProduct&quot;) public String findAllProduct() { log.info(&quot;进入用户服务....&quot;); //4.ribbon调用方式-@loadBalance String forObject = restTemplate.getForObject(&quot;http://products/product/findAll&quot;, String.class); return forObject; }} 注意：products为注册到consul中的应用名称，即服务提供者的spring.application.name Ribbon负载均衡策略ribbon常用负载均衡算法 RoundRobinRule 轮训策略，按顺序循环选择server RandomRule 随机策略，随机选择server AvailabilityFilteringRule 可用过滤策略 会先过滤由于多次访问故障而处于断路器跳闸状态的服务，还有并发的连接数量超过阈值的服务，然后对剩余的服务列表按照轮询策略进行访问 WeightedResponseTimeRule 响应时间加权策略 根据平均响应的时间计算所有服务的权重，响应时间越快服务权重越大被选中的概率越高，刚启动时如果统计信息不足，则使用RoundRobinRule策略，等统计信息足够会切换到 RetryRule 重试策略 先按照RoundRobinRule的策略获取服务，如果获取失败则在制定时间内进行重试，获取可用的服务 BestAvailableRule 最低并发策略 会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务 修改服务的默认负载均衡策略修改服务（消费者）的配置文件 例如：修改成随机策略 12345678server.port=9999spring.application.name=users#注册consul服务的主机spring.cloud.consul.host=localhost#注册consul服务的端口spring.cloud.consul.port=8500#修改服务负载均衡策略products.ribbon.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.RandomRule 注意：上面的products为服务提供者的唯一标识 Ribbon停止维护官方停止维护说明：https://github.com/Netflix/ribbon","link":"/%E6%9C%8D%E5%8A%A1%E9%97%B4%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F%E5%8F%8ARibbon%E4%BD%BF%E7%94%A8/"},{"title":"稀疏数组和队列","text":"稀疏 sparsearray 数组先看一个实际的需求编写的五子棋程序中，有存盘退出和续上盘的功能。 稀疏数组举例说明因为该二维数组的很多值是默认值 0, 因此记录了很多没有意义的数据.-&gt;稀疏数组。 基本介绍当一个数组中大部分元素为0，或者为同一个值的数组时，可以使用稀疏数组来保存该数组。 稀疏数组的处理方法是: 记录数组一共有几行几列，有多少个不同的值 把具有不同值的元素的行列及值记录在一个小规模的数组中，从而缩小程序的规模 稀疏数组举例说明 应用实例 使用稀疏数组，来保留类似前面的二维数组(棋盘、地图等等) 把稀疏数组存盘，并且可以从新恢复原来的二维数组数 整体思路分析 二维数组转悉数数组的思路 遍历 原始的二维数组，得到有效数据的个数 sum 根据 sum 就可以创建 稀疏数组 sparseArr=int[sum +1][3] 将二维数组的有效数据存入到 稀疏数组 稀疏数组转原始的二维数组的思路 先读取 稀疏数组 的第一行，根据第一行的数据，创建 原始的二维数组，比如上面的 chessArr2=int[11][11] 在读取 稀疏数组 后几行的数据，并赋给 原始的二维数组 即可。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123package com.buubiu.sparsearray;/** * @comment: 稀疏数组 * @author: buubiu * @create: 2021/7/14 16:02 */public class SparseArray { public static void main(String[] args) { //创建一个 原始的二维数组 11*11 //0：表示没有棋子，1：表示 黑子，2：表示 蓝子 int[][] chessArr1 = new int[11][11]; chessArr1[1][2] = 1; chessArr1[2][3] = 2; //输出 原始的二维数组 System.out.println(&quot;原始的二维数组~~&quot;); for (int[] row : chessArr1) { for (int data : row) { System.out.printf(&quot;%d\\t&quot;, data); } System.out.println(); } //将二维数组 转稀疏数组 //1.先遍历二维数组 得到非0数据的个数 int sum = 0; for (int i = 0; i &lt; 11; i++) { for (int j = 0; j &lt; 11; j++) { if (chessArr1[i][j] != 0) { sum++; } } } //2. 创建对应的稀疏数组 int[][] sparseArr = new int[sum + 1][3]; //给稀疏数组赋值 sparseArr[0][0] = 11; sparseArr[0][1] = 11; sparseArr[0][2] = sum; //遍历二维数组，将非0的值存放到 sparseArr 中 int count = 0;//count 用与记录是第几个非0数据 for (int i = 0; i &lt; 11; i++) { for (int j = 0; j &lt; 11; j++) { if (chessArr1[i][j] != 0) { count++; sparseArr[count][0] = i; sparseArr[count][1] = j; sparseArr[count][2] = chessArr1[i][j]; } } } //输出稀疏数组的形式 System.out.println(); System.out.println(&quot;得到的稀疏数组为～～&quot;); for (int i = 0; i &lt; sparseArr.length; i++) { System.out.printf(&quot;%d\\t%d\\t%d\\t\\n&quot;, sparseArr[i][0], sparseArr[i][1], sparseArr[i][2]); } System.out.println(); //将稀疏数组 恢复成 原始的二维数组 /** * 1. 先读取 稀疏数组 的第一行，根据第一行的数据，创建 原始的二维数组 * 2. 在读取 稀疏数组 后几行的数据，并赋给 原始的二维数组 即可。 */ //1. 先读取 稀疏数组 的第一行，根据第一行的数据，创建 原始的二维数组 int[][] chessArr2 = new int[sparseArr[0][0]][sparseArr[0][1]]; //2. 在读取 稀疏数组 后几行的数据（从第二行开始），并赋给 原始的二维数组 即可。 for (int i = 1; i &lt; sparseArr.length; i++) { chessArr2[sparseArr[i][0]][sparseArr[i][1]] = sparseArr[i][2]; } //输出恢复后的二维数组 System.out.println(&quot;恢复后的二维数组&quot;); for (int[] row : chessArr2) { for (int data : row) { System.out.printf(&quot;%d\\t&quot;, data); } System.out.println(); } }}//运行结果：=====================================原始的二维数组~~0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 得到的稀疏数组为～～11 11 2 1 2 1 2 3 2 恢复后的二维数组0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 =====================================","link":"/%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84%E5%92%8C%E9%98%9F%E5%88%97/"},{"title":"算法-冒泡排序（Bubble Sort）","text":"定义冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 算法描述 比较相邻的元素。如果第一个比第二个大，就交换它们两个； 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数； 针对所有的元素重复以上的步骤，除了最后一个； 重复步骤1~3，直到排序完成。 动图演示 代码实现1234567public static void main(String[] args) { int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48}; // 只需要修改成对应的方法名就可以了 bubbleSort(array); System.out.println(Arrays.toString(array));} 123456789101112131415161718192021222324252627/** * Description:冒泡排序 * * @param array 需要排序的数组 */public static void bubbleSort(int[] array) { if (array == null || array.length &lt;= 1) { return; } int length = array.length; // 外层循环控制比较轮数i for (int i = 0; i &lt; length; i++) { // 内层循环控制每一轮比较次数，每进行一轮排序都会找出一个较大值 // (array.length - 1)防止索引越界，(array.length - 1 - i)减少比较次数 for (int j = 0; j &lt; length - 1 - i; j++) { // 前面的数大于后面的数就进行交换 if (array[j] &gt; array[j + 1]) { int temp = array[j + 1]; array[j + 1] = array[j]; array[j] = temp; } } }} 算法分析最佳情况：$T(n) = O(n)$ 最差情况：$T(n)=O(n^2)$ 平均情况：$T(n)=O(n^2)$ **n:**代表关键字的个数 **O:**算法复杂度 : 这里表中指的是算法的时间复杂度, 一般由O(1), O(n), O(logn), O(nlogn), O(n²), …, O(n!). 从左到右复杂度依次增大, 时间复杂度是指在多少时间内能够执行完这个算法, 常数时间内呢, 还是平方时间还是指数时间等等. 还有个概念叫空间复杂度, 这就指的是执行这个算法需要多少额外的空间. (源数组/链表所占的空间不算) 稳定性 : 算法的稳定性体现在执行算法之前, 若a = b, a在b的前面, 若算法执行完之后a依然在b的前面, 则这个算法是稳定的, 否则这个算法不稳定.","link":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%EF%BC%88Bubble-Sort%EF%BC%89/"},{"title":"算法-基数排序（Radix Sort）","text":"定义基数排序也是非比较的排序算法，对每一位进行排序，从最低位开始排序，复杂度为$O(n * k)$,为数组长度，k为数组中的数的最大的位数； 基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以是稳定的。 算法描述 取得数组中的最大数，并取得位数； arr为原始数组，从最低位开始取每个位组成radix数组； 对radix进行计数排序（利用计数排序适用于小范围数的特点）； 动图演示 代码实现1234567public static void main(String[] args) { int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48}; // 只需要修改成对应的方法名就可以了 radixSort(array); System.out.println(Arrays.toString(array));} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * Description: 基数排序 * * @param array * @return void */public static void radixSort(int[] array) { if (array == null || array.length &lt;= 1) { return; } int length = array.length; // 每位数字范围0~9，基为10 int radix = 10; int[] aux = new int[length]; int[] count = new int[radix + 1]; // 以关键字来排序的轮数，由位数最多的数字决定，其余位数少的数字在比较高位时，自动用0进行比较 // 将数字转换成字符串，字符串的长度就是数字的位数，字符串最长的那个数字也拥有最多的位数 int x = Arrays.stream(array).map(s -&gt; String.valueOf(s).length()).max().getAsInt(); // 共需要d轮计数排序, 从d = 0开始，说明是从个位开始比较，符合从右到左的顺序 for (int d = 0; d &lt; x; d++) { // 1. 计算频率，在需要的数组长度上额外加1 for (int i = 0; i &lt; length; i++) { // 使用加1后的索引，有重复的该位置就自增 count[digitAt(array[i], d) + 1]++; } // 2. 频率 -&gt; 元素的开始索引 for (int i = 0; i &lt; radix; i++) { count[i + 1] += count[i]; } // 3. 元素按照开始索引分类，用到一个和待排数组一样大临时数组存放数据 for (int i = 0; i &lt; length; i++) { // 填充一个数据后，自增，以便相同的数据可以填到下一个空位 aux[count[digitAt(array[i], d)]++] = array[i]; } // 4. 数据回写 for (int i = 0; i &lt; length; i++) { array[i] = aux[i]; } // 重置count[]，以便下一轮统计使用 for (int i = 0; i &lt; count.length; i++) { count[i] = 0; } }}/** * Description: 根据d，获取某个值的个位、十位、百位等，d = 0取出个位，d = 1取出十位，以此类推。对于不存在的高位，用0补 * * @param value * @param d * @return int */private static int digitAt(int value, int d) { return (value / (int) Math.pow(10, d)) % 10;} 算法分析最佳情况：$T(n) = O(n * k)$ 最差情况：$T(n) = O(n * k)$ 平均情况：$T(n) = O(n * k)$ 基数排序有两种方法： MSD 从高位开始进行排序 LSD 从低位开始进行排序 基数排序 vs 计数排序 vs 桶排序 这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异： 基数排序：根据键值的每位数字来分配桶 计数排序：每个桶只存储单一键值 桶排序：每个桶存储一定范围的数值","link":"/%E7%AE%97%E6%B3%95-%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F%EF%BC%88Radix-Sort%EF%BC%89/"},{"title":"算法-堆排序（Heap Sort）","text":"定义堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 算法描述 将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区； 将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]&lt;=R[n]； 由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。 动图演示 代码实现1234567public static void main(String[] args) { int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48}; // 只需要修改成对应的方法名就可以了 heapSort(array); System.out.println(Arrays.toString(array));} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * Description: 堆排序 * * @param array * @return void */public static void heapSort(int[] array) { if (array == null || array.length &lt;= 1) { return; } int length = array.length; //1.构建大顶堆 for (int i = length / 2 - 1; i &gt;= 0; i--) { //从第一个非叶子结点从下至上，从右至左调整结构 adjustHeap(array, i, length); } //2.调整堆结构+交换堆顶元素与末尾元素 for (int j = length - 1; j &gt; 0; j--) { //将堆顶元素与末尾元素进行交换 swap(array, 0, j); //重新对堆进行调整 adjustHeap(array, 0, j); }}/** * Description: 调整大顶堆（仅是调整过程，建立在大顶堆已构建的基础上） * * @param array * @param i * @param length * @return void */private static void adjustHeap(int[] array, int i, int length) { //先取出当前元素i int temp = array[i]; //从i结点的左子结点开始，也就是2i+1处开始 for (int k = i * 2 + 1; k &lt; length; k = k * 2 + 1) { //如果左子结点小于右子结点，k指向右子结点 if (k + 1 &lt; length &amp;&amp; array[k] &lt; array[k + 1]) { k++; } //如果子节点大于父节点，将子节点值赋给父节点（不用进行交换） if (array[k] &gt; temp) { array[i] = array[k]; i = k; } else { break; } } //将temp值放到最终的位置 array[i] = temp;}/** * Description: 交换元素位置 * * @param array * @param a * @param b * @return void */private static void swap(int[] array, int a, int b) { int temp = array[a]; array[a] = array[b]; array[b] = temp;} 算法分析最佳情况：$T(n) = O(nlogn)$ 最差情况：$T(n) = O(nlogn)$ 平均情况：$T(n) = O(nlogn)$","link":"/%E7%AE%97%E6%B3%95-%E5%A0%86%E6%8E%92%E5%BA%8F%EF%BC%88Heap-Sort%EF%BC%89/"},{"title":"算法-希尔排序（Shell Sort）","text":"定义希尔排序是希尔（Donald Shell）于1959年提出的一种排序算法。希尔排序也是一种插入排序，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序，同时该算法是冲破$O(n^2)$的第一批算法之一。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。 希尔排序是把记录按下表的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。 算法描述我们来看下希尔排序的基本步骤，在此我们选择增量 $gap=length/2$ ，缩小增量继续以 $gap = gap/2$ 的方式，这种增量选择我们可以用一个序列来表示，**{n/2,(n/2)/2…1}，称为增量序列**。希尔排序的增量序列的选择与证明是个数学难题，我们选择的这个增量序列是比较常用的，也是希尔建议的增量，称为希尔增量，但其实这个增量序列不是最优的。此处我们做示例使用希尔增量。 先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述： 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1； 按增量序列个数k，对序列进行k 趟排序； 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 过程演示 代码实现1234567public static void main(String[] args) { int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48}; // 只需要修改成对应的方法名就可以了 shellSort(array); System.out.println(Arrays.toString(array));} 12345678910111213141516171819202122232425262728293031323334/** * Description: 希尔排序 * * @param array * @return void */public static void shellSort(int[] array) { if (array == null || array.length &lt;= 1) { return; } int length = array.length; // temp为临时变量，gap增量默认是长度的一半，每次变为之前的一半，直到最终数组有序 int temp, gap = length / 2; while (gap &gt; 0) { for (int i = gap; i &lt; length; i++) { // 将当前的数与减去增量之后位置的数进行比较，如果大于当前数，将它后移 temp = array[i]; int preIndex = i - gap; while (preIndex &gt;= 0 &amp;&amp; array[preIndex] &gt; temp) { array[preIndex + gap] = array[preIndex]; preIndex -= gap; } // 将当前数放到空出来的位置 array[preIndex + gap] = temp; } gap /= 2; }} 算法分析最佳情况：$T(n) = O(nlog^2 n)$ 最差情况：$T(n) = O(nlog^2 n)$ 平均情况：$T(n) =O(nlog2n)$","link":"/%E7%AE%97%E6%B3%95-%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F%EF%BC%88Shell-Sort%EF%BC%89/"},{"title":"算法-归并排序（Merge Sort）","text":"定义和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是$O(nlogn)$的时间复杂度。代价是需要额外的内存空间。 归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。归并排序是一种稳定的排序方法。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。 算法描述 把长度为n的输入序列分成两个长度为n/2的子序列； 对这两个子序列分别采用归并排序； 将两个排序好的子序列合并成一个最终的排序序列。 动图演示 代码实现1234567public static void main(String[] args) { int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48}; // 只需要修改成对应的方法名就可以了 mergeSort(array); System.out.println(Arrays.toString(array));} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Description: 归并排序 * * @param array * @return void */public static void mergeSort(int[] array) { if (array == null || array.length &lt;= 1) { return; } sort(array, 0, array.length - 1);}private static void sort(int[] array, int left, int right) { if (left == right) { return; } int mid = left + ((right - left) &gt;&gt; 1); // 对左侧子序列进行递归排序 sort(array, left, mid); // 对右侧子序列进行递归排序 sort(array, mid + 1, right); // 合并 merge(array, left, mid, right);}private static void merge(int[] array, int left, int mid, int right) { int[] temp = new int[right - left + 1]; int i = 0; int p1 = left; int p2 = mid + 1; // 比较左右两部分的元素，哪个小，把那个元素填入temp中 while (p1 &lt;= mid &amp;&amp; p2 &lt;= right) { temp[i++] = array[p1] &lt; array[p2] ? array[p1++] : array[p2++]; } // 上面的循环退出后，把剩余的元素依次填入到temp中 // 以下两个while只有一个会执行 while (p1 &lt;= mid) { temp[i++] = array[p1++]; } while (p2 &lt;= right) { temp[i++] = array[p2++]; } // 把最终的排序的结果复制给原数组 for (i = 0; i &lt; temp.length; i++) { array[left + i] = temp[i]; }} 算法分析最佳情况：$T(n) = O(n)$ 最差情况：$T(n) = O(nlogn)$ 平均情况：$T(n) = O(nlogn)$","link":"/%E7%AE%97%E6%B3%95-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%EF%BC%88Merge-Sort%EF%BC%89/"},{"title":"算法-快速排序（Quick Sort）","text":"定义快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。 算法描述快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下： 从数列中挑出一个元素，称为 “基准”（pivot）； 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作； 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。 动图演示 代码实现1234567public static void main(String[] args) { int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48}; // 只需要修改成对应的方法名就可以了 quickSort(array); System.out.println(Arrays.toString(array));} 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Description: 快速排序 * * @param array * @return void */public static void quickSort(int[] array) { quickSort(array, 0, array.length - 1);}private static void quickSort(int[] array, int left, int right) { if (array == null || left &gt;= right || array.length &lt;= 1) { return; } int mid = partition(array, left, right); quickSort(array, left, mid); quickSort(array, mid + 1, right);}private static int partition(int[] array, int left, int right) { int temp = array[left]; while (right &gt; left) { // 先判断基准数和后面的数依次比较 while (temp &lt;= array[right] &amp;&amp; left &lt; right) { --right; } // 当基准数大于了 arr[left]，则填坑 if (left &lt; right) { array[left] = array[right]; ++left; } // 现在是 arr[right] 需要填坑了 while (temp &gt;= array[left] &amp;&amp; left &lt; right) { ++left; } if (left &lt; right) { array[right] = array[left]; --right; } } array[left] = temp; return left;} 算法分析最佳情况：$T(n) = O(nlogn)$ 最差情况：$T(n) = O(n^2)$ 平均情况：$T(n) = O(nlogn)$","link":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%EF%BC%88Quick-Sort%EF%BC%89/"},{"title":"算法-插入排序（Insertion Sort）","text":"定义插入排序（Insertion-Sort）的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 算法描述一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下： 从第一个元素开始，该元素可以认为已经被排序； 取出下一个元素，在已经排序的元素序列中从后向前扫描； 如果该元素（已排序）大于新元素，将该元素移到下一位置； 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置； 将新元素插入到该位置后； 重复步骤2~5。 动图演示 代码实现1234567public static void main(String[] args) { int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48}; // 只需要修改成对应的方法名就可以了 insertionSort(array); System.out.println(Arrays.toString(array));} 123456789101112131415161718192021222324252627282930/** * Description: 插入排序 * * @param array * @return void */public static void insertionSort(int[] array) { if (array == null || array.length &lt;= 1) { return; } int length = array.length; // 要插入的数 int insertNum; for (int i = 1; i &lt; length; i++) { insertNum = array[i]; // 已经排序好的元素个数 int j = i - 1; while (j &gt;= 0 &amp;&amp; array[j] &gt; insertNum) { // 从后到前循环，将大于insertNum的数向后移动一格 array[j + 1] = array[j]; j--; } // 将需要插入的数放在要插入的位置 array[j + 1] = insertNum; }} 算法分析最佳情况：$T(n) = O(n)$ 最差情况：$T(n) = O(n2)$ 平均情况：$T(n) = O(n2)$","link":"/%E7%AE%97%E6%B3%95-%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%EF%BC%88Insertion-Sort%EF%BC%89/"},{"title":"算法-桶排序（Bucket Sort）","text":"定义桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。 桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序） 算法描述 人为设置一个BucketSize，作为每个桶所能放置多少个不同数值（例如当BucketSize==5时，该桶可以存放｛1,2,3,4,5｝这几种数字，但是容量不限，即可以存放100个3）； 遍历输入数据，并且把数据一个一个放到对应的桶里去； 对每个不是空的桶进行排序，可以使用其它排序方法，也可以递归使用桶排序； 从不是空的桶里把排好序的数据拼接起来。 注意，如果递归使用桶排序为各个桶排序，则当桶数量为1时要手动减小BucketSize增加下一循环桶的数量，否则会陷入死循环，导致内存溢出。 图片演示 代码实现1234567public static void main(String[] args) { int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48}; // 只需要修改成对应的方法名就可以了 bucketSort(array); System.out.println(Arrays.toString(array));} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Description: 桶排序 * * @param array * @return void */public static void bucketSort(int[] array) { if (array == null || array.length &lt;= 1) { return; } // 建立桶，个数和待排序数组长度一样 int length = array.length; LinkedList&lt;Integer&gt;[] bucket = (LinkedList&lt;Integer&gt;[]) new LinkedList[length]; // 待排序数组中的最大值 int maxValue = Arrays.stream(array).max().getAsInt(); // 根据每个元素的值，分配到对应范围的桶中 for (int i = 0; i &lt; array.length; i++) { int index = toBucketIndex(array[i], maxValue, length); // 没有桶才建立桶(延时) if (bucket[index] == null) { bucket[index] = new LinkedList&lt;&gt;(); } // 有桶直接使用 bucket[index].add(array[i]); } // 对每个非空的桶排序，排序后顺便存入临时的List，则list中已经有序） List&lt;Integer&gt; temp = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; length; i++) { if (bucket[i] != null) { Collections.sort(bucket[i]); temp.addAll(bucket[i]); } } // 将temp中的数据写入原数组 for (int i = 0; i &lt; length; i++) { array[i] = temp.get(i); }}/** * Description: 映射函数，将值转换为应存放到的桶数组的索引 * * @param value * @param maxValue * @param length * @return int */private static int toBucketIndex(int value, int maxValue, int length) { return (value * length) / (maxValue + 1);} 算法分析桶排序最好情况下使用线性时间O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。 最佳情况：$T(n) = O(n+k)$ 最差情况：$T(n) = O(n+k)$ 平均情况：$T(n) = O(n^2)$","link":"/%E7%AE%97%E6%B3%95-%E6%A1%B6%E6%8E%92%E5%BA%8F%EF%BC%88Bucket-Sort%EF%BC%89/"},{"title":"算法-计数排序（Counting Sort）","text":"定义计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 计数排序(Counting sort)是一种稳定的排序算法。计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数。然后根据数组C来将A中的元素排到正确的位置。它只能对整数进行排序。 算法描述 找出待排序的数组中最大和最小的元素； 统计数组中每个值为i的元素出现的次数，存入数组C的第i项； 对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）； 反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。 动图演示 代码实现1234567public static void main(String[] args) { int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48}; // 只需要修改成对应的方法名就可以了 countingSort(array); System.out.println(Arrays.toString(array));} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Description: 计数排序 * * @param array * @return void */public static void countingSort(int[] array) { if (array == null || array.length &lt;= 1) { return; } int length = array.length; int max = array[0]; int min = array[0]; for (int i = 0; i &lt; length; i++) { if (max &lt; array[i]) { max = array[i]; } if (min &gt; array[i]) { min = array[i]; } } // 最大最小元素之间范围[min, max]的长度 int offset = max - min + 1; // 1. 计算频率，在需要的数组长度上额外加1 int[] count = new int[offset + 1]; for (int i = 0; i &lt; length; i++) { // 使用加1后的索引，有重复的该位置就自增 count[array[i] - min + 1]++; } // 2. 频率 -&gt; 元素的开始索引 for (int i = 0; i &lt; offset; i++) { count[i + 1] += count[i]; } // 3. 元素按照开始索引分类，用到一个和待排数组一样大临时数组存放数据 int[] aux = new int[length]; for (int i = 0; i &lt; length; i++) { // 填充一个数据后，自增，以便相同的数据可以填到下一个空位 aux[count[array[i] - min]++] = array[i]; } // 4. 数据回写 for (int i = 0; i &lt; length; i++) { array[i] = aux[i]; }} 算法分析当输入的元素是n 个0到k之间的整数时，它的运行时间是 O(n + k)。计数排序不是比较排序，排序的速度快于任何比较排序算法。由于用来计数的数组C的长度取决于待排序数组中数据的范围（等于待排序数组的最大值与最小值的差加上1），这使得计数排序对于数据范围很大的数组，需要大量时间和内存。 最佳情况：$T(n) = O(n+k)$ 最差情况：$T(n) = O(n+k)$ 平均情况：$T(n) = O(n+k)$","link":"/%E7%AE%97%E6%B3%95-%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F%EF%BC%88Counting-Sort%EF%BC%89/"},{"title":"算法-选择排序（Selection Sort）","text":"定义表现最稳定的排序算法之一，因为无论什么数据进去都是$O(n2)$的时间复杂度，所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。理论上讲，选择排序可能也是平时排序一般人想到的最多的排序方法了吧。 选择排序(Selection-sort)是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 算法描述n个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下： 初始状态：无序区为R[1…n]，有序区为空； 第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1…i-1]和R(i…n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1…i]和R[i+1…n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区； n-1趟结束，数组有序化了。 动图演示 代码实现1234567public static void main(String[] args) { int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48}; // 只需要修改成对应的方法名就可以了 selectionSort(array); System.out.println(Arrays.toString(array));} 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Description: 选择排序 * * @param array * @return void */public static void selectionSort(int[] array) { if (array == null || array.length &lt;= 1) { return; } int length = array.length; for (int i = 0; i &lt; length - 1; i++) { // 保存最小数的索引 int minIndex = i; for (int j = i + 1; j &lt; length; j++) { // 找到最小的数 if (array[j] &lt; array[minIndex]) { minIndex = j; } } // 交换元素位置 if (i != minIndex) { swap(array, minIndex, i); } }}/** * Description: 交换元素位置 * * @param array * @param a * @param b * @return void */private static void swap(int[] array, int a, int b) { int temp = array[a]; array[a] = array[b]; array[b] = temp;} 算法分析最佳情况：$T(n) = O(n^2)$ 最差情况：$T(n) = O(n^2)$ 平均情况：$T(n) = O(n^2)$","link":"/%E7%AE%97%E6%B3%95-%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%EF%BC%88Selection-Sort%EF%BC%89/"},{"title":"算法概述","text":"算法包括： 排序算法： 冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序、计数排序、桶排序、基数排序 搜索算法：回溯、递归、剪枝 图论：最短路径、最小生成树、网络流建模 动态规划：背包问题、最长子序列、计数问题 基础技巧：分治、倍增、二分法、贪心算法 宽度优先搜索 深度优先搜索 广度优先 双指针 扫描线 朴素贝叶斯 推荐算法","link":"/%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/"},{"title":"系统拓扑图涉及到的skywalking接口说明","text":"接口列表 序号 接口地址 接口说明 1 /apm/topo/global_topology 获取拓扑图 2 /apm/service/info 获取可用性、CPM、平均访问时间 3 /apm/topo/topology_client_metric 获取客户端延迟、cpmC 4 /apm/topo/topology_server_metric 获取服务端延迟、cpmS 5 /apm/topo/topo_client_info 获取client端的数据 6 /apm/topo/topo_server_info 获取server端的数据 获取拓扑图 地址：/apm/topo/global_topology 请求方式：GET 请求参数说明 12345duration.end:2020-11-27 1504duration.start:2020-11-27 1404type:SWduration.step:MINUTEapp:673 返回值说明(这里只解释data里面的数据) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&quot;data&quot;: { &quot;getGlobalTopologyByLabel&quot;: { &quot;nodes&quot;: [{ --拓扑图的服务节点集合 &quot;id&quot;: &quot;32&quot;,--服务节点ID &quot;name&quot;: &quot;sc-nacos-demo-8789&quot;,--节点服务名称 &quot;type&quot;: &quot;SpringMVC&quot;,--节点服务类型 &quot;isReal&quot;: &quot;true&quot;,--是否是真实的 &quot;nodeType&quot;: 0 }, { &quot;id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;User&quot;, &quot;type&quot;: &quot;USER&quot;, &quot;isReal&quot;: &quot;false&quot;, &quot;nodeType&quot;: 0 }, { &quot;id&quot;: &quot;18&quot;, &quot;name&quot;: &quot;bufx-sc-nacos-demo-8789&quot;, &quot;type&quot;: &quot;SpringMVC&quot;, &quot;isReal&quot;: &quot;true&quot;, &quot;nodeType&quot;: 0 } ], &quot;calls&quot;: [{ --拓扑图的链路结合 &quot;id&quot;: &quot;18_18&quot;,--链路ID &quot;source&quot;: &quot;18&quot;,--链路起始节点ID &quot;target&quot;: &quot;18&quot;,--链路结束阶段ID &quot;callType&quot;: &quot;SpringRestTemplate&quot;,--链路类型 &quot;detectPoint&quot;: null, &quot;detectPoints&quot;: [--链路侦查端类型 &quot;CLIENT&quot;, &quot;SERVER&quot; ] }, { &quot;id&quot;: &quot;32_32&quot;, &quot;source&quot;: &quot;32&quot;, &quot;target&quot;: &quot;32&quot;, &quot;callType&quot;: &quot;SpringRestTemplate&quot;, &quot;detectPoint&quot;: null, &quot;detectPoints&quot;: [ &quot;CLIENT&quot;, &quot;SERVER&quot; ] }, { &quot;id&quot;: &quot;1_18&quot;, &quot;source&quot;: &quot;1&quot;, &quot;target&quot;: &quot;18&quot;, &quot;callType&quot;: &quot;&quot;, &quot;detectPoint&quot;: null, &quot;detectPoints&quot;: [ &quot;SERVER&quot; ] } ] }}} 获取可用性、CPM、平均访问时间 地址：/apm/service/info 请求方式：GET 请求参数说明 123456type:SWapp:673serviceId:32duration.start:2020-11-27 1945duration.end:2020-11-27 2045duration.step:MINUTE 返回值说明(这里只解释data里面的数据) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&quot;data&quot;: { &quot;data&quot;: { &quot;getSlowEndpoint&quot;: [], &quot;getServiceInstanceThroughput&quot;: [], &quot;getServiceInstances&quot;: [], &quot;getServiceTopology&quot;: {}, &quot;getResponseTimeTrend&quot;: { --延迟 &quot;values&quot;: [ { &quot;value&quot;: 1 --具体的值 }, { &quot;value&quot;: 2 }, { &quot;value&quot;: 1 } ] }, &quot;getThroughputTrend&quot;: { --每分钟请求量 &quot;values&quot;: [ { &quot;value&quot;: 12 --具体的值 }, { &quot;value&quot;: 12 }, { &quot;value&quot;: 12 } ] }, &quot;getSLATrend&quot;: { -- SLA &quot;values&quot;: [ { &quot;value&quot;: 5833 --具体的值 }, { &quot;value&quot;: 4166 }, { &quot;value&quot;: 5833 } ] }, &quot;getApdexScore&quot;: {}, &quot;servicePercentile&quot;: [] } } 获取客户端延迟、cpmC 地址：/apm/topo/topology_client_metric 请求方式：GET 请求参数说明 12345678app:673duration.end:2020-11-27+1548duration.start:2020-11-27+1448duration.step:MINUTEids:1,18,32type:SWidsS:1_18idsC:18_18,32_32 返回值说明(这里只解释data里面的数据) 12345678910111213141516171819202122232425262728&quot;data&quot;: { &quot;data&quot;: { &quot;cpmC&quot;: {--每分钟请求量数据 &quot;values&quot;: [ { &quot;id&quot;: &quot;18_18&quot;,--call链路的ID &quot;value&quot;: 12 --每分钟请求量值 }, { &quot;id&quot;: &quot;32_32&quot;, &quot;value&quot;: 12 } ] }, &quot;latencyC&quot;: {--延迟数据 &quot;values&quot;: [ { &quot;id&quot;: &quot;18_18&quot;,--call链路的ID &quot;value&quot;: 4-- 延迟的值 }, { &quot;id&quot;: &quot;32_32&quot;, &quot;value&quot;: 2 } ] } } } 获取服务端延迟、cpmC 地址：/apm/topo/topology_server_metric 请求方式：GET 请求参数说明 12345678app:673duration.step:MINUTEidsS:1_18idsC:18_18,32_32type:SWids:1,18,32duration.start:2020-11-27+1448duration.end:2020-11-27+1548 返回值说明(这里只解释data里面的数据) 123456789101112131415&quot;data&quot;: { &quot;data&quot;: { &quot;cpmS&quot;: {--每分钟请求量数据 &quot;values&quot;: [ { &quot;id&quot;: &quot;1_18&quot;,--call链路的ID &quot;value&quot;: 7--每分钟请求量值 } ] }, &quot;latencyS&quot;: {--延迟数据 &quot;values&quot;: [] } } } 获取client端的数据 地址：/apm/topo/topo_client_info 请求方式：GET 请求参数说明 123456app:673duration.step:MINUTEid:18_18type:SWduration.start:2020-11-27+1448duration.end:2020-11-27+1548 返回值说明(这里只解释data里面的数据) 12345678910111213141516171819202122232425262728293031323334&quot;data&quot;: { &quot;data&quot;: { &quot;getResponseTimeTrend&quot;: {--侦查端-客户端那里的响应时间 &quot;values&quot;: [ { &quot;value&quot;: 4--响应时间的值 }, { &quot;value&quot;: 5 } ] }, &quot;getThroughputTrend&quot;: {--侦查端-客户端那里的吞吐量 &quot;values&quot;: [ { &quot;value&quot;: 12--吞吐量的值 }, { &quot;value&quot;: 12 } ] }, &quot;getSLATrend&quot;: {-- 侦查端-客户端那里的SLA数据 &quot;values&quot;: [ { &quot;value&quot;: 5833-- SLA值 }, { &quot;value&quot;: 5000 } ] } } } 获取server端的数据 地址：/apm/topo/topo_server_info 请求方式：GET 请求参数说明 123456app:673duration.step:MINUTEtype:SWduration.start:2020-11-27+1448duration.end:2020-11-27+1548id:32_32 返回值说明(这里只解释data里面的数据) 12345678910111213141516171819202122232425262728293031323334&quot;data&quot;: { &quot;data&quot;: { &quot;getResponseTimeTrend&quot;: {--侦查端-服务端那里的响应时间 &quot;values&quot;: [ { &quot;value&quot;: 2 --响应时间的值 }, { &quot;value&quot;: 1 } ] }, &quot;getThroughputTrend&quot;: { --侦查端-服务端那里的吞吐量 &quot;values&quot;: [ { &quot;value&quot;: 12--吞吐量的值 }, { &quot;value&quot;: 12 } ] }, &quot;getSLATrend&quot;: { -- 侦查端-服务端那里的SLA数据 &quot;values&quot;: [ { &quot;value&quot;: 4166-- SLA值 }, { &quot;value&quot;: 7500 } ] } } } 查询系统日请求成功率 地址：/apm/call/slaForApp 请求方式：GET 请求参数说明 1appId:682 返回值说明(这里只解释data里面的数据) 1234567891011{ &quot;message&quot;: null, &quot;exceptionStackTrace&quot;: null, &quot;state&quot;: &quot;success&quot;, &quot;code&quot;: 200, &quot;data&quot;: { &quot;id&quot;: &quot;682&quot;,--系统ID &quot;value&quot;: 4901 --系统请求成功率 }, &quot;entity&quot;: null} 查询服务日请求成功率 地址：/apm/call/slaForService 请求方式：GET 请求参数说明 1serviceIds:32 返回值说明(这里只解释data里面的数据) 12345678910&quot;data&quot;: { &quot;slaForService&quot;: { &quot;values&quot;: [ { &quot;id&quot;: &quot;32&quot;, &quot;value&quot;: 5033 --日成功率 } ] }}","link":"/%E7%B3%BB%E7%BB%9F%E6%8B%93%E6%89%91%E5%9B%BE%E6%B6%89%E5%8F%8A%E5%88%B0%E7%9A%84skywalking%E6%8E%A5%E5%8F%A3%E8%AF%B4%E6%98%8E/"},{"title":"线性结构和非线性结构","text":"介绍数据结构包括:线性结构和非线性结构 线性结构 线性结构作为最常用的数据结构，其特点是数据元素之间存在一对一的线性关系 线性结构有两种不同的存储结构，即顺序存储结构(数组) 和 **链式存储结构(链表)**。 顺序存储的线性表称为顺序表，顺序表中的存储元素是连续的 链式存储的线性表称为链表，链表中的存储元素不一定是连续的，元素节点中存放了 数据元素以及相邻元素的地址信息 线性结构常见的有:数组、队列、链表和栈，后面我们会详细讲解. 非线性结构非线性结构包括:二维数组，多维数组，广义表，树结构，图结构","link":"/%E7%BA%BF%E6%80%A7%E7%BB%93%E6%9E%84%E5%92%8C%E9%9D%9E%E7%BA%BF%E6%80%A7%E7%BB%93%E6%9E%84/"},{"title":"集合容器-理论总结","text":"简介集合框架：用于存储数据的容器。 集合框架是为表示和操作集合而规定的一种统一的标准的体系结构。任何集合框架都包含三大块内容：对外的接口、接口的实现和对集合运算的算法。 接口：表示集合的抽象数据类型。接口允许我们操作集合时不必关注具体实现，从而达到“多态”。在面向对象编程语言中，接口通常用来形成规范。 实现：集合接口的具体实现，是重用性很高的数据结构。 算法：在一个实现了某个集合框架中的接口的对象身上完成某种有用的计算的方法，例如查找、排序等。这些算法通常是多态的，因为相同的方法可以在同一个接口被多个类实现时有不同的表现。事实上，算法是可复用的函数。它减少了程序设计的辛劳。 集合框架通过提供有用的数据结构和算法使你能集中注意力于你的程序的重要部分上，而不是为了让程序能正常运转而将注意力于低层设计上。通过这些在无关API之间的简易的互用性，使你免除了为改编对象或转换代码以便联合这些API而去写大量的代码。 它提高了程序速度和质量。 特点 对象封装数据，对象多了也需要存储。集合用于存储对象。 对象的个数确定可以使用数组，对象的个数不确定的可以用集合。因为集合是可变长度的。 集合和数组的区别 数组是固定长度的；集合可变长度的。 数组可以存储基本数据类型，也可以存储引用数据类型；集合只能存储引用数据类型。 数组存储的元素必须是同一个数据类型；集合存储的对象可以是不同数据类型。 数据结构：就是容器中存储数据的方式。 对于集合容器，有很多种。因为每一个容器的自身特点不同，其实原理在于每个容器的内部数据结构不同。 集合容器在不断向上抽取过程中，出现了集合体系。在使用一个体系的原则：参阅顶层内容。建立底层对象。 使用集合框架的好处 容量自增长； 提供了高性能的数据结构和算法，使编码更轻松，提高了程序速度和质量； 允许不同 API 之间的互操作，API之间可以来回传递集合； 可以方便地扩展或改写集合，提高代码复用性和可操作性。 通过使用JDK自带的集合类，可以降低代码维护和学习新API成本。 Iterator接口Iterator接口，用于遍历集合元素的接口。 在Iterator接口中定义了三个方法： 修饰与类型 方法与描述 boolean hasNext() 如果仍有元素可以迭代，则返回true。 E next() 返回迭代的下一个元素。 void remove() 从迭代器指向的 collection 中移除迭代器返回的最后一个元素（可选操作）。 每一个集合都有自己的数据结构(就是容器中存储数据的方式)，都有特定的取出自己内部元素的方式。为了便于操作所有的容器，取出元素。将容器内部的取出方式按照一个统一的规则向外提供，这个规则就是Iterator接口，使得对容器的遍历操作与其具体的底层实现相隔离，达到解耦的效果。 也就说，只要通过该接口就可以取出Collection集合中的元素，至于每一个具体的容器依据自己的数据结构，如何实现的具体取出细节，这个不用关心，这样就降低了取出元素和具体集合的耦合性。 使用迭代器遍历集合元素 123456789101112131415161718public static void main(String[] args) { List&lt;String&gt; list1 = new ArrayList&lt;&gt;(); list1.add(&quot;abc0&quot;); list1.add(&quot;abc1&quot;); list1.add(&quot;abc2&quot;); // while循环方式遍历 Iterator it1 = list1.iterator(); while (it1.hasNext()) { System.out.println(it1.next()); } // for循环方式遍历 for (Iterator it2 = list1.iterator(); it2.hasNext(); ) { System.out.println(it2.next()); }} 使用Iterator迭代器进行删除集合元素，则不会出现并发修改异常。 因为：在执行remove操作时，同样先执行checkForComodification()，然后会执行ArrayList的remove()方法，该方法会将modCount值加1，这里我们将expectedModCount=modCount，使之保持统一。 ListIterator接口ListIterator是一个功能更加强大的迭代器， 它继承于Iterator接口，只能用于各种List类型的访问。可以通过调用listIterator()方法产生一个指向List开始处的ListIterator， 还可以调用listIterator(n)方法创建一个一开始就指向列表索引为n的元素处的ListIterator。 特点 允许我们向前、向后两个方向遍历 List； 在遍历时修改 List 的元素； 遍历时获取迭代器当前游标所在位置。 常用API 修饰与类型 方法与描述 void add(E e) 将指定的元素插入到列表 （可选操作）。 boolean hasNext() 如果此列表迭代器在前进方向还有更多的元素时，返回 true。 boolean hasPrevious() 如果此列表迭代器在相反方向还有更多的元素时，返回 true。 E next() 返回列表中的下一个元素和光标的位置向后推进。 int nextIndex() 返回调用 next()后返回的元素索引。 E previous() 返回列表中的上一个元素和光标的位置向前移动。 int previousIndex() 返回调用previous() 后返回的元素索引 。 void remove() 删除列表中调用next()或previous()的返回最后一个元素。 void set(E e) 用指定元素替换列表中调用next()或previous()的返回最后一个元素。 Collection接口所有集合类都位于java.util包下。Java的集合类主要由两个接口派生而出：Collection和Map，Collection和Map是Java集合框架的根接口，这两个接口又包含了一些子接口或实现类。 Collection一次存一个元素，是单列集合； Map一次存一对元素，是双列集合。Map存储的一对元素：键–值，键（key）与值(value)间有对应(映射)关系。 单列集合继承关系图 Collection集合主要有List和Set两大接口 List：有序(元素存入集合的顺序和取出的顺序一致)，元素都有索引。元素可以重复。 Set：无序(存入和取出顺序有可能不一致)，不可以存储重复元素。必须保证元素唯一性。 List集合List是元素有序并且可以重复的集合。 List的主要实现：ArrayList， LinkedList， Vector。 List常用方法 ArrayList、LinkedList、Vector 的区别 ArrayList LinkedList Vector 底层实现 数组 双向链表 数组 同步性及效率 不同步，非线程安全，效率高，支持随机访问 不同步，非线程安全，效率高 同步，线程安全，效率低 特点 查询快，增删慢 查询慢，增删快 查询快，增删慢 默认容量 10 / 10 扩容机制 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1)；//1.5 倍 / 2 倍 总结： ArrayList 和 Vector 基于数组实现，对于随机访问get和set，ArrayList优于LinkedList，因为LinkedList要移动指针。 LinkedList 不会出现扩容的问题，所以比较适合随机位置增、删。但是其基于链表实现，所以在定位时需要线性扫描，效率比较低。 当操作是在一列数据的后面添加数据而不是在前面或中间，并且需要随机地访问其中的元素时，使用ArrayList会提供比较好的性能； 当你的操作是在一列数据的前面或中间添加或删除数据，并且按照顺序访问其中的元素时，就应该使用LinkedList了。 遍历时操作元素遍历集合时，同时操作集合中的元素（增删等） 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Description: for循环遍历 * 输出结果： * [a, b, c, d, e] * 由结果可知，第二个元素b并未删除，原因是当第一个元素b被删除后，它后面所有的元素都向前移动了一个单位，循环时导致第二个元素b漏掉了 */public static void remove(List&lt;String&gt; list) { for (int i = 0; i &lt; list.size(); i++) { String s = list.get(i); if (s.equals(&quot;b&quot;)) { list.remove(s); } }}/** * Description: foreach循环遍历 * * 会报错：java.util.ConcurrentModificationException。这是因为在这里，foreach循环遍历容器本质上是使用迭代器进行遍历的，会对修改次数modCount进行检查，不允许集合进行更改操作 */public static void remove2(List&lt;String&gt; list) { for (String s : list) { if (s.equals(&quot;b&quot;)) { list.remove(s); } System.out.println(s); }}/** * Description: 使用迭代器遍历 */public static void remove3(List&lt;String&gt; list) { Iterator&lt;String&gt; it = list.iterator(); while (it.hasNext()) { String s = it.next(); if (s.equals(&quot;b&quot;)) { it.remove(); } }} 使用迭代器遍历删除时，能够避免方法二中出现的问题。这是因为：在ArrayList中，modCount是指集合的修改次数，当进行add或者delete时，modCount会+1；expectedModCount是指集合的迭代器的版本号，初始值是modCount，但是当集合进行add或者delete操作时，modCount会+1，而expectedModCount不会改变，所以方法二中会抛出异常。但是it.remove操作时，会同步expectedModCount的值，把modCount的值赋予expectedModCount。所以不会抛出异常。 测试方法 1234567891011121314public static void main(String[] args) { List&lt;String&gt; arrayList = new ArrayList&lt;String&gt;(); arrayList.add(&quot;a&quot;); arrayList.add(&quot;b&quot;); arrayList.add(&quot;b&quot;); arrayList.add(&quot;c&quot;); arrayList.add(&quot;d&quot;); arrayList.add(&quot;e&quot;); // remove(arrayList); // remove2(arrayList); remove3(arrayList); System.out.println(arrayList);} 总结：如果想正确的循环遍历删除（增加）元素，需要使用方法三，也就是迭代器遍历删除（增加）的方法。 Set集合Set集合元素无序(存入和取出的顺序不一定一致)，并且没有重复对象。Set的主要实现类：HashSet， TreeSet。 Set常用方法 HashSet、TreeSet、LinkedHashSet的区别 HashSet TreeSet LinkedHashSet 底层实现 HashMap 红黑树 LinkedHashMap 重复性 不允许重复 不允许重复 不允许重复 有无序 无序 有序，支持两种排序方式，自然排序和定制排序，其中自然排序为默认的排序方式。 有序，以元素插入的顺序来维护集合的链接表 时间复杂度 add()，remove()，contains()方法的时间复杂度是O(1) add()，remove()，contains()方法的时间复杂度是O(logn) LinkedHashSet在迭代访问Set中的全部元素时，性能比HashSet好，但是插入时性能稍微逊色于HashSet，时间复杂度是 O(1)。 同步性 不同步，线程不安全 不同步，线程不安全 不同步，线程不安全 null值 允许null值 不支持null值，会抛出 java.lang.NullPointerException 异常。因为TreeSet应用 compareTo() 方法于各个元素来比较他们，当比较null值时会抛出 NullPointerException异常。 允许null值 比较 equals() compareTo() equals() HashSet如何检查重复当你把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals()方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让加入操作成功。hashCode()与equals()的相关规定： 如果两个对象相等，则hashcode一定也是相同的 两个对象相等，equals方法返回true 两个对象有相同的hashcode值，它们也不一定是相等的 综上，equals方法被覆盖过，则hashCode方法也必须被覆盖hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。 总结： HashSet是一个通用功能的Set，而LinkedHashSet 提供元素插入顺序保证，TreeSet是一个SortedSet实现，由Comparator 或者 Comparable指定的元素顺序存储元素。 Map接口Map 是一种把键对象和值对象映射的集合，它的每一个元素都包含一对键对象和值对象。 Map没有继承于Collection接口，从Map集合中检索元素时，只要给出键对象，就会返回对应的值对象。Map 的常用实现类：HashMap、TreeMap、HashTable、LinkedHashMap、ConcurrentHashMap 双列集合继承关系图 Map常用方法 HashMap、HashTable、TreeMap的区别 TreeMap：基于红黑树实现。 HashMap：基于哈希表实现。 HashTable：和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程可以同时写入 HashTable 并且不会导致数据不一致。它是遗留类，不应该去使用它。现在可以使用 ConcurrentHashMap 来支持线程安全，并且 ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。 LinkedHashMap：使用双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。 HashMap HashTable TreeMap 底层实现 哈希表（数组+链表） 哈希表（数组+链表） 红黑树 同步性 线程不同步 同步 线程不同步 null值 允许 key 和 Vale 是 null，但是只允许一个 key 为 null，且这个元素存放在哈希表 0 角标位置 不允许key、value 是 null value允许为null。 当未实现 Comparator 接口时，key 不可以为null 当实现 Comparator 接口时，若未对 null 情况进行判断，则可能抛 NullPointerException 异常。如果针对null情况实现了，可以存入，但是却不能正常使用get()访问，只能通过遍历去访问。 hash 使用hash(Object key)扰动函数对 key 的 hashCode 进行扰动后作为 hash 值 直接使用 key 的 hashCode() 返回值作为 hash 值 容量 容量为 2^4 且容量一定是 2^n 默认容量是11，不一定是 2^n 扩容 两倍，且哈希桶的下标使用 &amp;运算代替了取模 2倍+1，取哈希桶下标是直接用模运算 HashMap在JDK1.7和JDK1.8中有哪些不同 不同 JDK 1.7 JDK 1.8 存储结构 数组 + 链表 数组 + 链表 + 红黑树 初始化方式 单独函数：inflateTable() 直接集成到了扩容函数resize()中 hash值计算方式 扰动处理 = 9次扰动 = 4次位运算 + 5次异或运算 扰动处理 = 2次扰动 = 1次位运算 + 1次异或运算 存放数据的规则 无冲突时，存放数组；冲突时，存放链表 无冲突时，存放数组；冲突 &amp; 链表长度 &lt; 8：存放单链表；冲突 &amp; 链表长度 &gt; 8：树化并存放红黑树 插入数据方式 头插法（先讲原位置的数据移到后1位，再插入数据到该位置） 尾插法（直接插入到链表尾部/红黑树） 扩容后存储位置的计算方式 全部按照原来方法进行计算（即hashCode -&gt;&gt; 扰动函数 -&gt;&gt; (h&amp;length-1)） 按照扩容后的规律计算（即扩容后的位置=原位置 or 原位置 + 旧容量） 集合工具类CollectionsCollections：集合工具类，方便对集合的操作。这个类不需要创建对象，内部提供的都是静态方法。 静态方法： 1234567891011121314151617Collections.sort(list);//list集合进行元素的自然顺序排序。Collections.sort(list,new ComparatorByLen());//按指定的比较器方法排序。class ComparatorByLen implements Comparator&lt;String&gt;{ public int compare(String s1,String s2){ int temp = s1.length()-s2.length(); return temp==0?s1.compareTo(s2):temp; }}Collections.max(list);//返回list中字典顺序最大的元素。int index = Collections.binarySearch(list,&quot;zz&quot;);//二分查找，返回角标。Collections.reverseOrder();//逆向反转排序。Collections.shuffle(list);//随机对list中的元素进行位置的置换。//将非同步集合转成同步集合的方法：Collections中的 XXX synchronizedXXX(XXX); //原理：定义一个类，将集合所有的方法加同一把锁后返回。List synchronizedList(list);Map synchronizedMap(map); Collection 和 Collections的区别 Collections是个java.util下的类，是针对集合类的一个工具类,提供一系列静态方法,实现对集合的查找、排序、替换、线程安全化（将非同步的集合转换成同步的）等操作。 Collection是个java.util下的接口，它是各种集合结构的父接口，继承于它的接口主要有Set和List,提供了关于集合的一些操作,如插入、删除、判断一个元素是否其成员、遍历等。 数组工具类 Arrays用于操作数组对象的工具类，里面都是静态方法。 数组 -&gt; 集合：asList方法，将数组转换成list集合。 12String[] arr ={&quot;abc&quot;,&quot;kk&quot;,&quot;qq&quot;};List&lt;String&gt; list =Arrays.asList(arr);//将arr数组转成list集合。 将数组转换成集合，有什么好处呢？用aslist方法，将数组变成集合； 可以通过list集合中的方法来操作数组中的元素：isEmpty()、contains、indexOf、set；注意（局限性）：数组是固定长度，不可以使用集合对象增加或者删除等，会改变数组长度的功能方法。比如add、remove、clear。（会报不支持操作异常UnsupportedOperationException）； 如果数组中存储的引用数据类型，直接作为集合的元素可以直接用集合方法操作。 如果数组中存储的是基本数据类型，asList会将数组实体作为集合元素存在。 集合 -&gt; 数组：用的是Collection接口中的toArray()方法; 如果给toArray传递的指定类型的数据长度小于了集合的size，那么toArray方法，会自定再创建一个该类型的数据，长度为集合的size。 如果传递的指定的类型的数组的长度大于了集合的size，那么toArray方法，就不会创建新数组，直接使用该数组即可，并将集合中的元素存储到数组中，其他为存储元素的位置默认值null。 所以，在传递指定类型数组时，最好的方式就是指定的长度和size相等的数组。 将集合变成数组后有什么好处？限定了对集合中的元素进行增删操作，只要获取这些元素即可。 用基本数据类型的数组转换ArrayList，ArrayList的size有问题 1234567891011public static void main(String[] args) { int[] arr1 = { 1, 2, 3, 4, 5 }; List&lt;int[]&gt; intList = Arrays.asList(arr1); // intList size: 1 System.out.println(String.format(&quot;intList size: %s&quot;, intList.size())); Integer[] arr2 = { 1, 2, 3, 4, 5 }; List&lt;Integer&gt; integerList = Arrays.asList(arr2); // integerList size: 5 System.out.println(String.format(&quot;integerList size：%s&quot;, integerList.size()));} asList方法接受的参数是一个泛型的变长参数，我们知道基本数据类型是无法泛型化的，也就是说基本类型是无法作为asList方法的参数的， 要想作为泛型参数就必须使用其所对应的包装类型。但是这个这个实例中为什么没有出错呢？因为该实例是将int 类型的数组当做其参数，而在Java中数组是一个对象，它是可以泛型化的。所以该例子是不会产生错误的。既然例子是将整个int 类型的数组当做泛型参数，那么经过asList转换就只有一个int 的列表了. 结论： 在使用asList()时尽量不要将基本数据类型数组转List. asList转换得到的ArrayList不是java.util.ArrayList 123456public static void main(String[] args) { String[] arr = {&quot;abc&quot;, &quot;kk&quot;, &quot;qq&quot;}; List&lt;String&gt; list = Arrays.asList(arr); // 添加一个元素,抛出异常UnsupportedOperationException list.add(&quot;bb&quot;);} 原因： 此处ArrayList是Arrays的内部类,并没有add方法,add方法是父类AbstractList的,但是没有具体实现,而是直接抛出UnsupportedOperationException异常. 正确操作 123456public static void main(String[] args) { String[] arr = {&quot;abc&quot;, &quot;kk&quot;, &quot;qq&quot;}; // 使用new ArrayList包裹一层 List&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(arr)); list.add(&quot;bb&quot;);} 如何选用集合?主要根据集合的特点来选用，比如我们需要根据键值获取到元素值时就选用Map接口下的集合，需要排序时选择TreeMap,不需要排序时就选择HashMap,需要保证线程安全就选用ConcurrentHashMap.当我们只需要存放元素值时，就选择实现Collection接口的集合，需要保证元素唯一时选择实现Set接口的集合比如TreeSet或HashSet，不需要就选择实现List接口的比如ArrayList或LinkedList，然后再根据实现这些接口的集合的特点来选用。","link":"/%E9%9B%86%E5%90%88%E5%AE%B9%E5%99%A8-%E7%90%86%E8%AE%BA%E6%80%BB%E7%BB%93/"},{"title":"集合容器-问题总结","text":"集合容器概述什么是集合集合框架：用于存储数据的容器。 集合框架是为表示和操作集合而规定的一种统一的标准的体系结构。任何集合框架都包含三大块内容：对外的接口、接口的实现和对集合运算的算法。 接口：表示集合的抽象数据类型。接口允许我们操作集合时不必关注具体实现，从而达到“多态”。在面向对象编程语言中，接口通常用来形成规范。 实现：集合接口的具体实现，是重用性很高的数据结构。 算法：在一个实现了某个集合框架中的接口的对象身上完成某种有用的计算的方法，例如查找、排序等。这些算法通常是多态的，因为相同的方法可以在同一个接口被多个类实现时有不同的表现。事实上，算法是可复用的函数。它减少了程序设计的辛劳。 集合框架通过提供有用的数据结构和算法使你能集中注意力于你的程序的重要部分上，而不是为了让程序能正常运转而将注意力于低层设计上。通过这些在无关API之间的简易的互用性，使你免除了为改编对象或转换代码以便联合这些API而去写大量的代码。 它提高了程序速度和质量。 集合的特点集合的特点主要有如下两点： 对象封装数据，对象多了也需要存储。集合用于存储对象。 对象的个数确定可以使用数组，对象的个数不确定的可以用集合。因为集合是可变长度的。 集合和数组的区别 数组是固定长度的；集合可变长度的。 数组可以存储基本数据类型，也可以存储引用数据类型；集合只能存储引用数据类型。 数组存储的元素必须是同一个数据类型；集合存储的对象可以是不同数据类型。 数据结构：就是容器中存储数据的方式。 对于集合容器，有很多种。因为每一个容器的自身特点不同，其实原理在于每个容器的内部数据结构不同。 集合容器在不断向上抽取过程中，出现了集合体系。在使用一个体系的原则：参阅顶层内容。建立底层对象。 使用集合框架的好处 容量自增长； 提供了高性能的数据结构和算法，使编码更轻松，提高了程序速度和质量； 允许不同 API 之间的互操作，API之间可以来回传递集合； 可以方便地扩展或改写集合，提高代码复用性和可操作性。 通过使用JDK自带的集合类，可以降低代码维护和学习新API成本。 常用的集合类有哪些？Map接口和Collection接口是所有集合框架的父接口： Collection接口的子接口包括：Set接口和List接口 Map接口的实现类主要有：HashMap、TreeMap、Hashtable、ConcurrentHashMap以及Properties等 Set接口的实现类主要有：HashSet、TreeSet、LinkedHashSet等 List接口的实现类主要有：ArrayList、LinkedList、Stack以及Vector等 List，Set，Map三者的区别？List、Set、Map 是否继承自 Collection 接口？List、Map、Set 三个接口存取元素时，各有什么特点？ Java 容器分为 Collection 和 Map 两大类，Collection集合的子接口有Set、List、Queue三种子接口。我们比较常用的是Set、List，Map接口不是collection的子接口。 Collection集合主要有List和Set两大接口 List：一个有序（元素存入集合的顺序和取出的顺序一致）容器，元素可以重复，可以插入多个null元素，元素都有索引。常用的实现类有 ArrayList、LinkedList 和 Vector。 Set：一个无序（存入和取出顺序有可能不一致）容器，不可以存储重复元素，只允许存入一个null元素，必须保证元素唯一性。Set 接口常用实现类是 HashSet、LinkedHashSet 以及 TreeSet。 Map是一个键值对集合，存储键、值和之间的映射。 Key无序，唯一；value 不要求有序，允许重复。Map没有继承于Collection接口，从Map集合中检索元素时，只要给出键对象，就会返回对应的值对象。 Map 的常用实现类：HashMap、TreeMap、HashTable、LinkedHashMap、ConcurrentHashMap 集合框架底层数据结构Collection List Arraylist： Object数组 Vector： Object数组 LinkedList： 双向循环链表 Set HashSet（无序，唯一）：基于 HashMap 实现的，底层采用 HashMap 来保存元素 LinkedHashSet： LinkedHashSet 继承与 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 Hashmap 实现一样，不过还是有一点点区别的。 TreeSet（有序，唯一）： 红黑树(自平衡的排序二叉树。) Map HashMap： JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）.JDK1.8以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间 LinkedHashMap：LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。 HashTable： 数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的 TreeMap： 红黑树（自平衡的排序二叉树） 哪些集合类是线程安全的？ vector：就比arraylist多了个同步化机制（线程安全），因为效率较低，现在已经不太建议使用。在web应用中，特别是前台页面，往往效率（页面响应速度）是优先考虑的。 statck：堆栈类，先进后出。 hashtable：就比hashmap多了个线程安全。 enumeration：枚举，相当于迭代器。 Java集合的快速失败机制 “fail-fast”？是java集合的一种错误检测机制，当多个线程对集合进行结构上的改变的操作时，有可能会产生 fail-fast 机制。 例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出 ConcurrentModificationException 异常，从而产生fail-fast机制。 原因：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。 解决办法： 在遍历过程中，所有涉及到改变modCount值得地方全部加上synchronized。 使用CopyOnWriteArrayList来替换ArrayList 怎么确保一个集合不能被修改？可以使用 Collections. unmodifiableCollection(Collection c) 方法来创建一个只读集合，这样改变集合的任何操作都会抛出 Java. lang. UnsupportedOperationException 异常。 示例代码如下： 12345List&lt;String&gt; list = new ArrayList&lt;&gt;();list. add(&quot;x&quot;);Collection&lt;String&gt; clist = Collections. unmodifiableCollection(list);clist. add(&quot;y&quot;); // 运行时此行报错System. out. println(list. size()); Collection接口List接口迭代器 Iterator 是什么？Iterator 接口提供遍历任何 Collection 的接口。我们可以从一个 Collection 中使用迭代器方法来获取迭代器实例。迭代器取代了 Java 集合框架中的 Enumeration，迭代器允许调用者在迭代过程中移除元素。 Iterator 怎么使用？有什么特点？Iterator 使用代码如下： 123456List&lt;String&gt; list = new ArrayList&lt;&gt;();Iterator&lt;String&gt; it = list. iterator();while(it. hasNext()){ String obj = it. next(); System. out. println(obj);} Iterator 的特点是只能单向遍历，但是更加安全，因为它可以确保，在当前遍历的集合元素被更改的时候，就会抛出 ConcurrentModificationException 异常。 如何边遍历边移除 Collection 中的元素？边遍历边修改 Collection 的唯一正确方式是使用 Iterator.remove() 方法，如下： 12345Iterator&lt;Integer&gt; it = list.iterator();while(it.hasNext()){ *// do something* it.remove();} 一种最常见的错误代码如下： 123for(Integer i : list){ list.remove(i)} 运行以上错误代码会报 ConcurrentModificationException 异常。这是因为当使用 foreach(for(Integer i : list)) 语句时，会自动生成一个iterator 来遍历该 list，但同时该 list 正在被 Iterator.remove() 修改。Java 一般不允许一个线程在遍历 Collection 时另一个线程修改它。 Iterator 和 ListIterator 有什么区别？ Iterator 可以遍历 Set 和 List 集合，而 ListIterator 只能遍历 List。 Iterator 只能单向遍历，而 ListIterator 可以双向遍历（向前/后遍历）。 ListIterator 实现 Iterator 接口，然后添加了一些额外的功能，比如添加一个元素、替换一个元素、获取前面或后面元素的索引位置。 遍历一个 List 有哪些不同的方式？每种方法的实现原理是什么？Java 中 List 遍历的最佳实践是什么？遍历方式有以下几种： for 循环遍历，基于计数器。在集合外部维护一个计数器，然后依次读取每一个位置的元素，当读取到最后一个元素后停止。 迭代器遍历，Iterator。Iterator 是面向对象的一个设计模式，目的是屏蔽不同数据集合的特点，统一遍历集合的接口。Java 在 Collections 中支持了 Iterator 模式。 foreach 循环遍历。foreach 内部也是采用了 Iterator 的方式实现，使用时不需要显式声明 Iterator 或计数器。优点是代码简洁，不易出错；缺点是只能做简单的遍历，不能在遍历过程中操作数据集合，例如删除、替换。 最佳实践：Java Collections 框架中提供了一个 RandomAccess 接口，用来标记 List 实现是否支持 Random Access。 如果一个数据集合实现了该接口，就意味着它支持 Random Access，按位置读取元素的平均时间复杂度为 O(1)，如ArrayList。 如果没有实现该接口，表示不支持 Random Access，如LinkedList。 推荐的做法就是，支持 Random Access 的列表可用 for 循环遍历，否则建议用 Iterator 或 foreach 遍历。 说一下 ArrayList 的优缺点ArrayList的优点如下： ArrayList 底层以数组实现，是一种随机访问模式。ArrayList 实现了 RandomAccess 接口，因此查找的时候非常快。 ArrayList 在顺序添加一个元素的时候非常方便。 ArrayList 的缺点如下： 删除元素的时候，需要做一次元素复制操作。如果要复制的元素很多，那么就会比较耗费性能。 插入元素的时候，也需要做一次元素复制操作，缺点同上。 ArrayList 比较适合顺序添加、随机访问的场景。 如何实现数组和 List 之间的转换？ 数组转 List：使用 Arrays. asList(array) 进行转换。 List 转数组：使用 List 自带的 toArray() 方法。 代码示例： 123456789// list to arrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;123&quot;);list.add(&quot;456&quot;);list.toArray();// array to listString[] array = new String[]{&quot;123&quot;,&quot;456&quot;};Arrays.asList(array); ArrayList 和 LinkedList 的区别是什么？ 数据结构实现：ArrayList 是动态数组的数据结构实现，而 LinkedList 是双向链表的数据结构实现。 随机访问效率：ArrayList 比 LinkedList 在随机访问的时候效率要高，因为 LinkedList 是线性的数据存储方式，所以需要移动指针从前往后依次查找。 增加和删除效率：在非首尾的增加和删除操作，LinkedList 要比 ArrayList 效率要高，因为 ArrayList 增删操作要影响数组内的其他数据的下标。 内存空间占用：LinkedList 比 ArrayList 更占内存，因为 LinkedList 的节点除了存储数据，还存储了两个引用，一个指向前一个元素，一个指向后一个元素。 线程安全：ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 综合来说，在需要频繁读取集合中的元素时，更推荐使用 ArrayList，而在插入和删除操作较多时，更推荐使用 LinkedList。 补充：数据结构基础之双向链表 双向链表也叫双链表，是链表的一种，它的每个数据结点中都有两个指针，分别指向直接后继和直接前驱。所以，从双向链表中的任意一个结点开始，都可以很方便地访问它的前驱结点和后继结点。 ArrayList 和 Vector 的区别是什么？这两个类都实现了 List 接口（List 接口继承了 Collection 接口），他们都是有序集合 线程安全：Vector 使用了 Synchronized 来实现线程同步，是线程安全的，而 ArrayList 是非线程安全的。 性能：ArrayList 在性能方面要优于 Vector。 扩容：ArrayList 和 Vector 都会根据实际的需要动态的调整容量，只不过在 Vector 扩容每次会增加 1 倍，而 ArrayList 只会增加 50%。 Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。 Arraylist不是同步的，所以在不需要保证线程安全时时建议使用Arraylist。 插入数据时，ArrayList、LinkedList、Vector谁速度较快？阐述 ArrayList、Vector、LinkedList 的存储性能和特性？ArrayList、LinkedList、Vector 底层的实现都是使用数组方式存储数据。数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢。 Vector 中的方法由于加了 synchronized 修饰，因此 Vector 是线程安全容器，但性能上较ArrayList差。 LinkedList 使用双向链表实现存储，按序号索引数据需要进行前向或后向遍历，但插入数据时只需要记录当前项的前后项即可，所以 LinkedList 插入速度较快。 多线程场景下如何使用 ArrayList？ArrayList 不是线程安全的，如果遇到多线程场景，可以通过 Collections 的 synchronizedList 方法将其转换成线程安全的容器后再使用。例如像下面这样： 1234567List&lt;String&gt; synchronizedList = Collections.synchronizedList(list);synchronizedList.add(&quot;aaa&quot;);synchronizedList.add(&quot;bbb&quot;);for (int i = 0; i &lt; synchronizedList.size(); i++) { System.out.println(synchronizedList.get(i));} 为什么 ArrayList 的 elementData 加上 transient 修饰？ArrayList 中的数组定义如下： 1private transient Object[] elementData; 再看一下 ArrayList 的定义： 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 可以看到 ArrayList 实现了 Serializable 接口，这意味着 ArrayList 支持序列化。transient 的作用是说不希望 elementData 数组被序列化，重写了 writeObject 实现： 123456789101112private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{ *// Write out element count, and any hidden stuff* int expectedModCount = modCount; s.defaultWriteObject(); *// Write out array length* s.writeInt(elementData.length); *// Write out all elements in the proper order.* for (int i=0; i&lt;size; i++) s.writeObject(elementData[i]); if (modCount != expectedModCount) { throw new ConcurrentModificationException();} 每次序列化时，先调用 defaultWriteObject() 方法序列化 ArrayList 中的非 transient 元素，然后遍历 elementData，只序列化已存入的元素，这样既加快了序列化的速度，又减小了序列化之后的文件大小。 List 和 Set 的区别List , Set 都是继承自Collection 接口 List 特点：一个有序（元素存入集合的顺序和取出的顺序一致）容器，元素可以重复，可以插入多个null元素，元素都有索引。常用的实现类有 ArrayList、LinkedList 和 Vector。 Set 特点：一个无序（存入和取出顺序有可能不一致）容器，不可以存储重复元素，只允许存入一个null元素，必须保证元素唯一性。Set 接口常用实现类是 HashSet、LinkedHashSet 以及 TreeSet。 另外 List 支持for循环，也就是通过下标来遍历，也可以用迭代器，但是set只能用迭代，因为他无序，无法用下标来取得想要的值。 Set和List对比 Set：检索元素效率低下，删除和插入效率高，插入和删除不会引起元素位置改变。List：和数组类似，List可以动态增长，查找元素效率高，插入删除元素效率低，因为会引起其他元素位置改变 Set接口说一下 HashSet 的实现原理？HashSet 是基于 HashMap 实现的，HashSet的值存放于HashMap的key上，HashMap的value统一为PRESENT，因此 HashSet 的实现比较简单，相关 HashSet 的操作，基本上都是直接调用底层 HashMap 的相关方法来完成，HashSet 不允许重复的值。 HashSet如何检查重复？HashSet是如何保证数据不可重复的？向HashSet 中add ()元素时，判断元素是否存在的依据，不仅要比较hash值，同时还要结合equles 方法比较。HashSet 中的add ()方法会使用HashMap 的put()方法。 HashMap 的 key 是唯一的，由源码可以看出 HashSet 添加进去的值就是作为HashMap 的key，并且在HashMap中如果K/V相同时，会用新的V覆盖掉旧的V，然后返回旧的V。所以不会重复（ HashMap 比较key是否相等是先比较hashcode 再比较equals ）。 以下是HashSet 部分源码： 1234567891011private static final Object PRESENT = new Object();private transient HashMap&lt;E,Object&gt; map;public HashSet() { map = new HashMap&lt;&gt;();}public boolean add(E e) { // 调用HashMap的put方法,PRESENT是一个至始至终都相同的虚值 return map.put(e, PRESENT)==null;} hashCode（）与equals（）的相关规定： 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,则两个equals方法返回true 两个对象有相同的hashcode值，它们也不一定是相等的 综上，equals方法被覆盖过，则hashCode方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。 ==与equals的区别 ==是判断两个变量或实例是不是指向同一个内存空间 equals是判断两个变量或实例所指向的内存空间的值是不是相同 ==是指对内存地址进行比较 equals()是对字符串的内容进行比较 ==指引用是否相同 equals()指的是值是否相同 HashSet与HashMap的区别 HashMap HashSet 实现了Map接口 实现Set接口 存储键值对 仅存储对象 调用put（）向map中添加元素 调用add（）方法向Set中添加元素 HashMap使用键（Key）计算Hashcode HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性，如果两个对象不同的话，那么返回false HashMap相对于HashSet较快，因为它是使用唯一的键获取对象 HashSet较HashMap来说比较慢 QueueBlockingQueue是什么？Java.util.concurrent.BlockingQueue是一个队列，在进行检索或移除一个元素的时候，它会等待队列变为非空；当在添加一个元素时，它会等待队列中的可用空间。BlockingQueue接口是Java集合框架的一部分，主要用于实现生产者-消费者模式。我们不需要担心等待生产者有可用的空间，或消费者有可用的对象，因为它都在BlockingQueue的实现类中被处理了。Java提供了集中BlockingQueue的实现，比如ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue,、SynchronousQueue等。 在 Queue 中 poll()和 remove()有什么区别？ 相同点：都是返回第一个元素，并在队列中删除返回的对象。 不同点：如果没有元素 poll()会返回 null，而 remove()会直接抛出 NoSuchElementException 异常。 代码示例： 12345Queue&lt;String&gt; queue = new LinkedList&lt;String&gt;();queue. offer(&quot;string&quot;); // addSystem. out. println(queue. poll());System. out. println(queue. remove());System. out. println(queue. size()); Map接口说一下 HashMap 的实现原理？HashMap概述： HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 HashMap的数据结构： 在Java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。 HashMap 基于 Hash 算法实现的 当我们往Hashmap中put元素时，利用key的hashCode重新hash计算出当前对象的元素在数组中的下标 存储时，如果出现hash值相同的key，此时有两种情况。 如果key相同，则覆盖原始值； 如果key不同（出现冲突），则将当前的key-value放入链表中 获取时，直接找到hash值对应的下标，在进一步判断key是否相同，从而找到对应值。 理解了以上过程就不难明白HashMap是如何解决hash冲突的问题，核心就是使用了数组的存储方式，然后将冲突的key的对象放入链表中，一旦发现冲突就在链表中做进一步的对比。 需要注意Jdk 1.8中对HashMap的实现做了优化，当链表中的节点数据超过八个之后，该链表会转为红黑树来提高查询效率，从原来的O(n)到O(logn) HashMap在JDK1.7和JDK1.8中有哪些不同？HashMap的底层实现在Java中，保存数据有两种比较简单的数据结构：数组和链表。数组的特点是：寻址容易，插入和删除困难；链表的特点是：寻址困难，但插入和删除容易；所以我们将数组和链表结合在一起，发挥两者各自的优势，使用一种叫做拉链法的方式可以解决哈希冲突。 JDK1.8之前JDK1.8之前采用的是拉链法。拉链法：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。 JDK1.8之后相比于之前的版本，jdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。 JDK1.7 VS JDK1.8 比较JDK1.8主要解决或优化了一下问题： resize 扩容优化 引入了红黑树，目的是避免单条链表过长而影响查询效率，红黑树算法请参考 解决了多线程死循环问题，但仍是非线程安全的，多线程时可能会造成数据丢失问题。 不同 JDK 1.7 JDK 1.8 存储结构 数组 + 链表 数组 + 链表 + 红黑树 初始化方式 单独函数：inflateTable() 直接集成到了扩容函数resize()中 hash值计算方式 扰动处理 ：9次扰动 = 4次位运算 + 5次异或运算 扰动处理 ：2次扰动 = 1次位运算 + 1次异或运算 存放数据的规则 无冲突时，存放数组；冲突时，存放链表 无冲突时，存放数组；冲突 &amp; 链表长度 &lt; 8：存放单链表；冲突 &amp; 链表长度 &gt; 8：树化并存放红黑树 插入数据方式 头插法（先讲原位置的数据移到后1位，再插入数据到该位置） 尾插法（直接插入到链表尾部/红黑树） 扩容后存储位置的计算方式 全部按照原来方法进行计算（即hashCode -&gt;&gt; 扰动函数 -&gt;&gt; (h&amp;length-1)） 按照扩容后的规律计算（即扩容后的位置=原位置 or 原位置 + 旧容量） HashMap的put方法的具体流程？当我们put的时候，首先计算 key的hash值，这里调用了 hash方法，hash方法实际是让key.hashCode()与key.hashCode()&gt;&gt;&gt;16进行异或操作，高16bit补0，一个数和0异或不变，所以 hash 函数大概的作用就是：高16bit不变，低16bit和高16bit做了一个异或，目的是减少碰撞。按照函数注释，因为bucket数组大小是2的幂，计算下标index = (table.length - 1) &amp; hash，如果不做 hash 处理，相当于散列生效的只有几个低 bit 位，为了减少散列的碰撞，设计者综合考虑了速度、作用、质量之后，使用高16bit和低16bit异或来简单处理减少碰撞，而且JDK8中用了复杂度 O（logn）的树结构来提升碰撞下的性能。 putVal方法执行流程图 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public V put(K key, V value) { return putVal(hash(key), key, value, false, true);}static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);}//实现Map.put和相关方法final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤①：tab为空则创建 // table未初始化或者长度为0，进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 // (n - 1) &amp; hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中) if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶中已经存在元素 else { Node&lt;K,V&gt; e; K k; // 步骤③：节点key存在，直接覆盖value // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将第一个元素赋值给e，用e来记录 e = p; // 步骤④：判断该链为红黑树 // hash值不相等，即key不相等；为红黑树结点 // 如果当前元素类型为TreeNode，表示为红黑树，putTreeVal返回待存放的node, e可能为null else if (p instanceof TreeNode) // 放入树中 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 // 为链表结点 else { // 在链表最末插入结点 for (int binCount = 0; ; ++binCount) { // 到达链表的尾部 //判断该链表尾部指针是不是空的 if ((e = p.next) == null) { // 在尾部插入新结点 p.next = newNode(hash, key, value, null); //判断链表的长度是否达到转化红黑树的临界值，临界值为8 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //链表结构转树形结构 treeifyBin(tab, hash); // 跳出循环 break; } // 判断链表中结点的key值与插入的元素的key值是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 相等，跳出循环 break; // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表 p = e; } } //判断当前的key已经存在的情况下，再来一个相同的hash值、key值时，返回新来的value这个值 if (e != null) { // 记录e的value V oldValue = e.value; // onlyIfAbsent为false或者旧值为null if (!onlyIfAbsent || oldValue == null) //用新值替换旧值 e.value = value; // 访问后回调 afterNodeAccess(e); // 返回旧值 return oldValue; } } // 结构性修改 ++modCount; // 步骤⑥：超过最大容量就扩容 // 实际大小大于阈值则扩容 if (++size &gt; threshold) resize(); // 插入后回调 afterNodeInsertion(evict); return null;} ①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； ②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； ③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； ④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； ⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； ⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 HashMap的扩容操作是怎么实现的？①.在jdk1.8中，resize方法是在hashmap中的键值对大于阀值时或者初始化时，就调用resize方法进行扩容； ②.每次扩展的时候，都是扩展2倍； ③.扩展后Node对象的位置要么在原位置，要么移动到原偏移量两倍的位置。 在putVal()中，我们看到在这个函数里面使用到了2次resize()方法，resize()方法表示的在进行第一次初始化时会对其进行扩容，或者当该数组的实际大小大于其临界值值(第一次为12),这个时候在扩容的同时也会伴随的桶上面的元素进行重新分发，这也是JDK1.8版本的一个优化的地方，在1.7中，扩容之后需要重新去计算其Hash值，根据Hash值对其进行分发，但在1.8版本中，则是根据在同一个桶的位置中进行判断(e.hash &amp; oldCap)是否为0，重新进行hash分配后，该元素的位置要么停留在原始位置，要么移动到原始位置+增加的数组大小这个位置上 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table;//oldTab指向hash桶数组 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) {//如果oldCap不为空的话，就是hash桶数组不为空 if (oldCap &gt;= MAXIMUM_CAPACITY) {//如果大于最大容量了，就赋值为整数最大的阀值 threshold = Integer.MAX_VALUE; return oldTab;//返回 }//如果当前hash桶数组的长度在扩容后仍然小于最大容量 并且oldCap大于默认值16 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold 双倍扩容阀值threshold } // 旧的容量为0，但threshold大于零，代表有参构造有cap传入，threshold已经被初始化成最小2的n次幂 // 直接将该值赋给新的容量 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 无参构造创建的map，给出默认容量和threshold 16, 16*0.75 else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 新的threshold = 新的cap * 0.75 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; // 计算出新的数组长度后赋给当前成员变量table @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];//新建hash桶数组 table = newTab;//将新数组的值复制给旧的hash桶数组 // 如果原先的数组没有初始化，那么resize的初始化工作到此结束，否则进入扩容元素重排逻辑，使其均匀的分散 if (oldTab != null) { // 遍历新数组的所有桶下标 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { // 旧数组的桶下标赋给临时变量e，并且解除旧数组中的引用，否则就数组无法被GC回收 oldTab[j] = null; // 如果e.next==null，代表桶中就一个元素，不存在链表或者红黑树 if (e.next == null) // 用同样的hash映射算法把该元素加入新的数组 newTab[e.hash &amp; (newCap - 1)] = e; // 如果e是TreeNode并且e.next!=null，那么处理树中元素的重排 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // e是链表的头并且e.next!=null，那么处理链表中元素重排 else { // preserve order // loHead,loTail 代表扩容后不用变换下标，见注1 Node&lt;K,V&gt; loHead = null, loTail = null; // hiHead,hiTail 代表扩容后变换下标，见注1 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; // 遍历链表 do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) // 初始化head指向链表当前元素e，e不一定是链表的第一个元素，初始化后loHead // 代表下标保持不变的链表的头元素 loHead = e; else // loTail.next指向当前e loTail.next = e; // loTail指向当前的元素e // 初始化后，loTail和loHead指向相同的内存，所以当loTail.next指向下一个元素时， // 底层数组中的元素的next引用也相应发生变化，造成lowHead.next.next..... // 跟随loTail同步，使得lowHead可以链接到所有属于该链表的元素。 loTail = e; } else { if (hiTail == null) // 初始化head指向链表当前元素e, 初始化后hiHead代表下标更改的链表头元素 hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); // 遍历结束, 将tail指向null，并把链表头放入新数组的相应下标，形成新的映射。 if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab;} HashMap是怎么解决哈希冲突的？答：在解决这个问题之前，我们首先需要知道什么是哈希冲突，而在了解哈希冲突之前我们还要知道什么是哈希才行； 什么是哈希？Hash，一般翻译为“散列”，也有直接音译为“哈希”的，这就是把任意长度的输入通过散列算法，变换成固定长度的输出，该输出就是散列值（哈希值）；这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。 所有散列函数都有如下一个基本特性：根据同一散列函数计算出的散列值如果不同，那么输入值肯定也不同。但是，根据同一散列函数计算出的散列值如果相同，输入值不一定相同。 什么是哈希冲突？当两个不同的输入值，根据同一散列函数计算出相同的散列值的现象，我们就把它叫做碰撞（哈希碰撞）。 HashMap的数据结构在Java中，保存数据有两种比较简单的数据结构：数组和链表。数组的特点是：寻址容易，插入和删除困难；链表的特点是：寻址困难，但插入和删除容易；所以我们将数组和链表结合在一起，发挥两者各自的优势，使用一种叫做链地址法的方式可以解决哈希冲突： 这样我们就可以将拥有相同哈希值的对象组织成一个链表放在hash值所对应的bucket下，但相比于hashCode返回的int类型，我们HashMap初始的容量大小DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4（即2的四次方16）要远小于int类型的范围，所以我们如果只是单纯的用hashCode取余来获取对应的bucket这将会大大增加哈希碰撞的概率，并且最坏情况下还会将HashMap变成一个单链表，所以我们还需要对hashCode作一定的优化 hash()函数上面提到的问题，主要是因为如果使用hashCode取余，那么相当于参与运算的只有hashCode的低位，高位是没有起到任何作用的，所以我们的思路就是让hashCode取值出的高位也参与运算，进一步降低hash碰撞的概率，使得数据分布更平均，我们把这样的操作称为扰动，在JDK 1.8中的hash()函数如下： 1234static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);// 与自己右移16位进行异或运算（高低位异或）} 这比在JDK 1.7中，更为简洁，相比在1.7中的4次位运算，5次异或运算（9次扰动），在1.8中，只进行了1次位运算和1次异或运算（2次扰动）； JDK1.8新增红黑树 通过上面的链地址法（使用散列表）和扰动函数我们成功让我们的数据分布更平均，哈希碰撞减少，但是当我们的HashMap中存在大量数据时，加入我们某个bucket下对应的链表有n个元素，那么遍历时间复杂度就为O(n)，为了针对这个问题，JDK1.8在HashMap中新增了红黑树的数据结构，进一步使得遍历复杂度降低至O(logn)； 总结简单总结一下HashMap是使用了哪些方法来有效解决哈希冲突的： 1. 使用链地址法（使用散列表）来链接拥有相同hash值的数据；2. 使用2次扰动函数（hash函数）来降低哈希冲突的概率，使得数据分布更平均；3. 引入红黑树进一步降低遍历的时间复杂度，使得遍历更快； 能否使用任何类作为 Map 的 key？可以使用任何类作为 Map 的 key，然而在使用之前，需要考虑以下几点： 如果类重写了 equals() 方法，也应该重写 hashCode() 方法。 类的所有实例需要遵循与 equals() 和 hashCode() 相关的规则。 如果一个类没有使用 equals()，不应该在 hashCode() 中使用它。 用户自定义 Key 类最佳实践是使之为不可变的，这样 hashCode() 值可以被缓存起来，拥有更好的性能。不可变的类也可以确保 hashCode() 和 equals() 在未来不会改变，这样就会解决与可变相关的问题了。 为什么HashMap中String、Integer这样的包装类适合作为K？答：String、Integer等包装类的特性能够保证Hash值的不可更改性和计算准确性，能够有效的减少Hash碰撞的几率 都是final类型，即不可变性，保证key的不可更改性，不会存在获取hash值不同的情况 内部已重写了equals()、hashCode()等方法，遵守了HashMap内部的规范（不清楚可以去上面看看putValue的过程），不容易出现Hash值计算错误的情况； 如果使用Object作为HashMap的Key，应该怎么办呢？答：重写hashCode()和equals()方法 重写hashCode()是因为需要计算存储数据的存储位置，需要注意不要试图从散列码计算中排除掉一个对象的关键部分来提高性能，这样虽然能更快但可能会导致更多的Hash碰撞； 重写equals()方法，需要遵守自反性、对称性、传递性、一致性以及对于任何非null的引用值x，x.equals(null)必须返回false的这几个特性，目的是为了保证key在哈希表中的唯一性； HashMap为什么不直接使用hashCode()处理后的哈希值直接作为table的下标？答：hashCode()方法返回的是int整数类型，其范围为-(2 ^ 31)~(2 ^ 31 - 1)，约有40亿个映射空间，而HashMap的容量范围是在16（初始化默认值）~2 ^ 30，HashMap通常情况下是取不到最大值的，并且设备上也难以提供这么多的存储空间，从而导致通过hashCode()计算出的哈希值可能不在数组大小范围内，进而无法匹配存储位置； 那怎么解决呢？ HashMap自己实现了自己的hash()方法，通过两次扰动使得它自己的哈希值高低位自行进行异或运算，降低哈希碰撞概率也使得数据分布更平均； 在保证数组长度为2的幂次方的时候，使用hash()运算之后的值与运算（&amp;）（数组长度 - 1）来获取数组下标的方式进行存储，这样一来是比取余操作更加有效率，二来也是因为只有当数组长度为2的幂次方时，h&amp;(length-1)才等价于h%length，三来解决了“哈希值与数组大小范围不匹配”的问题； HashMap 的长度为什么是2的幂次方为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀，每个链表/红黑树长度大致相同。这个实现就是把数据存到哪个链表/红黑树中的算法。 这个算法应该如何设计呢？ 我们首先可能会想到采用%取余的操作来实现。但是，重点来了：“取余(%)操作中如果除数是2的幂次则等价于与其除数减一的与(&amp;)操作（也就是说 hash%length==hash&amp;(length-1)的前提是 length 是2的 n 次方；）。” 并且 采用二进制位操作 &amp;，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是2的幂次方。 那为什么是两次扰动呢？ 答：这样就是加大哈希值低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性&amp;均匀性，最终减少Hash冲突，两次就够了，已经达到了高位低位同时参与运算的目的； HashMap 与 HashTable 有什么区别？ 线程安全： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过 synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 效率： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它； 对Null key 和Null value的支持： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛NullPointerException。 初始容量大小和每次扩充容量大小的不同： ①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小。也就是说 HashMap 总是使用2的幂作为哈希表的大小，后面会介绍到为什么是2的幂次方。 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。 推荐使用：在 Hashtable 的类注释可以看到，Hashtable 是保留类不建议使用，推荐在单线程环境下使用 HashMap 替代，如果需要多线程使用则用 ConcurrentHashMap 替代。 如何决定使用 HashMap 还是 TreeMap？对于在Map中插入、删除和定位元素这类操作，HashMap是最好的选择。然而，假如你需要对一个有序的key集合进行遍历，TreeMap是更好的选择。基于你的collection的大小，也许向HashMap中添加元素会更快，将map换为TreeMap进行有序key的遍历。 HashMap 和 ConcurrentHashMap 的区别 ConcurrentHashMap对整个桶数组进行了分割分段(Segment)，然后在每一个分段上都用lock锁进行保护，相对于HashTable的synchronized锁的粒度更精细了一些，并发性能更好，而HashMap没有锁机制，不是线程安全的。（JDK1.8之后ConcurrentHashMap启用了一种全新的方式实现,利用CAS算法。） HashMap的键值对允许有null，但是ConCurrentHashMap都不允许。 ConcurrentHashMap 和 Hashtable 的区别？ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。 底层数据结构： JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式（重要）： ① 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。（默认分配16个Segment，比Hashtable效率提高16倍。） 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 两者的对比图： HashTable: JDK1.7的ConcurrentHashMap： JDK1.8的ConcurrentHashMap（TreeBin: 红黑二叉树节点 Node: 链表节点）： 答：ConcurrentHashMap 结合了 HashMap 和 HashTable 二者的优势。HashMap 没有考虑同步，HashTable 考虑了同步的问题。但是 HashTable 在每次同步执行时都要锁住整个结构。 ConcurrentHashMap 锁的方式是稍微细粒度的。 ConcurrentHashMap 底层具体实现知道吗？实现原理是什么？JDK1.7 首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 在JDK1.7中，ConcurrentHashMap采用Segment + HashEntry的方式进行实现，结构如下： 一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。 该类包含两个静态内部类 HashEntry 和 Segment ；前者用来封装映射表的键值对，后者用来充当锁的角色； Segment 是一种可重入的锁 ReentrantLock，每个 Segment 守护一个HashEntry 数组里得元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 锁。 JDK1.8 在JDK1.8中，放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现，synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。 结构如下： 附加源码，有需要的可以看看 插入元素过程（建议去看看源码）： 如果相应位置的Node还没有初始化，则调用CAS插入相应的数据； 1234else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin} 如果相应位置的Node不为空，且当前该节点不处于移动状态，则对该节点加synchronized锁，如果该节点的hash不小于0，则遍历链表更新节点或插入新节点； 12345678910111213141516171819if (fh &gt;= 0) { binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) { pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; } }} 如果该节点是TreeBin类型的节点，说明是红黑树结构，则通过putTreeVal方法往红黑树中插入节点；如果binCount不为0，说明put操作对数据产生了影响，如果当前链表的个数达到8个，则通过treeifyBin方法转化为红黑树，如果oldVal不为空，说明是一次更新操作，没有对元素个数产生影响，则直接返回旧值； 如果插入的是一个新节点，则执行addCount()方法尝试更新元素个数baseCount； 辅助工具类Array 和 ArrayList 有何区别？ Array 可以存储基本数据类型和对象，ArrayList 只能存储对象。 Array 是指定固定大小的，而 ArrayList 大小是自动扩展的。 Array 内置方法没有 ArrayList 多，比如 addAll、removeAll、iteration 等方法只有 ArrayList 有。 对于基本类型数据，集合使用自动装箱来减少编码工作量。但是，当处理固定大小的基本数据类型的时候，这种方式相对比较慢。 如何实现 Array 和 List 之间的转换？ Array 转 List： Arrays. asList(array) ； List 转 Array：List 的 toArray() 方法。 comparable 和 comparator的区别？ comparable接口实际上是出自java.lang包，它有一个 compareTo(Object obj)方法用来排序 comparator接口实际上是出自 java.util 包，它有一个compare(Object obj1, Object obj2)方法用来排序 一般我们需要对一个集合使用自定义排序时，我们就要重写compareTo方法或compare方法，当我们需要对某一个集合实现两种排序方式，比如一个song对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写compareTo方法和使用自制的Comparator方法或者以两个Comparator来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的Collections.sort(). Collection 和 Collections 有什么区别？ java.util.Collection 是一个集合接口（集合类的一个顶级接口）。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式，其直接继承接口有List与Set。 Collections则是集合类的一个工具类/帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。 TreeMap 和 TreeSet 在排序时如何比较元素？Collections 工具类中的 sort()方法如何比较元素？TreeSet 要求存放的对象所属的类必须实现 Comparable 接口，该接口提供了比较元素的 compareTo()方法，当插入元素时会回调该方法比较元素的大小。TreeMap 要求存放的键值对映射的键必须实现 Comparable 接口从而根据键对元素进 行排 序。 Collections 工具类的 sort 方法有两种重载的形式， 第一种要求传入的待排序容器中存放的对象比较实现 Comparable 接口以实现元素的比较； 第二种不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是Comparator 接口的子类型（需要重写 compare 方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小的算法，也是对回调模式的应用（Java 中对函数式编程的支持）。","link":"/%E9%9B%86%E5%90%88%E5%AE%B9%E5%99%A8-%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"},{"title":"升级Hexo以及主题步骤","text":"升级Hexo 比如本次更新为7.3.0 查看最新hexo生成的依赖版本在其他目录重新初始化hexo项目 12$ npm install hexo@latest$ npx hexo init test 查看test目录里面的package.json，比较里面的依赖版本，有没有大版本升级（比如从0.0.1升级到了2.0.0）就需要在老项目改一下前版本号 执行npm命令查看依赖版本可以通过npm查看依赖版本来进一步确认是否需要升级 1234$ npm outdated$ npm uptate$ rm -f node_modules package-lock.json$ npm install 升级主题直接到theme目录里面git升级即可 123456789$ cd theme/XXXX$ git checkout master$ git fetch upstream$ git merge upstream$ git fetch --tags$ git merge upstream --tags$ git checkout develop$ git merge TAG$ git push origin 升级完成重新生成静态文件 启动 12$ npx hexo clean$ npx hexo g &amp;&amp; npx hexo d","link":"/%E5%8D%87%E7%BA%A7Hexo%E4%BB%A5%E5%8F%8A%E4%B8%BB%E9%A2%98%E6%AD%A5%E9%AA%A4/"},{"title":"JVM-009-运行时数据区-虚拟机栈-方法返回地址（Return Address）","text":"定义 存放调用方法（栈帧）的 pc寄存器的值 一个方法的结束，有两种方式： 正常执行完成 出现未处理的异常，非正常退出 无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的pc计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定，栈帧中一般不会保存这部分信息。 本质上，方法的退出就是当前栈帧出栈的过程。此时，需要恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去。 正常完成出口和异常完成出口的区别在于：通过异常完成出口退出的不会给他的上层调用者产生任何的返回值。 当一个方法开始执行后，只有两种方式可以退出这个方法： 正常完成出口含义执行引擎遇到任意一个方法返回的字节码指令（return），会有返回值传递给上层的方法调用者，简称正常完成出口； 返回指令一个方法在正常调用完成之后，究竟需要使用哪一个返回指令，还需要根据方法返回值的实际数据类型而定。 在字节码指令中，返回指令包含： ireturn：当返回值是boolean，byte，char，short和int类型时使用 lreturn：Long类型 freturn：Float类型 dreturn：Double类型 areturn：引用类型 return：返回值类型为void的方法、实例初始化方法、类和接口的初始化方法 异常完成出口含义在方法执行过程中遇到异常（Exception），并且这个异常没有在方法内进行处理，也就是只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，简称异常完成出口。 异常处理表方法执行过程中，抛出异常时的异常处理，存储在一个异常处理表，方便在发生异常的时候找到处理异常的代码 异常处理表： 反编译字节码文件，可得到 Exception table from ：字节码指令起始地址 to ：字节码指令结束地址 target ：出现异常跳转至地址为 19 的指令执行 type ：捕获异常的类型","link":"/JVM-009-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88-%E6%96%B9%E6%B3%95%E8%BF%94%E5%9B%9E%E5%9C%B0%E5%9D%80%EF%BC%88Return-Address%EF%BC%89/"},{"title":"JVM-011-运行时数据区-虚拟机栈-相关面试题","text":"第一题举例栈溢出的情况？（StackOverFlowError） 通过设置 -Xss 设置栈的大小后，当超出这个次数，就会报 SOF（StackOverFlowError） 设置动态时，超出整个物理内存的话，就是报 OOM（OutofMemoryError） 第二题调整栈大小，就能保证不出现溢出吗？ 不能，原因同上，只能保证SOF出现的几率小 第三题分配的栈内存越大越好吗？ 不是的，只是避免出现内存溢出的出现的较早。 第四题垃圾回收是否会涉及到虚拟机栈？ 不涉及 位置 是否有内存溢出Error 垃圾回收是否存在GC PC寄存器 无 不存在 虚拟机栈 有，SOF，OOM 不存在 本地方法栈(在HotSpot的实现中和虚拟机栈一样) 有，SOF，OOM 不存在 堆 有，OOM 存在 方法区 有，OOM 存在 第五题方法中定义的局部变量是否线程安全？ 如果对象是在内部产生，并在内部消亡，没有返回到外部，那么它就是线程安全的，反之则是线程不安全的。 具体问题具体分析 如果只有一个线程才可以操作此数据，则必是线程安全的。 如果有多个线程操作此数据，则此数据是共享数据。如果不考虑同步机制的话，会存在线程安全问题。 例如： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 面试题： * 方法中定义的局部变量是否线程安全？具体情况具体分析 * * 何为线程安全？ * 如果只有一个线程才可以操作此数据，则必是线程安全的。 * 如果有多个线程操作此数据，则此数据是共享数据。如果不考虑同步机制的话，会存在线程安全问题。 */public class StringBuilderTest { int num = 10; //s1的声明方式是线程安全的（只在方法内部用了） public static void method1(){ //StringBuilder:线程不安全 StringBuilder s1 = new StringBuilder(); s1.append(&quot;a&quot;); s1.append(&quot;b&quot;); //... } //sBuilder的操作过程：是线程不安全的（作为参数传进来，可能被其它线程操作） public static void method2(StringBuilder sBuilder){ sBuilder.append(&quot;a&quot;); sBuilder.append(&quot;b&quot;); //... } //s1的操作：是线程不安全的（有返回值，可能被其它线程操作） public static StringBuilder method3(){ StringBuilder s1 = new StringBuilder(); s1.append(&quot;a&quot;); s1.append(&quot;b&quot;); return s1; } //s1的操作：是线程安全的（s1自己消亡了，最后返回的只是s1.toString的一个新对象） public static String method4(){ StringBuilder s1 = new StringBuilder(); s1.append(&quot;a&quot;); s1.append(&quot;b&quot;); return s1.toString(); } public static void main(String[] args) { StringBuilder s = new StringBuilder(); new Thread(() -&gt; { s.append(&quot;a&quot;); s.append(&quot;b&quot;); }).start(); method2(s); }}","link":"/JVM-011-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88-%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"title":"JVM-010-运行时数据区-虚拟机栈-一些附加信息","text":"介绍 栈帧中还允许携带与Java虚拟机实现相关的一些附加信息。例如：对程序调试提供支持的信息。","link":"/JVM-010-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88-%E4%B8%80%E4%BA%9B%E9%99%84%E5%8A%A0%E4%BF%A1%E6%81%AF/"},{"title":"JVM-012-本地方法区(本地方法接口和本地方法库)","text":"定义使用 native 关键字修饰的方法，就叫做本地方法。 本地方法区也叫本地方法接口或者本地方法库。简单地讲，一个本地方法（Native Method）是一个Java调用非Java代码的接囗。一个Native Method是这样一个Java方法：该方法的实现由非Java语言实现，比如C。这个特征并非Java所特有，很多其它的编程语言都有这一机制，比如在C++中，你可以用extern 告知C++编译器去调用一个C的函数。 “A native method is a Java method whose implementation is provided by non-java code.”（本地方法是一个非Java的方法，它的具体实现是非Java代码的实现） 在定义一个native method 时，并不提供实现体（有些像定义一个Java interface），因为其实现体是由非java语言在外面实现的。 本地接口的作用是融合不同的编程语言为Java所用，它的初衷是融合C/C++程序。 例如： 注意：标识符native可以与其它java标识符连用，但是abstract除外 12345678910public class IHaveNatives { public native void Native1(int x); public native static long Native2(); private native synchronized float Native3(Object o); native void Native4(int[] ary) throws Exception; } 作用为什么要使用 Native Method？ Java使用起来非常方便，然而有些层次的任务用Java实现起来不容易，或者我们对程序的效率很在意时，问题就来了。 与Java环境外交互有时Java应用需要与Java外面的硬件环境交互，这是本地方法存在的主要原因。你可以想想Java需要与一些底层系统，如操作系统或某些硬件交换信息时的情况。本地方法正是这样一种交流机制：它为我们提供了一个非常简洁的接口，而且我们无需去了解Java应用之外的繁琐的细节。 与操作系统的交互 JVM支持着Java语言本身和运行时库，它是Java程序赖以生存的平台，它由一个解释器（解释字节码）和一些连接到本地代码的库组成。 然而不管怎样，它毕竟不是一个完整的系统，它经常依赖于一底层系统的支持。这些底层系统常常是强大的操作系统。 通过使用本地方法，我们得以用Java实现了jre的与底层系统的交互，甚至JVM的一些部分就是用C写的。 还有，如果我们要使用一些Java语言本身没有提供封装的操作系统的特性时，我们也需要使用本地方法。 Sun’s Java Sun的解释器是用C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分是用Java实现的，它也通过一些本地方法与外界交互。 例如：类java.lang.Thread的setPriority()方法是用Java实现的，但是它实现调用的是该类里的本地方法setPriority0()。这个本地方法是用C实现的，并被植入JVM内部在Windows 95的平台上，这个本地方法最终将调用Win32 setpriority() API。这是一个本地方法的具体实现由JVM直接提供，更多的情况是本地方法由外部的动态链接库（external dynamic link library）提供，然后被JVM调用。 本地方法的现状目前该方法使用的越来越少了，除非是与硬件有关的应用，比如通过Java程序驱动打印机或者Java系统管理生产设备，在企业级应用中已经比较少见。因为现在的异构领域间的通信很发达，比如可以使用Socket通信，也可以使用Web Service等等，不多做介绍。","link":"/JVM-012-%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E5%8C%BA-%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%8E%A5%E5%8F%A3%E5%92%8C%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E5%BA%93/"},{"title":"JVM-013-运行时数据区-本地方法栈(Native Method Stack)","text":"定义 Java 虚拟机栈用于管理 Java 方法的调用，而本地方法栈用于管理本地方法的调用。 底层 本地方法栈，也是线程私有的。 允许被实现成固定或者是可动态扩展的内存大小（在内存溢出方面和虚拟机栈相同） 如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java虚拟机将会抛出一个stackoverflowError 异常。 如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么Java虚拟机将会抛出一个outofMemoryError异常。 本地方法一般是使用C语言或C++语言实现的。 它的具体做法是Native Method Stack中登记native方法，在Execution Engine 执行时加载本地方法库。 使用说明 当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。 本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区 它甚至可以直接使用本地处理器中的寄存器 直接从本地内存的堆中分配任意数量的内存 并不是所有的JVM都支持本地方法。因为Java虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。如果JVM产品不打算支持native方法，也可以无需实现本地方法栈。 JVM 在调用 native 方法时，通常会在虚拟机栈中创建一个特殊的栈帧，通常用于保存局部变量和返回地址，但不涉及 JVM 的局部变量表、操作数栈等结构，而是作为一个占位符，指向本地方法的实现。这些机制在本地代码执行中由底层平台的调用约定负责，而不是 JVM 的规范直接管理。 在Hotspot JVM中，直接将本地方法栈和虚拟机栈合二为一。","link":"/JVM-013-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88-Native-Method-Stack/"},{"title":"JVM-014-运行时数据区-堆(Heap)-堆的核心概念","text":"介绍 一个 JVM 实例只存在一个堆内存，堆也是 Java 内存管理的核心区域。 Java 堆区在 JVM 启动的时候即被创建，其空间大小也就确定了。是 JVM 管理的最大一块内存空间。 堆内存的大小是可以调节的。 《Java虚拟机规范》规定，堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的。 所有的线程共享Java堆，在这里还可以划分线程私有的缓冲区（Thread Local Allocation Buffer，TLAB）。 《Java虚拟机规范》中对Java堆的描述是：所有的对象实例以及数组都应当在运行时分配在堆上。（The heap is the run-time data area from which memory for all class instances and arrays is allocated） 从实际使用角度看：“几乎”所有的对象实例都在堆分配内存，但并非全部。因为还有一些对象是在栈上分配的（逃逸分析，标量替换） 数组和对象可能永远不会存储在栈上（不一定），因为栈帧中保存引用，这个引用指向对象或者数组在堆中的位置。 在方法结束后，堆中的对象不会马上被移除，仅仅在垃圾收集的时候才会被移除。 如果堆中对象马上被回收，那么用户线程就会受到影响，因为有stop the word堆，是GC（Garbage Collection，垃圾收集器）执行垃圾回收的重点区域。 堆内存细分现代垃圾收集器大部分都基于分代收集理论设计，堆空间细分为： Java7 及之前堆内存逻辑上分为三部分：新生区+养老区+永久区 Young/New Generation Space 新生区 又被划分为Eden区和Survivor区 Old/Tenure generation space 养老区 Perm/Permanent Space 永久区 Java 8及之后堆内存逻辑上分为三部分：新生区+养老区+元空间 Young/New Generation Space 新生区 又被划分为Eden区和Survivor区 Old/Tenure generation space 养老区 Meta Space 元空间 Meta 新生区 &lt;–&gt; 新生代 &lt;–&gt; 年轻代 、 养老区 &lt;–&gt; 老年区 &lt;–&gt; 老年代、 永久区 &lt;–&gt; 永久代 堆空间内部结构 JDK7以及之前 JDK8以及之后","link":"/JVM-014-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E5%A0%86-Heap-%E5%A0%86%E7%9A%84%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/"},{"title":"JVM-015-运行时数据区-堆(Heap)-设置堆内存大小和OOM","text":"设置堆内存Java 堆区用于存储Java对象实例，那么堆的大小在JVM启动时就已经设定好了，可以通过选项”-Xms“和”-Xmx“来进行设置。 -Xms用于表示堆区的起始内存，等价于-XX:InitialHeapSize -Xmx则用于表示堆区的最大内存，等价于-XX:MaxHeapSize -Xms-Xms 用来设置堆空间（年轻代+老年代）的初始内存大小 -X 是jvm的运行参数 ms 是memory start 例如：-Xms1024、-Xms10K、-Xms20M、-Xms2G -Xmx-Xmx 用来设置堆空间（年轻代+老年代）的最大内存大小 例如：-Xmx1024、-Xmx10K、-Xmx20M、-Xmx2G 使用方法 一旦堆区中的内存大小超过 -Xmx 所指定的最大内存时，将会抛出OutofMemoryError异常。 通常会将-Xms和-Xmx两个参数配置相同的值，其目的是为了能够在Java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小，从而提高性能 假设两个不一样，初始内存小，最大内存大。在运行期间如果堆内存不够用了，会一直扩容直到最大内存。如果内存够用且多了，也会不断的缩容释放。频繁的扩容和释放造成不必要的压力，避免在GC之后调整堆内存给服务器带来压力。如果两个设置一样的就少了频繁扩容和缩容的步骤。内存不够了就直接报OOM 默认情况 初始内存大小：物理电脑内存大小除以64 最大内存大小：物理电脑内存大小除以4 代码： 123456789101112131415161718192021222324252627public class HeapSpaceInitial { public static void main(String[] args) { //返回Java虚拟机中的堆内存总量 long initialMemory = Runtime.getRuntime().totalMemory() / 1024 / 1024; //返回Java虚拟机试图使用的最大堆内存量 long maxMemory = Runtime.getRuntime().maxMemory() / 1024 / 1024; System.out.println(&quot;-Xms : &quot; + initialMemory + &quot;M&quot;); System.out.println(&quot;-Xmx : &quot; + maxMemory + &quot;M&quot;); System.out.println(&quot;系统内存大小为：&quot; + initialMemory * 64.0 / 1024 + &quot;G&quot;); System.out.println(&quot;系统内存大小为：&quot; + maxMemory * 4.0 / 1024 + &quot;G&quot;); try { Thread.sleep(1000000); } catch (InterruptedException e) { e.printStackTrace(); } }}==============-Xms : 245M-Xmx : 3641M系统内存大小为：15.3125G系统内存大小为：14.22265625G 手动设置以IDEA为例： 代码： 12345678910111213141516171819202122public class HeapSpaceInitial { public static void main(String[] args) { //返回Java虚拟机中的堆内存总量 long initialMemory = Runtime.getRuntime().totalMemory() / 1024 / 1024; //返回Java虚拟机试图使用的最大堆内存量 long maxMemory = Runtime.getRuntime().maxMemory() / 1024 / 1024; System.out.println(&quot;-Xms : &quot; + initialMemory + &quot;M&quot;); System.out.println(&quot;-Xmx : &quot; + maxMemory + &quot;M&quot;); try { Thread.sleep(1000000); } catch (InterruptedException e) { e.printStackTrace(); } }}==============-Xms : 575M-Xmx : 575M 少25M的原因如下： 查看设置的参数通过命令行(jps / jstat)查看 先查到进程id(通过 jps 命令) 123$ jps13237 HeapSpaceInitial13339 Jps 在查看内存分配情况（通过 jstat 命令） 123$ jstat -gc 13237 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 25600.0 25600.0 0.0 0.0 153600.0 15360.5 409600.0 0.0 4480.0 781.5 384.0 76.6 0 0.000 0 0.000 0.000 字段解释： 字段 含义 示例值 S0C 年轻代的 S0 区总容量（单位：KB）。 25600 KB（25 MB） S1C 年轻代的 S1 区总容量（单位：KB）。 25600 KB（25 MB） S0U 年轻代的 S0 区已使用的内存（单位：KB）。 0 KB S1U 年轻代的 S1 区已使用的内存（单位：KB）。 0 KB EC 年轻代的 Eden 区总容量（单位：KB）。 153600 KB（150 MB） EU 年轻代的 Eden 区已使用的内存（单位：KB）。 15360.5 KB（15 MB） OC 老年代（Old Generation）总容量（单位：KB）。 409600 KB（400 MB） OU 老年代（Old Generation）已使用的内存（单位：KB）。 0 KB MC 元空间（Metaspace）的总容量（单位：KB）。 4480 KB（4.4 MB） MU 元空间（Metaspace）已使用的内存（单位：KB）。 781.5 KB CCSC 压缩类空间（Compressed Class Space）的总容量（单位：KB）。 384 KB CCSU 压缩类空间（Compressed Class Space）已使用的内存（单位：KB）。 76.6 KB YGC Young Generation 的 GC 次数，即 Minor GC 的次数。 0 次 YGCT Young Generation 的 GC 总时间，以秒为单位。 0.000 秒 FGC Full GC 的次数，即对整个堆（Young + Old Generation）的垃圾回收次数。 0 次 FGCT Full GC 的总时间，以秒为单位。 0.000 秒 GCT 垃圾回收的总时间，包括 Minor GC 和 Full GC 的时间（单位：秒）。 0.000 秒 计算年轻代和老年代（其中年轻代的S0区和S1区两个只有一个能使用，另一个用不了），所以： 25600+25600+153600+409600 = 614400K 614400 /1024 = 600M 25600+153600+409600 = 588800K 588800 /1024 = 575M 通过JVM参数(-XX:+PrintGCDetails)查看意思是：程序执行完后打印 GC 过程中的细节 代码： 12345678910111213141516171819202122232425public class HeapSpaceInitial { public static void main(String[] args) { //返回Java虚拟机中的堆内存总量 long initialMemory = Runtime.getRuntime().totalMemory() / 1024 / 1024; //返回Java虚拟机试图使用的最大堆内存量 long maxMemory = Runtime.getRuntime().maxMemory() / 1024 / 1024; System.out.println(&quot;-Xms : &quot; + initialMemory + &quot;M&quot;); System.out.println(&quot;-Xmx : &quot; + maxMemory + &quot;M&quot;); }}==============-Xms : 575M-Xmx : 575MHeap PSYoungGen total 179200K, used 9216K [0x00000007b3800000, 0x00000007c0000000, 0x00000007c0000000) eden space 153600K, 6% used [0x00000007b3800000,0x00000007b41001a0,0x00000007bce00000) from space 25600K, 0% used [0x00000007be700000,0x00000007be700000,0x00000007c0000000) to space 25600K, 0% used [0x00000007bce00000,0x00000007bce00000,0x00000007be700000) ParOldGen total 409600K, used 0K [0x000000079a800000, 0x00000007b3800000, 0x00000007b3800000) object space 409600K, 0% used [0x000000079a800000,0x000000079a800000,0x00000007b3800000) Metaspace used 3075K, capacity 4496K, committed 4864K, reserved 1056768K class space used 328K, capacity 388K, committed 512K, reserved 1048576K 分析方法同上。 手动模拟OOM代码： 1234567891011121314151617181920212223242526package com.buubiu;import java.util.ArrayList;import java.util.Random;public class OOMTest { public static void main(String[] args) { ArrayList&lt;Picture&gt; list = new ArrayList&lt;&gt;(); while(true){ try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } list.add(new Picture(new Random().nextInt(1024 * 1024))); } }}class Picture{ private byte[] pixels; public Picture(int length) { this.pixels = new byte[length]; }} 设置堆内存 -Xms600m -Xmx600m 输出结果： 123Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at com.buubiu.Picture.&lt;init&gt;(OOMTest.java:24) at com.buubiu.OOMTest.main(OOMTest.java:15) 观察堆内存变化 原因：模拟的大对象导致堆内存溢出","link":"/JVM-015-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E5%A0%86-Heap-%E8%AE%BE%E7%BD%AE%E5%A0%86%E5%86%85%E5%AD%98%E5%A4%A7%E5%B0%8F%E5%92%8COOM/"},{"title":"JVM-016-运行时数据区-堆(Heap)-年轻代和老年代","text":"定义 存储在 JVM 中的 Java 对象可以被划分为两类： 一类是生命周期较短的瞬时对象，这类对象的创建和消亡都非常迅速 另外一类对象的生命周期却非常长，在某些极端的情况下还能与 JVM 的生命周期保持一致。 Java 堆区进一步细分的话：可以分为 年轻代(YoungGen)和老年代(OldGen) 其中年轻代又可以划分为：Eden（伊甸园）空间与Survivor0（幸存者0）空间、Survivor1（幸存者1）空间（有时也叫做 from区、to区） 参数调整 注意：下面的参数开发中一般不会手动调 配置新生代与老年代在堆结构的占比 默认-XX:NewRatio=2，表示新生代占1，老年代占2，新生代占整个堆的1/3 可以修改 -XX:NewRatio=4，表示新生代占1，老年代占4，新生代占整个堆的1/5 该参数的实际值可以通过命令行 jinfo查看： 1234$ jps5596 NewRatioTest$ jinfo -flag NewRatio 5586-XX:NewRatio=2 或者通过 jvisualvm查看： 在HotSpot中，Eden空间和另外两个survivor空间缺省所占的比例是8 : 1 : 1 但是实际上通过上图可以看到：Eden 与 两个Survivor占比是：6:1:1(150:25:25) 原因：默认有个自适应的内存分配策略，我们可以关闭这个参数，但是也不管用 参数为：-XX:-UseAdaptiveSizePolicy：减号表示关闭 要想真正的8:1:1，必须手动指定一下分配参数值：-XX:SurvivorRatio=8 若在 JDK 7 中开启了 -XX:+UseAdaptiveSizePolicy，JVM 会动态调整 JVM 堆中各个区域的大小以及进入老年代的年龄 此时 –XX:NewRatio 和 -XX:SurvivorRatio 将会失效，而 JDK 8 是默认开启-XX:+UseAdaptiveSizePolicy 在 JDK 8中，不要随意关闭-XX:+UseAdaptiveSizePolicy，除非对堆内存的划分有明确的规划 每次 GC 后都会重新计算 Eden、From Survivor、To Survivor 的大小 几乎所有的Java对象都是在Eden区被new出来的，除非这个对象非常大，超过 Eden区的大小了，可能会直接进入 老年代区 了。 绝大部分的 Java 对象的销毁都在新生代进行了。 IBM公司的专门研究表明，新生代中80%的对象都是“朝生夕死”的。 可以使用选项-Xmn设置新生代最大内存大小，但这个参数一般使用默认值就可以了。 当既设置 -XX:NewRatio，又设置 -Xmn时，以 -Xmn为生效。","link":"/JVM-016-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E5%A0%86-Heap-%E5%B9%B4%E8%BD%BB%E4%BB%A3%E5%92%8C%E8%80%81%E5%B9%B4%E4%BB%A3/"},{"title":"JVM-017-运行时数据区-堆(Heap)-对象分配的过程","text":"概述 为新对象分配内存是一件非常严谨和复杂的任务，JVM的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法与内存回收算法密切相关，所以还需要考虑GC执行完内存回收后是否会在内存空间中产生内存碎片。 对象分配过程对象分配的一般过程 new 的对象先放伊甸园区。此区有大小限制。 当伊甸园的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对伊甸园区进行垃圾回收，这个垃圾回收操作叫做 Minor GC 或者 YGC(Young GC) ，目的是将伊甸园区的不再被其他对象所引用的对象进行销毁；再加载新的对象放到伊甸园区。 然后将伊甸园中的剩余对象移动到幸存者0区（或者叫做 to 区），此时把对象的年龄标记为1 我们把幸存者区为空的区叫做 to 区，非空的叫做 from 区 最初始的话，会随机选个区为to区 总之：谁是空区谁就是to区 ​ 所以说：在 YGC 后，伊甸园区肯定是空的了 如果下一次伊甸园区又满了，再次触发垃圾回收YGC，此时除了将伊甸园中的剩余对象移动到幸存者1区外（这些对象的年龄记为1），还有上次幸存下来的放到幸存者0区的，如果没有被回收，也会被放到幸存者1区（这些对象的年龄记为2）。 如果再次经历垃圾回收，此时会重新放回幸存者0区，接着再去幸存者1区，反复移动 当幸存者区的对象的年龄超过15，或者说反复移动15次以上，JVM 就会把这些对象晋升（Promotion）到老年代。 这个 15 次数可以设置，默认是 15 次。 可以设置参数： -XX:MaxTenuringThreshold=&lt;N&gt;进行设置。 不过，设置的值应该在 0-15，否则会爆出以下错误： 1MaxTenuringThreshold of 20 is invalid; must be between 0 and 15 为什么年龄只能是 0-15? 因为记录年龄的区域在对象头中，这个区域的大小通常是 4 位。这 4 位可以表示的最大二进制数字是 1111，即十进制的 15。因此，对象的年龄被限制为 0 到 15。 在老年代，相对悠闲。当老年代内存不足时，会再次触发GC（Major GC 或者 OGC(Old GC)），进行老年代的内存清理。 若老年代执行了 Major GC 之后发现依然无法进行对象的保存，就会产生 OOM 异常。 1java.lang.OutOfMemoryError: Java heap space 总结： 针对幸存者 s0,s1 区：复制之后有交换，谁空谁是 to。 关于垃圾回收：频繁在年轻代收集，很少在老年代收集，几乎不在 永久区/元空间 收集。 对象分配的特殊情况 如果来了一个新对象，先看看 Eden 是否放的下？ 如果 Eden 放得下，则直接放到 Eden 区 如果 Eden 放不下，则触发 Minor GC(YGC) ，执行垃圾回收，看看还能不能放下？ 将对象放到老年区有两种情况： 如果 Eden 执行了 Minor GC(YGC) 还是无法放不下该对象，说明是超大对象，直接放到老年代 那万一老年代都放不下，则先触发 FGC|Major GC(Old GC)(这里把FGC和OGC混着用了)，再看看能不能放下，放得下最好，但如果还是放不下，那只能报 OOM 如果 Eden 区满了，将对象往幸存区复制时，发现幸存区放不下，那只能让他们直接晋升至老年区 对象分配示意图 JVM调试工具 JDK命令行 Eclipse：Memory Analyzer Tool Jconsole Visual VM（实时监控，推荐） Jprofiler（IDEA插件） Java Flight Recorder（实时监控） GCViewer GCEasy Minor GC、Major GC、Full GCJVM 在进行 GC 时，并非每次都对上面三个内存（新生代、老年代和方法区（永久代））区域一起回收的，大部分时候回收的都是指新生代。 针对Hotspot VM的实现，它里面的GC按照回收区域又分为两大种类型：一种是部分收集（Partial GC），一种是整堆收集（Full GC） 部分收集（Partial GC）定义：不是完整收集整个Java堆的垃圾收集。其中又分为： 新生代收集（Minor GC/Young GC）：只是新生代（Eden，s0，s1）的垃圾收集 老年代收集（Major GC/Old GC）：只是老年代的圾收集。 目前，只有CMS GC会有单独收集老年代的行为。 注意，很多时候Major GC会和Full GC混淆使用，需要具体分辨是老年代回收还是整堆回收。 混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集。 目前，只有 G1 GC 会有这种行为。 整堆收集（Full GC）定义：收集整个 Java 堆和方法区的垃圾收集。 GC策略的触发机制年轻代GC年轻代GC（Minor GC）触发机制： 当年轻代空间不足时，就会触发Minor GC，这里的年轻代满指的是Eden代满，Survivor满不会引发GC，在Eden区满的时候，会顺带触发s0区的GC。（每次Minor GC会清理年轻代的内存） 因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。这一定义既清晰又易于理解。 Minor GC会引发STW（Stop The World），暂停其它用户的线程，等垃圾回收结束，用户线程才恢复运行 老年代GC老年代GC（Major GC/Old GC/Full GC）触发机制： 指发生在老年代的 GC，对象从老年代消失时，就表示 Major Gc 或 Full GC 发生了 出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 Parallel Scavenge 收集器的收集策略里就有直接进行 MajorGC 的策略选择过程）。 Major GC 的速度一般会比 Minor GC 慢10倍以上，STW的时间更长。 如果 Major GC 后，内存还不足，就报 OOM 了。 Full GCFull GC 触发机制，有以下五种情况： 调用 System.gc() 时，系统建议执行 Full GC，但是不必然执行 老年代空间不足 方法区空间不足 通过 Minor GC 后进入老年代的平均大小大于老年代的可用内存 由 Eden 区、survivor space0（From Space）区向 survivor space1（To Space）区复制时，对象大小大于 To Space 可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 说明：Full GC 是开发或调优中尽量要避免的。这样STW时间会短一些 堆空间分代思想为什么要把Java堆分代？不分代就不能正常工作了吗？ 经研究，不同对象的生命周期不同。70%-99%的对象是临时对象。 新生代：有Eden、两块大小相同的survivor（又称为from/to或s0/s1）构成，to总为空。 老年代：存放新生代中经历多次GC仍然存活的对象。 其实不分代完全可以，分代的唯一理由就是优化GC性能。如果没有分代，那所有的对象都在一块，就如同把一个学校的人都关在一个教室。GC的时候要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而很多对象都是朝生夕死的，如果分代的话，把新创建的对象放到某一地方，当GC的时候先把这块存储“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。 为对象分配内存TLAB背景 堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据 由于对象实例的创建在JVM中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的 为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度 概述 TLAB：Thread Local Allocation Buffer 从内存模型而不是垃圾收集的角度，对Eden区域继续进行划分，JVM为每个线程分配了一个私有缓存区域，它包含在Eden空间内。 多线程同时分配内存时，使用TLAB可以避免一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此我们可以将这种内存分配方式称之为快速分配策略。 基本上所有OpenJDK衍生出来的JVM都提供了TLAB的设计。 使用说明 尽管不是所有的对象实例都能够在TLAB中成功分配内存，但JVM确实是将TLAB作为内存分配的首选。 在程序中，开发人员可以通过选项-XX:UseTLAB设置是否开启TLAB空间，默认是开启的。 默认情况下，TLAB空间的内存非常小，仅占有整个Eden空间的1%，当然我们可以通过选项-XX:TLABWasteTargetPercent设置TLAB空间所占用Eden空间的百分比大小。 一旦对象在TLAB空间分配内存失败时，JVM就会尝试着通过使用加锁机制确保数据操作的原子性，从而直接在Eden空间中分配内存。 TLAB分配过程如下： 对象分配总结 如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并将对象年龄设为1。 对象在Survivor区中每熬过一次MinorGC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁，其实每个JVM、每个GC都有所不同）时，就会被晋升到老年代 针对不同年龄段的对象分配策略（或对象提升(Promotion)规则如下所示： 优先分配到Eden 大对象直接分配到老年代 尽量避免程序中出现过多的大对象 长期存活的对象分配到老年代 动态对象年龄判断 Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累加，当累加到某个年龄时，所累加的大小超过了 Survivor 区的一半，则取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值 如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。 老年代空间分配担保 -XX:HandlePromotionFailure：（见下面解释） 堆空间常用参数设置总结官方文档：https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html -XX:+PrintFlagsInitial : 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal ：查看所有的参数的最终值（可能会存在修改，不再是初始值） 修改后显示的值会有一个冒号 := 具体查看某个参数的命令行指令：jinfo -flag SurvivorRatio 进程id -Xms：初始堆空间内存 （默认为物理内存的1/64） -Xmx：最大堆空间内存（默认为物理内存的1/4） -Xmn：设置新生代的大小。(初始值及最大值) -XX:NewRatio：配置新生代与老年代在堆结构的占比 -XX:SurvivorRatio：设置新生代中Eden和S0/S1空间的比例 如果S0/S1区分配的比较小的话，不合理，因为对象等不到年龄为15就会被送到老年代了，这样导致 Minor GC/YGC 失去意义了。 如果S0/S1区分配的比较大的话，也不合理，因为Eden区较小的话，则 Minor GC/YGC 出现的频率就会变高，而GC频率高的话，STW（用户线程停止操作）的总体时间也会高，最后会影响整体的性能。 -XX:MaxTenuringThreshold：设置新生代垃圾的最大年龄 -XX:+PrintGCDetails：输出详细的GC处理日志 打印gc简要信息：① -XX:+PrintGC 或者 ② -verbose:gc -XX:HandlePromotionFailure：是否设置空间分配担保 参数说明： 在发生Minor GC之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。 如果大于，则此次Minor GC是安全的，正常 Minor GC 即可。 但如果小于，则虚拟机会查看-XX:HandlePromotionFailure设置值是否允担保失败。 如果HandlePromotionFailure=true，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小。 如果大于，则尝试进行一次Minor GC，但这次Minor GC依然是有风险的；在这步，若小于了，则会进行 Old GC。 如果小于，则进行一次Full GC。 如果HandlePromotionFailure=false，则进行一次Full GC。 JDK 1.5 默认关闭，JDK 1.6 默认开启 在JDK6 Update 24之后，HandlePromotionFailure参数不会再影响到虚拟机的空间分配担保策略，观察openJDK中的源码变化，虽然源码中还定义了HandlePromotionFailure参数，但是在代码中已经不会再使用它。 JDK6 Update 24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升老年代的平均大小就会进行Minor GC，否则将进行Full GC。 在允许担保失败并尝试进行YoungGC后，可能会出现三种情况： ① YoungGC后，存活对象小于survivor大小，此时存活对象进入survivor区中 ② YoungGC后，存活对象大于survivor大小，但是小于老年大可用空间大小，此时直接进入老年代。 ③ YoungGC后，存活对象大于survivor大小，也大于老年大可用空间大小，老年代也放不下这些对象了，此时就会发生“Handle Promotion Failure”，就触发了 Full GC。如果 Full GC后，老年代还是没有足够的空间，此时就会发生OOM内存溢出了。","link":"/JVM-017-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E5%A0%86-Heap-%E5%AF%B9%E8%B1%A1%E5%88%86%E9%85%8D%E7%9A%84%E8%BF%87%E7%A8%8B/"},{"title":"JVM-018-运行时数据区-堆(Heap)-逃逸分析(Escape Analysis)","text":"背景 堆是分配对象的唯一选择么？ 在《深入理解Java虚拟机》中关于Java堆内存有这样一段描述： 随着JIT(及时编译器)编译期的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。 在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的常识。但是，有一种特殊情况，那就是如果经过逃逸分析（Escape Analysis）后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需在堆上分配内存，也无须进行垃圾回收了。这也是最常见的堆外存储技术。 此外，基于OpenJDK深度定制的TaoBao VM，其中创新的GCIH（GC invisible heap）技术实现off-heap，将生命周期较长的Java对象从heap中移至heap外，并且GC不能管理GCIH内部的Java对象，以此达到降低GC的回收频率和提升GC的回收效率的目的。 概述 如何将堆上的对象分配到栈，需要使用逃逸分析手段。 这是一种可以有效减少Java程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。 通过逃逸分析，Java Hotspot编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。 原理逃逸分析的基本行为就是分析对象动态作用域： 当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸。 当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为调用参数传递到其他地方中。 逃逸分析举例 没有发生逃逸的对象，则可以分配到栈（无线程安全问题）上，随着方法执行的结束，栈空间就被移除（也就无需GC） 123456public void my_method() { V v = new V(); // use v // .... v = null;} 下面代码中的 StringBuffer sb 发生了逃逸，不能在栈上分配 123456public static StringBuffer createStringBuffer(String s1, String s2) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb;} 如果想要StringBuffer sb不发生逃逸，可以这样写 123456public static String createStringBuffer(String s1, String s2) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb.toString();} 总结：如何快速的判断是否发生了逃逸分析，就看new的对象实体是否有可能在方法外被调用。 12345678910111213141516171819202122232425262728293031323334353637/** * 逃逸分析 */public class EscapeAnalysis { public EscapeAnalysis obj; /* 1. 方法返回值 方法返回EscapeAnalysis对象，发生逃逸 */ public EscapeAnalysis getInstance(){ return obj == null? new EscapeAnalysis() : obj; } /* 2. 给成员变量赋值 为成员属性赋值，发生逃逸 */ public void setObj(){ this.obj = new EscapeAnalysis(); } //思考：如果当前的obj引用声明为static的？仍然会发生逃逸。 /* 对象的作用域仅在当前方法中有效，没有发生逃逸 */ public void useEscapeAnalysis(){ EscapeAnalysis e = new EscapeAnalysis(); } /* 引用成员变量的值，发生逃逸 */ public void useEscapeAnalysis1(){ EscapeAnalysis e = getInstance(); //getInstance().xxx()同样会发生逃逸 }} 所以综上所述：开发中能使用局部变量的，就不要使用在方法外定义。 逃逸分析参数设置 在JDK 6u23（JDK 1.7） 版本之后，HotSpot中默认就已经开启了逃逸分析 如果使用的是较早的版本，开发人员则可以通过： 选项-XX:+DoEscapeAnalysis显式开启逃逸分析 通过选项-XX:+PrintEscapeAnalysis查看逃逸分析的筛选结果","link":"/JVM-018-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E5%A0%86-Heap-%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90-Escape-Analysis/"},{"title":"JVM-019-运行时数据区-堆(Heap)-逃逸分析-代码优化","text":"介绍使用逃逸分析，编译器可以对代码做如下优化： 栈上分配：将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会发生逃逸，对象可能是栈上分配的候选，而不是堆上分配 同步省略：如果一个对象被发现只有一个线程被访问到，那么对于这个对象的操作可以不考虑同步。 分离对象或标量替换：有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。 注意：逃逸分析只能在java服务器端的模式下才会开启，不过我们本地安装的java都是server端，从java 版本命令上可以看出： 栈上分配解释 JIT 编译器在编译期间根据逃逸分析的结果，发现如果一个对象并没有逃逸出方法的话，就可能被优化成栈上分配。分配完成后，继续在调用栈内执行，最后线程结束，栈空间被回收，局部变量对象也被回收。这样就无须进行垃圾回收了。 常见的非栈上分配的场景（即发生了逃逸） 给成员变量赋值、方法返回值、实例引用传递（所以我们可以在这三个场景进行优化，让对象未发生逃逸即可） 代码举例： 1234567891011121314151617181920212223242526272829303132/** * 逃逸分析 */public class EscapeAnalysis { public EscapeAnalysis obj; /* 1. 给成员变量赋值 给成员属性赋值，发生逃逸 */ public void setObj(){ this.obj = new EscapeAnalysis(); } /* 2. 方法返回值 方法返回EscapeAnalysis对象，发生逃逸 */ public EscapeAnalysis getInstance(){ return obj == null? new EscapeAnalysis() : obj; } /* 3. 实例引用传递 引用成员变量的值，发生逃逸 */ public void useEscapeAnalysis1(){ EscapeAnalysis e = getInstance(); //getInstance().xxx()同样会发生逃逸 }} Oracle Hotspot 并没有启用这一功能 例子代码： 123456789101112131415161718192021222324252627282930/** * 栈上分配测试 * -Xmx256m -Xms256m -XX:-DoEscapeAnalysis -XX:+PrintGCDetails */public class StackAllocation { public static void main(String[] args) { long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000000; i++) { alloc(); } // 查看执行时间 long end = System.currentTimeMillis(); System.out.println(&quot;花费的时间为： &quot; + (end - start) + &quot; ms&quot;); // 为了方便查看堆内存中对象个数，线程sleep try { Thread.sleep(1000000); } catch (InterruptedException e1) { e1.printStackTrace(); } } private static void alloc() { User user = new User();//未发生逃逸 } static class User { }} 未开启逃逸分析 修改JVM 参数为：-Xmx256m -Xms256m -XX:-DoEscapeAnalysis -XX:+PrintGCDetails 执行结果：发生了GC，并且时间为 52ms 开启逃逸分析 修改JVM 参数为：-Xmx256m -Xms256m -XX:+DoEscapeAnalysis -XX:+PrintGCDetails 执行结果：没有发生GC，并且时间为 4ms，因为user对象有大部分没有分配到堆空间中，伊甸园区根本就没有满。 同步省略（锁消除）解释 线程同步的代价是相当高的，同步的后果是降低并发性和性能。 在动态编译同步块的时候，JIT编译器可以借助逃逸分析来判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程。如果没有，那么JIT编译器在编译这个同步块的时候就会取消对这部分代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫同步省略，也叫锁消除。 例子代码1： 123456public void f() { Object hollis = new Object(); synchronized(hollis) { System.out.println(hollis); }} 代码中对hollis这个对象加锁，但是hollis对象的生命周期只在f()方法中，并不会被其他线程所访问到，所以在JIT编译阶段就会被优化掉，优化成： 代码2 1234public void f() { Object hellis = new Object(); System.out.println(hellis);} 查看代码1的字节码： 注意：字节码文件中并没有进行优化，可以看到加锁和释放锁的操作依然存在，同步省略操作是在解释运行时发生的 标量替换解释 标量（scalar）是指一个无法再分解成更小的数据的数据。Java中的原始数据类型就是标量。 相对的，那些还可以分解的数据叫做聚合量（Aggregate），Java中的对象就是聚合量，因为他可以分解成其他聚合量和标量。 在JIT阶段，如果经过逃逸分析，发现一个对象不会被外界访问，并且对象可以被进一步分解时，JVM 不会创建该对象，那么经过JIT优化，而会将该对象成员变量分解若干个被这个方法使用的成员变量所代替。这些代替的成员变量在栈帧或寄存器上分配空间。这个过程就是标量替换。 作用 可以大大减少堆内存的占用。因为一旦不需要创建对象了，那么就不再需要分配堆内存了。 标量替换为栈上分配提供了很好的基础。 参数设置-XX:+ElimilnateAllocations：开启了标量替换（默认打开），允许将对象打散分配在栈上。 例子代码： 123456789101112131415161718192021222324/** * 标量替换测试 */public class ScalarReplace { public static class User { public int id; public String name; } public static void alloc() { User user = new User();//未发生逃逸 user.id = 5; user.name = &quot;buubiu&quot;; } public static void main(String[] args) { long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000000; i++) { alloc(); } long end = System.currentTimeMillis(); System.out.println(&quot;花费的时间为： &quot; + (end - start) + &quot; ms&quot;); }} 未开启标量替换 设置 JVM 参数：-Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:-EliminateAllocations 执行结果： 开启标量替换 设置 JVM 参数：-Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:+EliminateAllocations 执行结果：时间缩短，并且没有发生GC 以上代码中，user 对象并没有逃逸出 alloc() 方法，并且 user 对象是可以拆解成标量的。那么，JIT 就不会直接创建 User 对象，而是直接使用两个标量 int id ，String name 来替代 User 对象。 1234private static void alloc() { int id = 5; String name = &quot;buubiu&quot;;} 逃逸分析并不是很成熟 关于逃逸分析的论文在1999年就已经发表了，但直到JDK1.6才有实现，而且这项技术到如今也并不是十分成熟的。 其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。 一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。 虽然这项技术并不十分成熟，但是它也是即时编译器优化技术中一个十分重要的手段。 注意到有一些观点，认为通过逃逸分析，JVM会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于JVM设计者的选择。据了解，Oracle Hotspot JVM中并未这么做，这一点在逃逸分析相关的文档里已经说明，所以可以明确在HotSpot虚拟机上，所有的对象实例都是创建在堆上。 目前很多书籍还是基于JDK7以前的版本，JDK已经发生了很大变化，intern字符串的缓存和静态变量曾经都被分配在永久代上，而永久代已经被元数据区取代。但是intern字符串缓存和静态变量并不是被转移到元数据区，而是直接在堆上分配，所以这一点同样符合前面一点的结论：对象实例都是分配在堆上。","link":"/JVM-019-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E5%A0%86-Heap-%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90-%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96/"},{"title":"JVM-020-运行时数据区-方法区(Method Area)-概述","text":"栈、堆、方法区的交互关系 方法区所在 JVM 中的位置： 三者之间是相互配合的关系，不是竞争关系。 从线程共享与否的角度来看： ThreadLocal：如何保证多个线程在并发环境下的安全性？典型场景就是数据库连接管理，以及会话管理。 从对象创建的代码上来看： Person 类的 .class 信息存放在方法区中 person 变量存放在 Java 栈的局部变量表中 真正的 person 对象存放在 Java 堆中 在 person 对象中，有个指针指向方法区中的 person 类型数据，表明这个 person 对象是用方法区中的 Person 类 new 出来的 从内存结构上来看： 对方法区的理解官方文档：https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5.4 《Java虚拟机规范》中明确说明：尽管所有的方法区在逻辑上是属于堆的一部分，但一些简单的实现可能不会选择去进行垃圾收集或者进行压缩。但对于HotSpotJVM而言，方法区还有一个别名叫做Non-Heap（非堆），目的就是要和堆分开。 所以，方法区可以看作是一块独立于Java堆的内存空间。 方法区主要存放的是 Class，而堆中主要存放的是实例化的对象 方法区（Method Area）与Java堆一样，是各个线程共享的内存区域。 方法区在JVM启动的时候被创建，并且它的实际的物理内存空间中和Java堆区一样都可以是不连续的。 方法区的大小，跟堆空间一样，可以选择固定大小或者可扩展。 方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机同样会抛出内存溢出错误：java.lang.OutofMemoryError:PermGen space(JDK8之前)或者java.lang.OutOfMemoryError:Metaspace(JDK8以及之后) 加载大量的第三方的jar包 Tomcat部署的工程过多（30~50个） 大量动态的生成反射类 关闭JVM就会释放这个区域的内存。 HotSpot方法区演进 在 JDK7 及以前，习惯上把方法区，称为永久代。JDK8开始，使用元空间取代了永久代。 本质上，方法区和永久代并不等价。仅是对Hotspot而言的可以看作等价。《Java虚拟机规范》对如何实现方法区，不做统一要求。例如：BEAJRockit / IBM J9 中不存在永久代的概念。 现在来看，当年使用永久代，不是好的idea。导致Java程序更容易 OOM（超过-XX:MaxPermsize上限） 而到了JDK8，终于完全废弃了永久代的概念，改用与JRockit、J9一样在本地内存中实现的元空间（Metaspace）来代替 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代最大的区别在于：元空间不在虚拟机设置的内存中，而是使用本地内存。 永久代、元空间二者并不只是名字变了，内部结构也调整了 根据《Java虚拟机规范》的规定，如果方法区无法满足新的内存分配需求时，将抛出OOM异常","link":"/JVM-020-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E6%96%B9%E6%B3%95%E5%8C%BA-Method-Area-%E6%A6%82%E8%BF%B0/"},{"title":"JVM-021-运行时数据区-方法区(Method Area)-设置方法区大小和OOM","text":"介绍方法区的大小不必是固定的，JVM可以根据应用的需要动态调整。 JDK7及以前 通过-XX:PermSize来设置永久代初始分配空间。默认值是20.75M 通过-XX:MaxPermSize来设定永久代最大可分配空间。32位机器默认是64M，64位机器默认是82M 当JVM加载的类信息容量超过了这个(MaxPermsize)值，会报异常OOM(OutofMemoryError:PermGen space)。 JDK8及之后 元数据区大小可以使用参数 -XX:MetaspaceSize 和 -XX:MaxMetaspaceSize 指定，替代上面原有的两个参数。 默认值依赖于平台： Windows下，-XX:MetaspaceSize 约为21M，-XX:MaxMetaspaceSize的值是-1，即没有限制。 Mac下，-XX:MetaspaceSize 也约为21M，-XX:MaxMetaspaceSize的值是-1，即没有限制。 与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常OutOfMemoryError:Metaspace -XX:MetaspaceSize：设置初始的元空间大小。对于一个 64位 的服务器端 JVM 来说，其默认的 -XX:MetaspaceSize值为21MB。这就是初始的高水位线，一旦触及这个水位线，Full GC将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。 如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁地GC，建议将-XX:MetaspaceSize设置为一个相对较高的值。 如何解决方法区的OOM 要解决OOM异常或heap space的异常，一般的手段是首先通过内存映像分析工具（如Eclipse Memory Analyzer）对dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory Overflow） 内存泄漏就是有大量的引用指向某些对象，但是这些对象以后不会使用了，但是因为它们还和GC ROOT有关联，所以导致以后这些对象也不会被回收，这就是内存泄漏的问题 如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链。于是就能找到泄漏对象是通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收它们的。掌握了泄漏对象的类型信息，以及GC Roots引用链的信息，就可以比较准确地定位出泄漏代码的位置。 如果不存在内存泄漏，换句话说内存溢出就是内存中的对象确实都存活着，还必须在使用中，那就应当检查虚拟机的堆参数（-Xmx与-Xms），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。","link":"/JVM-021-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E6%96%B9%E6%B3%95%E5%8C%BA-Method-Area-%E8%AE%BE%E7%BD%AE%E6%96%B9%E6%B3%95%E5%8C%BA%E5%A4%A7%E5%B0%8F%E5%92%8COOM/"},{"title":"JVM-022-运行时数据区-方法区(Method Area)-内部结构","text":"方法区存储了什么《深入理解Java虚拟机》书中对方法区（Method Area）存储内容描述如下：它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。 类型信息对每个加载的类型（类class、接口interface、枚举enum、注解annotation），JVM必须在方法区中存储以下类型信息： 这个类型的完整有效名称（全名=包名.类名） 这个类型直接父类的完整有效名（对于interface或是java.lang.Object，都没有父类） 这个类型的修饰符（public，abstract，final的某个子集） 这个类型实现接口的一个有序列表（因为可以实现多个类） 域（Field）信息或者叫 成员变量或属性。 JVM必须在方法区中保存类型的所有域的相关信息以及域的声明顺序。 域的相关信息包括：域名称，域类型，域修饰符（public，private，protected，static，final，volatile，transient的某个子集） 方法（Method）信息JVM必须保存所有方法的以下信息，同域信息一样包括声明顺序： 方法名称 方法的返回类型（包括 void 返回类型） 方法参数的数量和类型（按顺序） 方法的修饰符（public，private，protected，static，final，synchronized，native，abstract的一个子集） 方法的字节码（bytecodes）、操作数栈深度、局部变量表个数及参数（形参）个数（abstract和native方法除外） 异常表（abstract和native方法除外） 每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引 举例java 代码： 123456789101112131415161718192021222324252627282930313233package com.buubiu;import java.io.Serializable;/** * 测试方法区的内部构成 */public class MethodInnerStrucTest extends Object implements Comparable&lt;String&gt;, Serializable { //属性 public int num = 10; private static String str = &quot;测试方法的内部结构&quot;; //构造器 //方法 public void test1(){ int count = 20; System.out.println(&quot;count = &quot; + count); } public static int test2(int cal){ int result = 0; try { int value = 30; result = value / cal; } catch (Exception e) { e.printStackTrace(); } return result; } @Override public int compareTo(String o) { return 0; }} javap 反编译： javap -v -p MethodInnerStrucTest.class &gt; MethodInnerStrucTest.txt 反编译字节码文件，并输出值文本文件中，便于查看。参数 -p 确保能查看 private 权限类型的字段或方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445......//类型信息public class com.buubiu.MethodInnerStrucTest extends java.lang.Objectimplements java.lang.Comparable&lt;java.lang.String&gt;, java.io.Serializable minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER //类的权限信息 ......{ //域信息 public int num; descriptor: I //字段类型为 Integer flags: ACC_PUBLIC //字段权限修饰符为 public private static java.lang.String str; descriptor: Ljava/lang/String; //字段类型为 String flags: ACC_PRIVATE, ACC_STATIC //字段权限修饰符为 private 并且是静态 //方法信息-构造器 public com.buubiu.MethodInnerStrucTest(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 //操作数栈深度 局部变量表个数（包括形参this) 形参个数(这里的1表示有个this) ...... //方法信息-普通方法 public void test1(); descriptor: ()V //方法返回值类型为 void flags: ACC_PUBLIC //方法权限修饰符为 public Code: //字节码 stack=3, locals=2, args_size=1 //操作数栈深度 局部变量表个数（包括形参this) 形参个数(这里的1表示有个this) ...... //方法信息-普通方法 public static int test2(int); descriptor: (I)I //方法返回值类型为 int flags: ACC_PUBLIC, ACC_STATIC //方法权限修饰符为 public 并且为静态 Code: stack=2, locals=3, args_size=1 //操作数栈深度 局部变量表长度 参数个数(这里的1表示有个int) ...... Exception table: //异常表 from to target type 2 9 12 Class java/lang/Exception...... 静态变量non-final 类型的类变量 静态变量是和类关联在一起的，随着类的加载而加载，他们成为类数据在逻辑上的一部分 类变量被类的所有实例共享，即使没有类实例时，你也可以访问它 举例 如下代码所示，即使我们把order设置为null，也不会出现空指针异常 这更加表明了 static 类型的字段和方法随着类的加载而加载，并不属于特定的类实例 1234567891011121314151617181920public class MethodAreaTest { public static void main(String[] args) { Order order = null; order.hello(); System.out.println(order.count); }}class Order { public static int count = 1; public static final int number = 2; public static void hello() { System.out.println(&quot;hello!&quot;); }}============hello!1 全局常量：static final 全局常量就是使用 static final 进行修饰 被声明为final的类变量的处理方法则不同，每个全局常量在编译的时候就会被分配了。 代码： 12345class Order { public static int count = 1; public static final int number = 2; ...} 字节码： 12345678public static int count; descriptor: I flags: ACC_PUBLIC, ACC_STATICpublic static final int number; descriptor: I flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL ConstantValue: int 2 //可以发现 staitc和final同时修饰的number 的值在编译上的时候已经初始化了。 运行时常量池常量池与运行时常量池 方法区，内部包含了运行时常量池 字节码文件，内部包含了常量池。 要弄清楚方法区，需要理解清楚ClassFile，因为加载类的信息都在方法区。 要弄清楚方法区的运行时常量池，需要理解清楚ClassFile中的常量池。 字节码文件(.class)中的常量池(Constant pool)被加载到方法区以后，我们就把对应的常量池结构叫作运行时常量池 常量池定义官方文档：https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html 一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述符信息外。还包含一项信息就是常量池表（Constant Pool Table），包括各种字面量(固定值，字符串等)和对类型、域和方法的符号引用。 字面量是源代码中的固定值的表示法，即通过字面我们就能知道其值的含义。字面量包括整数、浮点数和字符串字面量。常见的符号引用包括类符号引用、字段符号引用、方法符号引用、接口方法符号。 为什么需要常量池 一个java源文件中的类、接口，编译后产生一个字节码文件。而Java中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池。这个字节码包含了指向常量池的引用。在动态链接的时候会用到运行时常量池 比如一下代码： 12345public class SimpleClass { public void sayHello() { System.out.println(&quot;hello&quot;); }} 虽然上述代码只有194字节，但是里面却使用了String、System、PrintStream及Object等结构。这里的代码量其实很少了，如果代码多的话，引用的结构将会更多，这里就需要用到常量池了。 常量池存储什么存储的数据类型包括： 数量值(字面量) 字符串值 类引用 字段引用 方法引用 总结常量池、可以看做是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型。 运行时常量池定义 运行时常量池（Runtime Constant Pool）是方法区的一部分。 常量池表（Constant Pool Table）是Class字节码文件的一部分，用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 动态性 在加载类和接口到虚拟机后，就会创建对应的运行时常量池。 JVM为每个已加载的类型（类、接口、枚举或注解）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的。 运行时常量池中包含多种不同的常量，包括编译期就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或者字段引用。此时不再是常量池中的符号地址了，这里换为真实地址。 运行时常量池，相对于Class文件常量池的另一重要特征是：具备动态性，Java 语言并不要求常量一定只有编译期间才能产生，运行期间也可以将新的常量放入池中，String 类的 intern() 方法就是这样的 所以：运行时常量池有可能比常量池的内容多 运行时常量池类似于传统编程语言中的符号表（symbol table），但是它所包含的数据却比符号表要更加丰富一些。 当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则JVM会抛OutofMemoryError异常。","link":"/JVM-022-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E6%96%B9%E6%B3%95%E5%8C%BA-Method-Area-%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84/"},{"title":"JVM-023-运行时数据区-方法区(Method Area)-方法区的演进细节","text":"概述 首先明确：只有Hotspot才有永久代。 BEA JRockit、IBMJ9等来说，是不存在永久代的概念的。原则上如何实现方法区属于虚拟机实现细节，不受《Java虚拟机规范》管束，并不要求统一 Hotspot中方法区的变化： 版本 说明 JDK1.6及以前 有永久代（permanent generation），字符串常量池(StringTable)和静态变量存储在永久代上 JDK1.7 有永久代，但已经逐步 “去永久代”，字符串常量池(StringTable)和静态变量移动保存在堆中 JDK1.8 无永久代，类型信息，字段，方法，常量保存在本地内存的元空间，但字符串常量池(StringTable)和静态变量仍然在堆中。 字符串常量池 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。 永久代为什么要被元空间替换官方文档：https://openjdk.org/jeps/122 随着Java8的到来，HotSpot VM中再也见不到永久代了。但是这并不意味着类的元数据信息也消失了。这些数据被移到了一个与堆不相连的本地内存区域，这个区域叫做元空间（Metaspace）。 由于类的元数据分配在本地内存中，元空间的最大可分配空间就是系统可用内存空间。 所以被替换的原因有： 为永久代设置空间大小是很难确定的。 在某些场景下，如果动态加载类过多，容易产生Perm区永久代的OOM。比如某个实际Web工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现致命错误。Exception in thread 'dubbo client x.x connector' java.lang.OutOfMemoryError:PermGen space而元空间和永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。 因此，默认情况下，元空间的大小仅受本地内存限制。 对永久代进行调优是很困难的。 方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不再用的类型 方法区的垃圾回收主要是 Full GC，但是Full GC 既浪费时间并且发生的条件还很多，所以我们要减少 Full GC的发生。 字符串常量池(StringTable)为什么要调整到堆中JDK7中将StringTable放到了堆空间中。 因为永久代的回收效率很低，在Full GC的时候才会执行永久代的垃圾回收，而Full GC是老年代的空间不足、永久代不足时才会触发。 这就导致StringTable回收效率不高，而我们开发中会有大量的字符串被创建，回收效率低，导致永久代内存不足。放到堆里，能及时回收内存。 静态变量存储从《Java虚拟机规范》所定义的概念模型来看，所有Class相关的信息都应该存放在方法区之中，但方法区该如何实现，《Java虚拟机规范》并未做出规定，这就成了一件允许不同虚拟机自己灵活把握的事情。JDK7及其以后版本的HotSpot虚拟机选择把静态变量与类型在Java语言一端的映射Class对象存放在一起，存储于Java堆之中，从下面的代码也可以验证这一点。 代码并配置虚拟机参数： 12345678910111213/** * jdk7： * -Xms200m -Xmx200m -XX:PermSize=300m -XX:MaxPermSize=300m -XX:+PrintGCDetails * jdk 8： * -Xms200m -Xmx200m -XX:MetaspaceSize=300m -XX:MaxMetaspaceSize=300m -XX:+PrintGCDetails */public class StaticFieldTest { private static byte[] arr = new byte[1024 * 1024 * 100];//100MB public static void main(String[] args) { System.out.println(StaticFieldTest.arr); }} 结论： 静态引用对应的对象实体(也就是这个new byte[1024 * 1024 * 100])始终都存在堆空间， 只是那个静态变量(相当于arr变量名)在JDK6,JDK7,JDK8存放位置中有所变化","link":"/JVM-023-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E6%96%B9%E6%B3%95%E5%8C%BA-Method-Area-%E6%96%B9%E6%B3%95%E5%8C%BA%E7%9A%84%E6%BC%94%E8%BF%9B%E7%BB%86%E8%8A%82/"},{"title":"JVM-024-运行时数据区-方法区(Method Area)-垃圾回收","text":"概述 有些人认为方法区（如Hotspot虚拟机中的元空间或者永久代）是没有垃圾收集行为的，其实不然。《Java虚拟机规范》对方法区的约束是非常宽松的，提到过可以不要求虚拟机在方法区中实现垃圾收集。事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在（如JDK11时期的ZGC收集器就不支持类卸载）。 一般来说这个区域的回收效果比较难令人满意，尤其是类型的卸载，条件相当苛刻。但是这部分区域的回收有时又确实是必要的。以前sun公司的Bug列表中，曾出现过的若干个严重的Bug就是由于低版本的HotSpot虚拟机对此区域未完全回收而导致内存泄漏。 方法区的垃圾收集主要回收两部分内容：运行时常量池中废弃的常量和不再使用的类型(即：运行时常量池和类信息)。 运行时常量池回收（废弃常量）方法区运行时常量池包括两类：字面量和符号引用 字面量：比较接近Java语言层次的常量概念，如文本字符串、被声明为final的常量值等。 字面量是源代码中的固定值的表示法，即通过字面我们就能知道其值的含义。字面量包括整数、浮点数和字符串字面量。 符号引用：符号引用则属于编译原理方面的概念，常见的符号引用包括类符号引用、字段符号引用、方法符号引用、接口方法符号。包括下面三类常量： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 HotSpot虚拟机对运行时常量池的回收策略是很明确的，只要运行时常量池中的常量没有被任何地方引用，就可以被回收。回收废弃常量与回收Java堆中的对象非常类似。 类信息回收（类卸载） 判定一个常量是否“废弃”还是相对简单，而要判定一个类型是否属于“不再被使用的类”的条件就比较苛刻了。需要同时满足下面三个条件： 该类所有的实例都已经被回收，也就是Java堆中不存在该类及其任何派生子类的实例。 加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如OSGi、JSP的重加载等，否则通常是很难达成的。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 Java虚拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，没有引用了就必然会回收。关于是否要对类型进行回收，HotSpot虚拟机提供了-Xnoclassgc参数进行控制，还可以使用-verbose:class 以及 -XX：+TraceClass-Loading、-XX：+TraceClassUnLoading查看类加载和卸载信息 在大量使用反射、动态代理、CGLib等字节码框架，动态生成JSP以及OSGi这类频繁自定义类加载器的场景中，通常都需要Java虚拟机具备类型卸载的能力，以保证不会对方法区造成过大的内存压力。","link":"/JVM-024-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E6%96%B9%E6%B3%95%E5%8C%BA-Method-Area-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"title":"JVM-025-运行时数据区-总结与面试题","text":"总图 常见面试题 百度 三面：说一下JVM内存模型吧，有哪些区？分别干什么的？ 蚂蚁金服： Java8的内存分代改进 JVM内存分哪几个区，每个区的作用是什么？ 一面：JVM内存分布/内存结构？栈和堆的区别？堆的结构？为什么两个survivor区？ 二面：Eden和survior的比例分配 小米： jvm内存分区，为什么要有新生代和老年代 字节跳动： 二面：Java的内存分区 二面：讲讲jvm运行时数据库区 什么时候对象会进入老年代？ 京东： JVM的内存结构，Eden和Survivor比例。 JVM内存为什么要分成新生代，老年代，持久代。新生代中为什么要分为Eden和survivor。 天猫： 一面：Jvm内存模型以及分区，需要详细到每个区放什么。 一面：JVM的内存模型，Java8做了什么改动 拼多多： JVM内存分哪几个区，每个区的作用是什么？ 美团： java内存分配 jvm的永久代中会发生垃圾回收吗？ 一面：jvm内存分区，为什么要有新生代和老年代？","link":"/JVM-025-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E6%80%BB%E7%BB%93%E4%B8%8E%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"title":"JVM-026-运行时数据区-对象的实例化内存布局与访问定位","text":"创建对象的方式 new：最常见的方式、单例类中调用getInstance的静态类方法，XxxFactory的静态方法 Class的newInstance方法：在JDK9里面被标记为过时的方法，因为只能调用空参构造器，并且权限必须为 public Constructor的newInstance(Xxxx)：反射的方式，可以调用空参的，或者带参的构造器 使用clone()：不调用任何的构造器，要求当前的类需要实现Cloneable接口中的clone方法 使用反序列化：从文件中，从网络中获取一个对象的二进制流，序列化一般用于Socket的网络传输 第三方库 Objenesis 创建对象的过程从字节码的角度看Java 代码： 12345public class ObjectTest { public static void main(String[] args) { Object obj = new Object(); }} 字节码反编译： 123456789101112131415161718 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=2, args_size=1 0: new #2 // class java/lang/Object 3: dup 4: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 7: astore_1 8: return LineNumberTable: line 9: 0 line 10: 8 LocalVariableTable: Start Length Slot Name Signature 0 9 0 args [Ljava/lang/String; 8 1 1 obj Ljava/lang/Object;} 从具体执行的过程角度看 判断对象对应的类是否加载、链接、初始化 虚拟机遇到一条new指令，首先去检查这个指令的参数能否在Metaspace的常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载，解析和初始化。（即判断类元信息是否存在）。 如果该类没有加载，那么在双亲委派模式下，使用当前类加载器以ClassLoader + 包名 + 类名为key进行查找对应的.class文件，如果没有找到文件，则抛出ClassNotFoundException异常，如果找到，则进行类加载，并生成对应的Class对象。 为对象分配内存首先计算对象占用空间的大小，接着在堆中划分一块内存给新对象。 如果实例成员变量是引用变量，仅分配引用变量空间即可，即4个字节大小 如果内存规整：采用指针碰撞分配内存 如果内存是规整的，那么虚拟机将采用的是指针碰撞法（Bump The Point）来为对象分配内存。 意思是所有用过的内存在一边，空闲的内存放另外一边，中间放着一个指针作为分界点的指示器，分配内存就仅仅是把指针往空闲内存那边挪动一段与对象大小相等的距离罢了。如果垃圾收集器选择的是Serial 、ParNew这种基于压缩算法的，虚拟机采用这种分配方式。一般使用带Compact（整理）过程的收集器时，使用指针碰撞。 标记压缩（整理）算法会整理内存碎片，堆内存一边为对象，另一边为空闲区域 如果内存不规整，虚拟机需要维护一个列表，使用空闲列表分配 如果内存不是规整的，已使用的内存和未使用的内存相互交错，那么虚拟机将采用的是空闲列表来为对象分配内存。 意思是虚拟机维护了一个列表，记录上哪些内存块是可用的，再分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的内容。这种分配方式成为了 空闲列表（Free List）。 说明：选择哪种分配方式由Java堆是否规整所决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 处理并发安全问题在分配内存空间时，另外一个问题是及时保证 new 对象时候的线程安全性； 创建对象是非常频繁的操作，虚拟机需要解决并发问题。 虚拟机采用了两种方式解决并发问题： 对内存分配的操作进行同步处理，添加CAS(Compare And Swap) 锁，配上失败重试的方式来保证指针更新操作的原子性。 CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。 TLAB 把内存分配的动作按照线程划分在不同的空间制中进行，即每个线程在Java堆中（Eden区）预先分配一小块内内存，称为本地线程分配缓冲区（TLAB，Thread Local Allocation Buffer），虚拟机是否使用 TLAB，可以 通过 -XX:+UseTLAB参数来设定。 JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配 初始化分配到的空间内存分配结束后，虚拟机将分配到的内存空间都初始化为零值（不包括对象头）。这一步保证了对象的实例字段在Java 代码中可以不用赋初始值就可以直接使用，程序能访问到这些字段的数据类型所对应的零值。 给对象属性赋值的顺序： 属性的默认值初始化 显示初始化/代码块初始化（并列关系，谁先谁后看代码编写的顺序） 构造器初始化 设置对象的对象头将对象的所属类（即类的元数据信息）、对象的HashCode和对象的GC信息、锁信息等数据存储在对象的对象头中。这个过程的具体设置方式取决于JVM实现。 执行init方法进行初始化 在Java程序的视角看来，初始化才正式开始。初始化成员变量，执行实例化代码块，调用类的构造方法，并把堆内对象的首地址赋值给引用变量 因此一般来说（由字节码中跟随invokespecial指令所决定），new指令之后会接着就是执行init方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完成创建出来。 对象的内存布局我们 new 的对象是放到堆空间中的，那么堆空间中的对象里面都有哪几部分结构呢 具体的内存布局： 示例代码： Customer.java12345678910111213141516public class Customer { int id = 1001; String name; Account acct; { name = &quot;匿名客户&quot;; } public Customer(){ acct = new Account(); }}class Account{} CustomerTest.java12345public class CustomerTest { public static void main(String[] args) { Customer cust = new Customer(); }} 对象访问定位创建对象的目的是为了使用它，那么JVM是如何通过栈帧中的对象引用访问到其内部的对象实例呢？ （通过栈上 引用 （reference）访问），具体有两种实现方式： 句柄访问 缺点：在堆空间中开辟了一块空间作为句柄池，句柄池本身也会占用空间；通过两次指针访问才能访问到堆中的对象，效率低 优点：reference中存储稳定句柄地址，对象被移动（垃圾收集时移动对象很普遍）时只会改变句柄中实例数据指针即可，reference本身不需要被修改 直接指针（Hotspot 采用） 优点：直接指针是局部变量表中的引用，直接指向堆中的实例，效率高；在对象实例中有类型指针，指向的是方法区中的对象类型数据 缺点：对象被移动（垃圾收集时移动对象很普遍）时需要修改 reference 的值","link":"/JVM-026-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%AE%9E%E4%BE%8B%E5%8C%96%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%E4%B8%8E%E8%AE%BF%E9%97%AE%E5%AE%9A%E4%BD%8D/"},{"title":"JVM-027-运行时数据区-直接内存(JDK8及以上)","text":"概述 不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。 直接内存是在Java堆外的、直接向系统申请的内存区间。 来源于NIO(New IO / Non-Blocking IO)，通过存在堆中的DirectByteBuffer操作Native内存 通常，访问直接内存的速度会优于Java堆。即读写性能高。 因此出于性能考虑，读写频繁的场合可能会考虑使用直接内存。 Java的NIO库允许Java程序使用直接内存，用于数据缓冲区 简单理解： java process memory = java heap + native memory java进程中所占用的内存空间 = 堆空间 + 本地内存 非直接缓存区（IO）读写文件，需要与磁盘交互，需要由用户态切换到内核态。在内核态和用户态时，都需要内存，并且是使用IO(Stream流，通常由byte[]或者char[]组成)的方式。这里需要两份内存存储重复数据，效率低。 直接缓冲区（NIO）使用NIO时，操作系统划出的直接缓存区可以被java代码直接访问，只有一份。NIO适合对大文件的读写操作。 问题OOM 直接内存也可能导致OutofMemoryError异常。java.lang.OutOfMemoryError: Direct buffer memory 由于直接内存在Java堆外，因此它的大小不会直接受限于-Xmx指定的最大堆大小，但是系统内存是有限的，Java堆和直接内存的总和依然受限于操作系统能给出的最大内存。 直接内存大小可以通过-XX:MaxDirectMemorySize=10m设置 如果不指定，默认与堆的最大值-Xmx参数值一致 垃圾回收 分配回收成本较高 不受JVM内存回收管理","link":"/JVM-027-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98-JDK8%E5%8F%8A%E4%BB%A5%E4%B8%8A/"},{"title":"JVM-029-执行引擎-Java代码编译和执行的过程","text":"概述大部分的程序代码转换成物理机的目标代码或虚拟机能执行的指令集之前，都需要经过下图中的各个步骤： 前面橙色部分是编译生成生成字节码文件的过程（javac编译器来完成，也就是前端编译器），和JVM没有关系。 Java代码编译是由Java源码编译器（javac）来完成，流程图如下所示： 后面绿色（解释执行）和蓝色（即时编译）才是JVM需要考虑的过程 Java字节码的执行是由JVM执行引擎来完成，流程图如下所示： 解释器（Interpreter）解释器（Interpreter）：当Java虚拟机启动时会根据预定义的规范对字节码采用逐行解释的方式执行，将每条字节码文件中的内容“翻译”为对应平台的本地机器指令执行。 JIT编译器JIT（Just In Time Compiler）编译器：就是虚拟机将源代码一次性直接编译成和本地机器平台相关的机器语言，但并不是马上执行。 Java是半编译半解释型语言 JDK1.0时代，将Java语言定位为“解释执行”还是比较准确的。 再后来，Java也发展出可以直接生成本地代码的编译器。 现在JVM在执行Java代码的时候，通常都会将解释执行与编译执行二者结合起来进行。 JIT编译器将字节码翻译成本地代码后，就可以做一个缓存操作，存储在方法区的JIT 代码缓存中（执行效率更高了），并且在翻译成本地代码的过程中可以做优化。","link":"/JVM-029-%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E-Java%E4%BB%A3%E7%A0%81%E7%BC%96%E8%AF%91%E5%92%8C%E6%89%A7%E8%A1%8C%E7%9A%84%E8%BF%87%E7%A8%8B/"},{"title":"JVM-028-执行引擎-概述","text":"概念 执行引擎是Java虚拟机核心的组成部分之一。 “虚拟机”是一个相对于“物理机”的概念，这两种机器都有代码执行能力，其区别是物理机的执行引擎是直接建立在处理器、缓存、指令集和操作系统层面上的，而虚拟机的执行引擎则是由软件自行实现的，因此可以不受物理条件制约地定制指令集与执行引擎的结构体系，能够执行那些不被硬件直接支持的指令集格式。 JVM的主要任务是负责装载字节码到其内部，但字节码并不能够直接运行在操作系统之上，因为字节码指令并非等价于本地机器指令，它内部包含的仅仅只是一些能够被JVM所识别的字节码指令、符号表，以及其他辅助信息。 那么，如果想要让一个Java程序运行起来，执行引擎（Execution Engine）的任务就是将字节码指令解释/编译为对应平台上的本地机器指令才可以。简单来说，JVM中的执行引擎充当了将高级语言翻译为机器语言的译者。 执行引擎的工作过程从外观上来看，所有的Java虚拟机的执行引擎输入、输出都是一致的：输入的是字节码二进制流，处理过程是字节码解析执行，输出的是执行结果。 执行引擎在执行的过程中究竟需要执行什么样的字节码指令完全依赖于PC寄存器。 每当执行完一项指令操作后，PC寄存器就会更新下一条需要被执行的指令地址。 方法在执行的过程中，执行引擎有可能会通过存储在局部变量表中的对象引用准确定位到存储在Java堆区中的对象实例信息，以及通过对象头中的元数据指针定位到目标对象在方法区中的类型信息。","link":"/JVM-028-%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E-%E6%A6%82%E8%BF%B0/"},{"title":"JVM-030-执行引擎-机器码_指令_汇编语言","text":"总体介绍 机器码 各种用二进制编码方式表示的指令，叫做机器指令码。开始，人们就用它采编写程序，这就是机器语言。 机器语言虽然能够被计算机理解和接受，但和人们的语言差别太大，不易被人们理解和记忆，并且用它编程容易出差错。 用它编写的程序一经输入计算机，CPU直接读取运行，因此和其他语言编的程序相比，执行速度最快。 机器指令与CPU紧密相关，所以不同种类的CPU所对应的机器指令也就不同。 指令和指令集指令 由于机器码是由0和1组成的二进制序列，可读性实在太差，于是人们发明了指令。 指令就是把机器码中特定的0和1序列，简化成对应的指令（一般为英文简写，如mov，inc等），可读性稍好 由于不同的硬件平台，执行同一个操作，对应的机器码可能不同，所以不同的硬件平台的同一种指令（比如mov），对应的机器码也可能不同。 指令集不同的硬件平台，各自支持的指令，是有差别的。因此每个平台所支持的指令，称之为对应平台的指令集。 如常见的 x86指令集，对应的是x86架构的平台 ARM指令集，对应的是ARM架构的平台 汇编语言 由于指令的可读性还是太差，于是人们又发明了汇编语言。 在汇编语言中，用助记符（Mnemonics）代替机器指令的操作码，用地址符号（Symbol）或标号（Label）代替指令或操作数的地址。 在不同的硬件平台，汇编语言对应着不同的机器语言指令集，通过汇编过程转换成机器指令。 由于计算机只认识指令码，所以用汇编语言编写的程序还必须翻译（汇编）成机器指令码，计算机才能识别和执行。 高级语言 为了使计算机用户编程序更容易些，后来就出现了各种高级计算机语言。高级语言比机器语言、汇编语言更接近人的语言 当计算机执行高级语言编写的程序时，仍然需要把程序解释和编译成机器的指令码。完成这个过程的程序就叫做解释程序或编译程序（如下图）。 字节码 字节码是一种中间状态（中间码）的二进制代码（文件），它比机器码更抽象，需要直译器转译后才能成为机器码 字节码主要为了实现特定软件运行和软件环境，与硬件环境无关。 字节码的实现方式是通过编译器和虚拟机器。编译器将源码编译成字节码，特定平台上的虚拟机器将字节码转译为可以直接执行的指令。 字节码典型的应用为：Java bytecode C、C++源程序执行过程 编译过程又可以分成两个阶段：编译和汇编。 编译过程：是读取源程序（字符流），对之进行词法和语法的分析，将高级语言指令转换为功能等效的汇编代码 汇编过程：实际上指把汇编语言代码翻译成目标机器指令的过程。","link":"/JVM-030-%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E-%E6%9C%BA%E5%99%A8%E7%A0%81-%E6%8C%87%E4%BB%A4-%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/"},{"title":"JVM-031-执行引擎-解释器和JIT编译器","text":"解释器引入JVM设计者们的初衷仅仅只是单纯地为了满足Java程序实现跨平台特性，因此避免采用静态编译的方式由高级语言直接生成本地机器指令，从而诞生了实现解释器在运行时采用逐行解释字节码执行程序的想法。 解释器真正意义上所承担的角色就是一个运行时“翻译者”，将字节码文件中的内容“翻译”为对应平台的本地机器指令执行。 当一条字节码指令被解释执行完成后，接着再根据PC寄存器中记录的下一条需要被执行的字节码指令执行解释操作。 解释器的分类在Java的发展历史里，一共有两套解释执行器，即古老的字节码解释器、现在普遍使用的模板解释器。 字节码解释器字节码解释器在执行时通过纯软件代码模拟字节码的执行，效率非常低下。 模板解释器而模板解释器将每一条字节码和一个模板函数相关联，模板函数中直接产生这条字节码执行时的机器码，从而很大程度上提高了解释器的性能。 在HotSpot VM中，解释器主要由Interpreter模块和Code模块构成。 Interpreter模块：实现了解释器的核心功能 Code模块：用于管理HotSpot VM在运行时生成的本地机器指令 解释器的现状 由于解释器在设计和实现上非常简单，因此除了Java语言之外，还有许多高级语言同样也是基于解释器执行的，比如Python、Perl、Ruby等。但是在今天，基于解释器执行已经沦落为低效的代名词，并且时常被一些C/C++程序员所调侃。 为了解决这个问题，JVM平台支持一种叫作即时编译的技术。即时编译的目的是避免函数被解释执行，而是将整个函数体编译成为机器码，每次函数执行时，只执行编译后的机器码即可，这种方式可以使执行效率大幅度提升。 不过无论如何，基于解释器的执行模式仍然为中间语言的发展做出了不可磨灭的贡献。 JIT编译器引入Java 代码执行的分类 第一种是将源代码编译成字节码文件，然后在运行时通过解释器将字节码文件转为机器码执行 第二种是编译执行（直接编译成机器码）。现代虚拟机为了提高执行效率，会使用即时编译技术（JIT，Just In Time）将方法编译成机器码后再执行 HotSpot VM是目前市面上高性能虚拟机的代表作之一。它采用解释器与即时编译器并存的架构。在Java虚拟机运行时，解释器和即时编译器能够相互协作，各自取长补短，尽力去选择最合适的方式来权衡编译本地代码的时间和直接解释执行代码的时间。 在今天，Java程序的运行性能早已脱胎换骨，已经达到了可以和C/C++ 程序一较高下的地步。 为什么还需要解释器有些开发人员会感觉到诧异，既然HotSpot VM中已经内置JIT编译器了，那么为什么还需要再使用解释器来“拖累”程序的执行性能呢？比如JRockit VM内部就不包含解释器，字节码全部都依靠即时编译器编译后执行。 首先明确两点 当程序启动后，解释器可以马上发挥作用，响应速度快，省去编译的时间，立即执行。 编译器要想发挥作用，把代码编译成本地代码，需要一定的执行时间，但编译为本地代码后，执行效率高。 所以 尽管JRockit VM中程序的执行性能会非常高效，但程序在启动时必然需要花费更长的时间来进行编译。对于服务端应用来说，启动时间并非是关注重点，但对于那些看中启动时间的应用场景而言，或许就需要采用解释器与即时编译器并存的架构来换取一个平衡点。 在此模式下，在Java虚拟器启动时，解释器可以首先发挥作用，而不必等待即时编译器全部编译完成后再执行，这样可以省去许多不必要的编译时间。随着时间的推移，编译器发挥作用，把越来越多的代码编译成本地代码，获得更高的执行效率。–HotSpot JVM的执行方式 同时，解释执行在编译器进行激进优化不成立的时候，作为编译器的“逃生门”（后备方案）。 案例理论：注意解释执行与编译执行在线上环境微妙的辩证关系。 机器在热机状态（已经运行了一段时间叫热机状态）可以承受的负载要大于冷机状态（刚启动的时候叫冷机状态）。如果以热机状态时的流量进行切流，可能使处于冷机状态的服务器因无法承载流量而假死。 在生产环境发布过程中，以分批的方式进行发布，根据机器数量划分成多个批次，每个批次的机器数至多占到整个集群的1/8。曾经有这样的故障案例：某程序员在发布平台进行分批发布，在输入发布总批数时，误填写成分为两批发布。如果是热机状态，在正常情况下一半的机器可以勉强承载流量，但由于刚启动的JVM均是解释执行，还没有进行热点代码统计和JIT动态编译，导致机器启动之后，当前1/2发布成功的服务器马上全部宕机，此故障说明了JIT的存在。—阿里团队 举例12345678910111213141516public class JITTest { public static void main(String[] args) { ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 1000; i++) { list.add(&quot;让天下没有难学的技术&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } }} 通过 JVisualVM 查看 JIT 编译器执行的编译次数","link":"/JVM-031-%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E-%E8%A7%A3%E9%87%8A%E5%99%A8%E5%92%8CJIT%E7%BC%96%E8%AF%91%E5%99%A8/"},{"title":"JVM-032-执行引擎-JIT编译器深入理解","text":"概念解释 Java 语言的“编译期”其实是一段“不确定”的操作过程，因为它可能是指一个前端编译器（其实叫“编译器的前端”更准确一些）把.java文件转变成.class文件的过程。 也可能是指虚拟机的后端运行期编译器（JIT编译器，Just In Time Compiler）把字节码转变成机器码的过程。 还可能是指使用静态提前编译器（AOT编译器，Ahead of Time Compiler）直接把.java文件编译成本地机器代码的过程。（可能是后续发展的趋势） 比较常见的编译器： 前端编译器：Sun 的 javac、Eclipse JDT中的增量式编译器（ECJ）。JIT编译器：HotSpot VM的C1、C2编译器。AOT 编译器：GNU Compiler for the Java（GCJ）、Excelsior JET。 如何选择启动JIT编译器热点代码及探测方式 是否需要启动JIT编译器将字节码直接编译为对应平台的本地机器指令，则需要根据代码被调用执行的频率而定。 关于那些需要被编译为本地代码的字节码，也被称之为“热点代码”，JIT编译器在运行时会针对那些频繁被调用的“热点代码”做出深度优化，将其直接编译为对应平台的本地机器指令，以此提升Java程序的执行性能。 热点代码 一个被多次调用的方法，或者是一个方法体内部循环次数较多的循环体都可以被称之为“热点代码”。 因此都可以通过JIT编译器编译为本地机器指令。 由于这种编译方式发生在方法的执行过程中，因此也被称之为栈上替换，或简称为OSR (On StackReplacement)编译。 探测方式 一个方法究竟要被调用多少次，或者一个循环体究竟需要执行多少次循环才可以达到这个标准？必然需要一个明确的阈值，JIT编译器才会将这些“热点代码”编译为本地机器指令执行。这里主要依靠热点探测功能。 方法调用计数器与回边计数器目前HotSpot VM所采用的热点探测方式是基于计数器的热点探测。 采用基于计数器的热点探测，HotSpot VM将会为每一个方法都建立2个不同类型的计数器，分别为方法调用计数器（Invocation Counter）和回边计数器（Back Edge Counter）。 方法调用计数器用于统计方法的调用次数 回边计数器则用于统计循环体执行的循环次数 方法调用计数器这个计数器就用于统计方法被调用的次数，它的默认阀值在 Client 模式下是 1500 次，在 Server 模式下是 10000 次。超过这个阈值，就会触发JIT编译。 这个阀值可以通过虚拟机参数 -XX:CompileThreshold 来人为设定。 执行过程（原理） 当一个方法被调用时，会先检查该方法是否存在被JIT编译过的版本 如果存在，则优先使用编译后的本地代码来执行 如果不存在已被编译过的版本，则将此方法的调用计数器值加1，然后判断方法调用计数器与回边计数器值之和是否超过方法调用计数器的阀值。 如果已超过阈值，那么将会向即时编译器提交一个该方法的代码编译请求。 如果未超过阈值，则使用解释器对字节码文件解释执行 热度衰减 如果不做任何设置，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间之内方法被调用的次数。 当超过一定的时间限度，如果方法的调用次数仍然不足以让它提交给即时编译器编译，那这个方法的调用计数器就会被减少一半，这个过程称为方法调用计数器热度的衰减（Counter Decay），而这段时间就称为此方法统计的半衰周期（Counter Half Life Time）（半衰周期是化学中的概念，比如出土的文物通过查看C60来获得文物的年龄） 进行热度衰减的动作是在虚拟机进行垃圾收集时顺便进行的，可以使用虚拟机参数 -XX:-UseCounterDecay 来关闭热度衰减，让方法计数器统计方法调用的绝对次数，这样的话，只要系统运行时间足够长，绝大部分方法都会被编译成本地代码。 另外，可以使用 -XX:CounterHalfLifeTime 参数设置半衰周期的时间，单位是秒，jdk8中默认是30秒。 回边计数器它的作用是统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为“回边”（Back Edge）。显然，建立回边计数器统计的目的就是为了触发OSR编译。 HotSpotVM可以设置程序执行方法缺省（默认）情况下 HotSpot VM 是采用解释器与即时编译器并存的架构，当然开发人员可以根据具体的应用场景，通过命令显式地为Java虚拟机指定在运行时到底是完全采用解释器执行，还是完全采用即时编译器执行。如下所示： -Xint：完全采用解释器模式执行程序； -Xcomp：完全采用即时编译器模式执行程序。如果即时编译出现问题，解释器会介入执行 -Xmixed：采用解释器+即时编译器的混合模式共同执行程序。 12345678910111213141516171819$ java -versionopenjdk version &quot;1.8.0_322&quot;OpenJDK Runtime Environment (build 1.8.0_322-bre_2022_02_28_15_01-b00)OpenJDK 64-Bit Server VM (build 25.322-b00, mixed mode)$ java -Xint -versionopenjdk version &quot;1.8.0_322&quot;OpenJDK Runtime Environment (build 1.8.0_322-bre_2022_02_28_15_01-b00)OpenJDK 64-Bit Server VM (build 25.322-b00, interpreted mode)$ java -Xcomp -versionopenjdk version &quot;1.8.0_322&quot;OpenJDK Runtime Environment (build 1.8.0_322-bre_2022_02_28_15_01-b00)OpenJDK 64-Bit Server VM (build 25.322-b00, compiled mode)$ java -Xmixed -versionopenjdk version &quot;1.8.0_322&quot;OpenJDK Runtime Environment (build 1.8.0_322-bre_2022_02_28_15_01-b00)OpenJDK 64-Bit Server VM (build 25.322-b00, mixed mode) 代码举例： 12345678910111213141516171819202122232425262728293031323334/** * 测试解释器模式和JIT编译模式 * -Xint : 6520ms * -Xcomp : 950ms * -Xmixed : 936ms */public class IntCompTest { public static void main(String[] args) { long start = System.currentTimeMillis(); testPrimeNumber(1000000); long end = System.currentTimeMillis(); System.out.println(&quot;花费的时间为：&quot; + (end - start)); } public static void testPrimeNumber(int count){ for (int i = 0; i &lt; count; i++) { //计算100以内的质数 label:for(int j = 2;j &lt;= 100;j++){ for(int k = 2;k &lt;= Math.sqrt(j);k++){ if(j % k == 0){ continue label; } } //System.out.println(j); } } }} HotSpot VM中JIT分类C1和C2编译器在HotSpot VM中内嵌有两个JIT编译器，分别为Client Compiler和Server Compiler，但大多数情况下我们简称为C1编译器 和 C2编译器。开发人员可以通过如下命令显式指定Java虚拟机在运行时到底使用哪一种即时编译器，如下所示： -client：指定Java虚拟机运行在Client模式下，并使用C1编译器；C1编译器会对字节码进行简单和可靠的优化，耗时短，以达到更快的编译速度。 -server：指定Java虚拟机运行在server模式下，并使用C2编译器。C2进行耗时较长的优化，以及激进优化，但优化的代码执行效率更高。（使用C++） C1和C2编译器不同的优化策略在不同的编译器上有不同的优化策略： C1编译器上主要有方法内联，去虚拟化、冗余消除。 方法内联：将引用的函数代码编译到引用点处，这样可以减少栈帧的生成，减少参数传递以及跳转过程 去虚拟化：对唯一的实现类进行内联 冗余消除：在运行期间把一些不会执行的代码折叠掉 C2的优化主要是在全局层面，逃逸分析是优化的基础。基于逃逸分析在C2上有如下几种优化： 标量替换：用标量值代替聚合对象的属性值 栈上分配：对于未逃逸的对象分配对象在栈而不是堆 同步消除：清除同步锁操作，通常指synchronized 也就是说之前的逃逸分析，只有在C2（server模式下）才会触发。 分层编译策略分层编译（Tiered Compilation）策略：程序解释执行（不开启性能监控）可以触发C1编译，将字节码编译成机器码，可以进行简单优化，也可以加上性能监控，C2编译会根据性能监控信息进行激进优化。 不过在Java7版本之后，一旦开发人员在程序中显式指定命令“-server”时，默认将会开启分层编译策略，由C1编译器和C2编译器相互协作共同来执行编译任务。 总结 一般来讲，JIT编译出来的机器码性能比解释器高 C2编译器启动时长比C1慢，系统稳定执行以后，C2编译器执行速度远快于C1编译器 拓展Graal 编译器（与 C1/C2 并列） 自JDK10起，HotSpot又加入了一个全新的即时编译器：Graal编译器（与 C1/C2 并列） 编译效果短短几年时间就追平了G2编译器，未来可期（对应还出现了Graal虚拟机，是有可能替代Hotspot的虚拟机的） 目前，带着 “实验状态” 标签，需要使用开关参数 -XX:+UnlockExperimentalvMOptions -XX:+UseJVMCICompiler 去激活才能使用 AOT编译器（与 JIT 编译器并列） jdk9 引入了AOT编译器（静态提前编译器，Ahead Of Time Compiler）（与 JIT 编译器并列） Java 9引入了实验性 AOT 编译工具 jaotc。它借助了Graal编译器，将所输入的Java类文件转换为机器码，并存放至生成的动态共享库之中。 所谓AOT编译，是与即时编译相对立的一个概念。我们知道，即时编译指的是在程序的运行过程中，将字节码转换为可在硬件上直接运行的机器码，并部署至托管环境中的过程。而AOT编译指的则是在程序运行之前，便将字节码转换为机器码的过程。 文件转换流程：.java -&gt; .class -&gt; (使用jaotc) -&gt; .so 优缺点优点： Java虚拟机加载已经预编译成二进制库，可以直接执行。 不必等待即时编译器的预热，减少Java应用给人带来“第一次运行慢” 的不良体验 缺点： 破坏了 java “ 一次编译，到处运行”，必须为每个不同的硬件、系统编译对应的发行包 降低了Java链接过程的动态性，加载的代码在编译器就必须全部已知。 还需要继续优化中，最初只支持 Linux X64 java base","link":"/JVM-032-%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E-JIT%E7%BC%96%E8%AF%91%E5%99%A8%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/"},{"title":"JVM-033-StringTable-String的概述和基本操作","text":"String在JDk9中存储结构的变更String在jdk8及以前内部定义了final char value[]用于存储字符串数据。JDK9时改为final byte[] value 官方文档：http://openjdk.java.net/jeps/254 原因： String类的当前实现将字符存储在char数组中，每个字符使用两个字节(16位)。 从许多不同的应用程序收集的数据表明，字符串是堆使用的主要组成部分，而且大多数字符串对象只包含拉丁字符（Latin-1）。这些字符只需要一个字节的存储空间，因此这些字符串对象的内部char数组中有一半的空间将不会使用，产生了大量浪费。 之前 String 类使用 UTF-16编码 的 char[] 数组存储，现在改为 byte[] 数组 外加一个编码标识存储。该编码表示如果你的字符集编码是ISO-8859-1或者Latin-1，那么只需要一个字节存。如果你是其它字符集编码，比如UTF-8，你仍然用两个字节存 结论：String再也不用char[] 来存储了，改成了byte [] 加上编码标记，节约了一些空间 同时基于String的数据结构，例如StringBuffer和StringBuilder也同样做了修改 1234// jdk8及之前private final char value[];// jdk8之后private final byte[] value String 的基本特性定义 String：字符串，使用一对 “” 引起来表示 12String s1 = &quot;buubiu&quot; ; // 字面量的定义方式String s2 = new String(&quot;buubiu&quot;); // new 对象的方式 不可继承 String被声明为final的，不可被继承 支持序列化 String实现了Serializable接口：表示字符串是支持序列化的。实现了Comparable接口：表示String可以比较大小 不可变性 String：代表不可变的字符序列。简称：不可变性。 字符串常量池不允许存储相同的内容，所以 s1 == s2 为 true 1234567public void test1() { String s1 = &quot;abc&quot;;//字面量定义的方式 String s2 = &quot;abc&quot;; System.out.println(s1 == s2);//判断地址：true System.out.println(s1);//abc System.out.println(s2);//abc} 当对字符串重新赋值时，需要重写指定内存区域赋值，不能使用原有的value进行赋值，所以 s1 == s2 为 false 12345678public void test1() { String s1 = &quot;abc&quot;;//字面量定义的方式 String s2 = &quot;abc&quot;; s1 = &quot;hello&quot;; System.out.println(s1 == s2);//判断地址：false System.out.println(s1);//hello System.out.println(s2);//abc} 当对现有的字符串进行连接操作时，也需要重新指定内存区域赋值，不能使用原有的value进行赋值，所以 s2 为 abcdef 12345678public void test1() { String s1 = &quot;abc&quot;;//字面量定义的方式 String s2 = &quot;abc&quot;; s2 += &quot;def&quot;; System.out.println(s1 == s2);//判断地址：false System.out.println(s1);//abc System.out.println(s2);//abcdef} 当调用String的replace()方法修改指定字符或字符串时，也需要重新指定内存区域赋值，不能使用原有的value进行赋值，所以 s1 不会改变，s2 为 mbc 123456public void test3() { String s1 = &quot;abc&quot;;//字面量定义的方式 String s2 = s1.replace('a', 'm'); System.out.println(s1);//abc System.out.println(s2);//mbc} 笔试题： 1234567891011121314151617public class StringExer { String str = new String(&quot;good&quot;); char[] ch = {'t', 'e', 's', 't'}; public void change(String str, char ch[]) { str = &quot;test ok&quot;; ch[0] = 'b'; } public static void main(String[] args) { StringExer ex = new StringExer(); ex.change(ex.str, ex.ch); System.out.println(ex.str);//good System.out.println(ex.ch);//best }} 总结：通过字面量的方式（区别于new）给一个字符串赋值，此时的字符串值声明在字符串常量池中。 String 的底层结构字符串常量池是不会存储相同内容的字符串的 String的String Pool（字符串常量池）是一个固定大小的Hashtable，默认值大小长度是1009。如果放进String Pool的String非常多，就会造成Hash冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用String.intern()方法时性能会大幅下降。 使用 -XX:StringTablesize=xx可设置StringTable的长度 在JDK6中StringTable是固定的，就是1009的长度，所以如果常量池中的字符串过多就会导致效率下降很快，StringTablesize设置没有要求 在JDK7中，StringTable的长度默认值是60013，StringTablesize设置没有要求 JDK8 开始，设置 StringTable 的长度的话，1009 是可设置的最小值。 不同 StringTable 长度下，程序的性能 123456789101112131415161718192021222324252627/** * 产生10万个长度不超过10的字符串，包含a-z,A-Z */public class GenerateString { public static void main(String[] args) throws IOException { FileWriter fw = new FileWriter(&quot;words.txt&quot;); for (int i = 0; i &lt; 100000; i++) { //1 - 10 int length = (int)(Math.random() * (10 - 1 + 1) + 1); fw.write(getString(length) + &quot;\\n&quot;); } fw.close(); } public static String getString(int length){ String str = &quot;&quot;; for (int i = 0; i &lt; length; i++) { //65 - 90, 97-122 int num = (int)(Math.random() * (90 - 65 + 1) + 65) + (int)(Math.random() * 2) * 32; str += (char)num; } return str; }} 123456789101112131415161718192021222324252627282930public class StringTest2 { public static void main(String[] args) { BufferedReader br = null; try { br = new BufferedReader(new FileReader(&quot;words.txt&quot;)); long start = System.currentTimeMillis(); String data; while((data = br.readLine()) != null){ data.intern(); //如果字符串常量池中没有对应data的字符串的话，则在常量池中生成 } long end = System.currentTimeMillis(); System.out.println(&quot;花费的时间为：&quot; + (end - start));//1009:143ms 100009:47ms } catch (IOException e) { e.printStackTrace(); } finally { if(br != null){ try { br.close(); } catch (IOException e) { e.printStackTrace(); } } } }} -XX:StringTableSize=1009 ：程序耗时 143ms -XX:StringTableSize=100009 ：程序耗时 47ms String 的内存分配 在Java语言中有8种基本数据类型和一种比较特殊的类型String。这些类型为了使它们在运行过程中速度更快、更节省内存，都提供了一种常量池的概念。 常量池就类似一个Java系统级别提供的缓存。8种基本数据类型的常量池都是系统协调的，String类型的常量池比较特殊。它的主要使用方法有两种： 直接使用双引号声明出来的String对象会直接存储在常量池中。比如：String info=&quot;buubiu&quot;; 如果不是用双引号声明的String对象，可以使用String提供的intern()方法。 内存分配的演进： Java 6及以前，字符串常量池存放在永久代 Java 7中 Oracle的工程师对字符串池的逻辑做了很大的改变，即将字符串常量池的位置调整到Java堆内 所有的字符串都保存在堆（Heap）中，和其他普通对象一样，这样可以让你在进行调优应用时仅需要调整堆大小就可以了。 字符串常量池概念原本使用得比较多，但是这个改动使得我们有足够的理由让我们重新考虑在Java 7中使用String.intern()。 Java8元空间，字符串常量在堆 StringTable 为什么要调整？官方文档:https://www.oracle.com/java/technologies/javase/jdk7-relnotes.html#jdk7changes 为什么要调整位置？ 永久代的默认空间大小比较小 永久代垃圾回收频率低，大量的字符串无法及时回收，容易进行Full GC产生STW或者容易产生OOM：PermGen Space 堆中空间足够大，字符串可被及时回收 在JDK 7中，interned字符串不再在Java堆的永久代中分配，而是在Java堆的主要部分（称为年轻代和年老代）中分配，与应用程序创建的其他对象一起分配。 此更改将导致驻留在主Java堆中的数据更多，驻留在永久生成中的数据更少，因此可能需要调整堆大小。 代码示例123456789101112131415161718/** * jdk6中： * -XX:PermSize=6m -XX:MaxPermSize=6m -Xms6m -Xmx6m * * jdk8中： * -XX:MetaspaceSize=6m -XX:MaxMetaspaceSize=6m -Xms6m -Xmx6m */public class StringTest3 { public static void main(String[] args) { //使用Set保持着常量池引用，避免full gc回收常量池行为 Set&lt;String&gt; set = new HashSet&lt;String&gt;(); //在short可以取值的范围内足以让6MB的PermSize或heap产生OOM了。 short i = 0; while(true){ set.add(String.valueOf(i++).intern()); } }} 输出结果： jdk6: 1234Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: PermGen space at java.lang.String.intern(Native Method) at com.buubiu.java.StringTest3.main(StringTest3.java:22)Process finished with exit code 1 jdk8: 12345678Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at java.util.HashMap.resize(HashMap.java:703) at java.util.HashMap.putVal(HashMap.java:662) at java.util.HashMap.put(HashMap.java:611) at java.util.HashSet.add(HashSet.java:219) at com.buubiu.java.StringTest3.main(StringTest3.java:22)Process finished with exit code 1 String 的基本操作举例一Java语言规范里要求完全相同的字符串字面量，应该包含同样的Unicode字符序列（包含同一份码点序列的常量），并且必须是指向同一个String类实例。 1234567891011121314151617181920212223242526public class StringTest4 { public static void main(String[] args) { System.out.println();//2293 System.out.println(&quot;1&quot;);//2294 System.out.println(&quot;2&quot;); System.out.println(&quot;3&quot;); System.out.println(&quot;4&quot;); System.out.println(&quot;5&quot;); System.out.println(&quot;6&quot;); System.out.println(&quot;7&quot;); System.out.println(&quot;8&quot;); System.out.println(&quot;9&quot;); System.out.println(&quot;10&quot;);//2303 //如下的字符串&quot;1&quot; 到 &quot;10&quot;不会再次加载 System.out.println(&quot;1&quot;);//2304 System.out.println(&quot;2&quot;);//2304 System.out.println(&quot;3&quot;); System.out.println(&quot;4&quot;); System.out.println(&quot;5&quot;); System.out.println(&quot;6&quot;); System.out.println(&quot;7&quot;); System.out.println(&quot;8&quot;); System.out.println(&quot;9&quot;); System.out.println(&quot;10&quot;);//2304 }} 分析字符串常量池的变化 程序启动时已经加载了 2293 个字符串常量 加载了一个换行符（println），所以多了一个 加载了字符串常量 “1”~“9” 加载字符串常量 “10” 之后的字符串”1” 到 “10”不会再次加载 举例二1234567891011121314//官方示例代码class Memory { public static void main(String[] args) {//line 1 int i = 1;//line 2 Object obj = new Object();//line 3 Memory mem = new Memory();//line 4 mem.foo(obj);//line 5 }//line 9 private void foo(Object param) {//line 6 String str = param.toString();//line 7 System.out.println(str); }//line 8} 分析运行时内存（foo() 方法是实例方法，其实图中少了一个 this 局部变量） 在第7行创建了一个字符串 str，它存在堆空间的字符串常量池中，并且在foo()栈空间创建了一个引用来指向字符串常量池中。","link":"/JVM-033-StringTable-String%E7%9A%84%E6%A6%82%E8%BF%B0%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"title":"JVM-034-StringTable-字符串的拼接操作","text":"字符串的拼接操作原理 常量与常量的拼接结果在常量池中（堆中划分的一块内存），原理是编译期优化 常量池中不会存在相同内容的变量 拼接前后，只要其中有一个是变量，结果就在堆中（区别于1中的堆，在常量池之外的堆中）。变量拼接的原理是StringBuilder 如果拼接的结果调用intern()方法，根据该字符串是否在常量池中存在，分为： 如果存在，则返回字符串在常量池中的地址 如果字符串常量池中不存在该字符串，则在常量池中创建一份，并返回此对象的地址 案例一结论：常量与常量的拼接结果在常量池，原理是编译期优化 代码： 12345678@Testpublic void test1(){ String s1 = &quot;a&quot; + &quot;b&quot; + &quot;c&quot;;//编译期优化：等同于&quot;abc&quot; String s2 = &quot;abc&quot;; //&quot;abc&quot;一定是放在字符串常量池中，将此地址赋给s2 System.out.println(s1 == s2); //true，比较的是地址 System.out.println(s1.equals(s2)); //true，比较的是值} 分析：从两个角度去证明结论 反编译看class文件，S1 S2 都是一样的，所以 s1 == s2 与 s1.equals(s2) 都为 true 从字节码指令看 案例二结论：拼接前后，只要其中有一个是变量，结果就在堆中；调用 intern() 方法，则主动将字符串对象存入字符串常量池中，并将其地址返回 代码： 12345678910111213141516171819202122232425262728@Testpublic void test2(){ String s1 = &quot;javaEE&quot;; String s2 = &quot;hadoop&quot;; String s3 = &quot;javaEEhadoop&quot;; String s4 = &quot;javaEE&quot; + &quot;hadoop&quot;;//编译期优化 //如果拼接符号的前后出现了变量，则相当于在堆空间中new String()，具体的内容为拼接的结果：javaEEhadoop String s5 = s1 + &quot;hadoop&quot;; String s6 = &quot;javaEE&quot; + s2; String s7 = s1 + s2; System.out.println(s3 == s4);//true System.out.println(s3 == s5);//false System.out.println(s3 == s6);//false System.out.println(s3 == s7);//false System.out.println(s5 == s6);//false System.out.println(s5 == s7);//false System.out.println(s6 == s7);//false //intern():判断字符串常量池中是否存在javaEEhadoop值: //如果存在，则返回常量池中javaEEhadoop的地址； //如果字符串常量池中不存在javaEEhadoop，则在常量池中加载一份javaEEhadoop，并返回此对象的地址。 String s8 = s6.intern(); System.out.println(s3 == s8);//true System.out.println(s6 == s8);//false} 字符串拼接的底层细节变量拼接的原理代码： 123456789@Testpublic void test3(){ String s1 = &quot;a&quot;; String s2 = &quot;b&quot;; String s3 = &quot;ab&quot;; String s4 = s1 + s2;// System.out.println(s3 == s4);//false} 字节码： 原理： s1 + s2 的执行细节：(变量s是临时定义的） ① StringBuilder s = new StringBuilder(); ② s.append(“a”) ③ s.append(“b”) ④ s.toString() –&gt; 约等于 new String(“ab”)，但不等价 补充：在jdk5.0之后使用的是StringBuilder,在jdk5.0之前使用的是StringBuffer 常量或常量引用拼接(final)字符串拼接操作不一定使用的是StringBuilder!。 如果拼接符号左右两边都是字符串常量或常量引用变量，则仍然使用编译期优化，即非StringBuilder的方式。 举例： 12345678@Testpublic void test4(){ final String s1 = &quot;a&quot;; final String s2 = &quot;b&quot;; String s3 = &quot;ab&quot;; String s4 = s1 + s2; System.out.println(s3 == s4);//true} 字节码： 为变量 s4 赋值时，直接使用 #16 符号引用，即字符串常量 “ab”。 所以：针对于final修饰类、方法、基本数据类型、引用数据类型的量的结构时，能使用上final的时候建议使用上。 拼接操作与 append 操作的效率对比代码123456789101112131415161718192021222324252627282930@Testpublic void test6(){ long start = System.currentTimeMillis(); //method1(100000);//4014毫秒 method2(100000);//7毫秒 long end = System.currentTimeMillis(); System.out.println(&quot;花费的时间为：&quot; + (end - start));}public void method1(int highLevel){ String src = &quot;&quot;; for(int i = 0;i &lt; highLevel;i++){ src = src + &quot;a&quot;;//每次循环都会创建一个StringBuilder、String } //System.out.println(src);}public void method2(int highLevel){ //只需要创建一个StringBuilder StringBuilder src = new StringBuilder(); for (int i = 0; i &lt; highLevel; i++) { src.append(&quot;a&quot;); } //System.out.println(src);} 结论通过StringBuilder的append()的方式添加字符串的效率要远高于使用String的字符串拼接方式！ 详情原因： 创建对象的角度： StringBuilder的append()的方式：自始至终中只创建过一个StringBuilder的对象 使用String的字符串拼接方式：创建过多个StringBuilder和String对象 内存占用的角度； 使用String的字符串拼接方式：内存中由于创建过多个StringBuilder和String对象，内存占用更大；如果进行GC，需要花费额外的时间。 优化空间在实际开发中，如果基本确定要前前后后添加的字符串长度不高于某个限定值highLevel的情况下，建议使用构造器实例化，这样可以避免频繁扩容： StringBuilder s = new StringBuilder(highLevel); //底层是new char[highLevel]","link":"/JVM-034-StringTable-%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8B%BC%E6%8E%A5%E6%93%8D%E4%BD%9C/"},{"title":"JVM-035-StringTable-intern的使用以及StringTable的垃圾回收","text":"intern()的使用介绍 翻译： 字符串常量池最初是空的，由String类私有的维护。在调用intern方法时，如果池中已经包含了由equals(object)方法确定的与该字符串内容相等的字符串，则返回池中的字符串地址。否则，该字符串对象将被添加到池中，并返回该字符串对象的地址。 intern是一个native方法，调用的是底层C的方法 如果不是用双引号声明的String对象，可以使用String提供的intern方法：intern方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中。 比如：String myInfo = new string(&quot;I love atguigu&quot;).intern(); 也就是说，如果在任意字符串上调用String.intern方法，那么其返回结果所指向的那个类实例，必须和直接以常量形式出现的字符串实例完全相同。因此，下列表达式的值必定是true (&quot;a&quot;+&quot;b&quot;+&quot;c&quot;).intern()==&quot;abc&quot; 通俗点讲，Interned String就是确保字符串在内存里只有一份拷贝，这样可以节约内存空间，加快字符串操作任务的执行速度。注意，这个值会被存放在字符串内部池（String Intern Pool） 举例一如何保证变量s指向的是字符串常量池中的数据呢？ 答：有两种方式。 方式一：字面量声明 String s = &quot;buubiu&quot;; 方式二：无论前面String是如何定义的，后面都调用了intern()方法： String s = new String(&quot;buubiu&quot;).intern(); String s = new StringBuilder(&quot;buubiu&quot;).toString().intern(); 举例二new String(“ab”)会创建几个对象？ 代码： 12345public class StringNewTest { public static void main(String[] args) { String str = new String(&quot;ab&quot;); }} 字节码指令： 1234560 new #2 &lt;java/lang/String&gt; //在堆中创建了一个 String 对象3 dup4 ldc #3 &lt;ab&gt; //在字符串常量池中放入 对象“ab”（如果之前字符串常量池中没有 “ab” 的话）6 invokespecial #4 &lt;java/lang/String.&lt;init&gt;&gt;9 astore_110 return 答：通过字节码，知道是两个 new关键字在堆空间创建的 字符串常量池中的对象”ab”。 字节码指令：ldc 举例三new String(“a”) + new String(“b”) 会创建几个对象？ 代码： 123456public class StringNewTest { public static void main(String[] args) { String str = new String(&quot;a&quot;) + new String(&quot;b&quot;); }} 字节码指令： 123456789101112131415160 new #2 &lt;java/lang/StringBuilder&gt; //拼接字符串会创建一个 StringBuilder 对象3 dup4 invokespecial #3 &lt;java/lang/StringBuilder.&lt;init&gt;&gt;7 new #4 &lt;java/lang/String&gt; //创建 String 对象，对应于 new String(“a”)10 dup11 ldc #5 &lt;a&gt; //在字符串常量池中放入 “a”（如果之前字符串常量池中没有 “a” 的话）13 invokespecial #6 &lt;java/lang/String.&lt;init&gt;&gt;16 invokevirtual #7 &lt;java/lang/StringBuilder.append&gt;19 new #4 &lt;java/lang/String&gt; //创建 String 对象，对应于 new String(“b”)22 dup23 ldc #8 &lt;b&gt; //在字符串常量池中放入 “b”（如果之前字符串常量池中没有 “b” 的话）25 invokespecial #6 &lt;java/lang/String.&lt;init&gt;&gt;28 invokevirtual #7 &lt;java/lang/StringBuilder.append&gt;31 invokevirtual #9 &lt;java/lang/StringBuilder.toString&gt; //调用 StringBuilder 的 toString() 方法，会生成一个 String 对象34 astore_135 return 答： 对象1：new StringBuilder() 对象2： new String(“a”) 对象3： 常量池中的”a” 对象4： new String(“b”) 对象5： 常量池中的”b” 对象6 ：new String(“ab”) 深入剖析： StringBuilder的toString()； 强调一下，toString()的调用，在字符串常量池中，没有生成”ab” 总结intern()的使用（ jdk6 vs jdk7/8）总结String的intern()的使用： Jdk1.6中，将这个字符串对象尝试放入字符串常量池（串池）。 如果串池中有，则并不会放入。返回已有的串池中的对象的地址 如果没有，会把 此对象复制一份，放入串池，即创建了一个新地址，并返回串池中的对象地址 Jdk1.7起，将这个字符串对象尝试放入字符串常量池（串池）。 如果串池中有，则并不会放入。返回已有的串池中的对象的地址 如果没有，则会把 对象的引用地址复制一份，即还是原来的地址，放入串池，并返回串池中的引用地址。 举例四1234567891011121314public class StringIntern { public static void main(String[] args) { String s = new String(&quot;1&quot;); s.intern(); String s2 = &quot;1&quot;; System.out.println(s == s2);//jdk6：false jdk7/8：false String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;); s3.intern(); String s4 = &quot;11&quot;; System.out.println(s3 == s4);//jdk6：false jdk7/8：true }} 分析： 首先在jdk6中，字符串常量池是在永久代，即方法区中，而对象是分配在堆中，所以他们的地址永远不相等； 下面来分析在Jdk7/8中的情况： s == s2 虽然第四行 s.intern();，但是在调用此方法之前，字符串常量池中已经存在了”1” 由于是后调用intern()方法，并没有赋值给s，所以s还是指向在堆中的地址 而s2是字面量赋值，jvm直接把字符串常量池的“1”的地址返回给s2 所以结果为false 若第三行改为：String s = new String(&quot;1&quot;).intern();，则结果就为true了。 s3 == s4 经过举例三分析得到：执行完第8行的代码，在堆中有了一个new String(“11”)这样的String对象，但是在字符串常量池中没有”11” 所以s3变量记录的地址为：new String(“11”) 接着执行s3.intern()，在字符串常量池中生成”11” 在JDK6的版本中，字符串常量池还在永久代，所以直接在永久代生成”11”,也就有了新的地址 而在JDK7的后续版本中，字符串常量池被移动到了堆中，此时堆里已经有new String（”11”）了，出于节省空间的目的，直接将堆中的那个字符串的引用地址储存在字符串常量池中，即字符串常量池中存的是new String（”11”）在堆中的地址 s4变量记录的地址：使用的是上一行代码代码执行时，在常量池中生成的”11”的地址 所以在JDK7后续版本中，s3和s4指向的完全是同一个地址。 通过内存图来分析 jdk6: ​ jdk7/8: 举例五是举例四的拓展 12345678910public class StringIntern1 { public static void main(String[] args) { String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;); String s4 = &quot;11&quot;; String s5 = s3.intern(); System.out.println(s3 == s4);//jdk6：false jdk7/8：false System.out.println(s5 == s4);//jdk6：true jdk7/8：true }} 分析： 执行完第3行代码以后，字符串常量池中，不存在”11” 第4行代码：在字符串常量池中生成对象”11” s3 是堆中的 “11” ，s4 是字符串常量池中的 “11”，所以 s3 不等于 s4 s5 是从字符串常量池中取回来的引用，所以s5等于s4 举例六123456789public class StringExer1 { public static void main(String[] args) { String s = new String(&quot;a&quot;) + new String(&quot;b&quot;); String s2 = s.intern(); System.out.println(s2 == &quot;ab&quot;);//jdk6:true jdk7/8:true System.out.println(s == &quot;ab&quot;);//jdk6:false jdk7/8:true }} 分析： 执行第三行代码，相当于new String(“ab”)，并且在执行完以后，字符串常量池中并没有”ab” 执行第四行代码后，若是jdk6：在字符串常量池（此时在永久代）中创建一个字符串”ab”；若是jdk7/8：字符串常量池（此时在堆中）中没有创建字符串”ab”,而是创建一个引用，指向new String(“ab”)， 将此引用返回 图解： 变形题一123456789101112public class StringExer1 { public static void main(String[] args) { //加一行这个 String x = &quot;ab&quot;; String s = new String(&quot;a&quot;) + new String(&quot;b&quot;);//new String(&quot;ab&quot;) String s2 = s.intern(); System.out.println(s2 == &quot;ab&quot;);//jdk6/jdk7/8：true System.out.println(s == &quot;ab&quot;);//jdk6/jdk7/8：false }} 分析： 变形题二12345678910public class StringExer2 { public static void main(String[] args) { String s1 = new String(&quot;ab&quot;);//执行完以后，会在字符串常量池中生成&quot;ab&quot; // String s1 = new String(&quot;a&quot;) + new String(&quot;b&quot;);//执行完以后，不会在字符串常量池中生成&quot;ab&quot; s1.intern(); String s2 = &quot;ab&quot;; System.out.println(s1 == s2);//注释3行结果：jdk6/jdk7/8：true 注释4行结果：jdk6/jdk7/8：false }} intern() 的效率测试（内存空间角度）代码123456789101112131415161718192021222324public class StringIntern2 { static final int MAX_COUNT = 1000 * 10000; static final String[] arr = new String[MAX_COUNT]; public static void main(String[] args) { Integer[] data = new Integer[]{1,2,3,4,5,6,7,8,9,10}; long start = System.currentTimeMillis(); for (int i = 0; i &lt; MAX_COUNT; i++) {// arr[i] = new String(String.valueOf(data[i % data.length])); arr[i] = new String(String.valueOf(data[i % data.length])).intern(); } long end = System.currentTimeMillis(); System.out.println(&quot;花费的时间为：&quot; + (end - start)); try { Thread.sleep(1000000); } catch (InterruptedException e) { e.printStackTrace(); } System.gc(); }} 采用第10行执行的话，相当于直接 new String ：由于每个 String 对象都是 new 出来的，所以程序需要维护大量存放在堆空间中的 String 实例，程序内存占用也会变高，如图： 采用第11行执行的话，相当于使用 intern() 方法：由于数组中字符串的引用都指向字符串常量池中的字符串，所以程序需要维护的 String 对象更少，内存占用也更低， 原理：调用了intern()方法使用了字符串常量池里的字符串，那么前面堆里的字符串便会被GC掉，这也是intern省内存的关键原因 如图： 结论 对于程序中大量使用已存在的字符串时，尤其存在很多已经重复的字符串时，使用intern()方法能够节省很大的内存空间。 大的网站平台，需要内存中存储大量的字符串。比如社交网站，很多人都存储：北京市、海淀区等信息。这时候如果字符串都调用intern() 方法，就会很明显降低内存的大小。 StringTable 的垃圾回收代码： 12345678910111213141516/** * String的垃圾回收: * -Xms15m -Xmx15m -XX:+PrintStringTableStatistics -XX:+PrintGCDetails */public class StringGCTest { public static void main(String[] args) { int total = 0; int total = 100; int total = 10000; int total = 100000; for (int j = 0; j &lt; total; j++) { //String.valueOf底层实际上是调用的 new String() String.valueOf(j).intern(); } }} 分析： 依次把total的数值从0改到100000，打印出字符串常量池的大小，如图： 以上分析得出当total为100000时，实际上字符串常量池里面是没有增加十万个的，因为发生了GC（YoungGC ），如图： 说明 StringTable 区发生了垃圾回收 G1 中的 String 去重操作官方文档：http://openjdk.java.net/jeps/192 背景 注意不是字符串常量池的去重操作，字符串常量池本身就没有重复的 对许多Java应用（有大的也有小的）做的测试得出以下结果： 堆存活数据集合里面String对象占了25% 堆存活数据集合里面重复的String对象有13.5% String对象的平均长度是45 许多大规模的Java应用的瓶颈在于内存，测试表明，在这些类型的应用里面，Java堆中存活的数据集合差不多25%是String对象。更进一步，这里面差不多一半String对象是重复的，重复的意思是说：string1.equals(string2)= true。堆上存在重复的String对象必然是一种内存的浪费。这个项目将在G1垃圾收集器中实现自动持续对重复的String对象进行去重，这样就能避免浪费内存。 实现步骤 当垃圾收集器工作的时候，会访问堆上存活的对象。对每一个访问的对象都会检查是否是候选的要去重的String对象。 如果是，把这个对象的一个引用插入到队列中等待后续的处理。一个去重的线程在后台运行，处理这个队列。处理队列的一个元素意味着从队列删除这个元素，然后尝试去重它引用的String对象。 使用一个Hashtable来记录所有的被String对象使用的不重复的char数组。当去重的时候，会查这个Hashtable，来看堆上是否已经存在一个一模一样的char数组。 如果存在，String对象会被调整引用那个数组，释放对原来的数组的引用，最终会被垃圾收集器回收掉。 如果查找失败，char数组会被插入到Hashtable，这样以后用的时候就可以共享这个数组了。 命令行选项启动去重 UseStringDeduplication(bool) ：开启String去重，默认是不开启的，需要手动开启。 PrintStringDeduplicationStatistics(bool) ：打印详细的去重统计信息 stringDeduplicationAgeThreshold(uintx) ：达到这个年龄的String对象被认为是去重的候选对象","link":"/JVM-035-StringTable-intern%E7%9A%84%E4%BD%BF%E7%94%A8%E4%BB%A5%E5%8F%8AStringTable%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"title":"JVM-036-垃圾回收-概述","text":"什么是垃圾 垃圾是指在运行程序中没有任何指针指向的对象，这个对象就是需要被回收的垃圾。 外文：An object is considered garbage when it can no longer be reached from any pointer in the running program. 如果不及时对内存中的垃圾进行清理，那么，这些垃圾对象所占的内存空间会一直保留到应用程序结束，被保留的空间无法被其他对象使用，甚至可能导致内存溢出。 为什么需要GC 对于高级语言来说，一个基本认知是如果不进行垃圾回收，内存迟早都会被消耗完，因为不断地分配内存空间而不进行回收，就好像不停地生产生活垃圾而从来不打扫一样。 除了释放没用的对象，垃圾回收也可以清除内存里的记录碎片。碎片整理将所占用的堆内存移到堆的一端，以便JVM将整理出的内存分配给新的对象。 随着应用程序所应付的业务越来越庞大、复杂，用户越来越多，没有GC就不能保证应用程序的正常进行。而经常造成STW的GC又跟不上实际的需求，所以才会不断地尝试对GC进行优化。 早期垃圾回收 在早期的C/C++时代，垃圾回收基本上是手工进行的。开发人员可以使用new关键字进行内存申请，并使用delete关键字进行内存释放。比如以下代码： 1234MibBridge *pBridge= new cmBaseGroupBridge()；//如果注册失败，使用Delete释放该对象所占内存区域if(pBridge-&gt;Register(kDestroy)！=NO ERROR) delete pBridge； 这种方式可以灵活控制内存释放的时间，但是会给开发人员带来频繁申请和释放内存的管理负担。倘若有一处内存区间由于程序员编码的问题忘记被回收，那么就会产生内存泄漏，垃圾对象永远无法被清除，随着系统运行时间的不断增长，垃圾对象所耗内存可能持续上升，直到出现内存溢出并造成应用程序崩溃。 有了垃圾回收机制后，上述代码极有可能变成这样 12MibBridge *pBridge=new cmBaseGroupBridge(); pBridge-&gt;Register(kDestroy); 现在，除了Java以外，C#、Python、Ruby等语言都使用了自动垃圾回收的思想，也是未来发展趋势，可以说这种自动化的内存分配和垃圾回收方式已经成为了现代开发语言必备的标准。 Java垃圾回收机制采用 自动内存管理 优点 自动内存管理，无需开发人员手动参与内存的分配与回收，这样降低内存泄漏和内存溢出的风险 没有垃圾回收器，java也会和c++一样，各种悬垂指针，野指针，泄露问题让你头疼不已。 自动内存管理机制，将程序员从繁重的内存管理中释放出来，可以更专心地专注于业务开发 Oracle官网关于垃圾回收的介绍 https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/toc.html 缺点 对于Java开发人员而言，自动内存管理就像是一个黑匣子，如果过度依赖于“自动”，那么这将会是一场灾难，最严重的就会弱化Java开发人员在程序出现内存溢出时定位问题和解决问题的能力。 此时，了解JVM的自动内存分配和内存回收原理就显得非常重要，只有在真正了解JVM是如何管理内存后，我们才能够在遇见OutofMemoryError时，快速地根据错误异常日志定位问题和解决问题。 当需要排查各种内存溢出、内存泄漏问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，我们就必须对这些“自动化”的技术实施必要的监控和调节。 应该关心哪些区域的回收 垃圾收集器可以对年轻代回收，也可以对老年代回收，甚至是全堆和方法区的回收， 其中，Java堆是垃圾收集器的工作重点 从次数上讲： 频繁收集Young区 较少收集Old区 基本不收集Perm区（或元空间）","link":"/JVM-036-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E6%A6%82%E8%BF%B0/"},{"title":"JVM-037-垃圾回收-相关算法-标记阶段","text":"对象存活判断在堆里存放着几乎所有的Java对象实例，在GC执行垃圾回收之前，首先需要区分出内存中哪些是存活对象，哪些是已经死亡的对象。只有被标记为己经死亡的对象，GC才会在执行垃圾回收时，释放掉其所占用的内存空间，因此这个过程我们可以称为垃圾标记阶段。 那么在JVM中究竟是如何标记一个死亡对象呢？简单来说，当一个对象已经不再被任何的存活对象继续引用时，就可以宣判为已经死亡。 判断对象存活一般有两种方式：引用计数算法和可达性分析算法。 引用计数算法定义引用计数算法（Reference Counting）比较简单，对每个对象保存一个整型的引用计数器属性。用于记录对象被引用的情况。 实现思路对于一个对象A，只要有任何一个对象引用了A，则A的引用计数器就加1；当引用失效时，引用计数器就减1。只要对象A的引用计数器的值为0，即表示对象A不可能再被使用，可进行回收。 优缺点优点： 实现简单，垃圾对象便于辨识； 判定效率高，回收没有延迟性。 缺点: 它需要单独的字段存储计数器，这样的做法增加了存储空间的开销。 每次赋值都需要更新计数器，伴随着加法和减法操作，这增加了时间开销。 引用计数器有一个严重的问题，即无法处理循环引用的情况。这是一条致命缺陷，导致在Java的垃圾回收器中没有使用这类算法。 循环引用当p的指针断开的时候，内部的引用形成一个循环，计数器都还算1，无法被回收，这就是循环引用，从而造成内存泄漏 总结 引用计数算法，是很多语言的资源回收选择，例如因人工智能而更加火热的Python，它更是同时支持引用计数和垃圾收集机制。 具体哪种最优是要看场景的，业界有大规模实践中仅保留引用计数机制，以提高吞吐量的尝试。 Java并没有选择引用计数，是因为其存在一个基本的难题，也就是很难处理循环引用关系。 Python如何解决循环引用？ 手动解除：很好理解，就是在合适的时机，解除引用关系。 使用弱引用weakref，weakref是Python提供的标准库，旨在解决循环引用。 可达性分析算法定义 相对于引用计数算法而言，可达性分析算法不仅同样具备实现简单和执行高效等特点，更重要的是该算法可以有效地解决在引用计数算法中循环引用的问题，防止内存泄漏的发生。 相较于引用计数算法，这里的可达性分析就是Java、C#选择的。这种类型的垃圾收集通常也叫作追踪性垃圾收集（Tracing Garbage Collection）或者叫作根搜索算法。 实现思路所谓”GC Roots”根集合就是一组必须活跃的引用，基本思路： 可达性分析算法是以根对象集合（GC Roots）为起始点，按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达。 使用可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索所走过的路径称为引用链（Reference Chain） 如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象己经死亡，可以标记为垃圾对象。 在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象。 GC Roots包含什么元素固定的元素： 虚拟机栈中引用的对象 比如：各个线程被调用的方法中使用到的参数、局部变量等。 本地方法栈内JNI（通常说的本地方法）引用的对象 堆（JDK1.6及以前在方法区）中类静态属性引用的对象 比如：Java类的引用类型静态变量 堆（JDK1.6及以前在方法区）中常量引用的对象 比如：字符串常量池（String Table）里的引用 所有被同步锁synchronized持有的对象 Java虚拟机内部的引用。 基本数据类型对应的Class对象，一些常驻的异常对象（如：NullPointerException、OutofMemoryError），系统类加载器。 反映java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。 其他元素： 除了这些固定的GC Roots集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整GC Roots集合。比如：分代收集和局部回收（PartialGC）。 如果只针对Java堆中的某一块区域进行垃圾回收（比如：典型的只针对新生代），必须考虑到这个区域的对象完全有可能被其他区域的对象所引用（因为内存区域是虚拟机自己虚拟出来的，物理上不是孤立封闭的），这时候就需要一并将关联的区域对象也加入GC Roots集合中去考虑，才能保证可达性分析的准确性。 总结：由于GC Root采用栈方式存放变量和指针，所以如果一个指针，它保存了堆内存里面的对象，但是自己又不存放在堆内存里面，那它就是一个GC Root。 注意 如果要使用可达性分析算法来判断内存是否可回收，那么分析工作必须在一个能保障一致性的快照中进行。这点不满足的话分析结果的准确性就无法保证。 这点也是导致GC进行时必须”Stop The World“的一个重要原因。 即使是号称（几乎）不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。","link":"/JVM-037-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95-%E6%A0%87%E8%AE%B0%E9%98%B6%E6%AE%B5/"},{"title":"JVM-039-垃圾回收-MAT与JProfiler的GC Roots溯源","text":"MAT 介绍 MAT是Memory Analyzer的简称，它是一款功能强大的Java堆内存分析器。用于查找内存泄漏以及查看内存消耗情况。 MAT是基于Eclipse开发的，是一款免费的性能分析工具。 可以在http://www.eclipse.org/mat 下载并使用MAT 为了实时分析GC Roots是哪些东西，中间需要用到一个dump的文件 获取 dump 文件方式代码： GCRootsTest.java12345678910111213141516171819202122232425public class GCRootsTest { public static void main(String[] args) { List&lt;Object&gt; numList = new ArrayList&lt;&gt;(); Date birth = new Date(); for (int i = 0; i &lt; 100; i++) { numList.add(String.valueOf(i)); try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(&quot;数据添加完毕，请操作：&quot;); new Scanner(System.in).next(); numList = null; birth = null; System.out.println(&quot;numList、birth已置空，请操作：&quot;); new Scanner(System.in).next(); System.out.println(&quot;结束&quot;); }} numList 和 birth 在第一次捕捉内存快照的时候，为 GC Roots 之后 numList 和 birth 置为 null ，对应的引用对象被回收，在第二次捕捉内存快照的时候，就不再是 GC Roots 方式一：命令行使用 jmap 方式二：使用JVisualVM捕获的heap dump文件是一个临时文件，关闭JVisualVM后自动删除，若要保留，需要将其另存为文件。 先执行第一步，然后停下来，去生成此步骤dump文件 输入命令，继续执行程序 我们接着捕获第二张堆内存快照 右键 –&gt; 另存为即可 使用 MAT 查看堆内存快照 打开 MAT ，选择File –&gt; Open File，打开刚刚的两个dump文件，我们先打开第一个dump文件 选择Java Basics –&gt; GC Roots 第一次捕捉堆内存快照时，GC Roots 中包含代码定义的两个局部变量，类型分别为 ArrayList 和 Date，Total:21 打开第二个dump文件，第二次捕获内存快照时，由于两个局部变量引用的对象被释放，所以这两个局部变量不再作为 GC Roots ，从 Total Entries = 19 也可以看出（少了两个 GC Roots） JProfiler GC Roots 溯源在实际开发中，很少会查看所有的GC Roots。一般都是查看某一个或几个对象的GC Root是哪个，这个过程叫GC Roots 溯源 下面使用 JProfiler 进行 GC Roots 溯源演示 代码: 12345678910111213141516171819202122232425public class GCRootsTest { public static void main(String[] args) { List&lt;Object&gt; numList = new ArrayList&lt;&gt;(); Date birth = new Date(); for (int i = 0; i &lt; 100; i++) { numList.add(String.valueOf(i)); try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(&quot;数据添加完毕，请操作：&quot;); new Scanner(System.in).next(); numList = null; birth = null; System.out.println(&quot;numList、birth已置空，请操作：&quot;); new Scanner(System.in).next(); System.out.println(&quot;结束&quot;); }} JProfiler 分析 OOM代码： 1234567891011121314151617181920212223242526package com.buubiu;import java.util.ArrayList;/** * -Xms8m -Xmx8m -XX:+HeapDumpOnOutOfMemoryError * HeapDumpOnOutOfMemoryError：这个参数的意思是当程序出现OOM的时候就会在当前工程目录生成一个dump文件 *.hprof */public class HeapOOM { byte[] buffer = new byte[1 * 1024 * 1024];//1MB public static void main(String[] args) { ArrayList&lt;HeapOOM&gt; list = new ArrayList&lt;&gt;(); int count = 0; try{ while(true){ list.add(new HeapOOM()); count++; } }catch (Throwable e){ System.out.println(&quot;count = &quot; + count); e.printStackTrace(); } }} 输出结果： 123456789java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid31770.hprof ...Heap dump file created [7332138 bytes in 0.017 secs]count = 6java.lang.OutOfMemoryError: Java heap space at com.buubiu.HeapOOM.&lt;init&gt;(HeapOOM.java:10) at com.buubiu.HeapOOM.main(HeapOOM.java:18)Process finished with exit code 0 用JProfiler打开这个dump文件 可以找到这个超大对象 可以发现是main() 线程中出问题，并且是18行","link":"/JVM-039-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-MAT%E4%B8%8EJProfiler%E7%9A%84GC-Roots%E6%BA%AF%E6%BA%90/"},{"title":"JVM-040-垃圾回收-相关算法-清除阶段","text":"引入当成功区分出内存中存活对象和死亡对象后，GC接下来的任务就是执行垃圾回收，释放掉无用对象所占用的内存空间，以便有足够的可用内存空间为新对象分配内存。目前在JVM中比较常见的三种垃圾收集算法是 标记-清除算法（Mark-Sweep） 复制算法（Copying） 标记-压缩算法（Mark-Compact） 标记-清除算法（Mark-Sweep）背景标记-清除算法（Mark-Sweep）是一种非常基础和常见的垃圾收集算法，该算法被J.McCarthy等人在1960年提出并并应用于Lisp语言。 执行过程当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（也被称为stop the world），然后进行两项工作，第一项则是标记，第二项则是清除 标记：Collector从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的Header中记录为可达对象。（注意：标记的是被引用的对象，也就是可达对象，并非标记的是即将被清除的垃圾对象） 清除：Collector对堆内存从头到尾进行线性的遍历，如果发现某个对象在其Header中没有标记为可达对象，则将其回收。 图示 内存分配方式采用空闲列表分配内存 优缺点优点 是一种非常基础和常见的垃圾收集算法 比较容易被人想到 缺点 标记清除算法的效率不算高 在进行GC的时候，需要停止整个应用程序，用户体验较差 这种方式清理出来的空闲内存是不连续的，容易产生内碎片，而且需要维护一个空闲列表 注意：何为清除？这里所谓的清除并不是真的置空，而是把需要清除的对象地址保存在空闲的地址列表里。下次有新对象需要加载时，判断垃圾的位置空间是否够，如果够，就存放（也就是覆盖原有的地址）。 关于空闲列表是在为对象分配内存的时候提过：空闲列表与指针碰撞 如果内存规整 采用指针碰撞的方式进行内存分配 如果内存不规整(或者说不连续的) 虚拟机需要维护一个空闲列表 采用空闲列表分配内存 复制算法（Copying）背景为了解决标记-清除算法在垃圾收集效率方面的缺陷，M.L.Minsky于1963年发表了著名的论文，“使用双存储区的Lisp语言垃圾收集器CA LISP Garbage Collector Algorithm Using Serial Secondary Storage）”。M.L.Minsky在该论文中描述的算法被人们称为复制（Copying）算法，它也被M.L.Minsky本人成功地引入到了Lisp语言的一个实现版本中。 原理将活着的内存空间分为两块，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象；然后在交换两个内存的角色，最后完成垃圾回收。 新生代里面就用到了复制算法，Eden区和S0区存活对象整体复制到S1区 图示 内存分配方式采用指针碰撞的方式进行内存分配 优缺点优点 没有标记和清除过程，实现简单，运行高效 复制过去以后保证空间的连续性，不会出现“碎片”问题。 缺点 此算法的缺点也是很明显的，就是需要两倍的内存空间。 对于G1这种分拆成为大量region的GC，复制而不是移动，意味着GC需要维护region之间对象引用关系，不管是内存占用或者时间开销也不小 如果系统中的存活对象很多，那么复制算法需要复制的存活对象数量就很大，这样的话效率很低 场景在新生代，对常规应用的垃圾回收，一次通常可以回收70% - 99% 的内存空间。回收性价比很高。所以现在的商业虚拟机都是用这种收集算法回收新生代。 标记-压缩算法（Mark-Compact）背景 复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代，更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活对象较多，复制的成本也将很高。因此，基于老年代垃圾回收的特性，需要使用其他的算法。 标记-清除算法的确可以应用在老年代中，但是该算法不仅执行效率低下，而且在执行完内存回收后还会产生内存碎片，所以JVM的设计者需要在此基础之上进行改进。标记-压缩（Mark-Compact）算法由此诞生。 1970年前后，G.L.Steele、C.J.Chene和D.s.Wise等研究者发布标记-压缩算法。在许多现代的垃圾收集器中，人们都使用了标记-压缩算法或其改进版本。 执行过程 第一阶段和标记清除算法一样，从根节点开始标记所有被引用对象 第二阶段将所有的存活对象压缩到内存的一端，按顺序排放。 最后，清理边界外所有的空间。 与标记-清除算法的比较 标记-压缩算法的最终效果等同于标记-清除算法执行完成后，再进行一次内存碎片整理，因此，也可以把它称为标记-清除-压缩（Mark-Sweep-Compact）算法。 二者的本质差异在于标记-清除算法是一种非移动式的回收算法，标记-压缩是移动式的。是否移动回收后的存活对象是一项优缺点并存的风险决策。 可以看到，标记的存活对象将会被整理，按照内存地址依次排列，而未被标记的内存会被清理掉。如此一来，当我们需要给新对象分配内存时，JVM只需要持有一个内存的起始地址即可，这比维护一个空闲列表显然少了许多开销。 内存分配方式采用指针碰撞的方式进行内存分配 优缺点优点 消除了标记-清除算法当中，内存区域分散的缺点，我们需要给新对象分配内存时，JVM只需要持有一个内存的起始地址即可。 消除了复制算法当中，内存减半的高额代价。 缺点 从效率上来说，标记-整理算法要低于复制算法，复制算法低于标记-清除算法。 移动对象的同时，如果对象被其他对象引用，则还需要调整引用的地址（因为HotSpot虚拟机采用的不是句柄池的方式，而是直接指针） 移动过程中，需要全程暂停用户应用程序。即：STW ，涉及到移动，时间比标记-清除长一些（其他算法也存在，只是暂停的时间长短不同） 对比三种算法 标记清除Mark-Sweep 标记整理Mark-Compact 复制Copying 速率 中等 最慢 最快 空间开销 少（但会堆积碎片） 少（不堆积碎片） 通常需要活对象的2倍大小（不堆积碎片） 移动对象 否 是 是 效率上来说，复制算法是当之无愧的老大，但是却浪费了太多内存。 而为了尽量兼顾上面提到的三个指标，标记-整理算法相对来说更平滑一些，但是效率上不尽如人意，它比复制算法多了一个标记的阶段，比标记-清除多了一个整理内存的阶段。","link":"/JVM-040-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95-%E6%B8%85%E9%99%A4%E9%98%B6%E6%AE%B5/"},{"title":"JVM-041-垃圾回收-相关算法-算法使用方式","text":"没有最好的算法，只有最合适的算法 分代收集算法(Generational Collecting)引入前面所有这些算法中，并没有一种算法可以完全替代其他算法，它们都具有自己独特的优势和特点。分代收集算法应运而生。分代的思想被现有的虚拟机广泛使用。几乎所有的垃圾回收器都区分新生代和老年代。 基本思想 分代收集算法，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率。 在Java程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关，比如Http请求中的Session对象、线程、Socket连接，这类对象跟业务直接挂钩，因此生命周期比较长。但是还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期会比较短，比如：String对象，由于其不变类的特性，系统会产生大量的这些对象，有些对象甚至只用一次即可回收。 场景目前几乎所有的GC都采用分代收集（Generational Collecting）算法执行垃圾回收的。 在HotSpot中，基于分代的概念，GC所使用的内存回收算法必须结合年轻代和老年代各自的特点。 年轻代（Young Gen） 年轻代特点：区域相对老年代较小，对象生命周期短、存活率低，回收频繁。使用方法：这种情况复制算法的回收整理，速度是最快的。复制算法的效率只和当前存活对象大小有关，因此很适用于年轻代的回收。而复制算法内存利用率不高的问题，通过hotspot中的两个survivor的设计得到缓解。 老年代（Tenured Gen） 老年代特点：区域较大，对象生命周期长、存活率高，回收不及年轻代频繁。使用方法：这种情况存在大量存活率高的对象，复制算法明显变得不合适。一般是由标记-清除或者是标记-清除与标记-整理的混合实现。 Mark阶段的开销与存活对象的数量成正比。 Sweep阶段的开销与所管理区域的大小成正相关。 Compact阶段的开销与存活对象的数据成正比。 以HotSpot中的CMS回收器为例，CMS是基于Mark-Sweep实现的，对于对象的回收效率很高。对于碎片问题，CMS采用基于Mark-Compact算法的Serial Old回收器作为补偿措施：当内存回收不佳（碎片导致的Concurrent Mode Failure时），将采用Serial Old执行Full GC以达到对老年代内存的整理。 增量收集算法(Incremental Collecting)引入上述现有的算法，在垃圾回收过程中，应用软件将处于一种Stop the World的状态。在Stop the World状态下，应用程序所有的线程都会挂起，暂停一切正常的工作，等待垃圾回收的完成。如果垃圾回收时间过长，应用程序会被挂起很久，将严重影响用户体验或者系统的稳定性。为了解决这个问题，增量收集（Incremental Collecting）算法诞生了。 基本思想 如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。 总的来说，增量收集算法的基础仍是传统的标记-清除和复制算法。增量收集算法通过对线程间冲突的妥善处理，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作。 优缺点优点： 使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间，使得用一种低延时的、并发的方式去执行，让用户体验会好一些。 缺点： 但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。 分区算法主要针对G1收集器来说的 引入一般来说，在相同条件下，堆空间越大，一次GC时所需要的时间就越长，有关GC产生的停顿也越长。为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。 基本思想分代算法将按照对象的生命周期长短划分成两个部分，分区算法将整个堆空间划分成连续的不同小区间。每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。 总结注意，这些只是基本的算法思路，实际GC实现过程要复杂的多，目前还在发展中的前沿GC都是复合算法，并且并行和并发兼备。","link":"/JVM-041-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95-%E7%AE%97%E6%B3%95%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"title":"JVM-042-垃圾回收-相关概念的概述-System.gc()的理解","text":"概念 在默认情况下，通过System.gc()者Runtime.getRuntime().gc() 的调用，会显式触发Full GC，同时对老年代和新生代进行回收，尝试释放被丢弃对象占用的内存。 然而System.gc()调用附带一个免责声明，无法保证对垃圾收集器的调用(不能确保立即生效) JVM实现者可以通过System.gc() 调用来决定JVM的GC行为。而一般情况下，垃圾回收应该是自动进行的，无须手动触发，否则就太过于麻烦了。在一些特殊情况下，如我们正在编写一个性能基本测试，我们可以在运行之间调用System.gc()。 示例示例一123456789101112131415public class SystemGCTest { public static void main(String[] args) { new SystemGCTest(); System.gc();//提醒jvm的垃圾回收器执行gc,但是不确定是否马上执行gc //与Runtime.getRuntime().gc();的作用一样。// System.runFinalization();//强制调用使用引用的对象的finalize()方法 } //如果发生了GC，这个finalize()一定会被调用 @Override protected void finalize() throws Throwable { super.finalize(); System.out.println(&quot;SystemGCTest 重写了finalize()&quot;); }} 输出结果不确定：有时候会调用 finalize() 方法，有时候并不会调用 示例二123456789101112131415161718192021222324252627282930313233343536373839//加上参数： -XX:+PrintGCDetailspublic class LocalVarGC { public void localvarGC1() { byte[] buffer = new byte[10 * 1024 * 1024];//10MB System.gc(); } public void localvarGC2() { byte[] buffer = new byte[10 * 1024 * 1024]; buffer = null; System.gc(); } public void localvarGC3() { { byte[] buffer = new byte[10 * 1024 * 1024]; } System.gc(); } public void localvarGC4() { { byte[] buffer = new byte[10 * 1024 * 1024]; } int value = 10; System.gc(); } public void localvarGC5() { localvarGC1(); System.gc(); } public static void main(String[] args) { LocalVarGC local = new LocalVarGC(); //通过在main方法调用这几个方法进行测试 local.localvarGC1(); }} 调用 localvarGC1() 方法 执行 System.gc() 仅仅是将年轻代的 buffer 数组对象放到了老年代，buffer对象仍然没有回收，只是放到了老年代 调用 localvarGC2() 方法 由于 buffer 数组对象没有引用指向它，执行 System.gc() 将被回收 调用 localvarGC3() 方法 虽然出了代码块的作用域，但是 buffer 数组对象并没有被回收 原因： 看看字节码：实例方法局部变量表第一个变量肯定是 this 发现局部变量表的大小是 2。但是局部变量表里只有一个索引为0，实际上索引为1的位置是buffer在占用着，执行 System.gc() 时，栈中还有 buffer 变量指向堆中的字节数组，所以没有进行GC 调用 localvarGC4() 方法 出了代码块的作用域， buffer 数组对象被回收了 原因： 出了代码块时，buffer 就出了其作用域范围，此时没有为 value 开启新的槽，value 变量直接占据了 buffer 变量的槽（Slot），导致堆中的字节数组没有引用再指向它，执行 System.gc() 时被回收。 value 位于局部变量表中索引为 1 的位置。value这个局部变量把原本属于buffer的slot给占用了，这样栈上就没有buffer变量指向new byte[10 * 1024 * 1024]实例了。 调用 localvarGC5() 方法 局部变量出了方法范围就是失效了，堆中的字节数组一定被回收了，通过局部变量表槽数也能看出来，就1个this了。","link":"/JVM-042-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%9A%84%E6%A6%82%E8%BF%B0-System-gc-%E7%9A%84%E7%90%86%E8%A7%A3/"},{"title":"JVM-043-垃圾回收-相关概念的概述-内存溢出与内存泄漏","text":"内存溢出(OutOfMemoryError)概念 内存溢出相对于内存泄漏来说，尽管更容易被理解，但是同样的，内存溢出也是引发程序崩溃的罪魁祸首之一。 由于GC一直在发展，所以一般情况下，除非应用程序占用的内存增长速度非常快，造成垃圾回收已经跟不上内存消耗的速度，否则不太容易出现OOM的情况。 大多数情况下，GC会进行各种年龄段的垃圾回收，实在不行了就放大招，来一次独占式的Full GC操作，这时候会回收大量的内存，供应用程序继续使用。 Javadoc中对OutofMemoryError的解释是，没有空闲内存，并且垃圾收集器也无法提供更多内存。 原因分析首先说没有空闲内存的情况：说明Java虚拟机的堆内存不够。原因有二： 原因一Java虚拟机的堆内存设置不够 比如：可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如我们要处理比较可观的数据量，但是没有显式指定JVM堆大小或者指定数值偏小。我们可以通过参数-Xms 、-Xmx来调整。 原因二代码中创建了大量大对象，并且长时间不能被垃圾收集器收集（存在被引用） 对于老版本的Oracle JDK，因为永久代的大小是有限的，并且JVM对永久代垃圾回收（如，常量池回收、卸载不再需要的类型）非常不积极，所以当我们不断添加新类型的时候，永久代出现OutOfMemoryError也非常多见。尤其是在运行时存在大量动态类型生成的场合；类似intern字符串缓存占用太多空间，也会导致OOM问题。对应的异常信息，会标记出来和永久代相关：”java.lang.OutOfMemoryError:PermGen space“。 随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的OOM有所改观，出现OOM，异常信息则变成了：”java.lang.OutofMemoryError:Metaspace“。直接内存不足，也会导致OOM。 其他 这里面隐含着一层意思是，在抛出OutofMemoryError之前，通常垃圾收集器会被触发，尽其所能去清理出空间。 例如：在引用机制分析中，涉及到JVM会去尝试回收软引用指向的对象等。 在java.nio.BIts.reserveMemory()方法中，我们能清楚的看到，System.gc()会被调用，以清理空间。 当然，也不是在任何情况下垃圾收集器都会被触发的 比如，我们去分配一个超大对象，类似一个超大数组超过堆的最大值，JVM可以判断出垃圾收集并不能解决这个问题，所以直接抛出OutofMemoryError。 内存泄漏(Memory Leak)概念 严格定义 也称作“存储渗漏”。严格来说，只有对象不会再被程序用到了，但是GC又不能回收他们的情况，才叫内存泄漏。 宽泛定义 但实际情况很多时候一些不太好的实践（或疏忽）会导致对象的生命周期变得很长甚至导致OOM，也可以叫做宽泛意义上的“内存泄漏”。 举例： 比如定义变量的时候，可以把变量定义到方法内为局部变量的，但是定义到了方法外面，成为了类变量，甚至是static静态类变量，生命周期就更长了。 比如在写web程序时，经常会把一下数据存到应用程序会话级别中（session)，但是有些对象本身没有必要设置到会话级别中去，导致这些对象的生命周期就会很长。 尽管内存泄漏并不会立刻引起程序崩溃，但是一旦发生内存泄漏，程序中的可用内存就会被逐步蚕食，直至耗尽所有内存，最终出现OutofMemory异常，导致程序崩溃。 注意，这里的存储空间并不是指物理内存，而是指虚拟内存大小，这个虚拟内存大小取决于磁盘交换区设定的大小。 eclipse官方图解左边的图：Java使用可达性分析算法，最上面的数据不可达，就是需要被回收的对象。 右边的图：后期有一些对象不用了，按道理应该断开引用，但是存在一些链没有断开（图示中的Forgotten Reference Memory Leak），从而导致没有办法被回收。 严格举例 单例模式单例的生命周期和应用程序是一样长的，所以在单例程序中，如果持有对外部对象的引用的话，那么这个外部对象是不能被回收的，则会导致内存泄漏的产生。 一些提供close()的资源未关闭导致内存泄漏数据库连接 dataSourse.getConnection()，网络连接socket和io连接必须手动close，否则是不能被回收的。","link":"/JVM-043-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%9A%84%E6%A6%82%E8%BF%B0-%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E4%B8%8E%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/"},{"title":"JVM-044-垃圾回收-相关概念的概述-Stop The World","text":"概念Stop-the-World，简称STW，指的是GC事件发生过程中，会产生应用程序的停顿。停顿产生时整个应用程序线程都会被暂停，没有任何响应，有点像卡死的感觉，这个停顿称为STW。 为什么会有STW可达性分析算法中枚举根节点（GC Roots）会导致所有Java执行线程停顿： 分析工作必须在一个能确保一致性的快照中进行 一致性指整个分析期间整个执行系统看起来像被冻结在某个时间点上 如果出现分析过程中对象引用关系还在不断变化，则分析结果的准确性无法保证 说明 被STW中断的应用程序线程会在完成GC之后恢复，频繁中断会让用户感觉像是网速不快造成电影卡带一样，所以我们需要减少STW的发生。 STW事件和采用哪款GC无关，所有的GC都有这个事件。 哪怕是G1也不能完全避免Stop-the-world情况发生，只能说垃圾回收器越来越优秀，回收效率越来越高，尽可能地缩短了暂停时间。 STW是JVM在后台自动发起和自动完成的。在用户不可见的情况下，把用户正常的工作线程全部停掉。 开发中不要用System.gc() ，这会导致Stop-the-World的发生。 举例证明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class StopTheWorldDemo { public static class WorkThread extends Thread { List&lt;byte[]&gt; list = new ArrayList&lt;byte[]&gt;(); public void run() { try { while (true) { for(int i = 0;i &lt; 1000;i++){ byte[] buffer = new byte[1024]; list.add(buffer); } if(list.size() &gt; 10000){ list.clear(); System.gc();//会触发full gc，进而会出现STW事件 } } } catch (Exception ex) { ex.printStackTrace(); } } } public static class PrintThread extends Thread { public final long startTime = System.currentTimeMillis(); public void run() { try { while (true) { // 每秒打印时间信息 long t = System.currentTimeMillis() - startTime; System.out.println(t / 1000 + &quot;.&quot; + t % 1000); Thread.sleep(1000); } } catch (Exception ex) { ex.printStackTrace(); } } } public static void main(String[] args) { WorkThread w = new WorkThread(); PrintThread p = new PrintThread(); w.start(); p.start(); }} 关闭工作线程 w ，观察输出：当前时间间隔与上次时间间隔基本是每隔1秒打印一次 123456780.11.12.23.24.35.36.37.3 开启工作线程 w ，观察打印输出：当前时间间隔与上次时间间隔相差 1.3s ，可以明显感受到 Stop the World 的存在 1234560.11.42.73.84.125.13","link":"/JVM-044-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%9A%84%E6%A6%82%E8%BF%B0-Stop-The-World/"},{"title":"JVM-045-垃圾回收-相关概念的概述-并行与并发","text":"程序的并发与并行并发(Concurrent)概念 在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理器上运行 并发不是真正意义上的“同时进行”，只是CPU把一个时间段划分成几个时间片段（时间区间），然后在这几个时间区间之间来回切换。由于CPU处理的速度非常快，只要时间间隔处理得当，即可让用户感觉是多个应用程序同时在进行 并行(Parallel)概念 当系统有一个以上CPU时，当一个CPU执行一个进程时，另一个CPU可以执行另一个进程，两个进程互不抢占CPU资源，可以同时进行，我们称之为并行（Parallel） 其实决定并行的因素不是CPU的数量，而是CPU的核心数量，比如一个CPU多个核也可以并行 适合科学计算，后台处理等弱交互场景 并发与并行比较 并发，指的是多个事情，在同一时间段内同时发生了。 并行，指的是多个事情，在同一时间点上同时发生了。 并发的多个任务之间是互相抢占资源的。 并行的多个任务之间是不互相抢占资源的。 只有在多CPU或者一个CPU多核的情况中，才会发生并行。否则，看似同时发生的事情，其实都是并发执行的。 垃圾回收的并发与并行并行与串行在谈论垃圾收集器的上下文语境中，它们可以解释如下： 并行(Parallel) 指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。 如ParNew、Parallel Scavenge、Parallel Old 串行（Serial） 相较于并行的概念，单线程执行。 如Serial，Serial Old 如果内存不够，则程序暂停，启动JVM垃圾回收器进行垃圾回收（单线程） 并发(Concurrent) 指同一时间段内，用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），垃圾回收线程在执行时不会停顿用户程序的运行。 用户程序在继续运行，而垃圾收集程序线程运行于另一个CPU上； 如：CMS、G1 只是同一时间段内并发，并不是没有STW，在某个时间点的时候也可能有STW。","link":"/JVM-045-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%9A%84%E6%A6%82%E8%BF%B0-%E5%B9%B6%E8%A1%8C%E4%B8%8E%E5%B9%B6%E5%8F%91/"},{"title":"JVM-046-垃圾回收-相关概念的概述-安全点与安全区域","text":"安全点(Safepoint)概念程序执行时并非在所有地方都能停顿下来开始GC，只有在特定的位置才能停顿下来开始GC，这些位置称为“安全点（Safepoint）”。 Safe Point的选择很重要，如果太少可能导致GC等待的时间太长，如果太频繁可能导致运行时的性能问题。大部分指令的执行时间都非常短暂，通常会根据“是否具有让程序长时间执行的特征”为标准。比如：选择一些执行时间较长的指令作为Safe Point，如方法调用、循环跳转和异常跳转等。 实际执行时如何在GC发生时，检查所有线程都跑到最近的安全点停顿下来呢？ 抢先式中断：（目前没有虚拟机采用了） 首先中断所有线程。如果还有线程不在安全点，就恢复线程，让线程跑到安全点。 主动式中断： 设置一个中断标志，各个线程运行到Safe Point的时候主动轮询这个标志，如果中断标志为真，则将自己进行中断挂起。 安全区域(Safe Region)概念Safepoint 机制保证了程序执行时，在不太长的时间内就会遇到可进入GC的Safepoint。但是，程序“不执行”的时候呢？例如线程处于Sleep状态或Blocked 状态，这时候线程无法响应JVM的中断请求，“走”到安全点去中断挂起，JVM也不太可能等待线程被唤醒。对于这种情况，就需要安全区域（Safe Region）来解决。 安全区域是指在一段代码片段中，对象的引用关系不会发生变化，在这个区域中的任何位置开始GC都是安全的。我们也可以把Safe Region看做是被扩展了的Safepoint。 实际执行时 当线程运行到Safe Region的代码时，首先标识已经进入了Safe Region，如果这段时间内发生GC，JVM会忽略标识为Safe Region状态的线程，让这些线程STW。 当线程即将离开Safe Region时，会检查JVM是否已经完成GC，如果完成了，则继续运行，否则线程必须等待直到收到可以安全离开Safe Region的信号为止；","link":"/JVM-046-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%9A%84%E6%A6%82%E8%BF%B0-%E5%AE%89%E5%85%A8%E7%82%B9%E4%B8%8E%E5%AE%89%E5%85%A8%E5%8C%BA%E5%9F%9F/"},{"title":"JVM-047-垃圾回收-相关概念的概述-在谈引用","text":"引入我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存中；如果内存空间在进行垃圾收集后还是很紧张，则可以抛弃这些对象。 在JDK1.2版之后，Java对引用的概念进行了扩充，将引用分为： 强引用（Strong Reference） 软引用（Soft Reference） 弱引用（Weak Reference） 虚引用（Phantom Reference） 这4种引用强度依次逐渐减弱。 除强引用外，其他3种引用均可以在java.lang.ref包中找到它们的身影。如下图，显示了这3种引用类型对应的类，开发人员可以在应用程序中直接使用它们。 场景Reference子类中只有终结器引用是包内可见的，其他3种引用类型均为public，可以在应用程序中直接使用。 强引用（StrongReference）：最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，即类似“object obj=new Object()”这种引用关系。无论任何情况下，只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象。宁可报OOM，也不会GC强引用 软引用（SoftReference）：在系统将要发生内存溢出之前，将会把这些对象列入回收范围之中进行第二次回收。如果这次回收后还没有足够的内存，才会抛出内存溢出异常。 弱引用（WeakReference）：被弱引用关联的对象只能生存到下一次垃圾收集之前。当垃圾收集器工作时，无论内存空间是否足够，都会回收掉被弱引用关联的对象。 虚引用（PhantomReference）：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来获得一个对象的实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 强引用(StrongReference)-不回收定义在Java程序中，最常见的引用类型是强引用（普通系统99%以上都是强引用），也就是我们最常见的普通对象引用，也是默认的引用类型。 当在Java语言中使用new操作符创建一个新的对象，并将其赋值给一个变量的时候，这个变量就成为指向该对象的一个强引用。 只要强引用的对象是可触及的(可达的)，垃圾收集器就永远不会回收掉被引用的对象。 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，就是可以当做垃圾被收集了，当然具体回收时机还是要看垃圾收集策略。 相对的，软引用、弱引用和虚引用的对象是软可触及、弱可触及和虚可触及的，在一定条件下，都是可以被回收的。所以，强引用是造成Java内存泄漏的主要原因之一。 举例代码： 1234567891011121314151617public class StrongReferenceTest { public static void main(String[] args) { StringBuffer str = new StringBuffer (&quot;Hello,buubiu&quot;); StringBuffer str1 = str; str = null; System.gc(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(str1); }} 输出： 1Hello,buubiu 解析： 局部变量str指向stringBuffer实例所在堆空间，通过str可以操作该实例，那么str就是stringBuffer实例的强引用. 对应内存结构： StringBuffer str = new StringBuffer(&quot;hello,buubiu&quot;); 此时，如果再运行一个赋值语句： StringBuffer str1 = str; 对应内存结构： 说明本例中的两个引用，都是强引用，强引用具备以下特点： 强引用可以直接访问目标对象。 强引用所指向的对象在任何时候都不会被系统回收，虚拟机宁愿抛出OOM异常，也不会回收强引用所指向对象。 强引用可能导致内存泄漏。 软引用(Soft Reference)-内存不足即回收定义软引用是用来描述一些还有用，但非必需的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。 说明垃圾回收器在某个时刻决定回收软可达的对象的时候，会清理软引用，并可选地把引用存放到一个引用队列（Reference Queue）。 类似弱引用，只不过Java虚拟机会尽量让软引用的存活时间长一些，迫不得已才清理。 一句话概括：当内存足够时，不会回收软引用可达的对象。内存不够时，会回收软引用的可达对象 用法在JDK1.2版之后提供了SoftReference类来实现软引用 123Object obj = new Object();// 声明强引用SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null; //销毁强引用 举例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.buubiu;import java.lang.ref.SoftReference;public class SoftReferenceTest { public static class User { public User(int id, String name) { this.id = id; this.name = name; } public int id; public String name; @Override public String toString() { return &quot;[id=&quot; + id + &quot;, name=&quot; + name + &quot;] &quot;; } } public static void main(String[] args) { //创建对象，建立软引用// SoftReference&lt;User&gt; userSoftRef = new SoftReference&lt;User&gt;(new User(1, &quot;buubiu&quot;)); //上面的一行代码，等价于如下的三行代码 User u1 = new User(1,&quot;buubiu&quot;); SoftReference&lt;User&gt; userSoftRef = new SoftReference&lt;User&gt;(u1); u1 = null;//取消强引用 //从软引用中重新获得强引用对象 System.out.println(userSoftRef.get()); System.out.println(&quot;---目前内存还不紧张---&quot;); System.gc(); System.out.println(&quot;After GC:&quot;);// //垃圾回收之后获得软引用中的对象 System.out.println(userSoftRef.get());//由于堆空间内存足够，所有不会回收软引用的可达对象。 System.out.println(&quot;---下面开始内存紧张了---&quot;); try { //让系统认为内存资源紧张、不够// byte[] b = new byte[1024 * 1024 * 7]; byte[] b = new byte[1024 * 7168 - 340 * 1024]; } catch (Throwable e) { e.printStackTrace(); } finally { //再次从软引用中获取数据 System.out.println(userSoftRef.get());//在报OOM之前，垃圾回收器会回收软引用的可达对象。 } }} JVM参数： -Xms10m -Xmx10m -XX:+PrintGCDetails 注释掉42行的时候，输出： 注释掉41行的时候，输出： 使用场景软引用通常用来实现内存敏感的缓存。比如：高速缓存就有用到软引用。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 弱引用(Weak Reference)-发现即回收定义 弱引用也是用来描述那些非必需对象，只被弱引用关联的对象只能生存到下一次垃圾收集发生为止。在系统GC时，只要发现弱引用，不管系统堆空间使用是否充足，都会回收掉只被弱引用关联的对象。 但是，由于垃圾回收器的线程通常优先级很低，因此，并不一定能很快地发现持有弱引用的对象。在这种情况下，弱引用对象可以存在较长的时间。 弱引用和软引用一样，在构造弱引用时，也可以指定一个引用队列，当弱引用对象被回收时，就会加入指定的引用队列，通过这个队列可以跟踪对象的回收情况。 弱引用对象与软引用对象的最大不同就在于，当GC在进行回收时，需要通过算法检查是否回收软引用对象，而对于弱引用对象，GC总是进行回收。弱引用对象更容易、更快被GC回收。 使用场景软引用、弱引用都非常适合来保存那些可有可无的缓存数据。如果这么做，当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出。而当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而起到加速系统的作用。 用法在JDK1.2版之后提供了WeakReference类来实现弱引用 1234// 声明强引用Object obj = new Object();WeakReference&lt;Object&gt; sf = new WeakReference&lt;Object&gt;(obj);obj = null; //销毁强引用 举例代码： 123456789101112131415161718192021222324252627282930313233package com.buubiu;import java.lang.ref.WeakReference;public class WeakReferenceTest { public static class User { public User(int id, String name) { this.id = id; this.name = name; } public int id; public String name; @Override public String toString() { return &quot;[id=&quot; + id + &quot;, name=&quot; + name + &quot;] &quot;; } } public static void main(String[] args) { //构造了弱引用 WeakReference&lt;User&gt; userWeakRef = new WeakReference&lt;User&gt;(new User(1, &quot;buubiu&quot;)); //从弱引用中重新获取对象 System.out.println(userWeakRef.get()); System.gc(); // 不管当前内存空间足够与否，都会回收它的内存 System.out.println(&quot;After GC:&quot;); //重新尝试从弱引用中获取对象 System.out.println(userWeakRef.get()); }} 输出（执行垃圾回收后，软引用对象必定被清除）： 123[id=1, name=buubiu] After GC:null 虚引用(Phantom Reference)-对象回收跟踪定义 也称为“幽灵引用”或者“幻影引用”，是所有引用类型中最弱的一个。 一个对象是否有虚引用的存在，完全不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它和没有引用几乎是一样的，随时都可能被垃圾回收器回收。 它不能单独使用，也无法通过虚引用来获取被引用的对象。当试图通过虚引用的get()方法取得对象时，总是null 。 使用场景为一个对象设置虚引用关联的唯一目的在于跟踪垃圾回收过程。比如：能在这个对象被收集器回收时收到一个系统通知。 用法 虚引用必须和引用队列一起使用。虚引用在创建时必须提供一个引用队列作为参数。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象后，将这个虚引用加入引用队列，以通知应用程序对象的回收情况。 由于虚引用可以跟踪对象的回收时间，因此，也可以将一些资源释放操作放置在虚引用中执行和记录。 在JDK1.2版之后提供了PhantomReference类来实现虚引用。 1234567// 声明强引用Object obj = new Object();// 声明引用队列ReferenceQueue phantomQueue = new ReferenceQueue();// 声明虚引用（还需要传入引用队列）PhantomReference&lt;Object&gt; sf = new PhantomReference&lt;Object&gt;(obj, phantomQueue);obj = null; 举例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package com.buubiu;import java.lang.ref.PhantomReference;import java.lang.ref.ReferenceQueue;public class PhantomReferenceTest { public static PhantomReferenceTest obj;//当前类对象的声明 static ReferenceQueue&lt;PhantomReferenceTest&gt; phantomQueue = null;//引用队列 public static class CheckRefQueue extends Thread { @Override public void run() { while (true) { if (phantomQueue != null) { PhantomReference&lt;PhantomReferenceTest&gt; objt = null; try { objt = (PhantomReference&lt;PhantomReferenceTest&gt;) phantomQueue.remove(); } catch (InterruptedException e) { e.printStackTrace(); } if (objt != null) { System.out.println(&quot;追踪垃圾回收过程：PhantomReferenceTest实例被GC了&quot;); } } } } } @Override protected void finalize() throws Throwable { //finalize()方法只能被调用一次！ super.finalize(); System.out.println(&quot;调用当前类的finalize()方法&quot;); obj = this; } public static void main(String[] args) { Thread t = new CheckRefQueue(); t.setDaemon(true);//设置为守护线程：当程序中没有非守护线程时，守护线程也就执行结束。 t.start(); phantomQueue = new ReferenceQueue&lt;PhantomReferenceTest&gt;(); obj = new PhantomReferenceTest(); //构造了 PhantomReferenceTest 对象的虚引用，并指定了引用队列 PhantomReference&lt;PhantomReferenceTest&gt; phantomRef = new PhantomReference&lt;PhantomReferenceTest&gt;(obj, phantomQueue); try { //不可获取虚引用中的对象 System.out.println(phantomRef.get()); System.out.println(&quot;第 1 次 gc&quot;); //将强引用去除 obj = null; //第一次进行GC,由于对象可复活，GC无法回收该对象 System.gc(); Thread.sleep(1000); if (obj == null) { System.out.println(&quot;obj 是 null&quot;); } else { System.out.println(&quot;obj 可用&quot;); } System.out.println(&quot;第 2 次 gc&quot;); obj = null; System.gc(); //一旦将obj对象回收，就会将此虚引用存放到引用队列中。 Thread.sleep(1000); if (obj == null) { System.out.println(&quot;obj 是 null&quot;); } else { System.out.println(&quot;obj 可用&quot;); } } catch (InterruptedException e) { e.printStackTrace(); } }} 第一次尝试获取虚引用的值，发现无法获取的，这是因为虚引用是无法直接获取对象的值，然后进行第一次GC，因为会调用finalize方法，将对象复活了，所以对象没有被回收 但是调用第二次GC操作的时候，因为finalize方法只能执行一次，所以就触发了GC操作，将对象回收了，同时将会触发第二个操作就是将待回收的对象存入到引用队列中。 输出结果： 1234567null第 1 次 gc调用当前类的finalize()方法obj 可用第 2 次 gc追踪垃圾回收过程：PhantomReferenceTest实例被GC了obj 是 null 终结器引用(Final Reference)-了解即可 它用于实现对象的finalize() 方法，也可以称为终结器引用 无需手动编码，其内部配合引用队列使用 在GC时，终结器引用入队。由Finalizer线程通过终结器引用找到被引用对象调用它的finalize()方法，第二次GC时才回收被引用的对象","link":"/JVM-047-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%9A%84%E6%A6%82%E8%BF%B0-%E5%9C%A8%E8%B0%88%E5%BC%95%E7%94%A8/"},{"title":"JVM-048-垃圾回收器-概述与分类","text":"垃圾回收器概述 垃圾收集器没有在规范中进行过多的规定，可以由不同的厂商、不同版本的JVM来实现。 由于JDK的版本处于高速迭代过程中，因此Java发展至今已经衍生了众多的GC版本。 从不同角度分析垃圾收集器，可以将GC分为不同的类型。 Java不同版本新特性 语法层面：Lambda表达式、switch、自动拆箱装箱、enum、泛型等。 API层面：Stream API、新的日期时间、Optional、String、集合框架等。 底层优化：JVM优化、GC的变化、元空间、静态域、字符串常量池等。 垃圾回收器分类按线程数分按线程数分（垃圾回收的线程数），可以分为串行垃圾回收器和并行垃圾回收器。 串行回收指的是在同一时间段内只允许有一个CPU用于执行垃圾回收操作，此时工作线程被暂停，直至垃圾收集工作结束。 在诸如单CPU处理器或者较小的应用内存等硬件平台不是特别优越的场合，串行回收器的性能表现可以超过并行回收器和并发回收器。所以，串行回收默认被应用在客户端的Client模式下的JVM中。 在并发能力比较强的CPU上，并行回收器产生的停顿时间要短于串行回收器。 和串行回收相反，并行收集可以运用多个CPU同时执行垃圾回收，因此提升了应用的吞吐量，不过并行回收仍然与串行回收一样，采用独占式，使用了“Stop-the-World”机制。 按工作模式分按照工作模式分，可以分为并发式垃圾回收器和独占式垃圾回收器。 并发式垃圾回收器与应用程序线程交替工作，以尽可能减少应用程序的停顿时间。 独占式垃圾回收器（Stop the World）一旦运行，就停止应用程序中的所有用户线程，直到垃圾回收过程完全结束。 按碎片处理方式分按碎片处理方式分，可分为压缩式垃圾回收器和非压缩式垃圾回收器。 压缩式垃圾回收器会在回收完成后，对存活对象进行压缩整理，消除回收后的碎片。 再分配对象空间使用：指针碰撞 非压缩式的垃圾回收器不进行这步操作。 再分配对象空间使用：空闲列表 按工作的内存区间分按工作的内存区间分，又可分为年轻代垃圾回收器和老年代垃圾回收器。","link":"/JVM-048-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-%E6%A6%82%E8%BF%B0%E4%B8%8E%E5%88%86%E7%B1%BB/"},{"title":"JVM-049-垃圾回收器-评估GC的性能指标","text":"指标 吞吐量：运行用户代码的时间占总运行时间的比例。 （总运行时间 = 程序的运行时间 + 内存回收的时间） 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例。 暂停时间：执行垃圾收集时，程序的工作线程被暂停的时间。 收集频率：相对于应用程序的执行，收集操作发生的频率。 内存占用：Java堆区所占的内存大小。 快速：一个对象从诞生到被回收所经历的时间。 指标关系 吞吐量、暂停时间、内存占用这三者共同构成一个“不可能三角”。三者总体的表现会随着技术进步而越来越好。一款优秀的收集器通常最多同时满足其中的两项。 这三项里，暂停时间的重要性日益凸显。因为随着硬件发展，内存占用多些越来越能容忍，硬件性能的提升也有助于降低收集器运行时对应用程序的影响，即提高了吞吐量。而内存的扩大，对延迟反而带来负面效果。 简单来说，主要抓住两点： 吞吐量 暂停时间 吞吐量（throughput） 吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间 /（运行用户代码时间+垃圾收集时间） 比如：虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 这种情况下，应用程序能容忍较高的暂停时间，因此，高吞吐量的应用程序有更长的时间基准，快速响应是不必考虑的 吞吐量优先，意味着在单位时间内，STW的时间最短：0.2+0.2=0.4 暂停时间（pause time） “暂停时间”是指一个时间段内应用程序线程暂停，让GC线程执行的状态。 例如，GC期间100毫秒的暂停时间意味着在这100毫秒期间内没有应用程序线程是活动的 暂停时间优先，意味着尽可能让单次STW的时间最短：0.1+0.1 + 0.1+ 0.1+ 0.1=0.5，但是总的GC时间可能会长 吞吐量 vs 暂停时间 高吞吐量较好，因为这会让应用程序的最终用户感觉只有应用程序线程在做“生产性”工作。直觉上，吞吐量越高程序运行越快。 低暂停时间（低延迟）较好，因为从最终用户的角度来看，不管是GC还是其他原因导致一个应用被挂起始终是不好的。这取决于应用程序的类型，有时候甚至短暂的200毫秒暂停都可能打断终端用户体验。因此，具有较低的暂停时间是非常重要的，特别是对于一个交互式应用程序。 不幸的是”高吞吐量”和”低暂停时间”是一对相互竞争的目标（矛盾）。 因为如果选择以吞吐量优先，那么必然需要降低内存回收的执行频率，但是这样会导致GC需要更长的暂停时间来执行内存回收。 相反的，如果选择以低延迟优先为原则，那么为了降低每次执行内存回收时的暂停时间，也只能频繁地执行内存回收，但这又引起了年轻代内存的缩减和导致程序吞吐量的下降。 在设计（或使用）GC算法时，我们必须确定我们的目标：一个GC算法只可能针对两个目标之一（即只专注于较大吞吐量或最小暂停时间），或尝试找到一个二者的折衷。 现在标准(G1)：**在最大吞吐量优先的情况下，降低停顿时间**(即在固定的STW时间内，提高吞吐量)","link":"/JVM-049-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-%E8%AF%84%E4%BC%B0GC%E7%9A%84%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/"},{"title":"JVM-050-垃圾回收器-不同的垃圾回收器概述","text":"引入垃圾收集机制是Java的招牌能力，极大地提高了开发效率。那么，Java常见的垃圾收集器有哪些？ 垃圾收集器发展史有了虚拟机，就一定需要收集垃圾的机制，这就是Garbage Collection，对应的产品我们称为Garbage Collector。 1999年随JDK1.3.1一起来的是串行方式的Serial GC，它是第一款GC。ParNew垃圾收集器是Serial收集器的多线程（并行）版本 2002年2月26日，Parallel GC和Concurrent Mark Sweep GC跟随JDK1.4.2一起发布· Parallel GC在JDK6之后成为HotSpot默认GC。 2012年，在JDK1.7u4版本中，G1可用。 2017年，JDK9中G1变成默认的垃圾收集器，以替代CMS。 2018年3月，JDK10中G1垃圾回收器的并行完整垃圾回收，实现并行性来改善最坏情况下的延迟。 2018年9月，JDK11发布。引入Epsilon 垃圾回收器，又被称为 “No-Op(无操作)“ 回收器。同时，引入ZGC：可伸缩的低延迟垃圾回收器（Experimental） 2019年3月，JDK12发布。增强G1，自动返回未用堆内存给操作系统。同时，引入Shenandoah GC（OpenJDK）：低停顿时间的GC（Experimental）。 2019年9月，JDK13发布。增强ZGC，自动返回未用堆内存给操作系统。 2020年3月，JDK14发布。删除CMS垃圾回收器。扩展ZGC在macOS和Windows上的应用 7款经典的垃圾收集器 串行回收器：Serial、Serial old 并行回收器：ParNew、Parallel Scavenge、Parallel old 并发回收器：CMS、G1 官方文档： https://www.oracle.com/technetwork/java/javase/memorymanagement-whitepaper-150215.pdf 7款经典回收器与垃圾分代之间的关系 新生代收集器：Serial、ParNew、Parallel Scavenge； 老年代收集器：Serial old、Parallel old、CMS； 整堆收集器：G1； 垃圾收集器的组合关系不同厂商、不同版本的虚拟机实现差别很大。HotSpot虚拟机在JDK7/8后所有收集器及组合（连线），如下图： 两个收集器间有连线，表明它们可以搭配使用： Serial/Serial old Serial/CMS （JDK8标为废弃，JDK9移除） ParNew/Serial Old （JDK8标为废弃，JDK9移除） ParNew/CMS （JDK14移除） Parallel Scavenge/Serial Old （JDK14标为废弃） Parallel Scavenge/Parallel Old G1 其中Serial Old作为CMS出现”Concurrent Mode Failure”失败的后备预案。 （红色虚线）由于维护和兼容性测试的成本，在JDK 8时将Serial+CMS、ParNew+Serial Old这两个组合声明为废弃（JEP173），并在JDK9中完全取消了这些组合的支持（JEP214），即：移除。 （绿色虚线）JDK14中：弃用Parallel Scavenge和Serial Old GC组合（JEP366） （青色虚线）JDK14中：删除CMS垃圾回收器（JEP363） 综上所述： JDK8以前可选：Serial/Serial old、Serial/CMS、ParNew/Serial Old、ParNew/CMS、Parallel Scavenge/Serial Old、Parallel Scavenge/Parallel Old、G1 JDK8可选： Serial/Serial old、ParNew/CMS、Parallel Scavenge/Serial Old、Parallel Scavenge/Parallel Old（默认）、G1 JDK9可选：Serial/Serial old、ParNew/CMS、Parallel Scavenge/Serial Old、Parallel Scavenge/Parallel Old、G1（默认） JDK14可选：Serial/Serial old、Parallel Scavenge/Parallel Old、G1（默认） 说明 为什么要有很多收集器，一个不够吗？因为Java的使用场景很多，移动端，服务器等。所以就需要针对不同的场景，提供不同的垃圾收集器，提高垃圾收集的性能。 虽然我们会对各个收集器进行比较，但并非为了挑选一个最好的收集器出来。没有一种放之四海皆准、任何场景下都适用的完美收集器存在，更加没有万能的收集器。所以我们选择的只是对具体应用最合适的收集器。 如何查看默认的垃圾收集器 -XX:+PrintCommandLineFlags：查看命令行相关参数（包含使用的垃圾收集器） 使用命令行指令：jinfo -flag 相关垃圾回收器参数 进程ID 代码： 12345678910111213141516171819202122package com.buubiu;import java.util.ArrayList;/** * -XX:+PrintCommandLineFlags */public class GCUseTest { public static void main(String[] args) { ArrayList&lt;byte[]&gt; list = new ArrayList&lt;&gt;(); while(true){ byte[] arr = new byte[100]; list.add(arr); try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } }} JDK8在 JDK 8 下，设置 JVM 参数 -XX:+PrintCommandLineFlags 程序打印输出：-XX:+UseParallelGC 表示使用使用 ParallelGC ，ParallelGC 默认和 Parallel Old 绑定使用 1-XX:InitialHeapSize=268435456 -XX:MaxHeapSize=4294967296 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 通过命令行指令查看 命令行命令 1234jpsjinfo -flag UseParallelGC 进程idjinfo -flag UseParallelOldGC 进程idjinfo -flag UseG1GC 进程id JDK 8 中默认使用 ParallelGC 和 ParallelOldGC 的组合 JDK9~211-XX:ConcGCThreads=2 -XX:G1ConcRefinementThreads=8 -XX:GCDrainStackTargetSize=64 -XX:InitialHeapSize=268435456 -XX:MarkStackSize=4194304 -XX:MaxHeapSize=4294967296 -XX:MinHeapSize=6815736 -XX:+PrintCommandLineFlags -XX:ReservedCodeCacheSize=251658240 -XX:+SegmentedCodeCache -XX:+UseCompressedOops -XX:+UseG1GC","link":"/JVM-050-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-%E4%B8%8D%E5%90%8C%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%E6%A6%82%E8%BF%B0/"},{"title":"JVM-051-垃圾回收器-Serial回收器(串行回收)","text":"引入 Serial收集器是最基本、历史最悠久的垃圾收集器。JDK1.3之前回收新生代唯一的选择。 Serial收集器作为HotSpot中Client模式下的默认新生代垃圾收集器。 说明 Serial收集器采用复制算法、串行回收和”Stop-the-World”机制的方式执行内存回收。 除了年轻代之外，Serial收集器还提供用于执行老年代垃圾收集的Serial Old收集器。Serial old收集器同样也采用了串行回收和”Stop the World”机制，只不过内存回收算法使用的是标记-压缩算法。 Serial Old是运行在Client模式下默认的老年代的垃圾回收器 Serial Old在Server模式下主要有两个用途： 与新生代的Parallel Scavenge配合使用 作为老年代CMS收集器的后备垃圾收集方案 图示 这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明只会使用一个CPU（串行）或一条收集线程去完成垃圾收集工作。更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束（Stop The World） 优势 简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 运行在Client模式下的虚拟机是个不错的选择。 在用户的桌面应用场景中，可用内存一般不大（几十MB至一两百MB），可以在较短时间内完成垃圾收集（几十ms至一百多ms），只要不频繁发生，使用串行回收器是可以接受的。 相关JVM参数在HotSpot虚拟机中，使用-XX:+UseSerialGC参数可以指定年轻代和老年代都使用串行收集器。 等价于新生代用Serial GC，且老年代用Serial Old GC 代码： 123456789101112131415161718192021222324package com.buubiu;import java.util.ArrayList;/** * -XX:+PrintCommandLineFlags * * -XX:+UseSerialGC:表明新生代使用Serial GC ，同时老年代使用Serial Old GC */public class GCUseTest { public static void main(String[] args) { ArrayList&lt;byte[]&gt; list = new ArrayList&lt;&gt;(); while(true){ byte[] arr = new byte[100]; list.add(arr); try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } }} JVM参数： -XX:+PrintCommandLineFlags -XX:+UseSerialGC 输出： 1-XX:InitialHeapSize=268435456 -XX:MaxHeapSize=4294967296 -XX:+PrintCommandLineFlags -XX:ReservedCodeCacheSize=251658240 -XX:+SegmentedCodeCache -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseSerialGC 总结 这种垃圾收集器大家了解，现在已经不用串行的了。而且在限定单核CPU才可以用。现在都不是单核的了。 对于交互较强的应用而言，这种垃圾收集器是不能接受的。一般在Java Web应用程序中是不会采用串行垃圾收集器的。","link":"/JVM-051-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-Serial%E5%9B%9E%E6%94%B6%E5%99%A8-%E4%B8%B2%E8%A1%8C%E5%9B%9E%E6%94%B6/"},{"title":"JVM-053-垃圾回收器-Parallel Scavenge回收器(吞吐量优先)","text":"引入HotSpot的年轻代中除了拥有ParNew收集器是基于并行回收的以外，Parallel Scavenge收集器（简称Parallel收集器）同样也采用了复制算法、并行回收和”Stop the World”机制。 与ParNew比较那么Parallel收集器的出现是否多此一举？ 和ParNew收集器不同，Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput），它也被称为吞吐量优先的垃圾收集器。 自适应调节策略也是Parallel Scavenge与ParNew一个重要区别。（动态调整内存分配情况，以达到一个最优的吞吐量或低延迟） 说明 高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。因此，常见在服务器环境中使用。例如，那些执行批量处理、订单处理、工资支付、科学计算的应用程序。 Parallel 收集器在JDK1.6时提供了用于执行老年代垃圾收集的 Parallel Old 收集器，用来代替老年代的Serial Old收集器。 Parallel Old收集器采用了标记-压缩算法，但同样也是基于并行回收和”Stop-the-World”机制。 在程序吞吐量优先的应用场景中，Parallel收集器和Parallel Old收集器的组合，在server模式下的内存回收性能很不错。 在Java8中，默认是此垃圾收集器。 图示 相关JVM参数 -XX:+UseParallelGC 手动指定年轻代使用Parallel并行收集器执行内存回收任务。 -XX:+UseParallelOldGC 手动指定老年代使用ParallelOld并行回收收集器。 上面两个参数分别适用于新生代和老年代。jdk8是默认开启的。默认开启一个，另一个也会被开启。（互相激活） -XX:ParallelGCThreads 设置年轻代并行收集器的线程数。一般地，最好与CPU数量相等，以避免过多的线程数影响垃圾收集性能。 在默认情况下，当CPU数量小于8个，ParallelGCThreads的值等于CPU数量。 当CPU数量大于8个，ParallelGCThreads的值等于3+[5*CPU_Count]/8] -XX:MaxGCPauseMillis 设置垃圾收集器最大停顿时间（即STW的时间）。单位是毫秒。 为了尽可能地把停顿时间控制在XX:MaxGCPauseMillis 以内，收集器在工作时会调整Java堆大小或者其他一些参数。 对于用户来讲，停顿时间越短体验越好。但是在服务器端，我们注重高并发，整体的吞吐量。所以服务器端适合Parallel，进行控制。 该参数使用需谨慎。 -XX:GCTimeRatio 垃圾收集时间占总时间的比例，即等于 1 / (N+1) ，用于衡量吞吐量的大小。 取值范围(0, 100)。默认值99，也就是垃圾回收时间占比不超过1。 与前一个-XX:MaxGCPauseMillis参数有一定矛盾性，STW暂停时间越长，Radio参数就容易超过设定的比例。 如果把此参数设置为19，那允许的最大GC时间就占总时间的5%（即1/（19+1）），默认值为99，就是允许最大1%（即1/（99+1））的垃圾收集时间。","link":"/JVM-053-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-Parallel-Scavenge%E5%9B%9E%E6%94%B6%E5%99%A8-%E5%90%9E%E5%90%90%E9%87%8F%E4%BC%98%E5%85%88/"},{"title":"JVM-052-垃圾回收器-ParNew回收器(并行回收)","text":"引入 如果说Serial GC是年轻代中的单线程垃圾收集器，那么ParNew收集器则是Serial收集器的多线程版本。 Par意思是Parallel的缩写，New：意思是只能处理新生代 ParNew 收集器除了采用并行回收的方式执行内存回收外，两款垃圾收集器之间几乎没有任何区别。ParNew收集器在年轻代中同样也是采用复制算法、”Stop-the-World”机制。 ParNew 是很多JVM运行在Server模式下新生代的默认垃圾收集器。 图示 对于新生代，回收次数频繁，使用并行方式高效。 对于老年代，回收次数少，使用串行方式节省资源。（CPU并行需要切换线程，串行可以省去切换线程的资源） 这里（官方配对）的老年代默认使用的是SerialOld，其实它还可以使用CMS收集器 说明Q：由于ParNew收集器基于并行回收，那么是否可以断定ParNew收集器的回收效率在任何场景下都会比Serial收集器更高效？ A：不能 ParNew收集器运行在多CPU的环境下，由于可以充分利用多CPU、多核心等物理硬件资源优势，可以更快速地完成垃圾收集，提升程序的吞吐量。 但是在单个CPU的环境下，ParNew收集器不比Serial收集器更高效。虽然Serial收集器是基于串行回收，但是由于CPU不需要频繁地做任务切换，因此可以有效避免多线程交互过程中产生的一些额外开销。 相关JVM参数 在程序中，开发人员可以通过选项-XX:+UseParNewGC手动指定使用ParNew收集器执行内存回收任务。它表示年轻代使用并行收集器，不影响老年代 ，老年代默认使用Serial Old。 -XX:ParallelGCThreads限制线程数量，默认开启和CPU数据相同的线程数。 代码： 12345678910111213141516171819202122232425package com.buubiu;import java.util.ArrayList;/** * -XX:+PrintCommandLineFlags * * -XX:+UseParNewGC：标明新生代使用ParNew GC，同时老年代默认使用Serial Old GC * -XX:+UseConcMarkSweepGC：表明老年代使用CMS GC。同时，年轻代会触发对ParNew 的使用 */public class GCUseTest { public static void main(String[] args) { ArrayList&lt;byte[]&gt; list = new ArrayList&lt;&gt;(); while(true){ byte[] arr = new byte[100]; list.add(arr); try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } }} JVM参数： -XX:+PrintCommandLineFlags -XX:+UseParNewGC 输出： 1-XX:InitialHeapSize=268435456 -XX:MaxHeapSize=4294967296 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParNewGC 切换老年代GC为CMS： JVM参数： -XX:+PrintCommandLineFlags -XX:+UseParNewGC -XX:+UseConcMarkSweepGC 或不指定年轻代为UseParNewGC，因为如果老年代使用CMS GC的话，同时，年轻代会触发对ParNew 的使用 -XX:+PrintCommandLineFlags -XX:+UseConcMarkSweepGC 输出： 1-XX:InitialHeapSize=268435456 -XX:MaxHeapSize=4294967296 -XX:MaxNewSize=697933824 -XX:MaxTenuringThreshold=6 -XX:OldPLABSize=16 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC","link":"/JVM-052-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-ParNew%E5%9B%9E%E6%94%B6%E5%99%A8-%E5%B9%B6%E8%A1%8C%E5%9B%9E%E6%94%B6/"},{"title":"JVM-054-垃圾回收器-CMS回收器(低延时)","text":"引入 在JDK1.5时期，Hotspot推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器：CMS（Concurrent-Mark-Sweep）收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程同时工作。 CMS收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间。停顿时间越短（低延迟）就越适合与用户交互的程序，良好的响应速度能提升用户体验。 目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。 CMS的垃圾收集算法采用标记-清除算法，并且也会”Stop-the-World” 不幸的是，CMS作为老年代的收集器，却无法与JDK1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作（因为实现的框架不一样，没办法兼容使用），所以在JDK1.5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者Serial收集器中的一个。 在G1出现之前，CMS使用还是非常广泛的。一直到今天，仍然有很多系统使用CMS GC。 工作原理 CMS整个过程比之前的收集器要复杂，整个过程分为4个主要阶段，即初始标记阶段、并发标记阶段、重新标记阶段和并发清除阶段。(涉及STW的阶段主要是：初始标记 和 重新标记) 初始标记（Initial-Mark）阶段：在这个阶段中，程序中所有的工作线程都将会因为“Stop-the-World”机制而出现短暂的暂停，这个阶段的主要任务仅仅只是标记出GC Roots能直接关联到的对象。一旦标记完成之后就会恢复之前被暂停的所有应用线程。由于直接关联对象比较小，所以这里的速度非常快。 并发标记（Concurrent-Mark）阶段：从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行。 重新标记（Remark）阶段：由于在并发标记阶段中，程序的工作线程会和垃圾收集线程同时运行或者交叉运行，因此为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段会因为“Stop-the-World”机制而出现短暂的暂停，这个停顿时间通常会比初始标记阶段稍长一些，但也远比并发标记阶段的时间短。 并发清除（Concurrent-Sweep）阶段：此阶段清理删除掉标记阶段判断的已经死亡的对象，释放内存空间。由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。 分析 尽管CMS收集器采用的是并发回收（非独占式），但是在其初始化标记和再次标记这两个阶段中仍然需要执行“Stop-the-World”机制暂停程序中的工作线程，不过暂停时间并不会太长，因此可以说明目前所有的垃圾收集器都做不到完全不需要“Stop-the-World”，只是尽可能地缩短暂停时间。 由于最耗费时间的并发标记与并发清除阶段都不需要暂停工作，所以整体的回收是低停顿的。 另外，由于在垃圾收集阶段用户线程没有中断，所以在CMS回收过程中，还应该确保应用程序用户线程有足够的内存可用。因此，CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，而是当堆内存使用率达到某一阈值时，便开始进行回收，以确保应用程序在CMS工作过程中依然有足够的空间支持应用程序运行。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure” 失败，这时虚拟机将启动后备预案：临时启用Serial old收集器来重新进行老年代的垃圾收集，执行 Full GC(Full GC 是一个概念，表示对整个堆空间进行回收，而 Serial Old 收集器是其中的一部分，专注于老年代的回收。)，这样停顿时间就很长了。 CMS收集器的垃圾收集算法采用的是标记-清除算法，这意味着每次执行完内存回收后，由于被执行内存回收的无用对象所占用的内存空间极有可能是不连续的一些内存块，不可避免地将会产生一些内存碎片。那么CMS在为新对象分配内存空间时，将无法使用指针碰撞（Bump the Pointer）技术，而只能够选择空闲列表（Free List）执行内存分配。 不采用标记-压缩的原因为什么 CMS 不采用标记-压缩(Mark Compack)算法呢？ 答案其实很简答，因为当并发清除的时候，用Compact整理内存的话，原来的用户线程使用的内存就无法使用了，要保证用户线程能继续执行，前提的它运行的资源不受影响（即不能改变它所使用对象的地址）。Mark Compact更适合“stop the world”这种场景下使用。 优缺点优点 并发收集 低延迟 弊端 会产生内存碎片，导致并发清除后，用户线程可用的空间不足。在无法分配大对象的情况下，不得不提前触发Full GC。 CMS收集器对CPU资源非常敏感。在并发阶段，它虽然不会导致用户停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。 CMS收集器无法处理浮动垃圾。可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。在并发标记阶段由于程序的工作线程和垃圾收集线程是同时运行或者交叉运行的，那么在并发标记阶段如果产生新的垃圾对象，CMS将无法对这些垃圾对象进行标记，最终会导致这些新产生的垃圾对象没有被及时回收，从而只能在下一次执行GC时释放这些之前未被回收的内存空间。 特别解释说明： 重新标记阶段修正的是：在并发标记阶段怀疑是垃圾(GC roots 不关联)，但是需要（在重新标记阶段）确认一下它是不是真的是垃圾(确认GC roots是不是真的不关联)； 但是还有一部分对象，在初始标记以及并发标记的时候本身不是垃圾(GC roots有关联)，但是在用户线程同时运行的时候变成了垃圾(GC roots无关联)，这部分数据就是浮动垃圾，在重新标记阶段是无法处理的。 相关JVM参数 -XX:+UseConcMarkSweepGC：手动指定使用CMS收集器执行内存回收任务。 开启该参数后会自动将-XX:+UseParNewGC打开。即：ParNew（Young区）+CMS（Old区）+Serial Old（Old区备选方案）的组合。 -XX:CMSInitiatingOccupanyFraction：设置堆内存使用率的阈值，一旦达到该阈值，便开始进行回收。 JDK5及以前版本的默认值为68，即当老年代的空间使用率达到68%时，会执行一次CMS回收。**JDK6及以上版本默认值为92%**。 如果内存增长缓慢，则可以设置一个稍大的值，大的阀值可以有效降低CMS的触发频率，减少老年代回收的次数可以较为明显地改善应用程序性能。反之，如果应用程序内存使用率增长很快，则应该降低这个阈值，以避免频繁触发老年代进行备选方案的SerialOldGC串行收集器。因此通过该选项便可以有效降低Full GC（对整个堆进行垃圾回收）的执行次数。 -XX:+UseCMSCompactAtFullCollection：用于指定在执行完Full GC后对内存空间进行压缩整理，以此避免内存碎片的产生。不过由于内存压缩整理过程无法并发执行，所带来的问题就是停顿时间变得更长了。 -XX:CMSFullGCsBeforeCompaction：设置在执行多少次Full GC后对内存空间进行压缩整理，跟上面的命令是组合。 -XX:ParallelCMSThreads：设置CMS的线程数量。 CMS默认启动的线程数是 (ParallelGCThreads + 3) / 4 ParallelGCThreads是年轻代并行收集器的线程数，可以当做是 CPU 最大支持的线程数。当CPU资源比较紧张时，受到CMS收集器线程的影响，应用程序的性能在垃圾回收阶段可能会非常糟糕。 JDK 后续版本中 CMS 的变化 JDK9新特性：CMS被标记为Deprecate了（JEP291）如果对JDK9及以上版本的HotSpot虚拟机使用参数-XX:+UseConcMarkSweepGC来开启CMS收集器的话，用户会收到一个警告信息，提示CMS未来将会被废弃。 JDK14新特性：删除CMS垃圾回收器（JEP363） 移除了CMS垃圾收集器，如果在JDK14中使用XX:+UseConcMarkSweepGC的话，JVM不会报错，只是给出一个warning信息，但是不会exit。JVM会自动回退以默认GC方式启动JVM 小结HotSpot有这么多的垃圾回收器，那么Serial GC、Parallel GC、Concurrent Mark Sweep GC这三个GC有什么不同呢？ 如果你想要最小化地使用内存和并行开销，请选Serial GC； 如果你想要最大化应用程序的吞吐量，请选Parallel GC； 如果你想要最小化GC的中断或停顿时间，请选CMS GC。","link":"/JVM-054-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-CMS%E5%9B%9E%E6%94%B6%E5%99%A8-%E4%BD%8E%E5%BB%B6%E6%97%B6/"},{"title":"JVM-055-垃圾回收器-G1回收器-概述(区域化分代式)","text":"引入既然我们已经有了前面几个强大的 GC ，为什么还要发布 Garbage First（G1）GC？ 原因就在于应用程序所应对的业务越来越庞大、复杂，用户越来越多，没有GC就不能保证应用程序正常进行，而经常造成STW的GC又跟不上实际的需求，所以才会不断地尝试对GC进行优化。G1（Garbage-First）垃圾回收器是在Java7 update4之后引入的一个新的垃圾回收器，是当今收集器技术发展的最前沿成果之一。 与此同时，为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间（pause time），同时兼顾良好的吞吐量。 官方给G1设定的目标是在延迟可控的情况下获得尽可能高的吞吐量，所以才担当起“全功能收集器”的重任与期望。 名字由来为什么名字叫Garbage First(G1)呢？ 因为G1是一个并行回收器，它把堆内存分割为很多不相关的区域（Region）（物理上不连续的）。使用不同的Region来表示Eden、幸存者0区，幸存者1区，老年代等。 G1 GC有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。 由于这种方式的侧重点在于回收垃圾最大量的区间（Region），所以我们给G1一个名字：垃圾优先（Garbage First）。 说明 G1（Garbage-First）是一款面向服务端应用的垃圾收集器，主要针对配备多核CPU及大容量内存的机器，以极高概率满足GC停顿时间的同时，还兼具高吞吐量的性能特征。 在JDK1.7版本正式启用，移除了Experimental(实验性)的标识，是JDK9以后的默认垃圾回收器，取代了CMS回收器以及Parallel+Parallel Old组合。被Oracle官方称为“全功能的垃圾收集器”。 与此同时，CMS已经在JDK9中被标记为废弃（deprecated）。G1在JDK8中还不是默认的垃圾回收器，需要使用-XX:+UseG1GC来启用。","link":"/JVM-055-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-G1%E5%9B%9E%E6%94%B6%E5%99%A8-%E6%A6%82%E8%BF%B0-%E5%8C%BA%E5%9F%9F%E5%8C%96%E5%88%86%E4%BB%A3%E5%BC%8F/"},{"title":"JVM-056-垃圾回收器-G1回收器-G1的特点","text":"特点（优势）与其他GC收集器相比，G1使用了全新的分区算法，其特点注意有四点； 并行与并发兼备 并行性：G1在回收期间，可以有多个GC线程同时工作，有效利用多核计算能力。此时用户线程STW 并发性：G1拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此，一般来说，不会在整个回收阶段发生完全阻塞应用程序的情况 分代收集 从分代上看，G1依然属于分代型垃圾回收器，它会区分年轻代和老年代，年轻代依然有Eden区和Survivor区。但从堆的结构上看，它不要求整个Eden区、年轻代或者老年代都是连续的，也不再坚持固定大小和固定数量。 将堆空间分为若干个区域（Region），这些区域中包含了逻辑上的年轻代和老年代。 和之前的各类回收器不同，它同时兼顾年轻代和老年代。对比其他回收器，或者工作在年轻代，或者工作在老年代； G1的分代区域已经不是下面这样了 G1的分区是这样的一个区域 空间整合 CMS：采用“标记-清除”算法；有内存碎片；在若干次GC后进行一次碎片整理 G1将内存划分为一个个的region。内存的回收是以region作为基本单位的。Region之间是复制算法，但整体上实际可看作是标记-压缩（Mark-Compact）算法，两种算法都可以避免内存碎片。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。尤其是当Java堆非常大的时候，G1的优势更加明显。 可预测的停顿时间模型**即：软实时(soft real-time)**：不强求 必须要在设置的时间内垃圾回收结束（结束STW） 这是G1相对于CMS的另一大优势，G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。 由于分区的原因，G1可以只选取部分区域进行内存回收，这样缩小了回收的范围，因此对于全局停顿情况的发生也能得到较好的控制。 G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 相比于CMS GC，G1未必能做到CMS在最好情况下的延时停顿，但是最差情况要好很多。 缺点 相较于CMS，G1还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1无论是为了垃圾收集产生的内存占用（Footprint）还是程序运行时的额外执行负载（overload）都要比CMS要高。 从经验上来说，在小内存应用上CMS的表现大概率会优于G1，而G1在大内存应用上则发挥其优势。平衡点在6-8GB之间。","link":"/JVM-056-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-G1%E5%9B%9E%E6%94%B6%E5%99%A8-G1%E7%9A%84%E7%89%B9%E7%82%B9/"},{"title":"JVM-057-垃圾回收器-G1回收器-JVM参数设置与调优以及应用场景","text":"相关JVM参数设置这里列举主要常见的6个参数，其他参数可以参考官方文档： https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html -XX:+UseG1GC：手动指定使用G1垃圾收集器执行内存回收任务 -XX:G1HeapRegionSize：设置每个Region的大小。值为2的N次幂，范围是1MB到32MB之间，即1MB，2MB，4MB，8MB，16MB，32MB。目标是根据最小的Java堆大小划分出约2048个区域。默认是堆内存的1/2000。 比如设置为1，则堆内存为 1* 2048 = 2G；设置为32，则堆内存为 32 * 2048 = 64G -XX:MaxGCPauseMillis：设置期望达到的最大GC停顿时间指标，JVM会尽力实现，但不保证达到。默认值是200ms -XX:+ParallelGCThread：设置STW工作线程数的值。最多设置为8 -XX:ConcGCThreads：设置并发标记的线程数。将n设置为并行垃圾回收线程数（ParallelGCThreads）的1/4左右。 -XX:InitiatingHeapOccupancyPercent：设置触发并发GC周期的Java堆占用率阈值。超过此值，就触发GC。默认值是45。 简化JVM性能调优G1的设计原则就是简化JVM性能调优，开发人员只需要简单的三步（上面参数里面的前三个）即可完成调优： 第一步：开启G1垃圾收集器 第二步：设置堆的最大内存 第三步：设置最大的停顿时间 G1中提供了三种垃圾回收模式：YoungGC、Mixed GC和Full GC，在不同的条件下被触发。 适用场景 面向服务端应用，针对具有大内存、多处理器的机器。（在普通大小的堆里表现并不惊喜） 最主要的应用是需要低GC延迟，并具有大堆的应用程序提供解决方案； 如：在堆大小约6GB或更大时，可预测的暂停时间可以低于0.5秒；（G1通过每次只清理一部分而不是全部的Region的增量式清理来保证每次GC停顿时间不会过长）。 用来替换掉JDK1.5中的CMS收集器； 在下面的情况时，使用G1可能比CMS好： 超过50%的Java堆被活动数据占用； 对象分配频率或年代提升频率变化很大； GC停顿时间过长（长于0.5至1秒） HotSpot垃圾收集器里，除了G1以外，其他的垃圾收集器均使用内置的JVM线程执行GC的多线程操作，而G1 GC可以采用应用线程承担后台运行的GC工作，即当JVM的GC线程处理速度慢时，系统会调用应用程序线程帮助加速垃圾回收过程。","link":"/JVM-057-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-G1%E5%9B%9E%E6%94%B6%E5%99%A8-JVM%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%E4%B8%8E%E8%B0%83%E4%BC%98%E4%BB%A5%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/"},{"title":"JVM-058-垃圾回收器-G1回收器-分区Region详解","text":"引入化整为零 使用G1收集器时，它将整个Java堆划分成约2048个大小相同的独立Region块，每个Region块大小根据堆空间的实际大小而定，整体被控制在1MB到32MB之间，且为2的N次幂，即1MB，2MB，4MB，8MB，16MB，32MB。可以通过 -XX:G1HeapRegionSize设定。所有的Region大小相同，且在JVM生命周期内不会被改变。 Region的角色划分 虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。通过Region的动态分配方式实现逻辑上的连续。 一个Region有可能属于Eden，Survivor，Old/Tenured或者humongous内存区域。但是一个Region只可能属于一个角色。图中的E表示该Region属于Eden内存区域，S表示属于Survivor内存区域，O表示属于Old内存区域，H表示属于humongous(巨型对象)内存区域。图中空白的表示未使用的内存空间。 G1垃圾收集器还增加了一种新的内存区域，叫做Humongous内存区域，如图中的H块。主要用于存储大对象，如果超过0.5个Region，就放到H。官方文档 设置 H 的原因 对于堆中的大对象，默认直接会被分配到老年代，但是如果它是一个短期存在的大对象就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放大对象。如果一个H区装不下一个大对象，那么G1会寻找连续的H区来存储。为了能找到连续的H区，有时候不得不启动Full GC。G1的大多数行为都把H区作为老年代的一部分来看待。 Region内部存放细节 Bump - the - pointer ：指针碰撞 单个Region使用指针碰撞的方式来存放数据，上面allocated是已经使用的内存区域，top就是指针的位置，unallocate是没有使用的内存区域，当有新对象分配的时候，指针就会右移。 TLAB 单个Region里面也会划分出一部分空间来用于并发回收过程中的新对象分配，就是单独给每个线程分配一小份区域，这样多线程共享的时候就可以并行的执行，不需要同步的执行，可以提高分配对象的效率。","link":"/JVM-058-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-G1%E5%9B%9E%E6%94%B6%E5%99%A8-%E5%88%86%E5%8C%BARegion%E8%AF%A6%E8%A7%A3/"},{"title":"JVM-059-垃圾回收器-G1回收器-主要回收环节","text":"主要环节 年轻代GC（Young GC） 老年代并发标记过程（Concurrent Marking） 混合回收（Mixed GC） Full GC （第四个环节，不是主要的；如果需要，单线程、独占式、高强度的Full GC还是继续存在的。它针对GC的评估失败提供了一种失败保护机制，即强力回收。） 图示 顺时针，Young GC –&gt; Young GC+Concurrent Marking –&gt; Mixed GC顺序，进行垃圾回收 年轻代GC：应用程序分配内存，当年轻代的Eden区用尽时开始年轻代回收过程；G1的年轻代收集阶段是一个并行的独占式收集器。在年轻代回收期，G1 GC暂停所有应用程序线程，启动多线程执行年轻代回收。然后从年轻代区间移动存活对象到Survivor区间或者老年区间，也有可能是两个区间都会涉及。 年轻代GC + 老年代并发标记过程：当堆内存使用达到一定值（默认45%）时，开始老年代并发标记过程。 年轻代GC + 老年代GC 混合回收：标记完成马上开始混合回收过程。对于一个混合回收期，G1 GC从老年区间移动存活对象到空闲区间，这些空闲区间也就成为了老年代的一部分。和年轻代不同，老年代的G1回收器和其他GC不同，G1的老年代回收器不需要整个老年代被回收，一次只需要扫描/回收一小部分老年代的Region就可以了。同时，这个老年代Region是和年轻代一起被回收的。 举个例子：一个Web服务器，Java进程最大堆内存为4G，每分钟响应1500个请求，每45秒钟会新分配大约2G的内存。G1会每45秒钟进行一次年轻代回收，每31个小时整个堆的使用率会达到45%，会开始老年代并发标记过程，标记完成后开始四到五次的混合回收。 Remembered Set 记忆集 与 Write Barrier 写屏障引入（问题）一个对象被不同区域引用的问题 一个Region不可能是孤立的，一个Region中的对象可能被其他任意Region中对象引用，判断对象存活时，是否需要扫描整个Java堆才能保证准确？ 在其他的分代收集器，也存在这样的问题（而G1更突出，因为G1主要针对大堆） 回收新生代也不得不同时扫描老年代？这样的话会降低Minor GC的效率 问题解决办法 无论G1还是其他分代收集器，JVM都是使用Remembered Set(记忆集:简写Rset)来避免全堆扫描； 每个Region都有一个对应的Remembered Set 每次Reference类型数据写操作时，都会产生一个Write Barrier(写屏障)暂时中断操作； 然后检查将要写入的引用指向的对象是否和该Reference类型数据在不同的Region（其他收集器：检查老年代对象是否引用了新生代对象）； 如果不同，通过CardTable(卡表)把相关引用信息记录到引用指向对象的所在Region对应的Remembered Set中； 当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set；就可以保证不进行全局扫描，也不会有遗漏。","link":"/JVM-059-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-G1%E5%9B%9E%E6%94%B6%E5%99%A8-%E4%B8%BB%E8%A6%81%E5%9B%9E%E6%94%B6%E7%8E%AF%E8%8A%82/"},{"title":"JVM-061-垃圾回收器-垃圾回收器总结","text":"7 种垃圾回收器的比较截止JDK1.8，一共有7款不同的垃圾收集器。每一款的垃圾收集器都有不同的特点，在具体使用的时候，需要根据具体的情况选用不同的垃圾收集器。 垃圾收集器 分类 作用位置 使用算法 特点 适用场景 Serial 串行运行 作用于新生代 复制算法 响应速度优先 适用于单CPU环境下的client模式 ParNew 并行运行 作用于新生代 复制算法 响应速度优先 多CPU环境Server模式下与CMS配合使用 Parallel 并行运行 作用于新生代 复制算法 吞吐晕优先 适用于后台运算而不需要太多交互的场景 Serial Old 串行运行 作用于老年代 标记-压缩算法 响应速度优先 适用于单CPU环境下的Client模式 Parallel old 并行运行 作用于老年代 标记-压缩算法 吞吐量优先 适用于后台运算而不需要太多交互的场景 CMS 并发运行 作用于老年代 标记-清除算法 响应速度优先 适用于互联网或B/S业务 G1 并发、并行 作用于新生代、老年代 标记-压缩算法、复制算法 响应速度优先 面向服务端应用 GC发展阶段Serial(串行) ==&gt; Parallel(并行) ==&gt; CMS(并发) ==&gt; G1(并行、并发) ==&gt; ZGC 怎么选择垃圾回收器Java垃圾收集器的配置对于JVM优化来说是一个很重要的选择，选择合适的垃圾收集器可以让JVM的性能有一个很大的提升。 怎么选择垃圾收集器？ 优先调整堆的大小让JVM自适应完成。 如果内存小于100M，使用串行收集器 如果是单核、单机程序，并且没有停顿时间的要求，使用串行收集器 如果是多CPU、需要高吞吐量、允许停顿时间超过1秒，选择并行或者JVM自己选择 如果是多CPU、追求低停顿时间，需快速响应（比如延迟不能超过1秒，如互联网应用），使用并发收集器 官方推荐G1，性能高。现在互联网的项目，基本都是使用G1。 最后需要明确一个观点 没有最好的收集器，更没有万能的收集算法 调优永远是针对特定场景、特定需求，不存在一劳永逸的收集器 面试 对于垃圾收集，面试官可以循序渐进从理论、实践各种角度深入，也未必是要求面试者什么都懂。但如果你懂得原理，一定会成为面试中的加分项。 这里较通用、基础性的问题如下： 垃圾收集的算法有哪些？如何判断一个对象是否可以回收？ 垃圾收集器工作的基本流程。 另外，大家需要多关注垃圾回收器这一章的各种常用的参数","link":"/JVM-061-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%E6%80%BB%E7%BB%93/"},{"title":"JVM-062-垃圾回收器-GC日志分析","text":"常用参数配置通过阅读GC日志，我们可以了解Java虚拟机内存分配与回收策略。 内存分配与垃圾回收的参数列表 -XX:+PrintGC ：输出GC日志。类似：-verbose:gc -XX:+PrintGCDetails ：输出GC的详细日志 -XX:+PrintGCTimestamps ：输出GC的时间戳（以基准时间的形式） -XX:+PrintGCDatestamps ：输出GC的时间戳（以日期的形式，如2013-05-04T21: 53: 59.234 +0800） -XX:+PrintHeapAtGC ：在进行GC的前后打印出堆的信息 -Xloggc:…/logs/gc.log ：日志文件的输出路径 -XX:+PrintGC输出GC日志。类似：-verbose:gc 代码12345678910111213141516171819package com.buubiu;import java.util.ArrayList;public class GCLogTest { public static void main(String[] args) { ArrayList&lt;byte[]&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 500; i++) { byte[] arr = new byte[1024 * 100];//100KB list.add(arr);// try {// Thread.sleep(50);// } catch (InterruptedException e) {// e.printStackTrace();// } } }} JVM参数（jdk8环境）： -Xms60m -Xmx60m -XX:+PrintGC 输出123456[GC (Allocation Failure) 15305K-&gt;13746K(58880K), 0.0108823 secs][GC (Allocation Failure) 29098K-&gt;28912K(58880K), 0.0117239 secs][Full GC (Ergonomics) 28912K-&gt;28668K(58880K), 0.0121593 secs][Full GC (Ergonomics) 43970K-&gt;43772K(58880K), 0.0139989 secs]Process finished with exit code 0 参数解析这个只会显示总的GC堆的变化。 GC、Full GC: GC的类型，GC只在新生代上进行，Full GC包括永生代，新生代，老年代。 Allocation Failure： GC发生的原因。 15305K-&gt;13746K：堆在GC前的大小和GC后的大小。 58880K：现在的堆大小。 0.0108823 secs： GC特续的时间。 -XX:+PrintGCDetails代码12345678910111213141516171819package com.buubiu;import java.util.ArrayList;public class GCLogTest { public static void main(String[] args) { ArrayList&lt;byte[]&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 500; i++) { byte[] arr = new byte[1024 * 100];//100KB list.add(arr);// try {// Thread.sleep(50);// } catch (InterruptedException e) {// e.printStackTrace();// } } }} JVM参数（jdk8环境）： -Xms60m -Xmx60m -XX:+PrintGC -XX:+PrintGCDetails 当-XX:+PrintGC与-XX:+PrintGCDetails都配置的时候，以能输出详细的那个参数为主，即以-XX:+PrintGCDetails为主 输出123456789101112131415[GC (Allocation Failure) [PSYoungGen: 15298K-&gt;2528K(17920K)] 15298K-&gt;14046K(58880K), 0.0069092 secs] [Times: user=0.01 sys=0.02, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 17881K-&gt;2532K(17920K)] 29398K-&gt;29124K(58880K), 0.0082118 secs] [Times: user=0.01 sys=0.02, real=0.01 secs] [Full GC (Ergonomics) [PSYoungGen: 2532K-&gt;0K(17920K)] [ParOldGen: 26592K-&gt;28969K(40960K)] 29124K-&gt;28969K(58880K), [Metaspace: 3346K-&gt;3346K(1056768K)], 0.0060808 secs] [Times: user=0.02 sys=0.01, real=0.00 secs] [Full GC (Ergonomics) [PSYoungGen: 15303K-&gt;3500K(17920K)] [ParOldGen: 28969K-&gt;40570K(40960K)] 44273K-&gt;44070K(58880K), [Metaspace: 3365K-&gt;3365K(1056768K)], 0.0089153 secs] [Times: user=0.02 sys=0.01, real=0.01 secs] Heap PSYoungGen total 17920K, used 10120K [0x00000007bec00000, 0x00000007c0000000, 0x00000007c0000000) eden space 15360K, 65% used [0x00000007bec00000,0x00000007bf5e2158,0x00000007bfb00000) from space 2560K, 0% used [0x00000007bfd80000,0x00000007bfd80000,0x00000007c0000000) to space 2560K, 0% used [0x00000007bfb00000,0x00000007bfb00000,0x00000007bfd80000) ParOldGen total 40960K, used 40570K [0x00000007bc400000, 0x00000007bec00000, 0x00000007bec00000) object space 40960K, 99% used [0x00000007bc400000,0x00000007beb9e890,0x00000007bec00000) Metaspace used 3408K, capacity 4564K, committed 4864K, reserved 1056768K class space used 368K, capacity 388K, committed 512K, reserved 1048576KProcess finished with exit code 0 参数解析 GC、Full GC: 同样是GC的类型 Allocation Failure： GC发生的原因。 PSYoungGen：使用了Parallel Scavenge并行垃圾收集器的新生代GC前后大小的变化 ParOldGen：使用了Parallel Old并行垃圾收集器的老年代GC前后大小的变化 Metaspace：元数据区GC前后大小的变化，JDK1.8中引入了元数据区以替代永久代 xxx secs：指GC花费的时间 Times： user：指的是垃圾收集器花费的所有CPU时间 sys：花费在等待系统调用或系统事件的时间 real：GC从开始到结束的时间，包括其他进程占用时间片的实际时间。 -XX:+PrintGCTimeStamps代码12345678910111213141516171819package com.buubiu;import java.util.ArrayList;public class GCLogTest { public static void main(String[] args) { ArrayList&lt;byte[]&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 500; i++) { byte[] arr = new byte[1024 * 100];//100KB list.add(arr);// try {// Thread.sleep(50);// } catch (InterruptedException e) {// e.printStackTrace();// } } }} JVM参数（jdk8环境）： -Xms60m -Xmx60m -XX:+PrintGC -XX:+PrintGCTimeStamps 输出1234560.118: [GC (Allocation Failure) 15360K-&gt;13990K(58880K), 0.0068465 secs]0.126: [GC (Allocation Failure) 29250K-&gt;29008K(58880K), 0.0087277 secs]0.135: [Full GC (Ergonomics) 29008K-&gt;28869K(58880K), 0.0082276 secs]0.144: [Full GC (Ergonomics) 44172K-&gt;43970K(58880K), 0.0089184 secs]Process finished with exit code 0 参数解析 0.118 0.126：在每行的前面加上了虚拟机启动到现在执行的秒数 -XX:+PrintGCDateStamps代码12345678910111213141516171819package com.buubiu;import java.util.ArrayList;public class GCLogTest { public static void main(String[] args) { ArrayList&lt;byte[]&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 500; i++) { byte[] arr = new byte[1024 * 100];//100KB list.add(arr);// try {// Thread.sleep(50);// } catch (InterruptedException e) {// e.printStackTrace();// } } }} JVM参数（jdk8环境）： -Xms60m -Xmx60m -XX:+PrintGC -XX:+PrintGCDateStamps 输出1234562024-01-22T13:08:39.040+0800: [GC (Allocation Failure) 15298K-&gt;14006K(58880K), 0.0077802 secs]2024-01-22T13:08:39.049+0800: [GC (Allocation Failure) 29358K-&gt;29076K(58880K), 0.0098255 secs]2024-01-22T13:08:39.059+0800: [Full GC (Ergonomics) 29076K-&gt;28973K(58880K), 0.0104633 secs]2024-01-22T13:08:39.071+0800: [Full GC (Ergonomics) 44278K-&gt;44073K(58880K), 0.0101868 secs]Process finished with exit code 0 参数解析 2024-01-22T13:08:39.040+0800：在每行的前面加上了年月日时分秒时间 -Xloggc如果想把GC日志存到文件的话，是下面这个参数： -Xloggc:/path/to/gc.log 补充说明jvm参数： -Xms60m -Xmx60m -XX:+PrintGCDetails 输出： 12345678910111213[GC (Allocation Failure) [PSYoungGen: 15298K-&gt;2528K(17920K)] 15298K-&gt;14046K(58880K), 0.0188531 secs] [Times: user=0.01 sys=0.02, real=0.02 secs] [GC (Allocation Failure) [PSYoungGen: 17881K-&gt;2464K(17920K)] 29398K-&gt;29092K(58880K), 0.0104495 secs] [Times: user=0.02 sys=0.02, real=0.01 secs] [Full GC (Ergonomics) [PSYoungGen: 2464K-&gt;0K(17920K)] [ParOldGen: 26628K-&gt;28969K(40960K)] 29092K-&gt;28969K(58880K), [Metaspace: 3347K-&gt;3347K(1056768K)], 0.0208649 secs] [Times: user=0.02 sys=0.01, real=0.03 secs] [Full GC (Ergonomics) [PSYoungGen: 15303K-&gt;3500K(17920K)] [ParOldGen: 28969K-&gt;40570K(40960K)] 44273K-&gt;44071K(58880K), [Metaspace: 3378K-&gt;3378K(1056768K)], 0.0236503 secs] [Times: user=0.02 sys=0.01, real=0.02 secs] Heap PSYoungGen total 17920K, used 10120K [0x00000007bec00000, 0x00000007c0000000, 0x00000007c0000000) eden space 15360K, 65% used [0x00000007bec00000,0x00000007bf5e21c0,0x00000007bfb00000) from space 2560K, 0% used [0x00000007bfd80000,0x00000007bfd80000,0x00000007c0000000) to space 2560K, 0% used [0x00000007bfb00000,0x00000007bfb00000,0x00000007bfd80000) ParOldGen total 40960K, used 40570K [0x00000007bc400000, 0x00000007bec00000, 0x00000007bec00000) object space 40960K, 99% used [0x00000007bc400000,0x00000007beb9ea38,0x00000007bec00000) Metaspace used 3397K, capacity 4564K, committed 4864K, reserved 1056768K class space used 366K, capacity 388K, committed 512K, reserved 1048576K [GC和[Full GC说明了这次垃圾收集器的类型，如果有”Full”则说明GC发生了”Stop The World” 如果使用Serial收集器在新生代的名字是Default New Generation，显示的是”[DefNew” 如果使用Serial Old 收集器在新生代的名字是Default Old Generation，显示的是”[DefOld” 如果使用Parallel scavenge收集器在新生代的名字是”[PSYoungGen” 老年代的收集和新生代道理一样，名字也是收集器决定的 如果使用ParNew收集器在老生代的名字会变成”[ParNew”，意思是”Parallel New Generation” 如果使用Parallel Old 收集器在老生代的名字是”[PSOldGen” 如果使用G1收集器的话，会显示为”garbage-first heap” Allocation Failure 表明本次引起GC的原因是因为在年轻代中没有足够的空间能够存储新的数据了。 [PSYoungGen: 15298K-&gt;2528K(17920K)] 15298K-&gt;14046K(58880K) 中括号内：GC回收前年轻代大小 -&gt; 回收后大小（年轻代总大小） 中括号外：GC回收前年轻代和老年代大小 -&gt; 回收后大小（年轻代和老年代总大小） user代表用户态回收耗时，sys内核态回收耗时，real实际耗时。由于多核线程切换的原因，时间总和可能会超过real时间 文字解释1234567891011Heap（堆）PSYoungGen（Parallel Scavenge收集器新生代）total 9216K，used 6234K [0x00000000ff600000,0x0000000100000000,0x0000000100000000)eden space（堆中的Eden区默认占比是8）8192K，768 used [0x00000000ff600000,0x00000000ffc16b08,0x00000000ffe00000)from space（堆中的Survivor，这里是From Survivor区默认占比是1）1024K， 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000)to space（堆中的Survivor，这里是to Survivor区默认占比是1，需要先了解一下堆的分配策略）1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000) ParOldGen（老年代总大小和使用大小）total 10240K， used 7001K ［0x00000000fec00000,0x00000000ff600000,0x00000000ff600000)object space（显示个使用百分比）10240K，688 used [0x00000000fec00000,0x00000000ff2d6630,0x00000000ff600000)PSPermGen（永久代总大小和使用大小）total 21504K， used 4949K [0x00000000f9a00000,0x00000000faf00000,0x00000000fec00000)object space（显示个使用百分比，自己能算出来）21504K， 238 used [0x00000000f9a00000,0x00000000f9ed55e0,0x00000000faf00000) 图示解释 举例123456789101112131415161718192021package com.buubiu;/** * 在jdk7 和 jdk8中分别执行 * -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC */public class GCLogTest1 { private static final int _1MB = 1024 * 1024; public static void testAllocation() { byte[] allocation1, allocation2, allocation3, allocation4; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; allocation4 = new byte[4 * _1MB]; } public static void main(String[] agrs) { testAllocation(); }} JDK7 中的情况123456789101112[GC (Allocation Failure) [DefNew: 7893K-&gt;347K(9216K), 0.0062353 secs] 7893K-&gt;6491K(19456K), 0.0062611 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 9216K, used 4766K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000) eden space 8192K, 53% used [0x00000007bec00000, 0x00000007bf050a48, 0x00000007bf400000) from space 1024K, 33% used [0x00000007bf500000, 0x00000007bf556fb8, 0x00000007bf600000) to space 1024K, 0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000) tenured generation total 10240K, used 6144K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000) the space 10240K, 60% used [0x00000007bf600000, 0x00000007bfc00030, 0x00000007bfc00200, 0x00000007c0000000) Metaspace used 3223K, capacity 4564K, committed 4864K, reserved 1056768K class space used 342K, capacity 388K, committed 512K, reserved 1048576KProcess finished with exit code 0 首先会将3个2M的数组存放到Eden区，然后后面4M的数组来了后，将无法存储，因为Eden区只剩下2M的剩余空间了，那么将会进行一次Young GC操作，将原来Eden区的内容，存放到Survivor区，但是Survivor区也存放不下，那么就会直接晋级存入Old 区 然后将3个2M的数组存入到Eden区中 JDK8 中的情况123456789101112[GC (Allocation Failure) [DefNew: 6322K-&gt;668K(9216K), 0.0034812 secs] 6322K-&gt;4764K(19456K), 0.0035169 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 9216K, used 7050K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000) eden space 8192K, 77% used [0x00000000fec00000, 0x00000000ff23b668, 0x00000000ff400000) from space 1024K, 65% used [0x00000000ff500000, 0x00000000ff5a71d8, 0x00000000ff600000) to space 1024K, 0% used [0x00000000ff400000, 0x00000000ff400000, 0x00000000ff500000) tenured generation total 10240K, used 4096K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000) the space 10240K, 40% used [0x00000000ff600000, 0x00000000ffa00020, 0x00000000ffa00200, 0x0000000100000000) Metaspace used 3469K, capacity 4496K, committed 4864K, reserved 1056768K class space used 381K, capacity 388K, committed 512K, reserved 1048576KProcess finished with exit code 0 与 JDK7 不同的是，JDK8 直接判定 4M 的数组为大对象，直接怼到老年区去了。 部分jdk8版本还是像7一样，不会把4M直接放到老年代，可以用参数：-XX:PretenureSizeThreshold=4M 调整对象直接进入老年代的阈值参数，默认0 日志分析工具根据保存的日志文件来分析。 可以用一些工具去分析这些GC日志，常用的日志分析工具有： GCViewer、GCEasy(推荐)、GCHisto、GCLogViewer、Hpjmeter、garbagecat等","link":"/JVM-062-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-GC%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"title":"JVM-063-垃圾回收器-垃圾回收器的新发展","text":"介绍 GC仍然处于飞速发展之中，目前的默认选项G1 GC在不断的进行改进，很多我们原来认为的缺点，例如串行的Full GC、Card Table扫描的低效等，都已经被大幅改进，例如，JDK10以后，Full GC已经是并行运行，在很多场景下，其表现还略优于Parallel GC的并行Full GC实现。 即使是Serial GC，虽然比较古老，但是简单的设计和实现未必就是过时的，它本身的开销，不管是GC相关数据结构的开销，还是线程的开销，都是非常小的，所以随着云计算的兴起，在Serverless等新的应用场景下，Serial GC找到了新的舞台。 比较不幸的是CMS GC，因为其算法的理论缺陷等原因，虽然现在还有非常大的用户群体，但在JDK9中已经被标记为废弃，并在JDK14版本中移除 现在G1回收器已成为默认回收器好几年了。我们还看到了引入了两个新的收集器：ZGC（JDK11出现）和Shenandoah（Open JDK12），其特点：主打低停顿时间 EpsilonJEP318: Esplion：A No-Op Garbage Collecgtor （Epsilon垃圾回收器，“No-Op（无操作）”回收器） https://openjdk.org/jeps/318 Shenandoah引入Open JDK12的Shenandoash GC：低停顿时间的GC（实验性） Shenandoah无疑是众多GC中最孤独的一个。是第一款不由Oracle公司团队领导开发的Hotspot垃圾收集器。不可避免的受到官方的排挤。比如号称openJDK和OracleJDK没有区别的Oracle公司仍拒绝在OracleJDK12中支持Shenandoah。 Shenandoah垃圾回收器最初由RedHat进行的一项垃圾收集器研究项目Pauseless GC的实现，旨在针对JVM上的内存回收实现低停顿的需求。在2014年贡献给OpenJDK。 Red Hat研发Shenandoah团队对外宣称，Shenandoah垃圾回收器的暂停时间与堆大小无关，这意味着无论将堆设置为200MB还是200GB，99.9%的目标都可以把垃圾收集的停顿时间限制在十毫秒以内。不过实际使用性能将取决于实际工作堆的大小和工作负载。 比较数据 这是RedHat在2016年发表的论文数据，测试内容是使用ES对200GB的维基百科数据进行索引。从结果看： 停顿时间比其他几款收集器确实有了质的飞跃，但也未实现最大停顿时间控制在十毫秒以内的目标。 而吞吐量方面出现了明显的下降，总运行时间是所有测试收集器里最长的。 总结 Shenandoah GC的弱项：高运行负担下的吞吐量下降。 Shenandoah GC的强项：低延迟时间。 ZGCJDK11开始引入JEP 333: ZGC: A Scalable Low-Latency Garbage Collector (Experimental) （ZGC：可伸缩的低延迟回收器，属于试验性阶段） https://openjdk.org/jeps/333 定义官方：https://docs.oracle.com/en/java/javase/12/gctuning/ ZGC与Shenandoah目标高度相似，在尽可能对吞吐量影响不大的前提下，实现在任意堆内存大小下都可以把垃圾收集的停颇时间限制在十毫秒以内的低延迟。 《深入理解Java虚拟机》一书中这样定义ZGC：ZGC收集器是一款基于Region内存布局的，（暂时）不设分代的，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-压缩算法的，以低延迟为首要目标的一款垃圾收集器。 ZGC的工作过程可以分为4个阶段：并发标记 - 并发预备重分配 - 并发重分配 - 并发重映射 等。 ZGC几乎在所有地方并发执行的，除了初始标记的是STW的。所以停顿时间几乎就耗费在初始标记上，这部分的实际时间是非常少的。 比较数据吞吐量 max-JOPS：以低延迟为首要前提下的数据 critical-JOPS：不考虑低延迟下的数据 低延迟 在ZGC的强项停顿时间测试上，它毫不留情的将Parallel、G1拉开了两个数量级的差距。无论平均停顿、95%停顿、998停顿、99. 98停顿，还是最大停顿时间，ZGC都能毫不费劲控制在10毫秒以内。 发展虽然ZGC还在试验状态，没有完成所有特性，但此时性能已经相当亮眼，用“令人震惊、革命性”来形容，不为过。未来将在服务端、大内存、低延迟应用的首选垃圾收集器。 JEP 364：ZGC应用在macOS上 JEP 365：ZGC应用在Windows上 JDK14之前，ZGC仅Linux才支持。 尽管许多使用ZGC的用户都使用类Linux的环境，但在Windows和macOS上，人们也需要ZGC进行开发部署和测试。许多桌面应用也可以从ZGC中受益。因此，ZGC特性被移植到了Windows和macOS上。 现在mac或Windows上也能使用ZGC了，示例如下： -XX:+UnlockExperimentalVMOptions-XX：+UseZGC 其他垃圾回收器AliGCAliGC是阿里巴巴JVM团队基于G1算法，面向大堆（LargeHeap）应用场景。指定场景下的对比： Zing其他厂商也提供了各种独具一格的GC实现，例如比较有名的低延迟GC，Zing。","link":"/JVM-063-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%E7%9A%84%E6%96%B0%E5%8F%91%E5%B1%95/"},{"title":"JVM-064-Class文件结构-概述","text":"字节码文件的跨平台性 Java 语言，跨平台的（write once，run anywhere） 当 Java 源代码成功编译成字节码后，如果想在不同的平台上面运行，则无须再次编译。 这个优势不再那么吸引人了。Python、PHP、Perl、Ruby、Lisp 等有强大的解释器。 跨平台似乎已经快称为一门语言必选的特性。 Java 虚拟机：跨语言的平台 Java 虚拟机不和包括 Java 在内的任何语言绑定，它只与”Class 文件”这种特定的二进制文件格式所关联。无论使用何种语言进行软件开发， 只要能将源文件编译为正确的 Class 文件，那么这种语言就可以在 Java 虚拟机上执行，可以说，统一而强大的 Class 文件结构，就是 Java 虚拟机的基石、桥梁。 java虚拟机规范：https://docs.oracle.com/javase/specs/index.html 所有的 JVM 全部遵守 Java 虚拟机规范，也就是说所有的 JVM 环境都是一样的， 这样一来字节码文件可以在各种 JVM 上进行。 想要让一个 Java 程序正确地运行在 JVM 中，Java 源码就是必须要被编译为符合 JVM 规范的字节码 前端编译器的主要任务就是负责将符合 Java 语法规范的 Java 代码转换为符合 JVM 规范的字节码文件。 javac 是一种能够将 Java 源码编译为字节码的前端编译器。 javac 编译器在将 Java 源码编译为一个有效的字节码文件过程中经历了 4 个步骤，分别是词法分析、语法分析、语义分析以及生成字节码。 Oracle 的 JDK 软件包括两部分内容 一部分是将 Java 源代码编译成 Java 虚拟机的指令集的编译器 另一部分是用于实现 Java 虚拟机的运行时环境 前端编译器并不包含在 JVM 中 Java 的前端编译器 前端编译器 VS 后端编译器Java 源代码的编译结果是字节码，那么肯定需要有一种编译器能够将 Java 源码编译为字节码，承担这个重要责任的就是配置在 path 环境变量中的 javac 编译器。javac 是一种能够将 Java 源码编译为字节码的前端编译器。 HotSpot VM 并没有强制要求前端编译器只能使用 javac 来编译字节码，其实只要编译结果符合 JVM 规范都可以被 JVM 所识别即可。在 Java 的前端编译器领域，除了 javac 之外，还有一种被大家经常用到的前端编译器，那就是内置在 Eclipse 中的 ECJ（Eclipse Compiler for Java）编译器。和 javac 的全量式编译不同，ECJ 是一种增量式编译器。 在 Eclipse 中，当开发人员编写完代码后，使用”Ctrl + S”快捷键时，ECJ 编译器所采取的编译方案是把未编译部分的源码逐行进行编译，而非每次都全量编译。因此 ECJ 的编译效率会比 javac 更加迅速和高效，当然编译质量和 javac 相比大致还是一样的。 ECJ 不仅是 Eclipse 的默认内置前端编译器，在 Tomcat 中同样也是使用 ECJ 编译器来编译 JSP 文件。由于 ECJ 编译器是采用 GPLv2 的开源协议进行源代码公开，所以，大家可以登录 Eclipse 官网下载 ECJ 编译器的源码进行二次开发。 默认情况下，IntelliJ IDEA 使用 javac 编译器（还可以自己设置为 AspectJ 编译器 ajc）。 前端编译器并不会直接涉及编译优化等方面的技术，而是将这些具体优化细节移交给 HotSpot 的 JIT 编译器负责。 AOT （静态提前编译器， Ahead Of Time Compiler ）：提前把源代码编译成机器指令 透过字节码指令看代码细节BAT 面试题 类文件结构有几个部分? 知道字节码吗？字节码都有哪些？ Integer x = 5; int y = 5;比较 x == y 都经过哪些步骤？ 示例 1代码： 123456789101112131415161718package com.buubiu;public class IntegerTest { public static void main(String[] args) { Integer x = 5; int y = 5; System.out.println(x == y); // true Integer i1 = 10; Integer i2 = 10; System.out.println(i1 == i2);//true java.lang.Integer.IntegerCache Integer i3 = 128; Integer i4 = 128; System.out.println(i3 == i4);//false java.lang.Integer.IntegerCache }} 字节码： 12345678910111213141516171819202122232425262728293031323334353637383940414243 0 iconst_5 1 invokestatic #2 &lt;java/lang/Integer.valueOf : (I)Ljava/lang/Integer;&gt; 4 astore_1 5 iconst_5 6 istore_2 7 getstatic #3 &lt;java/lang/System.out : Ljava/io/PrintStream;&gt;10 aload_111 invokevirtual #4 &lt;java/lang/Integer.intValue : ()I&gt;14 iload_215 if_icmpne 22 (+7)18 iconst_119 goto 23 (+4)22 iconst_023 invokevirtual #5 &lt;java/io/PrintStream.println : (Z)V&gt;26 bipush 1028 invokestatic #2 &lt;java/lang/Integer.valueOf : (I)Ljava/lang/Integer;&gt;31 astore_332 bipush 1034 invokestatic #2 &lt;java/lang/Integer.valueOf : (I)Ljava/lang/Integer;&gt;37 astore 439 getstatic #3 &lt;java/lang/System.out : Ljava/io/PrintStream;&gt;42 aload_343 aload 445 if_acmpne 52 (+7)48 iconst_149 goto 53 (+4)52 iconst_053 invokevirtual #5 &lt;java/io/PrintStream.println : (Z)V&gt;56 sipush 12859 invokestatic #2 &lt;java/lang/Integer.valueOf : (I)Ljava/lang/Integer;&gt;62 astore 564 sipush 12867 invokestatic #2 &lt;java/lang/Integer.valueOf : (I)Ljava/lang/Integer;&gt;70 astore 672 getstatic #3 &lt;java/lang/System.out : Ljava/io/PrintStream;&gt;75 aload 577 aload 679 if_acmpne 86 (+7)82 iconst_183 goto 87 (+4)86 iconst_087 invokevirtual #5 &lt;java/io/PrintStream.println : (Z)V&gt;90 return 通过字节码文件可以看出，调用了Integer.valueOf()方法。 Integer部分源码： 1234567891011121314151617181920212223242526272829303132333435363738private static class IntegerCache { static final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; } private IntegerCache() {}}public static Integer valueOf(int i) { if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);} 通过观察源码可以看出-128-127不会new出新对象，而是用的Integer 的内部缓存，所以前两个值都为true 示例 2代码： 1234567891011package com.buubiu;public class StringTest { public static void main(String[] args) { String str = new String(&quot;hello&quot;) + new String(&quot;world&quot;); String str1 = &quot;helloworld&quot;; System.out.println(str == str1); // false String str2 = new String(&quot;helloworld&quot;); System.out.println(str == str2); // false }} 字节码： 123456789101112131415161718192021222324252627282930313233343536373839 0 new #2 &lt;java/lang/StringBuilder&gt; 3 dup 4 invokespecial #3 &lt;java/lang/StringBuilder.&lt;init&gt; : ()V&gt; 7 new #4 &lt;java/lang/String&gt;10 dup11 ldc #5 &lt;hello&gt;13 invokespecial #6 &lt;java/lang/String.&lt;init&gt; : (Ljava/lang/String;)V&gt;16 invokevirtual #7 &lt;java/lang/StringBuilder.append : (Ljava/lang/String;)Ljava/lang/StringBuilder;&gt;19 new #4 &lt;java/lang/String&gt;22 dup23 ldc #8 &lt;world&gt;25 invokespecial #6 &lt;java/lang/String.&lt;init&gt; : (Ljava/lang/String;)V&gt;28 invokevirtual #7 &lt;java/lang/StringBuilder.append : (Ljava/lang/String;)Ljava/lang/StringBuilder;&gt;31 invokevirtual #9 &lt;java/lang/StringBuilder.toString : ()Ljava/lang/String;&gt;34 astore_135 ldc #10 &lt;helloworld&gt;37 astore_238 getstatic #11 &lt;java/lang/System.out : Ljava/io/PrintStream;&gt;41 aload_142 aload_243 if_acmpne 50 (+7)46 iconst_147 goto 51 (+4)50 iconst_051 invokevirtual #12 &lt;java/io/PrintStream.println : (Z)V&gt;54 new #4 &lt;java/lang/String&gt;57 dup58 ldc #10 &lt;helloworld&gt;60 invokespecial #6 &lt;java/lang/String.&lt;init&gt; : (Ljava/lang/String;)V&gt;63 astore_364 getstatic #11 &lt;java/lang/System.out : Ljava/io/PrintStream;&gt;67 aload_168 aload_369 if_acmpne 76 (+7)72 iconst_173 goto 77 (+4)76 iconst_077 invokevirtual #12 &lt;java/io/PrintStream.println : (Z)V&gt;80 return 通过查看字节码指令，可以看到 str 是由 StringBuilder#toString 所得，是新创建的 String ，str1 指向常量池中的对象，str2 是新创建的 String ，因此互相都不相等 示例 3成员变量（非静态的）的赋值过程： 默认初始化 显式初始化 /代码块中初始化 构造器中初始化 有了对象之后，可以“对象.属性”或”对象.方法” 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.buubiu;/*成员变量（非静态的）的赋值过程： ① 默认初始化 - ② 显式初始化 /代码块中初始化 - ③ 构造器中初始化 - ④ 有了对象之后，可以“对象.属性”或&quot;对象.方法&quot; 的方式对成员变量进行赋值。 */class Father { int x = 10; public Father() { this.print(); x = 20; } public void print() { System.out.println(&quot;Father.x = &quot; + x); }}class Son extends Father { int x = 30; public Son() { this.print(); x = 40; } public void print() { System.out.println(&quot;Son.x = &quot; + x); }}public class SonTest { public static void main(String[] args) { Father f = new Son(); System.out.println(f.x); }}/*输出：Son.x = 0Son.x = 3020 */ Father 类的 &lt;init&gt; 字节码（即：public Father()的字节码）： 1234567891011 0 aload_0 1 invokespecial #1 &lt;java/lang/Object.&lt;init&gt; : ()V&gt; 4 aload_0 5 bipush 10 7 putfield #2 &lt;com/buubiu/Father.x : I&gt;10 aload_011 invokevirtual #3 &lt;com/buubiu/Father.print : ()V&gt;14 aload_015 bipush 2017 putfield #2 &lt;com/buubiu/Father.x : I&gt;20 return 字节码执行步骤： 执行父类 Object 的构造器 显式初始化 x 为 10 执行 print 方法 赋值 x 为 20 Son 类的 &lt;init&gt; 字节码（即：public Son()字节码）： 1234567891011 0 aload_0 1 invokespecial #1 &lt;com/buubiu/Father.&lt;init&gt; : ()V&gt; 4 aload_0 5 bipush 30 7 putfield #2 &lt;com/buubiu/Son.x : I&gt;10 aload_011 invokevirtual #3 &lt;com/buubiu/Son.print : ()V&gt;14 aload_015 bipush 4017 putfield #2 &lt;com/buubiu/Son.x : I&gt;20 return 字节码执行步骤： 执行父类Father的构造器 执行父类 Object 的构造器 显式初始化 x 为 10 执行 print 方法（因为多态，实际执行的是 Son 的 print 方法 ），这时Son中的x还没有显式赋值，只是默认赋值为0，所以输出：Son.x = 0 赋值 x 为 20 显式初始化为 30 执行 print 方法（因为多态，实际执行的是 Son 的的 print 方法 ），这时Son中的x已经显式赋值为30，所以输出：Son.x = 30 赋值 x 为 40，但是最后的f.x是调用的父类的属性（因为属性无法多态），所以输出：20","link":"/JVM-064-Class%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84-%E6%A6%82%E8%BF%B0/"},{"title":"JVM-060-垃圾回收器-G1回收器-垃圾回收过程详情","text":"过程一：年轻代GC解释说明 JVM启动时，G1先准备好Eden区，程序在运行过程中不断创建对象到Eden区，当Eden空间耗尽时，G1会启动一次年轻代垃圾回收过程。 年轻代回收只回收Eden区和Survivor区。 YGC时，首先G1停止应用程序的执行（Stop-The-World），G1创建回收集（Collection Set），回收集是指需要被回收的内存分段的集合，年轻代回收过程的回收集包含年轻代Eden区和Survivor区所有的内存分段。 图示 图的大致意思就是： 回收完E和S区，剩余存活的对象会复制到新的S区 S区达到一定的阈值可以晋升为O区 详细步骤 第一阶段，扫描根(GC Roots) 跟是包括：static变量指向的对象、正在执行的方法调用链条上的局部变量等，以及记忆集(RSet)记录的外部引用，以上这些都作为扫描存活对象的入口。 第二阶段，更新RSet 处理Dirty Card Queue(脏卡队列)中的card，更新RSet。此阶段完成后，RSet可以准确反映被老年代所在的内存分段中对象的引用 对于应用程序的引用赋值语句 object.field=object（field是老年代,object是新生代），JVM会在之前和之后执行特殊的操作以在dirty card queue中入队一个保存了对象引用信息的card。在年轻代回收的时候，G1会对Dirty Card Queue中所有的card进行处理，以更新RSet，保证RSet实时准确的反映引用关系。 那为什么不在引用赋值语句处直接更新RSet呢？这是为了性能的需要，RSet的处理需要线程同步，开销会很大，使用队列性能会好很多。 第三阶段，处理RSet 识别被老年代对象指向的Eden中的对象，这些被指向的Eden中的对象被认为是存活的对象。 第四阶段，复制对象。 此阶段，对象树被遍历（GC Roots 遍历关联的所有对象），Eden区内存段中存活的对象会被复制到Survivor区中空的内存分段，年龄记为1； Survivor区内存段中存活的对象：若年龄未达阈值，也会被复制到Survivor区中空的内存分段，并且年龄会加1；若达到阀值则会被复制到老年代（Old区）中空的内存分段。 如果Survivor空间不够，Eden空间的部分数据会直接晋升到老年代（Old区）空间。 第五阶段，处理引用 处理Soft，Weak，Phantom，Final，JNI Weak 等引用。最终Eden空间的数据为空，GC停止工作，而目标内存中的对象都是连续存储的，没有碎片，所以复制过程可以达到内存整理的效果，减少碎片。 过程二：并发标记过程 初始标记阶段 标记从根节点直接可达的对象。这个阶段是STW的，并且会触发一次年轻代GC。正是由于该阶段是STW的，所以我们只扫描根节点可达的对象，以节省时间。 根区域扫描（Root Region Scanning） G1 GC扫描Survivor区直接可达的老年代区域对象，并标记被引用的对象。这一过程必须在Young GC之前完成，因为Young GC会使用复制算法对Survivor区进行GC。 并发标记（Concurrent Marking） 在整个堆中进行并发标记（和应用程序并发执行），此过程可能被Young GC中断。 在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那这个区域会被立即回收。 同时，并发标记过程中，会计算每个区域的对象活性（区域中存活对象的比例）。 再次标记（Remark） 由于应用程序持续进行，需要修正上一次的标记结果。是STW的。G1中采用了比CMS更快的初始快照算法：Snapshot-At-The-Beginning（SATB）。 独占清理（cleanup，STW） 计算各个区域的存活对象和GC回收比例，并进行排序，识别可以混合回收的区域。为下阶段做铺垫。是STW的。 这个阶段并不会实际上去做垃圾的收集 并发清理阶段 识别并清理完全空闲的区域。 过程三：混合回收解释说明当越来越多的对象晋升到老年代Old Region时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即Mixed GC，该算法并不是一个Old GC，除了回收整个Young Region，还会回收一部分的Old Region。这里需要注意：是一部分老年代，而不是全部老年代。可以选择哪些Old Region进行收集，从而可以对垃圾回收的耗时时间进行控制。也要注意的是Mixed GC并不是Full GC。 图示 详细步骤 并发标记结束以后，老年代中百分百为垃圾的内存分段已经被回收了，部分为垃圾的内存分段被计算了出来。默认情况下，这些老年代的内存分段会分8次（可以通过-XX:G1MixedGCCountTarget设置）被回收。 混合回收的回收集（Collection Set）包括八分之一的老年代内存分段，Eden区内存分段，Survivor区内存分段。混合回收的算法和年轻代回收的算法完全一样，只是回收集多了老年代的内存分段。具体过程请参考上面的年轻代回收过程。 由于老年代中的内存分段默认分8次回收，G1会优先回收垃圾多的内存分段。垃圾占内存分段比例越高的，越会被先回收。并且有一个阈值会决定内存分段是否被回收。-XX:G1MixedGCLiveThresholdPercent，默认为65%，意思是垃圾占内存分段比例要达到65%才会被回收。如果垃圾占比太低，意味着存活的对象占比高，在复制的时候会花费更多的时间。 混合回收并不一定要进行8次。因为有一个阈值-XX:G1HeapWastePercent，默认值为10%，意思是允许整个堆内存中有10%的空间被浪费，意味着如果发现可以回收的垃圾占堆内存的比例低于10%，则不再进行混合回收。因为GC会花费很多的时间但是回收到的内存却很少。 过程四：Full GC解释说明G1的初衷就是要避免Full GC的出现。但是如果上述方式不能正常工作，G1会停止应用程序的执行（Stop-The-World），使用单线程的内存回收算法进行垃圾回收，性能会非常差，应用程序停顿时间会很长。 所以要避免Full GC的发生，一旦发生Full GC，就需要对JVM参数进行调整。 触发的原因什么时候会发生Full GC呢？ 比如堆内存太小，当G1在复制存活对象的时候没有空的内存分段可用，则会回退到Full GC，这种情况可以通过增大内存解决。 导致G1 Full GC的原因可能有两个： Evacuation（回收，排空）的时候没有足够的to-space（空闲空间）来存放晋升的对象； 并发处理过程完成之前空间耗尽。（并发标记的时候，造垃圾的速度比标记的还快） 设置的STW时间（暂停时间）太短的话，导致每次在GC的时候可以回收的Region就比较少，释放的空间也就比较少，此时用户线程有可能制造的垃圾比释放的空间多，在内存溢出之前会来一次Full GC。 补充从Oracle官方透露出来的信息可获知，回收阶段（Evacuation）其实本也有想过设计成与用户程序一起并发执行，但这件事情做起来比较复杂，考虑到G1只是回一部分Region，停顿时间是用户可控制的，所以并不迫切去实现，而选择把这个特性放到了G1之后出现的低延迟垃圾收集器（即ZGC）中。另外，还考虑到G1不是仅仅面向低延迟，停顿用户线程能够最大幅度提高垃圾收集效率，为了保证吞吐量所以才选择了完全暂停用户线程的实现方案。 G1 回收器的优化建议 年轻代大小 避免使用-Xmn或-XX:NewRatio等相关选项显式设置年轻代大小 因为固定年轻代的大小会覆盖可预测的暂停时间目标。年轻代GC是并行独占式的，所以最好让垃圾回收器自己去调节 暂停时间目标不要太过严苛 G1 GC的吞吐量目标是90%的应用程序时间和10%的垃圾回收时间 评估G1 GC的吞吐量时，暂停时间目标不要太严苛。目标太过严苛表示你愿意承受更多的垃圾回收开销，而这些会直接影响到吞吐量。","link":"/JVM-060-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8-G1%E5%9B%9E%E6%94%B6%E5%99%A8-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E8%BF%87%E7%A8%8B%E8%AF%A6%E6%83%85/"},{"title":"JVM-038-垃圾回收-对象的finalization机制","text":"概述 Java语言提供了对象终止（finalization）机制来允许开发人员提供对象被销毁之前的自定义处理逻辑。 当垃圾回收器发现没有引用指向一个对象，即：垃圾回收此对象之前，总会先调用这个对象的finalize()方法。 finalize() 方法允许在子类中被重写，用于在对象被回收时进行资源释放。通常在这个方法中进行一些资源释放和清理的工作，比如关闭文件、套接字和数据库连接等。 注意点 永远不要主动调用某个对象的finalize()方法，应该交给垃圾回收机制调用。理由包括下面三点： 在finalize()时可能会导致对象复活。 finalize()方法的执行时间是没有保障的，它完全由GC线程决定，极端情况下，若不发生GC，则finalize()方法将没有执行机会。 一个糟糕的finalize()会严重影响GC的性能。比如finalize是个死循环 从功能上来说，finalize()方法与C++中的析构函数比较相似，但是Java采用的是基于垃圾回收器的自动内存管理机制，所以finalize()方法在本质上不同于C++中的析构函数。 由于finalize()方法的存在，虚拟机中的对象一般处于三种可能的状态。 导致产生的对象三种状态如果从所有的根节点都无法访问到某个对象，说明对象己经不再使用了。一般来说，此对象需要被回收。但事实上，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段。一个无法触及的对象有可能在某一个条件下“复活”自己，如果这样，那么对它立即进行回收就是不合理的。为此，定义虚拟机中的对象可能的三种状态。如下： 可触及的：从根节点开始，可以到达这个对象。 可复活的：对象的所有引用都被释放，但是对象有可能在finalize()中复活。 不可触及的：对象的finalize()被调用，并且没有复活，那么就会进入不可触及状态。不可触及的对象不可能被复活，因为finalize()只会被调用一次。 以上3种状态中，是由于finalize()方法的存在，进行的区分。只有在对象不可触及时才可以被回收。 具体过程判定一个对象objA是否可回收，至少要经历两次标记过程： 如果对象objA到GC Roots没有引用链，则进行第一次标记。 进行筛选，判断此对象是否有必要执行finalize()方法 如果对象objA没有重写finalize()方法，或者finalize()方法已经被虚拟机调用过，则虚拟机视为“没有必要执行”，objA被判定为不可触及的。 如果对象objA重写了finalize()方法，且还未执行过，那么objA会被插入到F-Queue队列中，由一个虚拟机自动创建的、低优先级的Finalizer线程触发其finalize()方法执行。 finalize()方法是对象逃脱死亡的最后机会，稍后GC会对F-Queue队列中的对象进行第二次标记。如果objA在finalize()方法中与引用链上的任何一个对象建立了联系，那么在第二次标记时，objA会被移出“即将回收”集合。之后，该对象如果再次出现没有引用存在的情况，在这个情况下，finalize()方法不会被再次调用，对象会直接变成不可触及的状态，也就是说，一个对象的finalize()方法只会被调用一次。 通过 JVisual VM 查看 Finalizer 线程 代码演示 finalize() 方法可复活对象重写 CanReliveObj 类的 finalize()方法，在调用其 finalize()方法时，将 obj 指向当前类对象 this 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 测试Object类中finalize()方法，即对象的finalization机制。 * */public class CanReliveObj { public static CanReliveObj obj;//类变量，属于 GC Root //此方法只能被调用一次 @Override protected void finalize() throws Throwable { super.finalize(); System.out.println(&quot;调用当前类重写的finalize()方法&quot;); obj = this;//当前待回收的对象在finalize()方法中与引用链上的一个对象obj建立了联系 } public static void main(String[] args) { try { obj = new CanReliveObj(); // 对象第一次成功拯救自己 obj = null; System.gc();//调用垃圾回收器 System.out.println(&quot;第1次 gc&quot;); // 因为Finalizer线程优先级很低，暂停2秒，以等待它 Thread.sleep(2000); if (obj == null) { System.out.println(&quot;obj is dead&quot;); } else { System.out.println(&quot;obj is still alive&quot;); } System.out.println(&quot;第2次 gc&quot;); // 下面这段代码与上面的完全相同，但是这次自救却失败了 obj = null; System.gc(); // 因为Finalizer线程优先级很低，暂停2秒，以等待它 Thread.sleep(2000); if (obj == null) { System.out.println(&quot;obj is dead&quot;); } else { System.out.println(&quot;obj is still alive&quot;); } } catch (InterruptedException e) { e.printStackTrace(); } }} 如果注释掉finalize()方法 1234567//此方法只能被调用一次@Overrideprotected void finalize() throws Throwable { super.finalize(); System.out.println(&quot;调用当前类重写的finalize()方法&quot;); obj = this;//当前待回收的对象在finalize()方法中与引用链上的一个对象obj建立了联系} 输出结果： 1234第1次 gcobj is dead第2次 gcobj is dead 放开finalize()方法 输出结果： 12345第1次 gc调用当前类重写的finalize()方法obj is still alive第2次 gcobj is dead 第一次自救成功，但由于 finalize() 方法只会执行一次，所以第二次自救失败。","link":"/JVM-038-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E5%AF%B9%E8%B1%A1%E7%9A%84finalization%E6%9C%BA%E5%88%B6/"}],"tags":[{"name":"微服务","slug":"微服务","link":"/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Consul","slug":"Consul","link":"/tags/Consul/"},{"name":"DataGrip","slug":"DataGrip","link":"/tags/DataGrip/"},{"name":"Oracle","slug":"Oracle","link":"/tags/Oracle/"},{"name":"debian","slug":"debian","link":"/tags/debian/"},{"name":"BBR","slug":"BBR","link":"/tags/BBR/"},{"name":"Google","slug":"Google","link":"/tags/Google/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"ES6","slug":"ES6","link":"/tags/ES6/"},{"name":"ElasticSearch","slug":"ElasticSearch","link":"/tags/ElasticSearch/"},{"name":"Eureka","slug":"Eureka","link":"/tags/Eureka/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Gradle","slug":"Gradle","link":"/tags/Gradle/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"类加载子系统","slug":"类加载子系统","link":"/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F/"},{"name":"运行时数据区","slug":"运行时数据区","link":"/tags/%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"name":"程序计数器","slug":"程序计数器","link":"/tags/%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8/"},{"name":"虚拟机栈","slug":"虚拟机栈","link":"/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/"},{"name":"局部变量表","slug":"局部变量表","link":"/tags/%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E8%A1%A8/"},{"name":"操作数栈","slug":"操作数栈","link":"/tags/%E6%93%8D%E4%BD%9C%E6%95%B0%E6%A0%88/"},{"name":"动态链接","slug":"动态链接","link":"/tags/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5/"},{"name":"方法返回地址","slug":"方法返回地址","link":"/tags/%E6%96%B9%E6%B3%95%E8%BF%94%E5%9B%9E%E5%9C%B0%E5%9D%80/"},{"name":"一些附加信息","slug":"一些附加信息","link":"/tags/%E4%B8%80%E4%BA%9B%E9%99%84%E5%8A%A0%E4%BF%A1%E6%81%AF/"},{"name":"相关面试题","slug":"相关面试题","link":"/tags/%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"本地方法区","slug":"本地方法区","link":"/tags/%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E5%8C%BA/"},{"name":"本地方法接口","slug":"本地方法接口","link":"/tags/%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%8E%A5%E5%8F%A3/"},{"name":"本地方法库","slug":"本地方法库","link":"/tags/%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E5%BA%93/"},{"name":"本地方法栈","slug":"本地方法栈","link":"/tags/%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88/"},{"name":"堆","slug":"堆","link":"/tags/%E5%A0%86/"},{"name":"年轻代和老年代","slug":"年轻代和老年代","link":"/tags/%E5%B9%B4%E8%BD%BB%E4%BB%A3%E5%92%8C%E8%80%81%E5%B9%B4%E4%BB%A3/"},{"name":"对象分配的过程","slug":"对象分配的过程","link":"/tags/%E5%AF%B9%E8%B1%A1%E5%88%86%E9%85%8D%E7%9A%84%E8%BF%87%E7%A8%8B/"},{"name":"逃逸分析","slug":"逃逸分析","link":"/tags/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"name":"方法区","slug":"方法区","link":"/tags/%E6%96%B9%E6%B3%95%E5%8C%BA/"},{"name":"执行引擎","slug":"执行引擎","link":"/tags/%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/"},{"name":"StringTable","slug":"StringTable","link":"/tags/StringTable/"},{"name":"垃圾回收","slug":"垃圾回收","link":"/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"name":"垃圾回收器","slug":"垃圾回收器","link":"/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/"},{"name":"Class文件结构","slug":"Class文件结构","link":"/tags/Class%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"面试题","slug":"面试题","link":"/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"Java虚拟机","slug":"Java虚拟机","link":"/tags/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"Jenkins","slug":"Jenkins","link":"/tags/Jenkins/"},{"name":"Kibana","slug":"Kibana","link":"/tags/Kibana/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"Shell","slug":"Shell","link":"/tags/Shell/"},{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"Launchpad","slug":"Launchpad","link":"/tags/Launchpad/"},{"name":"Nexus3","slug":"Nexus3","link":"/tags/Nexus3/"},{"name":"Seata","slug":"Seata","link":"/tags/Seata/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"thymeleaf","slug":"thymeleaf","link":"/tags/thymeleaf/"},{"name":"SpringMVC","slug":"SpringMVC","link":"/tags/SpringMVC/"},{"name":"Swagger","slug":"Swagger","link":"/tags/Swagger/"},{"name":"TypeScript","slug":"TypeScript","link":"/tags/TypeScript/"},{"name":"WebLogic","slug":"WebLogic","link":"/tags/WebLogic/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/tags/Zookeeper/"},{"name":"Centos7","slug":"Centos7","link":"/tags/Centos7/"},{"name":"防火墙","slug":"防火墙","link":"/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"SSR","slug":"SSR","link":"/tags/SSR/"},{"name":"网易云","slug":"网易云","link":"/tags/%E7%BD%91%E6%98%93%E4%BA%91/"},{"name":"LDAP","slug":"LDAP","link":"/tags/LDAP/"},{"name":"存储过程","slug":"存储过程","link":"/tags/%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/"},{"name":"触发器","slug":"触发器","link":"/tags/%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"skywalking","slug":"skywalking","link":"/tags/skywalking/"},{"name":"文档编写","slug":"文档编写","link":"/tags/%E6%96%87%E6%A1%A3%E7%BC%96%E5%86%99/"},{"name":"服务器","slug":"服务器","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"亚马逊","slug":"亚马逊","link":"/tags/%E4%BA%9A%E9%A9%AC%E9%80%8A/"},{"name":"AWS","slug":"AWS","link":"/tags/AWS/"},{"name":"开发框架","slug":"开发框架","link":"/tags/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"},{"name":"文档","slug":"文档","link":"/tags/%E6%96%87%E6%A1%A3/"},{"name":"并发容器","slug":"并发容器","link":"/tags/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/"},{"name":"Lock体系","slug":"Lock体系","link":"/tags/Lock%E4%BD%93%E7%B3%BB/"},{"name":"并发工具","slug":"并发工具","link":"/tags/%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"Executor体系","slug":"Executor体系","link":"/tags/Executor%E4%BD%93%E7%B3%BB/"},{"name":"原子操作类","slug":"原子操作类","link":"/tags/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%B1%BB/"},{"name":"并发理论","slug":"并发理论","link":"/tags/%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA/"},{"name":"并发关键字","slug":"并发关键字","link":"/tags/%E5%B9%B6%E5%8F%91%E5%85%B3%E9%94%AE%E5%AD%97/"},{"name":"并发编程优缺点","slug":"并发编程优缺点","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%BC%98%E7%BC%BA%E7%82%B9/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"并发实践","slug":"并发实践","link":"/tags/%E5%B9%B6%E5%8F%91%E5%AE%9E%E8%B7%B5/"},{"name":"并发基础知识","slug":"并发基础知识","link":"/tags/%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"微信小程序","slug":"微信小程序","link":"/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"进程","slug":"进程","link":"/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"线程","slug":"线程","link":"/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"认证","slug":"认证","link":"/tags/%E8%AE%A4%E8%AF%81/"},{"name":"JWT","slug":"JWT","link":"/tags/JWT/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","link":"/tags/%E6%8E%92%E5%BA%8F/"},{"name":"集合编程","slug":"集合编程","link":"/tags/%E9%9B%86%E5%90%88%E7%BC%96%E7%A8%8B/"},{"name":"other","slug":"other","link":"/tags/other/"}],"categories":[{"name":"SpringCloud","slug":"SpringCloud","link":"/categories/SpringCloud/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"技术","slug":"技术","link":"/categories/%E6%8A%80%E6%9C%AF/"},{"name":"辅助工具","slug":"辅助工具","link":"/categories/%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"前端","slug":"前端","link":"/categories/%E5%89%8D%E7%AB%AF/"},{"name":"ElasticSearch","slug":"ElasticSearch","link":"/categories/ElasticSearch/"},{"name":"ES6","slug":"前端/ES6","link":"/categories/%E5%89%8D%E7%AB%AF/ES6/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"Gradle","slug":"Gradle","link":"/categories/Gradle/"},{"name":"ElasticSearch6","slug":"ElasticSearch/ElasticSearch6","link":"/categories/ElasticSearch/ElasticSearch6/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"},{"name":"ElasticSearch7","slug":"ElasticSearch/ElasticSearch7","link":"/categories/ElasticSearch/ElasticSearch7/"},{"name":"6.2","slug":"Gradle/6-2","link":"/categories/Gradle/6-2/"},{"name":"垃圾回收","slug":"JVM/垃圾回收","link":"/categories/JVM/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"name":"垃圾回收器","slug":"JVM/垃圾回收器","link":"/categories/JVM/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/"},{"name":"类加载子系统","slug":"JVM/类加载子系统","link":"/categories/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F/"},{"name":"运行时数据区","slug":"JVM/运行时数据区","link":"/categories/JVM/%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"name":"Class文件结构","slug":"JVM/Class文件结构","link":"/categories/JVM/Class%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Jenkins","slug":"Jenkins","link":"/categories/Jenkins/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/categories/Kubernetes/"},{"name":"本地方法区","slug":"JVM/本地方法区","link":"/categories/JVM/%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E5%8C%BA/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"SpringCloud Alibaba","slug":"SpringCloud-Alibaba","link":"/categories/SpringCloud-Alibaba/"},{"name":"Seata","slug":"Seata","link":"/categories/Seata/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"执行引擎","slug":"JVM/执行引擎","link":"/categories/JVM/%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/categories/SpringBoot/"},{"name":"字符串常量池","slug":"JVM/字符串常量池","link":"/categories/JVM/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/"},{"name":"SpringMVC","slug":"SpringMVC","link":"/categories/SpringMVC/"},{"name":"Swagger","slug":"Swagger","link":"/categories/Swagger/"},{"name":"TypeScript","slug":"前端/TypeScript","link":"/categories/%E5%89%8D%E7%AB%AF/TypeScript/"},{"name":"中间件","slug":"中间件","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/categories/Zookeeper/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"程序计数器","slug":"JVM/运行时数据区/程序计数器","link":"/categories/JVM/%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8/"},{"name":"虚拟机栈","slug":"JVM/运行时数据区/虚拟机栈","link":"/categories/JVM/%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/"},{"name":"APM","slug":"APM","link":"/categories/APM/"},{"name":"LDAP","slug":"LDAP","link":"/categories/LDAP/"},{"name":"并发编程","slug":"并发编程","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"微信","slug":"微信","link":"/categories/%E5%BE%AE%E4%BF%A1/"},{"name":"Kubernetes快速上手","slug":"Kubernetes/Kubernetes快速上手","link":"/categories/Kubernetes/Kubernetes%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"},{"name":"本地方法栈","slug":"JVM/运行时数据区/本地方法栈","link":"/categories/JVM/%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88/"},{"name":"深入理解Kubernetes","slug":"Kubernetes/深入理解Kubernetes","link":"/categories/Kubernetes/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kubernetes/"},{"name":"堆","slug":"JVM/运行时数据区/堆","link":"/categories/JVM/%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/%E5%A0%86/"},{"name":"数据结构","slug":"数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"方法区","slug":"JVM/运行时数据区/方法区","link":"/categories/JVM/%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/%E6%96%B9%E6%B3%95%E5%8C%BA/"},{"name":"并发容器","slug":"并发编程/并发容器","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/"},{"name":"Lock体系","slug":"并发编程/Lock体系","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/Lock%E4%BD%93%E7%B3%BB/"},{"name":"并发工具","slug":"并发编程/并发工具","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"Executor体系","slug":"并发编程/Executor体系","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/Executor%E4%BD%93%E7%B3%BB/"},{"name":"原子操作类","slug":"并发编程/原子操作类","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%B1%BB/"},{"name":"并发理论","slug":"并发编程/并发理论","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA/"},{"name":"并发关键字","slug":"并发编程/并发关键字","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E5%85%B3%E9%94%AE%E5%AD%97/"},{"name":"基础知识","slug":"并发编程/基础知识","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"知识体系","slug":"并发编程/知识体系","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"},{"name":"并发实践","slug":"并发编程/并发实践","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E5%AE%9E%E8%B7%B5/"},{"name":"微信小程序","slug":"微信/微信小程序","link":"/categories/%E5%BE%AE%E4%BF%A1/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"概述","slug":"数据结构与算法/概述","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%A6%82%E8%BF%B0/"},{"name":"数据结构","slug":"数据结构与算法/数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"集合容器","slug":"集合容器","link":"/categories/%E9%9B%86%E5%90%88%E5%AE%B9%E5%99%A8/"},{"name":"other","slug":"other","link":"/categories/other/"}],"pages":[{"title":"关于作者","text":"很惭愧只做了一点微小的工作谢谢大家","link":"/about/index.html"}]}